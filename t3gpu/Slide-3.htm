<html>

<head>
<meta http-equiv=Content-Type content="text/html; charset=windows-1252">
<meta name=Generator content="Microsoft Word 15 (filtered)">
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:Helvetica;
	panose-1:2 11 6 4 2 2 2 2 2 4;}
@font-face
	{font-family:Courier;
	panose-1:2 7 4 9 2 2 5 2 4 4;}
@font-face
	{font-family:"Tms Rmn";
	panose-1:2 2 6 3 4 5 5 2 3 4;}
@font-face
	{font-family:Helv;
	panose-1:2 11 6 4 2 2 2 3 2 4;}
@font-face
	{font-family:"New York";
	panose-1:2 4 5 3 6 5 6 2 3 4;}
@font-face
	{font-family:System;
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:Wingdings;
	panose-1:5 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"MS Mincho";
	panose-1:2 2 6 9 4 2 5 8 3 4;}
@font-face
	{font-family:Batang;
	panose-1:2 3 6 0 0 1 1 1 1 1;}
@font-face
	{font-family:SimSun;
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:PMingLiU;
	panose-1:2 1 6 1 0 1 1 1 1 1;}
@font-face
	{font-family:"MS Gothic";
	panose-1:2 11 6 9 7 2 5 8 2 4;}
@font-face
	{font-family:Dotum;
	panose-1:2 11 6 0 0 1 1 1 1 1;}
@font-face
	{font-family:SimHei;
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:MingLiU;
	panose-1:2 1 6 9 0 1 1 1 1 1;}
@font-face
	{font-family:Mincho;
	panose-1:2 2 6 9 4 3 5 8 3 5;}
@font-face
	{font-family:Gulim;
	panose-1:2 11 6 0 0 1 1 1 1 1;}
@font-face
	{font-family:Century;
	panose-1:2 4 6 4 5 5 5 2 3 4;}
@font-face
	{font-family:"Angsana New";
	panose-1:2 2 6 3 5 4 5 2 3 4;}
@font-face
	{font-family:"Cordia New";
	panose-1:2 11 3 4 2 2 2 2 2 4;}
@font-face
	{font-family:Mangal;
	panose-1:0 0 4 0 0 0 0 0 0 0;}
@font-face
	{font-family:Latha;
	panose-1:2 0 4 0 0 0 0 0 0 0;}
@font-face
	{font-family:Sylfaen;
	panose-1:1 10 5 2 5 3 6 3 3 3;}
@font-face
	{font-family:Vrinda;
	panose-1:0 0 4 0 0 0 0 0 0 0;}
@font-face
	{font-family:Raavi;
	panose-1:2 0 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:Shruti;
	panose-1:2 0 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:Sendnya;
	panose-1:0 0 4 0 0 0 0 0 0 0;}
@font-face
	{font-family:Gautami;
	panose-1:2 0 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:Tunga;
	panose-1:0 0 4 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Estrangelo Edessa";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:"Yu Gothic";
	panose-1:2 11 4 0 0 0 0 0 0 0;}
@font-face
	{font-family:DengXian;
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
@font-face
	{font-family:"Calibri Light";
	panose-1:2 15 3 2 2 2 4 3 2 4;}
@font-face
	{font-family:"Palatino Linotype";
	panose-1:2 4 5 2 5 5 5 3 3 4;}
@font-face
	{font-family:Verdana;
	panose-1:2 11 6 4 3 5 4 4 2 4;}
@font-face
	{font-family:"Arial Unicode MS";
	panose-1:2 11 6 4 2 2 2 2 2 4;}
@font-face
	{font-family:Aptos;}
@font-face
	{font-family:"Aptos Display";}
@font-face
	{font-family:"Segoe UI Emoji";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:Consolas;
	panose-1:2 11 6 9 2 2 4 3 2 4;}
@font-face
	{font-family:"Segoe UI";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:inherit;
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"var\(--font-mono\)";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:Marlett;
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Arial Black";
	panose-1:2 11 10 4 2 1 2 2 2 4;}
@font-face
	{font-family:"Bahnschrift Light";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Bahnschrift SemiLight";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:Bahnschrift;
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Bahnschrift SemiBold";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Bahnschrift Light SemiCondensed";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Bahnschrift SemiLight SemiConde";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Bahnschrift SemiCondensed";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Bahnschrift SemiBold SemiConden";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Bahnschrift Light Condensed";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Bahnschrift SemiLight Condensed";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Bahnschrift Condensed";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Bahnschrift SemiBold Condensed";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:Cambria;
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:Candara;
	panose-1:2 14 5 2 3 3 3 2 2 4;}
@font-face
	{font-family:"Candara Light";
	panose-1:2 14 5 2 3 3 3 2 2 4;}
@font-face
	{font-family:"Comic Sans MS";
	panose-1:3 15 7 2 3 3 2 2 2 4;}
@font-face
	{font-family:Constantia;
	panose-1:2 3 6 2 5 3 6 3 3 3;}
@font-face
	{font-family:Corbel;
	panose-1:2 11 5 3 2 2 4 2 2 4;}
@font-face
	{font-family:"Corbel Light";
	panose-1:2 11 3 3 2 2 4 2 2 4;}
@font-face
	{font-family:Ebrima;
	panose-1:2 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Franklin Gothic Medium";
	panose-1:2 11 6 3 2 1 2 2 2 4;}
@font-face
	{font-family:Gabriola;
	panose-1:4 4 6 5 5 16 2 2 13 2;}
@font-face
	{font-family:Gadugi;
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:Georgia;
	panose-1:2 4 5 2 5 4 5 2 3 3;}
@font-face
	{font-family:Impact;
	panose-1:2 11 8 6 3 9 2 5 2 4;}
@font-face
	{font-family:"Ink Free";
	panose-1:3 8 4 2 0 5 0 0 0 0;}
@font-face
	{font-family:"Javanese Text";
	panose-1:2 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Leelawadee UI";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Leelawadee UI Semilight";
	panose-1:2 11 4 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Lucida Console";
	panose-1:2 11 6 9 4 5 4 2 2 4;}
@font-face
	{font-family:"Lucida Sans Unicode";
	panose-1:2 11 6 2 3 5 4 2 2 4;}
@font-face
	{font-family:"Malgun Gothic";
	panose-1:2 11 5 3 2 0 0 2 0 4;}
@font-face
	{font-family:"\@Malgun Gothic";}
@font-face
	{font-family:"Malgun Gothic Semilight";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"\@Malgun Gothic Semilight";}
@font-face
	{font-family:"Microsoft Himalaya";
	panose-1:1 1 1 0 1 1 1 1 1 1;}
@font-face
	{font-family:"Microsoft JhengHei";
	panose-1:2 11 6 4 3 5 4 4 2 4;}
@font-face
	{font-family:"\@Microsoft JhengHei";}
@font-face
	{font-family:"Microsoft JhengHei UI";
	panose-1:2 11 6 4 3 5 4 4 2 4;}
@font-face
	{font-family:"\@Microsoft JhengHei UI";}
@font-face
	{font-family:"Microsoft JhengHei Light";
	panose-1:2 11 3 4 3 5 4 4 2 4;}
@font-face
	{font-family:"\@Microsoft JhengHei Light";}
@font-face
	{font-family:"Microsoft JhengHei UI Light";
	panose-1:2 11 3 4 3 5 4 4 2 4;}
@font-face
	{font-family:"\@Microsoft JhengHei UI Light";}
@font-face
	{font-family:"Microsoft New Tai Lue";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Microsoft PhagsPa";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Microsoft Sans Serif";
	panose-1:2 11 6 4 2 2 2 2 2 4;}
@font-face
	{font-family:"Microsoft Tai Le";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Microsoft YaHei";
	panose-1:2 11 5 3 2 2 4 2 2 4;}
@font-face
	{font-family:"\@Microsoft YaHei";}
@font-face
	{font-family:"Microsoft YaHei UI";
	panose-1:2 11 5 3 2 2 4 2 2 4;}
@font-face
	{font-family:"\@Microsoft YaHei UI";}
@font-face
	{font-family:"Microsoft YaHei Light";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"\@Microsoft YaHei Light";}
@font-face
	{font-family:"Microsoft YaHei UI Light";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"\@Microsoft YaHei UI Light";}
@font-face
	{font-family:"Microsoft Yi Baiti";
	panose-1:3 0 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:MingLiU-ExtB;
	panose-1:2 2 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@MingLiU-ExtB";}
@font-face
	{font-family:PMingLiU-ExtB;
	panose-1:2 2 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@PMingLiU-ExtB";}
@font-face
	{font-family:MingLiU_HKSCS-ExtB;
	panose-1:2 2 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@MingLiU_HKSCS-ExtB";}
@font-face
	{font-family:MingLiU_MSCS-ExtB;
	panose-1:2 2 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@MingLiU_MSCS-ExtB";}
@font-face
	{font-family:"Mongolian Baiti";
	panose-1:3 0 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@MS Gothic";
	panose-1:2 11 6 9 7 2 5 8 2 4;}
@font-face
	{font-family:"MS UI Gothic";
	panose-1:2 11 6 0 7 2 5 8 2 4;}
@font-face
	{font-family:"\@MS UI Gothic";}
@font-face
	{font-family:"MS PGothic";
	panose-1:2 11 6 0 7 2 5 8 2 4;}
@font-face
	{font-family:"\@MS PGothic";}
@font-face
	{font-family:"MV Boli";
	panose-1:2 0 5 0 3 2 0 9 0 0;}
@font-face
	{font-family:"Myanmar Text";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Nirmala UI";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Nirmala UI Semilight";
	panose-1:2 11 4 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Nirmala Text";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Nirmala Text Semilight";
	panose-1:2 11 4 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Sans Serif Collection";
	panose-1:2 11 5 2 4 5 4 2 2 4;}
@font-face
	{font-family:"Segoe Fluent Icons";
	panose-1:5 10 1 2 1 1 1 1 1 1;}
@font-face
	{font-family:"Segoe MDL2 Assets";
	panose-1:5 10 1 2 1 1 1 1 1 1;}
@font-face
	{font-family:"Segoe Print";
	panose-1:2 0 6 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe Script";
	panose-1:3 11 5 4 2 0 0 0 0 3;}
@font-face
	{font-family:"Segoe UI Black";
	panose-1:2 11 10 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Segoe UI Historic";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Segoe UI Light";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Segoe UI Semibold";
	panose-1:2 11 7 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Segoe UI Semilight";
	panose-1:2 11 4 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Segoe UI Symbol";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Segoe UI Variable Small Light";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Small Semilig";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Small";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Small Semibol";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Text Light";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Text Semiligh";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Text";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Text Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Display Light";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Display Semil";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Display";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Display Semib";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@SimSun";
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:NSimSun;
	panose-1:2 1 6 9 3 1 1 1 1 1;}
@font-face
	{font-family:"\@NSimSun";}
@font-face
	{font-family:SimSun-ExtB;
	panose-1:2 1 6 9 6 1 1 1 1 1;}
@font-face
	{font-family:"\@SimSun-ExtB";}
@font-face
	{font-family:"Sitka Small";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Small Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Text";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Text Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Subheading";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Subheading Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Heading";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Heading Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Display";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Display Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Banner";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Banner Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:Tahoma;
	panose-1:2 11 6 4 3 5 4 4 2 4;}
@font-face
	{font-family:"Trebuchet MS";
	panose-1:2 11 6 3 2 2 2 2 2 4;}
@font-face
	{font-family:Webdings;
	panose-1:5 3 1 2 1 5 9 6 7 3;}
@font-face
	{font-family:"\@Yu Gothic";
	panose-1:2 11 4 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Yu Gothic UI";
	panose-1:2 11 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@Yu Gothic UI";}
@font-face
	{font-family:"Yu Gothic UI Semibold";
	panose-1:2 11 7 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@Yu Gothic UI Semibold";}
@font-face
	{font-family:"Yu Gothic Light";
	panose-1:2 11 3 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@Yu Gothic Light";}
@font-face
	{font-family:"Yu Gothic UI Light";
	panose-1:2 11 3 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@Yu Gothic UI Light";}
@font-face
	{font-family:"Yu Gothic Medium";
	panose-1:2 11 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@Yu Gothic Medium";}
@font-face
	{font-family:"Yu Gothic UI Semilight";
	panose-1:2 11 4 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@Yu Gothic UI Semilight";}
@font-face
	{font-family:SimSun-ExtG;
	panose-1:2 1 6 9 6 1 1 1 1 1;}
@font-face
	{font-family:"\@SimSun-ExtG";}
@font-face
	{font-family:"Agency FB";
	panose-1:2 11 5 3 2 2 2 2 2 4;}
@font-face
	{font-family:Algerian;
	panose-1:4 2 7 5 4 10 2 6 7 2;}
@font-face
	{font-family:"Book Antiqua";
	panose-1:2 4 6 2 5 3 5 3 3 4;}
@font-face
	{font-family:"Arial Narrow";
	panose-1:2 11 6 6 2 2 2 3 2 4;}
@font-face
	{font-family:"Arial Rounded MT Bold";
	panose-1:2 15 7 4 3 5 4 3 2 4;}
@font-face
	{font-family:"Baskerville Old Face";
	panose-1:2 2 6 2 8 5 5 2 3 3;}
@font-face
	{font-family:"Bauhaus 93";
	panose-1:4 3 9 5 2 11 2 2 12 2;}
@font-face
	{font-family:"Bell MT";
	panose-1:2 2 5 3 6 3 5 2 3 3;}
@font-face
	{font-family:"Bernard MT Condensed";
	panose-1:2 5 8 6 6 9 5 2 4 4;}
@font-face
	{font-family:"Bodoni MT";
	panose-1:2 7 6 3 8 6 6 2 2 3;}
@font-face
	{font-family:"Bodoni MT Black";
	panose-1:2 7 10 3 8 6 6 2 2 3;}
@font-face
	{font-family:"Bodoni MT Condensed";
	panose-1:2 7 6 6 8 6 6 2 2 3;}
@font-face
	{font-family:"Bodoni MT Poster Compressed";
	panose-1:2 7 7 6 8 6 1 5 2 4;}
@font-face
	{font-family:"Bookman Old Style";
	panose-1:2 5 6 4 5 5 5 2 2 4;}
@font-face
	{font-family:"Bradley Hand ITC";
	panose-1:3 7 4 2 5 3 2 3 2 3;}
@font-face
	{font-family:"Britannic Bold";
	panose-1:2 11 9 3 6 7 3 2 2 4;}
@font-face
	{font-family:"Berlin Sans FB";
	panose-1:2 14 6 2 2 5 2 2 3 6;}
@font-face
	{font-family:"Berlin Sans FB Demi";
	panose-1:2 14 8 2 2 5 2 2 3 6;}
@font-face
	{font-family:Broadway;
	panose-1:4 4 9 5 8 11 2 2 5 2;}
@font-face
	{font-family:"Brush Script MT";
	panose-1:3 6 8 2 4 4 6 7 3 4;}
@font-face
	{font-family:"Bookshelf Symbol 7";
	panose-1:5 1 1 1 1 1 1 1 1 1;}
@font-face
	{font-family:"Californian FB";
	panose-1:2 7 4 3 6 8 11 3 2 4;}
@font-face
	{font-family:"Calisto MT";
	panose-1:2 4 6 3 5 5 5 3 3 4;}
@font-face
	{font-family:Castellar;
	panose-1:2 10 4 2 6 4 6 1 3 1;}
@font-face
	{font-family:"Century Schoolbook";
	panose-1:2 4 6 4 5 5 5 2 3 4;}
@font-face
	{font-family:Centaur;
	panose-1:2 3 5 4 5 2 5 2 3 4;}
@font-face
	{font-family:Chiller;
	panose-1:4 2 4 4 3 16 7 2 6 2;}
@font-face
	{font-family:"Colonna MT";
	panose-1:4 2 8 5 6 2 2 3 2 3;}
@font-face
	{font-family:"Cooper Black";
	panose-1:2 8 9 4 4 3 11 2 4 4;}
@font-face
	{font-family:"Copperplate Gothic Bold";
	panose-1:2 14 7 5 2 2 6 2 4 4;}
@font-face
	{font-family:"Copperplate Gothic Light";
	panose-1:2 14 5 7 2 2 6 2 4 4;}
@font-face
	{font-family:"Curlz MT";
	panose-1:4 4 4 4 5 7 2 2 2 2;}
@font-face
	{font-family:Dubai;
	panose-1:2 11 5 3 3 4 3 3 2 4;}
@font-face
	{font-family:"Dubai Light";
	panose-1:2 11 3 3 3 4 3 3 2 4;}
@font-face
	{font-family:"Dubai Medium";
	panose-1:2 11 6 3 3 4 3 3 2 4;}
@font-face
	{font-family:Elephant;
	panose-1:2 2 9 4 9 5 5 2 3 3;}
@font-face
	{font-family:"Engravers MT";
	panose-1:2 9 7 7 8 5 5 2 3 4;}
@font-face
	{font-family:"Eras Bold ITC";
	panose-1:2 11 9 7 3 5 4 2 2 4;}
@font-face
	{font-family:"Eras Demi ITC";
	panose-1:2 11 8 5 3 5 4 2 8 4;}
@font-face
	{font-family:"Eras Light ITC";
	panose-1:2 11 4 2 3 5 4 2 8 4;}
@font-face
	{font-family:"Eras Medium ITC";
	panose-1:2 11 6 2 3 5 4 2 8 4;}
@font-face
	{font-family:"Felix Titling";
	panose-1:4 6 5 5 6 2 2 2 10 4;}
@font-face
	{font-family:Forte;
	panose-1:3 6 9 2 4 5 2 7 2 3;}
@font-face
	{font-family:"Franklin Gothic Book";
	panose-1:2 11 5 3 2 1 2 2 2 4;}
@font-face
	{font-family:"Franklin Gothic Demi";
	panose-1:2 11 7 3 2 1 2 2 2 4;}
@font-face
	{font-family:"Franklin Gothic Demi Cond";
	panose-1:2 11 7 6 3 4 2 2 2 4;}
@font-face
	{font-family:"Franklin Gothic Heavy";
	panose-1:2 11 9 3 2 1 2 2 2 4;}
@font-face
	{font-family:"Franklin Gothic Medium Cond";
	panose-1:2 11 6 6 3 4 2 2 2 4;}
@font-face
	{font-family:"Freestyle Script";
	panose-1:3 8 4 2 3 2 5 11 4 4;}
@font-face
	{font-family:"French Script MT";
	panose-1:3 2 4 2 4 6 7 4 6 5;}
@font-face
	{font-family:"Footlight MT Light";
	panose-1:2 4 6 2 6 3 10 2 3 4;}
@font-face
	{font-family:Garamond;
	panose-1:2 2 4 4 3 3 1 1 8 3;}
@font-face
	{font-family:Gigi;
	panose-1:4 4 5 4 6 16 7 2 13 2;}
@font-face
	{font-family:"Gill Sans MT";
	panose-1:2 11 5 2 2 1 4 2 2 3;}
@font-face
	{font-family:"Gill Sans MT Condensed";
	panose-1:2 11 5 6 2 1 4 2 2 3;}
@font-face
	{font-family:"Gill Sans Ultra Bold Condensed";
	panose-1:2 11 10 6 2 1 4 2 2 3;}
@font-face
	{font-family:"Gill Sans Ultra Bold";
	panose-1:2 11 10 2 2 1 4 2 2 3;}
@font-face
	{font-family:"Gloucester MT Extra Condensed";
	panose-1:2 3 8 8 2 6 1 1 1 1;}
@font-face
	{font-family:"Gill Sans MT Ext Condensed Bold";
	panose-1:2 11 9 2 2 1 4 2 2 3;}
@font-face
	{font-family:"Century Gothic";
	panose-1:2 11 5 2 2 2 2 2 2 4;}
@font-face
	{font-family:"Goudy Old Style";
	panose-1:2 2 5 2 5 3 5 2 3 3;}
@font-face
	{font-family:"Goudy Stout";
	panose-1:2 2 9 4 7 3 11 2 4 1;}
@font-face
	{font-family:"Harlow Solid Italic";
	panose-1:4 3 6 4 2 15 2 2 13 2;}
@font-face
	{font-family:Harrington;
	panose-1:4 4 5 5 5 10 2 2 7 2;}
@font-face
	{font-family:Haettenschweiler;
	panose-1:2 11 7 6 4 9 2 6 2 4;}
@font-face
	{font-family:"High Tower Text";
	panose-1:2 4 5 2 5 5 6 3 3 3;}
@font-face
	{font-family:"Imprint MT Shadow";
	panose-1:4 2 6 5 6 3 3 3 2 2;}
@font-face
	{font-family:"Informal Roman";
	panose-1:3 6 4 2 3 4 6 11 2 4;}
@font-face
	{font-family:"Blackadder ITC";
	panose-1:4 2 5 5 5 16 7 2 13 2;}
@font-face
	{font-family:"Edwardian Script ITC";
	panose-1:3 3 3 2 4 7 7 13 8 4;}
@font-face
	{font-family:"Kristen ITC";
	panose-1:3 5 5 2 4 2 2 3 2 2;}
@font-face
	{font-family:Jokerman;
	panose-1:4 9 6 5 6 13 6 2 7 2;}
@font-face
	{font-family:"Juice ITC";
	panose-1:4 4 4 3 4 10 2 2 2 2;}
@font-face
	{font-family:"Kunstler Script";
	panose-1:3 3 4 2 2 6 7 13 13 6;}
@font-face
	{font-family:"Wide Latin";
	panose-1:2 10 10 7 5 5 5 2 4 4;}
@font-face
	{font-family:"Lucida Bright";
	panose-1:2 4 6 2 5 5 5 2 3 4;}
@font-face
	{font-family:"Lucida Calligraphy";
	panose-1:3 1 1 1 1 1 1 1 1 1;}
@font-face
	{font-family:"Lucida Fax";
	panose-1:2 6 6 2 5 5 5 2 2 4;}
@font-face
	{font-family:"Lucida Handwriting";
	panose-1:3 1 1 1 1 1 1 1 1 1;}
@font-face
	{font-family:"Lucida Sans";
	panose-1:2 11 6 2 3 5 4 2 2 4;}
@font-face
	{font-family:"Lucida Sans Typewriter";
	panose-1:2 11 5 9 3 5 4 3 2 4;}
@font-face
	{font-family:Magneto;
	panose-1:4 3 8 5 5 8 2 2 13 2;}
@font-face
	{font-family:"Maiandra GD";
	panose-1:2 14 5 2 3 3 8 2 2 4;}
@font-face
	{font-family:"Matura MT Script Capitals";
	panose-1:3 2 8 2 6 6 2 7 2 2;}
@font-face
	{font-family:Mistral;
	panose-1:3 9 7 2 3 4 7 2 4 3;}
@font-face
	{font-family:"Modern No\. 20";
	panose-1:2 7 7 4 7 5 5 2 3 3;}
@font-face
	{font-family:"Monotype Corsiva";
	panose-1:3 1 1 1 1 2 1 1 1 1;}
@font-face
	{font-family:"MT Extra";
	panose-1:5 5 1 2 1 2 5 2 2 2;}
@font-face
	{font-family:"Niagara Engraved";
	panose-1:4 2 5 2 7 7 3 3 2 2;}
@font-face
	{font-family:"Niagara Solid";
	panose-1:4 2 5 2 7 7 2 2 2 2;}
@font-face
	{font-family:"OCR A Extended";
	panose-1:2 1 5 9 2 1 2 1 3 3;}
@font-face
	{font-family:"Old English Text MT";
	panose-1:3 4 9 2 4 5 8 3 8 6;}
@font-face
	{font-family:Onyx;
	panose-1:4 5 6 2 8 7 2 2 2 3;}
@font-face
	{font-family:"MS Outlook";
	panose-1:5 1 1 0 1 0 0 0 0 0;}
@font-face
	{font-family:"Palace Script MT";
	panose-1:3 3 3 2 2 6 7 12 11 5;}
@font-face
	{font-family:Papyrus;
	panose-1:3 7 5 2 6 5 2 3 2 5;}
@font-face
	{font-family:Parchment;
	panose-1:3 4 6 2 4 7 8 4 8 4;}
@font-face
	{font-family:Perpetua;
	panose-1:2 2 5 2 6 4 1 2 3 3;}
@font-face
	{font-family:"Perpetua Titling MT";
	panose-1:2 2 5 2 6 5 5 2 8 4;}
@font-face
	{font-family:Playbill;
	panose-1:4 5 6 3 10 6 2 2 2 2;}
@font-face
	{font-family:"Poor Richard";
	panose-1:2 8 5 2 5 5 5 2 7 2;}
@font-face
	{font-family:Pristina;
	panose-1:3 6 4 2 4 4 6 8 2 4;}
@font-face
	{font-family:"Rage Italic";
	panose-1:3 7 5 2 4 5 7 7 3 4;}
@font-face
	{font-family:Ravie;
	panose-1:4 4 8 5 5 8 9 2 6 2;}
@font-face
	{font-family:"MS Reference Sans Serif";
	panose-1:2 11 6 4 3 5 4 4 2 4;}
@font-face
	{font-family:"MS Reference Specialty";
	panose-1:5 0 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Rockwell Condensed";
	panose-1:2 6 6 3 5 4 5 2 1 4;}
@font-face
	{font-family:Rockwell;
	panose-1:2 6 6 3 2 2 5 2 4 3;}
@font-face
	{font-family:"Rockwell Extra Bold";
	panose-1:2 6 9 3 4 5 5 2 4 3;}
@font-face
	{font-family:"Script MT Bold";
	panose-1:3 4 6 2 4 6 7 8 9 4;}
@font-face
	{font-family:"Showcard Gothic";
	panose-1:4 2 9 4 2 1 2 2 6 4;}
@font-face
	{font-family:"Snap ITC";
	panose-1:4 4 10 7 6 10 2 2 2 2;}
@font-face
	{font-family:Stencil;
	panose-1:4 4 9 5 13 8 2 2 4 4;}
@font-face
	{font-family:"Tw Cen MT";
	panose-1:2 11 6 2 2 1 4 2 6 3;}
@font-face
	{font-family:"Tw Cen MT Condensed";
	panose-1:2 11 6 6 2 1 4 2 2 3;}
@font-face
	{font-family:"Tw Cen MT Condensed Extra Bold";
	panose-1:2 11 8 3 2 2 2 2 2 4;}
@font-face
	{font-family:"Tempus Sans ITC";
	panose-1:4 2 4 4 3 13 7 2 2 2;}
@font-face
	{font-family:"Viner Hand ITC";
	panose-1:3 7 5 2 3 5 2 2 2 3;}
@font-face
	{font-family:Vivaldi;
	panose-1:3 2 6 2 5 5 6 9 8 4;}
@font-face
	{font-family:"Vladimir Script";
	panose-1:3 5 4 2 4 4 7 7 3 5;}
@font-face
	{font-family:"Wingdings 2";
	panose-1:5 2 1 2 1 5 7 7 7 7;}
@font-face
	{font-family:"Wingdings 3";
	panose-1:5 4 1 2 1 8 7 7 7 7;}
@font-face
	{font-family:"Cascadia Code ExtraLight";
	panose-1:2 11 6 9 2 0 0 2 0 4;}
@font-face
	{font-family:"Cascadia Code Light";
	panose-1:2 11 6 9 2 0 0 2 0 4;}
@font-face
	{font-family:"Cascadia Code SemiLight";
	panose-1:2 11 6 9 2 0 0 2 0 4;}
@font-face
	{font-family:"Cascadia Code";
	panose-1:2 11 6 9 2 0 0 2 0 4;}
@font-face
	{font-family:"Cascadia Code SemiBold";
	panose-1:2 11 6 9 2 0 0 2 0 4;}
@font-face
	{font-family:"Cascadia Mono ExtraLight";
	panose-1:2 11 6 9 2 0 0 2 0 4;}
@font-face
	{font-family:"Cascadia Mono Light";
	panose-1:2 11 6 9 2 0 0 2 0 4;}
@font-face
	{font-family:"Cascadia Mono SemiLight";
	panose-1:2 11 6 9 2 0 0 2 0 4;}
@font-face
	{font-family:"Cascadia Mono";
	panose-1:2 11 6 9 2 0 0 2 0 4;}
@font-face
	{font-family:"Cascadia Mono SemiBold";
	panose-1:2 11 6 9 2 0 0 2 0 4;}
@font-face
	{font-family:Abadi;}
@font-face
	{font-family:"Abadi ExtraLight";}
@font-face
	{font-family:Abel;}
@font-face
	{font-family:"Abril Fatface";}
@font-face
	{font-family:"ADLaM Display";}
@font-face
	{font-family:Aharoni;}
@font-face
	{font-family:"Al Fresco";}
@font-face
	{font-family:"Alasassy Caps";}
@font-face
	{font-family:Aldhabi;}
@font-face
	{font-family:Alef;}
@font-face
	{font-family:Aleo;}
@font-face
	{font-family:"Aleo Light";}
@font-face
	{font-family:"Amasis MT Pro";}
@font-face
	{font-family:"Amasis MT Pro Black";}
@font-face
	{font-family:"Amasis MT Pro Light";}
@font-face
	{font-family:"Amasis MT Pro Medium";}
@font-face
	{font-family:"Amatic SC";}
@font-face
	{font-family:AngsanaUPC;}
@font-face
	{font-family:Anton;}
@font-face
	{font-family:Aparajita;}
@font-face
	{font-family:"Aptos Black";}
@font-face
	{font-family:"Aptos ExtraBold";}
@font-face
	{font-family:"Aptos Light";}
@font-face
	{font-family:"Aptos Mono";}
@font-face
	{font-family:"Aptos Narrow";}
@font-face
	{font-family:"Aptos SemiBold";}
@font-face
	{font-family:"Aptos Serif";}
@font-face
	{font-family:"Aptos Slab";}
@font-face
	{font-family:"Aptos Slab Black";}
@font-face
	{font-family:"Aptos Slab ExtraBold";}
@font-face
	{font-family:"Aptos Slab Light";}
@font-face
	{font-family:"Aptos Slab SemiBold";}
@font-face
	{font-family:"Arabic Typesetting";}
@font-face
	{font-family:"Aref Ruqaa";}
@font-face
	{font-family:"Arial Nova";}
@font-face
	{font-family:"Arial Nova Cond";}
@font-face
	{font-family:"Arial Nova Cond Light";}
@font-face
	{font-family:"Arial Nova Light";}
@font-face
	{font-family:Assistant;}
@font-face
	{font-family:"Assistant ExtraBold";}
@font-face
	{font-family:"Assistant ExtraLight";}
@font-face
	{font-family:"Assistant Light";}
@font-face
	{font-family:"Assistant SemiBold";}
@font-face
	{font-family:Athiti;}
@font-face
	{font-family:"Athiti ExtraLight";}
@font-face
	{font-family:"Athiti Light";}
@font-face
	{font-family:"Athiti Medium";}
@font-face
	{font-family:"Athiti SemiBold";}
@font-face
	{font-family:"Atkinson Hyperlegible Mono";}
@font-face
	{font-family:"Atkinson Hyperlegible Next";}
@font-face
	{font-family:"Avenir Next LT Pro";}
@font-face
	{font-family:"Avenir Next LT Pro Demi";}
@font-face
	{font-family:"Avenir Next LT Pro Light";}
@font-face
	{font-family:"Baguet Script";}
@font-face
	{font-family:Barlow;}
@font-face
	{font-family:"Barlow Black";}
@font-face
	{font-family:"Barlow Condensed";}
@font-face
	{font-family:"Barlow Condensed Black";}
@font-face
	{font-family:"Barlow Condensed ExtraBold";}
@font-face
	{font-family:"Barlow Condensed ExtraLight";}
@font-face
	{font-family:"Barlow Condensed Light";}
@font-face
	{font-family:"Barlow Condensed Medium";}
@font-face
	{font-family:"Barlow Condensed SemiBold";}
@font-face
	{font-family:"Barlow Condensed Thin";}
@font-face
	{font-family:"Barlow ExtraBold";}
@font-face
	{font-family:"Barlow ExtraLight";}
@font-face
	{font-family:"Barlow Light";}
@font-face
	{font-family:"Barlow Medium";}
@font-face
	{font-family:"Barlow Semi Condensed";}
@font-face
	{font-family:"Barlow Semi Condensed Black";}
@font-face
	{font-family:"Barlow Semi Condensed ExLight";}
@font-face
	{font-family:"Barlow Semi Condensed ExtraBold";}
@font-face
	{font-family:"Barlow Semi Condensed Light";}
@font-face
	{font-family:"Barlow Semi Condensed Medium";}
@font-face
	{font-family:"Barlow Semi Condensed SemiBold";}
@font-face
	{font-family:"Barlow Semi Condensed Thin";}
@font-face
	{font-family:"Barlow SemiBold";}
@font-face
	{font-family:"Barlow Thin";}
@font-face
	{font-family:BatangChe;}
@font-face
	{font-family:"Bebas Neue";}
@font-face
	{font-family:Bembo;}
@font-face
	{font-family:Bierstadt;}
@font-face
	{font-family:"Bierstadt Display";}
@font-face
	{font-family:Biome;}
@font-face
	{font-family:"Biome Light";}
@font-face
	{font-family:"Boucherie Block";}
@font-face
	{font-family:"Boucherie Sans";}
@font-face
	{font-family:"Browallia New";}
@font-face
	{font-family:BrowalliaUPC;}
@font-face
	{font-family:"Buxton Sketch";}
@font-face
	{font-family:"Caveat Brush";}
@font-face
	{font-family:Cavolini;}
@font-face
	{font-family:"Centaur Now Caption";}
@font-face
	{font-family:"Centaur Now Display";}
@font-face
	{font-family:"Centaur Now Text";}
@font-face
	{font-family:"Chamberi Super Display";}
@font-face
	{font-family:Charmonman;}
@font-face
	{font-family:"Chilgok Gwon Anja";}
@font-face
	{font-family:"Chilgok Kim Yeongbun";}
@font-face
	{font-family:"Chilgok Lee Jonghui";}
@font-face
	{font-family:"Chilgok Lee Wonsun";}
@font-face
	{font-family:Chonburi;}
@font-face
	{font-family:"Cochocib Script Latin Pro";}
@font-face
	{font-family:"Concert One";}
@font-face
	{font-family:Congenial;}
@font-face
	{font-family:"Congenial Black";}
@font-face
	{font-family:"Congenial Light";}
@font-face
	{font-family:"Congenial SemiBold";}
@font-face
	{font-family:"Congenial UltraLight";}
@font-face
	{font-family:Convection;}
@font-face
	{font-family:"Convection Condensed";}
@font-face
	{font-family:"Convection Extra Bold";}
@font-face
	{font-family:"Convection Symbol";}
@font-face
	{font-family:"Convection UI";}
@font-face
	{font-family:CordiaUPC;}
@font-face
	{font-family:Dante;}
@font-face
	{font-family:DaunPenh;}
@font-face
	{font-family:David;}
@font-face
	{font-family:Daytona;}
@font-face
	{font-family:"Daytona Condensed";}
@font-face
	{font-family:"Daytona Condensed Light";}
@font-face
	{font-family:"Daytona Light";}
@font-face
	{font-family:"DengXian Light";}
@font-face
	{font-family:"Didact Gothic";}
@font-face
	{font-family:DilleniaUPC;}
@font-face
	{font-family:"DM Mono";}
@font-face
	{font-family:"DM Mono Light";}
@font-face
	{font-family:"DM Mono Medium";}
@font-face
	{font-family:"DM Sans";}
@font-face
	{font-family:"DM Sans Medium";}
@font-face
	{font-family:"DM Serif Display";}
@font-face
	{font-family:"DM Serif Text";}
@font-face
	{font-family:DokChampa;}
@font-face
	{font-family:Dosis;}
@font-face
	{font-family:"Dosis ExtraBold";}
@font-face
	{font-family:"Dosis ExtraLight";}
@font-face
	{font-family:"Dosis Light";}
@font-face
	{font-family:"Dosis Medium";}
@font-face
	{font-family:"Dosis SemiBold";}
@font-face
	{font-family:DotumChe;}
@font-face
	{font-family:"Dreaming Outloud Pro";}
@font-face
	{font-family:"Dreaming Outloud Script Pro";}
@font-face
	{font-family:"EB Garamond";}
@font-face
	{font-family:"EB Garamond ExtraBold";}
@font-face
	{font-family:"EB Garamond Medium";}
@font-face
	{font-family:"EB Garamond SemiBold";}
@font-face
	{font-family:"Elephant Pro";}
@font-face
	{font-family:EucrosiaUPC;}
@font-face
	{font-family:Euphemia;}
@font-face
	{font-family:Fahkwang;}
@font-face
	{font-family:"Fahkwang ExtraLight";}
@font-face
	{font-family:"Fahkwang Light";}
@font-face
	{font-family:"Fahkwang Medium";}
@font-face
	{font-family:"Fahkwang SemiBold";}
@font-face
	{font-family:"Fairwater Script";}
@font-face
	{font-family:"Fairwater Script Light";}
@font-face
	{font-family:FangSong;}
@font-face
	{font-family:"Fave Script Bold Pro";}
@font-face
	{font-family:"Fira Code";}
@font-face
	{font-family:"Fira Code Light";}
@font-face
	{font-family:"Fira Code Medium";}
@font-face
	{font-family:"Fira Code Retina";}
@font-face
	{font-family:"Fira Mono";}
@font-face
	{font-family:"Fira Mono Medium";}
@font-face
	{font-family:"Fira Sans";}
@font-face
	{font-family:"Fira Sans Black";}
@font-face
	{font-family:"Fira Sans Condensed";}
@font-face
	{font-family:"Fira Sans Condensed Black";}
@font-face
	{font-family:"Fira Sans Condensed ExtraBold";}
@font-face
	{font-family:"Fira Sans Condensed ExtraLight";}
@font-face
	{font-family:"Fira Sans Condensed Light";}
@font-face
	{font-family:"Fira Sans Condensed Medium";}
@font-face
	{font-family:"Fira Sans Condensed SemiBold";}
@font-face
	{font-family:"Fira Sans Condensed Thin";}
@font-face
	{font-family:"Fira Sans Extra Condensed";}
@font-face
	{font-family:"Fira Sans Extra Condensed Black";}
@font-face
	{font-family:"Fira Sans Extra Condensed Light";}
@font-face
	{font-family:"Fira Sans Extra Condensed Thin";}
@font-face
	{font-family:"Fira Sans ExtraBold";}
@font-face
	{font-family:"Fira Sans ExtraLight";}
@font-face
	{font-family:"Fira Sans Light";}
@font-face
	{font-family:"Fira Sans Medium";}
@font-face
	{font-family:"Fira Sans SemiBold";}
@font-face
	{font-family:"Fira Sans Thin";}
@font-face
	{font-family:"Fjalla One";}
@font-face
	{font-family:"Forte Forward";}
@font-face
	{font-family:"Frank Ruhl Libre";}
@font-face
	{font-family:"Frank Ruhl Libre Black";}
@font-face
	{font-family:"Frank Ruhl Libre Light";}
@font-face
	{font-family:"Frank Ruhl Libre Medium";}
@font-face
	{font-family:FrankRuehl;}
@font-face
	{font-family:"Fredoka One";}
@font-face
	{font-family:FreesiaUPC;}
@font-face
	{font-family:Gabriela;}
@font-face
	{font-family:Gaegu;}
@font-face
	{font-family:"Gaegu Light";}
@font-face
	{font-family:"Georgia Pro";}
@font-face
	{font-family:"Georgia Pro Black";}
@font-face
	{font-family:"Georgia Pro Cond";}
@font-face
	{font-family:"Georgia Pro Cond Black";}
@font-face
	{font-family:"Georgia Pro Cond Light";}
@font-face
	{font-family:"Georgia Pro Cond Semibold";}
@font-face
	{font-family:"Georgia Pro Light";}
@font-face
	{font-family:"Georgia Pro Semibold";}
@font-face
	{font-family:"Gill Sans Nova";}
@font-face
	{font-family:"Gill Sans Nova Cond";}
@font-face
	{font-family:"Gill Sans Nova Cond Lt";}
@font-face
	{font-family:"Gill Sans Nova Cond Ultra Bold";}
@font-face
	{font-family:"Gill Sans Nova Cond XBd";}
@font-face
	{font-family:"Gill Sans Nova Light";}
@font-face
	{font-family:"Gill Sans Nova Ultra Bold";}
@font-face
	{font-family:Gisha;}
@font-face
	{font-family:"Goudy Type";}
@font-face
	{font-family:Grandview;}
@font-face
	{font-family:"Grandview Display";}
@font-face
	{font-family:Grotesque;}
@font-face
	{font-family:"Grotesque Light";}
@font-face
	{font-family:GulimChe;}
@font-face
	{font-family:Gungsuh;}
@font-face
	{font-family:GungsuhChe;}
@font-face
	{font-family:"Hadassah Friedlaender";}
@font-face
	{font-family:"Hammersmith One";}
@font-face
	{font-family:Heebo;}
@font-face
	{font-family:"Heebo Black";}
@font-face
	{font-family:"Heebo ExtraBold";}
@font-face
	{font-family:"Heebo Light";}
@font-face
	{font-family:"Heebo Medium";}
@font-face
	{font-family:"Heebo Thin";}
@font-face
	{font-family:HGGothicE;}
@font-face
	{font-family:HGMaruGothicMPRO;}
@font-face
	{font-family:HGMinchoE;}
@font-face
	{font-family:HGPGothicE;}
@font-face
	{font-family:HGPMinchoE;}
@font-face
	{font-family:HGPSoeiKakugothicUB;}
@font-face
	{font-family:HGSGothicE;}
@font-face
	{font-family:HGSMinchoE;}
@font-face
	{font-family:HGSoeiKakugothicUB;}
@font-face
	{font-family:HGSSoeiKakugothicUB;}
@font-face
	{font-family:Hind;}
@font-face
	{font-family:"Hind Colombo";}
@font-face
	{font-family:"Hind Colombo Light";}
@font-face
	{font-family:"Hind Colombo Medium";}
@font-face
	{font-family:"Hind Colombo SemiBold";}
@font-face
	{font-family:"Hind Guntur";}
@font-face
	{font-family:"Hind Guntur Light";}
@font-face
	{font-family:"Hind Guntur Medium";}
@font-face
	{font-family:"Hind Guntur SemiBold";}
@font-face
	{font-family:"Hind Jalandhar";}
@font-face
	{font-family:"Hind Jalandhar Light";}
@font-face
	{font-family:"Hind Jalandhar Medium";}
@font-face
	{font-family:"Hind Jalandhar SemiBold";}
@font-face
	{font-family:"Hind Kochi";}
@font-face
	{font-family:"Hind Kochi Light";}
@font-face
	{font-family:"Hind Kochi Medium";}
@font-face
	{font-family:"Hind Kochi SemiBold";}
@font-face
	{font-family:"Hind Light";}
@font-face
	{font-family:"Hind Madurai";}
@font-face
	{font-family:"Hind Madurai Light";}
@font-face
	{font-family:"Hind Madurai Medium";}
@font-face
	{font-family:"Hind Madurai SemiBold";}
@font-face
	{font-family:"Hind Medium";}
@font-face
	{font-family:"Hind Mysuru";}
@font-face
	{font-family:"Hind Mysuru Light";}
@font-face
	{font-family:"Hind Mysuru Medium";}
@font-face
	{font-family:"Hind Mysuru SemiBold";}
@font-face
	{font-family:"Hind SemiBold";}
@font-face
	{font-family:"Hind Siliguri";}
@font-face
	{font-family:"Hind Siliguri Light";}
@font-face
	{font-family:"Hind Siliguri Medium";}
@font-face
	{font-family:"Hind Siliguri SemiBold";}
@font-face
	{font-family:"Hind Vadodara";}
@font-face
	{font-family:"Hind Vadodara Light";}
@font-face
	{font-family:"Hind Vadodara Medium";}
@font-face
	{font-family:"Hind Vadodara SemiBold";}
@font-face
	{font-family:"IBM Plex Mono";}
@font-face
	{font-family:"IBM Plex Mono ExtraLight";}
@font-face
	{font-family:"IBM Plex Mono Light";}
@font-face
	{font-family:"IBM Plex Mono Medium";}
@font-face
	{font-family:"IBM Plex Mono SemiBold";}
@font-face
	{font-family:"IBM Plex Mono Thin";}
@font-face
	{font-family:"IBM Plex Sans";}
@font-face
	{font-family:"IBM Plex Sans Condensed";}
@font-face
	{font-family:"IBM Plex Sans Condensed Light";}
@font-face
	{font-family:"IBM Plex Sans Condensed Medium";}
@font-face
	{font-family:"IBM Plex Sans Condensed Thin";}
@font-face
	{font-family:"IBM Plex Sans ExtraLight";}
@font-face
	{font-family:"IBM Plex Sans Light";}
@font-face
	{font-family:"IBM Plex Sans Medium";}
@font-face
	{font-family:"IBM Plex Sans SemiBold";}
@font-face
	{font-family:"IBM Plex Sans Thin";}
@font-face
	{font-family:"IBM Plex Serif";}
@font-face
	{font-family:"IBM Plex Serif ExtraLight";}
@font-face
	{font-family:"IBM Plex Serif Light";}
@font-face
	{font-family:"IBM Plex Serif Medium";}
@font-face
	{font-family:"IBM Plex Serif SemiBold";}
@font-face
	{font-family:"IBM Plex Serif Thin";}
@font-face
	{font-family:Inconsolata;}
@font-face
	{font-family:"Inconsolata Black";}
@font-face
	{font-family:"Inconsolata Bold";}
@font-face
	{font-family:"Inconsolata Condensed";}
@font-face
	{font-family:"Inconsolata Condensed Black";}
@font-face
	{font-family:"Inconsolata Condensed Bold";}
@font-face
	{font-family:"Inconsolata Condensed ExtraBold";}
@font-face
	{font-family:"Inconsolata Condensed Light";}
@font-face
	{font-family:"Inconsolata Condensed Medium";}
@font-face
	{font-family:"Inconsolata Condensed SemiBold";}
@font-face
	{font-family:"Inconsolata Expanded";}
@font-face
	{font-family:"Inconsolata Expanded Black";}
@font-face
	{font-family:"Inconsolata Expanded Bold";}
@font-face
	{font-family:"Inconsolata Expanded ExtraBold";}
@font-face
	{font-family:"Inconsolata Expanded ExtraLight";}
@font-face
	{font-family:"Inconsolata Expanded Light";}
@font-face
	{font-family:"Inconsolata Expanded Medium";}
@font-face
	{font-family:"Inconsolata Expanded SemiBold";}
@font-face
	{font-family:"Inconsolata ExtraBold";}
@font-face
	{font-family:"Inconsolata ExtraCondensed";}
@font-face
	{font-family:"Inconsolata ExtraCondensed Bold";}
@font-face
	{font-family:"Inconsolata ExtraExpanded";}
@font-face
	{font-family:"Inconsolata ExtraExpanded Black";}
@font-face
	{font-family:"Inconsolata ExtraExpanded Bold";}
@font-face
	{font-family:"Inconsolata ExtraExpanded Light";}
@font-face
	{font-family:"Inconsolata ExtraLight";}
@font-face
	{font-family:"Inconsolata Light";}
@font-face
	{font-family:"Inconsolata Medium";}
@font-face
	{font-family:"Inconsolata SemiBold";}
@font-face
	{font-family:"Inconsolata SemiCondensed";}
@font-face
	{font-family:"Inconsolata SemiCondensed Black";}
@font-face
	{font-family:"Inconsolata SemiCondensed Bold";}
@font-face
	{font-family:"Inconsolata SemiCondensed Light";}
@font-face
	{font-family:"Inconsolata SemiExpanded";}
@font-face
	{font-family:"Inconsolata SemiExpanded Black";}
@font-face
	{font-family:"Inconsolata SemiExpanded Bold";}
@font-face
	{font-family:"Inconsolata SemiExpanded Light";}
@font-face
	{font-family:"Inconsolata SemiExpanded Medium";}
@font-face
	{font-family:"Inconsolata UltraCondensed";}
@font-face
	{font-family:"Inconsolata UltraCondensed Bold";}
@font-face
	{font-family:"Inconsolata UltraExpanded";}
@font-face
	{font-family:"Inconsolata UltraExpanded Black";}
@font-face
	{font-family:"Inconsolata UltraExpanded Bold";}
@font-face
	{font-family:"Inconsolata UltraExpanded Light";}
@font-face
	{font-family:IrisUPC;}
@font-face
	{font-family:"Iskoola Pota";}
@font-face
	{font-family:Italianno;}
@font-face
	{font-family:JasmineUPC;}
@font-face
	{font-family:"Josefin Sans";}
@font-face
	{font-family:"Josefin Sans Bold";}
@font-face
	{font-family:"Josefin Sans Light";}
@font-face
	{font-family:"Josefin Sans SemiBold";}
@font-face
	{font-family:"Josefin Sans Thin";}
@font-face
	{font-family:"Josefin Slab";}
@font-face
	{font-family:"Josefin Slab Light";}
@font-face
	{font-family:"Josefin Slab SemiBold";}
@font-face
	{font-family:"Josefin Slab Thin";}
@font-face
	{font-family:Jumble;}
@font-face
	{font-family:KaiTi;}
@font-face
	{font-family:Kalinga;}
@font-face
	{font-family:Karla;}
@font-face
	{font-family:"Karla ExtraBold";}
@font-face
	{font-family:"Karla ExtraLight";}
@font-face
	{font-family:"Karla Light";}
@font-face
	{font-family:"Karla Medium";}
@font-face
	{font-family:"Karla Tamil Inclined";}
@font-face
	{font-family:"Karla Tamil Upright";}
@font-face
	{font-family:Kartika;}
@font-face
	{font-family:Kermit;}
@font-face
	{font-family:"Kermit Condensed";}
@font-face
	{font-family:"Kermit Expanded";}
@font-face
	{font-family:"Kermit Extrabold";}
@font-face
	{font-family:"Kermit Extrabold Condensed";}
@font-face
	{font-family:"Kermit Extrabold Expanded";}
@font-face
	{font-family:"Kermit Extralight";}
@font-face
	{font-family:"Kermit Extralight Condensed";}
@font-face
	{font-family:"Kermit Extralight Expanded";}
@font-face
	{font-family:"Kermit Light";}
@font-face
	{font-family:"Kermit Light Condensed";}
@font-face
	{font-family:"Kermit Light Expanded";}
@font-face
	{font-family:"Kermit Semibold";}
@font-face
	{font-family:"Kermit Semibold Condensed";}
@font-face
	{font-family:"Kermit Semibold Expanded";}
@font-face
	{font-family:"Kermit Thin";}
@font-face
	{font-family:"Kermit Thin Condensed";}
@font-face
	{font-family:"Kermit Thin Expanded";}
@font-face
	{font-family:"Khmer UI";}
@font-face
	{font-family:Kigelia;}
@font-face
	{font-family:"Kigelia Arabic";}
@font-face
	{font-family:"Kigelia Arabic Light";}
@font-face
	{font-family:"Kigelia Light";}
@font-face
	{font-family:"Klee One";}
@font-face
	{font-family:"Klee One SemiBold";}
@font-face
	{font-family:KodchiangUPC;}
@font-face
	{font-family:Kokila;}
@font-face
	{font-family:Krub;}
@font-face
	{font-family:"Krub ExtraLight";}
@font-face
	{font-family:"Krub Light";}
@font-face
	{font-family:"Krub Medium";}
@font-face
	{font-family:"Krub SemiBold";}
@font-face
	{font-family:Lalezar;}
@font-face
	{font-family:"Lao UI";}
@font-face
	{font-family:Lato;}
@font-face
	{font-family:"Lato Black";}
@font-face
	{font-family:"Lato ExtraBold";}
@font-face
	{font-family:"Lato ExtraLight";}
@font-face
	{font-family:"Lato Light";}
@font-face
	{font-family:"Lato Medium";}
@font-face
	{font-family:"Lato SemiBold";}
@font-face
	{font-family:"Lato Thin";}
@font-face
	{font-family:Leelawadee;}
@font-face
	{font-family:"Levenim MT";}
@font-face
	{font-family:"Libre Barcode 128";}
@font-face
	{font-family:"Libre Barcode 128 Text";}
@font-face
	{font-family:"Libre Barcode 39";}
@font-face
	{font-family:"Libre Barcode 39 Extended";}
@font-face
	{font-family:"Libre Barcode 39 Extended Text";}
@font-face
	{font-family:"Libre Barcode 39 Text";}
@font-face
	{font-family:"Libre Barcode EAN13 Text";}
@font-face
	{font-family:"Libre Baskerville";}
@font-face
	{font-family:"Libre Franklin";}
@font-face
	{font-family:"Libre Franklin Black";}
@font-face
	{font-family:"Libre Franklin ExtraBold";}
@font-face
	{font-family:"Libre Franklin ExtraLight";}
@font-face
	{font-family:"Libre Franklin Light";}
@font-face
	{font-family:"Libre Franklin Medium";}
@font-face
	{font-family:"Libre Franklin SemiBold";}
@font-face
	{font-family:"Libre Franklin Thin";}
@font-face
	{font-family:Ligconsolata;}
@font-face
	{font-family:LilyUPC;}
@font-face
	{font-family:Livvic;}
@font-face
	{font-family:"Livvic Black";}
@font-face
	{font-family:"Livvic ExtraLight";}
@font-face
	{font-family:"Livvic Light";}
@font-face
	{font-family:"Livvic Medium";}
@font-face
	{font-family:"Livvic SemiBold";}
@font-face
	{font-family:"Livvic Thin";}
@font-face
	{font-family:Lobster;}
@font-face
	{font-family:"Lobster Two";}
@font-face
	{font-family:Lora;}
@font-face
	{font-family:"Lora Medium";}
@font-face
	{font-family:"Mangal Pro";}
@font-face
	{font-family:Meddon;}
@font-face
	{font-family:Meiryo;}
@font-face
	{font-family:"Meiryo UI";}
@font-face
	{font-family:Merriweather;}
@font-face
	{font-family:"Merriweather Black";}
@font-face
	{font-family:"Merriweather Light";}
@font-face
	{font-family:"Merriweather Sans";}
@font-face
	{font-family:"Merriweather Sans ExtraBold";}
@font-face
	{font-family:"Merriweather Sans Light";}
@font-face
	{font-family:"Microsoft GothicNeo";}
@font-face
	{font-family:"Microsoft GothicNeo Light";}
@font-face
	{font-family:"Microsoft Uighur";}
@font-face
	{font-family:MingLiU_HKSCS;}
@font-face
	{font-family:MingLiU_MSCS;}
@font-face
	{font-family:Miriam;}
@font-face
	{font-family:"Miriam Fixed";}
@font-face
	{font-family:"Miriam Libre";}
@font-face
	{font-family:Mitr;}
@font-face
	{font-family:"Mitr ExtraLight";}
@font-face
	{font-family:"Mitr Light";}
@font-face
	{font-family:"Mitr Medium";}
@font-face
	{font-family:"Mitr SemiBold";}
@font-face
	{font-family:"Modern Love";}
@font-face
	{font-family:"Modern Love Caps";}
@font-face
	{font-family:"Modern Love Grunge";}
@font-face
	{font-family:Montserrat;}
@font-face
	{font-family:"Montserrat Black";}
@font-face
	{font-family:"Montserrat ExtraBold";}
@font-face
	{font-family:"Montserrat ExtraLight";}
@font-face
	{font-family:"Montserrat Light";}
@font-face
	{font-family:"Montserrat Medium";}
@font-face
	{font-family:"Montserrat SemiBold";}
@font-face
	{font-family:"Montserrat Thin";}
@font-face
	{font-family:MoolBoran;}
@font-face
	{font-family:"Mr Gabe";}
@font-face
	{font-family:"MS PMincho";}
@font-face
	{font-family:"Mystical Woods Rough Script";}
@font-face
	{font-family:"Mystical Woods Smooth Script";}
@font-face
	{font-family:"Nanum Brush Script";}
@font-face
	{font-family:"Nanum Pen";}
@font-face
	{font-family:NanumGothic;}
@font-face
	{font-family:NanumGothicCoding;}
@font-face
	{font-family:NanumGothicExtraBold;}
@font-face
	{font-family:NanumMyeongjo;}
@font-face
	{font-family:NanumMyeongjoExtraBold;}
@font-face
	{font-family:Narkisim;}
@font-face
	{font-family:"Neue Haas Grotesk Text Pro";}
@font-face
	{font-family:"News Gothic MT";}
@font-face
	{font-family:Nina;}
@font-face
	{font-family:"Nordique Inline";}
@font-face
	{font-family:"Noto Music";}
@font-face
	{font-family:"Noto Nastaliq Urdu";}
@font-face
	{font-family:"Noto Sans";}
@font-face
	{font-family:"Noto Sans AnatoHiero";}
@font-face
	{font-family:"Noto Sans Avestan";}
@font-face
	{font-family:"Noto Sans Bassa Vah";}
@font-face
	{font-family:"Noto Sans Batak";}
@font-face
	{font-family:"Noto Sans Bhaiksuki";}
@font-face
	{font-family:"Noto Sans Brahmi";}
@font-face
	{font-family:"Noto Sans Buginese";}
@font-face
	{font-family:"Noto Sans Buhid";}
@font-face
	{font-family:"Noto Sans Carian";}
@font-face
	{font-family:"Noto Sans CaucAlban";}
@font-face
	{font-family:"Noto Sans Chakma";}
@font-face
	{font-family:"Noto Sans Coptic";}
@font-face
	{font-family:"Noto Sans Cuneiform";}
@font-face
	{font-family:"Noto Sans Cypriot";}
@font-face
	{font-family:"Noto Sans Deseret";}
@font-face
	{font-family:"Noto Sans Devanagari";}
@font-face
	{font-family:"Noto Sans Devanagari Black";}
@font-face
	{font-family:"Noto Sans Devanagari ExtraBold";}
@font-face
	{font-family:"Noto Sans Devanagari ExtraLight";}
@font-face
	{font-family:"Noto Sans Devanagari Light";}
@font-face
	{font-family:"Noto Sans Devanagari Medium";}
@font-face
	{font-family:"Noto Sans Devanagari SemiBold";}
@font-face
	{font-family:"Noto Sans Devanagari Thin";}
@font-face
	{font-family:"Noto Sans Devanagari UI";}
@font-face
	{font-family:"Noto Sans Devanagari UI Black";}
@font-face
	{font-family:"Noto Sans Devanagari UI Light";}
@font-face
	{font-family:"Noto Sans Devanagari UI Medium";}
@font-face
	{font-family:"Noto Sans Devanagari UI Thin";}
@font-face
	{font-family:"Noto Sans Duployan";}
@font-face
	{font-family:"Noto Sans EgyptHiero";}
@font-face
	{font-family:"Noto Sans Elbasan";}
@font-face
	{font-family:"Noto Sans Elymaic";}
@font-face
	{font-family:"Noto Sans Glagolitic";}
@font-face
	{font-family:"Noto Sans Gothic";}
@font-face
	{font-family:"Noto Sans Grantha";}
@font-face
	{font-family:"Noto Sans Gujarati";}
@font-face
	{font-family:"Noto Sans Gujarati Black";}
@font-face
	{font-family:"Noto Sans Gujarati ExtraBold";}
@font-face
	{font-family:"Noto Sans Gujarati ExtraLight";}
@font-face
	{font-family:"Noto Sans Gujarati Light";}
@font-face
	{font-family:"Noto Sans Gujarati Medium";}
@font-face
	{font-family:"Noto Sans Gujarati SemiBold";}
@font-face
	{font-family:"Noto Sans Gujarati Thin";}
@font-face
	{font-family:"Noto Sans Gujarati UI";}
@font-face
	{font-family:"Noto Sans Gujarati UI Black";}
@font-face
	{font-family:"Noto Sans Gujarati UI ExtraBold";}
@font-face
	{font-family:"Noto Sans Gujarati UI Light";}
@font-face
	{font-family:"Noto Sans Gujarati UI Medium";}
@font-face
	{font-family:"Noto Sans Gujarati UI SemiBold";}
@font-face
	{font-family:"Noto Sans Gujarati UI Thin";}
@font-face
	{font-family:"Noto Sans Gunjala Gondi";}
@font-face
	{font-family:"Noto Sans Hanunoo";}
@font-face
	{font-family:"Noto Sans Hatran";}
@font-face
	{font-family:"Noto Sans ImpAramaic";}
@font-face
	{font-family:"Noto Sans Indic Siyaq Numbers";}
@font-face
	{font-family:"Noto Sans InsPahlavi";}
@font-face
	{font-family:"Noto Sans InsParthi";}
@font-face
	{font-family:"Noto Sans Javanese";}
@font-face
	{font-family:"Noto Sans Kaithi";}
@font-face
	{font-family:"Noto Sans Kharoshthi";}
@font-face
	{font-family:"Noto Sans Khojki";}
@font-face
	{font-family:"Noto Sans Khudawadi";}
@font-face
	{font-family:"Noto Sans Lepcha";}
@font-face
	{font-family:"Noto Sans Limbu";}
@font-face
	{font-family:"Noto Sans Linear A";}
@font-face
	{font-family:"Noto Sans Linear B";}
@font-face
	{font-family:"Noto Sans Lycian";}
@font-face
	{font-family:"Noto Sans Lydian";}
@font-face
	{font-family:"Noto Sans Mahajani";}
@font-face
	{font-family:"Noto Sans Mandaic";}
@font-face
	{font-family:"Noto Sans Manichaean";}
@font-face
	{font-family:"Noto Sans Marchen";}
@font-face
	{font-family:"Noto Sans Masaram Gondi";}
@font-face
	{font-family:"Noto Sans Math";}
@font-face
	{font-family:"Noto Sans Mayan Numerals";}
@font-face
	{font-family:"Noto Sans Mende Kikakui";}
@font-face
	{font-family:"Noto Sans Meroitic";}
@font-face
	{font-family:"Noto Sans Miao";}
@font-face
	{font-family:"Noto Sans Modi";}
@font-face
	{font-family:"Noto Sans Mongolian";}
@font-face
	{font-family:"Noto Sans Mro";}
@font-face
	{font-family:"Noto Sans Multani";}
@font-face
	{font-family:"Noto Sans Myanmar";}
@font-face
	{font-family:"Noto Sans Myanmar Blk";}
@font-face
	{font-family:"Noto Sans Myanmar ExtBd";}
@font-face
	{font-family:"Noto Sans Myanmar ExtLt";}
@font-face
	{font-family:"Noto Sans Myanmar Light";}
@font-face
	{font-family:"Noto Sans Myanmar Med";}
@font-face
	{font-family:"Noto Sans Myanmar SemBd";}
@font-face
	{font-family:"Noto Sans Myanmar Thin";}
@font-face
	{font-family:"Noto Sans Myanmar UI";}
@font-face
	{font-family:"Noto Sans Myanmar UI Black";}
@font-face
	{font-family:"Noto Sans Myanmar UI ExtraBold";}
@font-face
	{font-family:"Noto Sans Myanmar UI ExtraLight";}
@font-face
	{font-family:"Noto Sans Myanmar UI Light";}
@font-face
	{font-family:"Noto Sans Myanmar UI Medium";}
@font-face
	{font-family:"Noto Sans Myanmar UI SemiBold";}
@font-face
	{font-family:"Noto Sans Myanmar UI Thin";}
@font-face
	{font-family:"Noto Sans Nabataean";}
@font-face
	{font-family:"Noto Sans Newa";}
@font-face
	{font-family:"Noto Sans NewTaiLue";}
@font-face
	{font-family:"Noto Sans NKo";}
@font-face
	{font-family:"Noto Sans Nushu";}
@font-face
	{font-family:"Noto Sans Ogham";}
@font-face
	{font-family:"Noto Sans Old Italic";}
@font-face
	{font-family:"Noto Sans Old Permic";}
@font-face
	{font-family:"Noto Sans Old Turkic";}
@font-face
	{font-family:"Noto Sans OldHung";}
@font-face
	{font-family:"Noto Sans OldNorArab";}
@font-face
	{font-family:"Noto Sans OldPersian";}
@font-face
	{font-family:"Noto Sans OldSogdian";}
@font-face
	{font-family:"Noto Sans OldSouArab";}
@font-face
	{font-family:"Noto Sans Oriya";}
@font-face
	{font-family:"Noto Sans Oriya Blk";}
@font-face
	{font-family:"Noto Sans Oriya Thin";}
@font-face
	{font-family:"Noto Sans Oriya UI";}
@font-face
	{font-family:"Noto Sans Oriya UI Blk";}
@font-face
	{font-family:"Noto Sans Oriya UI Thin";}
@font-face
	{font-family:"Noto Sans Osage";}
@font-face
	{font-family:"Noto Sans Osmanya";}
@font-face
	{font-family:"Noto Sans Pahawh Hmong";}
@font-face
	{font-family:"Noto Sans Palmyrene";}
@font-face
	{font-family:"Noto Sans PauCinHau";}
@font-face
	{font-family:"Noto Sans PhagsPa";}
@font-face
	{font-family:"Noto Sans Phoenician";}
@font-face
	{font-family:"Noto Sans PsaPahlavi";}
@font-face
	{font-family:"Noto Sans Rejang";}
@font-face
	{font-family:"Noto Sans Runic";}
@font-face
	{font-family:"Noto Sans Samaritan";}
@font-face
	{font-family:"Noto Sans Saurashtra";}
@font-face
	{font-family:"Noto Sans Sharada";}
@font-face
	{font-family:"Noto Sans Shavian";}
@font-face
	{font-family:"Noto Sans Siddham";}
@font-face
	{font-family:"Noto Sans Sogdian";}
@font-face
	{font-family:"Noto Sans Soyombo";}
@font-face
	{font-family:"Noto Sans Syloti Nagri";}
@font-face
	{font-family:"Noto Sans Symbols2";}
@font-face
	{font-family:"Noto Sans Syriac";}
@font-face
	{font-family:"Noto Sans Syriac Black";}
@font-face
	{font-family:"Noto Sans Syriac Thin";}
@font-face
	{font-family:"Noto Sans Tagalog";}
@font-face
	{font-family:"Noto Sans Tagbanwa";}
@font-face
	{font-family:"Noto Sans Tai Le";}
@font-face
	{font-family:"Noto Sans Tai Viet";}
@font-face
	{font-family:"Noto Sans Takri";}
@font-face
	{font-family:"Noto Sans Tamil Supplement";}
@font-face
	{font-family:"Noto Sans Thai Looped Black";}
@font-face
	{font-family:"Noto Sans Thai Looped Bold";}
@font-face
	{font-family:"Noto Sans Thai Looped ExtLight";}
@font-face
	{font-family:"Noto Sans Thai Looped Extrabold";}
@font-face
	{font-family:"Noto Sans Thai Looped Light";}
@font-face
	{font-family:"Noto Sans Thai Looped Medium";}
@font-face
	{font-family:"Noto Sans Thai Looped Regular";}
@font-face
	{font-family:"Noto Sans Thai Looped Semibold";}
@font-face
	{font-family:"Noto Sans Thai Looped Thin";}
@font-face
	{font-family:"Noto Sans Tifinagh";}
@font-face
	{font-family:"Noto Sans Tirhuta";}
@font-face
	{font-family:"Noto Sans Ugaritic";}
@font-face
	{font-family:"Noto Sans Vai";}
@font-face
	{font-family:"Noto Sans Wancho";}
@font-face
	{font-family:"Noto Sans WarangCiti";}
@font-face
	{font-family:"Noto Sans Yi";}
@font-face
	{font-family:"Noto Sans Zanabazar";}
@font-face
	{font-family:"Noto Serif";}
@font-face
	{font-family:"Noto Serif Ahom";}
@font-face
	{font-family:"Noto Serif Balinese";}
@font-face
	{font-family:"Noto Serif Dogra";}
@font-face
	{font-family:"Noto Serif Grantha";}
@font-face
	{font-family:"Noto Serif Myanmar";}
@font-face
	{font-family:"Noto Serif Myanmar Blk";}
@font-face
	{font-family:"Noto Serif Myanmar ExtBd";}
@font-face
	{font-family:"Noto Serif Myanmar ExtLt";}
@font-face
	{font-family:"Noto Serif Myanmar Light";}
@font-face
	{font-family:"Noto Serif Myanmar Med";}
@font-face
	{font-family:"Noto Serif Myanmar SemBd";}
@font-face
	{font-family:"Noto Serif Myanmar Thin";}
@font-face
	{font-family:"Noto Serif Tangut";}
@font-face
	{font-family:"Noto Traditional Nushu";}
@font-face
	{font-family:Nunito;}
@font-face
	{font-family:"Nunito Black";}
@font-face
	{font-family:"Nunito ExtraBold";}
@font-face
	{font-family:"Nunito ExtraLight";}
@font-face
	{font-family:"Nunito Light";}
@font-face
	{font-family:"Nunito Sans";}
@font-face
	{font-family:"Nunito Sans Black";}
@font-face
	{font-family:"Nunito Sans ExtraBold";}
@font-face
	{font-family:"Nunito Sans ExtraLight";}
@font-face
	{font-family:"Nunito Sans Light";}
@font-face
	{font-family:"Nunito Sans SemiBold";}
@font-face
	{font-family:"Nunito SemiBold";}
@font-face
	{font-family:Nyala;}
@font-face
	{font-family:OCRB;}
@font-face
	{font-family:"Open Sans";}
@font-face
	{font-family:"Open Sans ExtraBold";}
@font-face
	{font-family:"Open Sans Light";}
@font-face
	{font-family:"Open Sans SemiBold";}
@font-face
	{font-family:Oranienbaum;}
@font-face
	{font-family:Oswald;}
@font-face
	{font-family:"Oswald ExtraLight";}
@font-face
	{font-family:"Oswald Light";}
@font-face
	{font-family:"Oswald Medium";}
@font-face
	{font-family:"Oswald SemiBold";}
@font-face
	{font-family:Oxygen;}
@font-face
	{font-family:"Oxygen Light";}
@font-face
	{font-family:"Oxygen Mono";}
@font-face
	{font-family:Pacifico;}
@font-face
	{font-family:Palanquin;}
@font-face
	{font-family:"Palanquin ExtraLight";}
@font-face
	{font-family:"Palanquin Light";}
@font-face
	{font-family:"Palanquin Medium";}
@font-face
	{font-family:"Palanquin SemiBold";}
@font-face
	{font-family:"Palanquin Thin";}
@font-face
	{font-family:"Patrick Hand";}
@font-face
	{font-family:"Patrick Hand SC";}
@font-face
	{font-family:"Petit Formal Script";}
@font-face
	{font-family:"Plantagenet Cherokee";}
@font-face
	{font-family:"Playfair Display";}
@font-face
	{font-family:"Playfair Display Black";}
@font-face
	{font-family:"Playfair Display SC";}
@font-face
	{font-family:"Playfair Display SC Black";}
@font-face
	{font-family:"Poiret One";}
@font-face
	{font-family:Poppins;}
@font-face
	{font-family:"Poppins Black";}
@font-face
	{font-family:"Poppins ExtraBold";}
@font-face
	{font-family:"Poppins ExtraLight";}
@font-face
	{font-family:"Poppins Light";}
@font-face
	{font-family:"Poppins Medium";}
@font-face
	{font-family:"Poppins SemiBold";}
@font-face
	{font-family:"Poppins Thin";}
@font-face
	{font-family:Posterama;}
@font-face
	{font-family:Pridi;}
@font-face
	{font-family:"Pridi ExtraLight";}
@font-face
	{font-family:"Pridi Light";}
@font-face
	{font-family:"Pridi Medium";}
@font-face
	{font-family:"Pridi SemiBold";}
@font-face
	{font-family:Prompt;}
@font-face
	{font-family:"Prompt Black";}
@font-face
	{font-family:"Prompt ExtraBold";}
@font-face
	{font-family:"Prompt ExtraLight";}
@font-face
	{font-family:"Prompt Light";}
@font-face
	{font-family:"Prompt Medium";}
@font-face
	{font-family:"Prompt SemiBold";}
@font-face
	{font-family:"Prompt Thin";}
@font-face
	{font-family:"PT Mono";}
@font-face
	{font-family:"PT Sans";}
@font-face
	{font-family:"PT Sans Caption";}
@font-face
	{font-family:"PT Sans Narrow";}
@font-face
	{font-family:"PT Serif";}
@font-face
	{font-family:"PT Serif Caption";}
@font-face
	{font-family:Quattrocento;}
@font-face
	{font-family:"Quattrocento Sans";}
@font-face
	{font-family:Questrial;}
@font-face
	{font-family:"Quire Sans";}
@font-face
	{font-family:"Quire Sans Light";}
@font-face
	{font-family:"Quire Sans Pro Light";}
@font-face
	{font-family:Raleway;}
@font-face
	{font-family:"Raleway Black";}
@font-face
	{font-family:"Raleway ExtraBold";}
@font-face
	{font-family:"Raleway ExtraLight";}
@font-face
	{font-family:"Raleway Light";}
@font-face
	{font-family:"Raleway Medium";}
@font-face
	{font-family:"Raleway SemiBold";}
@font-face
	{font-family:"Raleway Thin";}
@font-face
	{font-family:"Rastanty Cortez";}
@font-face
	{font-family:"Reem Kufi";}
@font-face
	{font-family:Roboto;}
@font-face
	{font-family:"Roboto Black";}
@font-face
	{font-family:"Roboto Condensed";}
@font-face
	{font-family:"Roboto Condensed Light";}
@font-face
	{font-family:"Roboto Condensed Medium";}
@font-face
	{font-family:"Roboto Light";}
@font-face
	{font-family:"Roboto Medium";}
@font-face
	{font-family:"Roboto Mono";}
@font-face
	{font-family:"Roboto Mono Light";}
@font-face
	{font-family:"Roboto Mono Medium";}
@font-face
	{font-family:"Roboto Mono Thin";}
@font-face
	{font-family:"Roboto Serif 20pt";}
@font-face
	{font-family:"Roboto Serif 20pt Black";}
@font-face
	{font-family:"Roboto Serif 20pt ExtraBold";}
@font-face
	{font-family:"Roboto Serif 20pt ExtraLight";}
@font-face
	{font-family:"Roboto Serif 20pt Light";}
@font-face
	{font-family:"Roboto Serif 20pt Medium";}
@font-face
	{font-family:"Roboto Serif 20pt SemiBold";}
@font-face
	{font-family:"Roboto Serif 20pt Thin";}
@font-face
	{font-family:"Roboto Slab";}
@font-face
	{font-family:"Roboto Slab Black";}
@font-face
	{font-family:"Roboto Slab ExtraBold";}
@font-face
	{font-family:"Roboto Slab ExtraLight";}
@font-face
	{font-family:"Roboto Slab Light";}
@font-face
	{font-family:"Roboto Slab Medium";}
@font-face
	{font-family:"Roboto Slab SemiBold";}
@font-face
	{font-family:"Roboto Slab Thin";}
@font-face
	{font-family:"Roboto Thin";}
@font-face
	{font-family:"Rockwell Light";}
@font-face
	{font-family:"Rockwell Nova";}
@font-face
	{font-family:"Rockwell Nova Cond";}
@font-face
	{font-family:"Rockwell Nova Cond Light";}
@font-face
	{font-family:"Rockwell Nova Extra Bold";}
@font-face
	{font-family:"Rockwell Nova Light";}
@font-face
	{font-family:Rod;}
@font-face
	{font-family:"Sabon Next LT";}
@font-face
	{font-family:Sacramento;}
@font-face
	{font-family:Sagona;}
@font-face
	{font-family:"Sagona Book";}
@font-face
	{font-family:"Sagona ExtraLight";}
@font-face
	{font-family:"Sakkal Majalla";}
@font-face
	{font-family:"Sanskrit Text";}
@font-face
	{font-family:Seaford;}
@font-face
	{font-family:"Seaford Display";}
@font-face
	{font-family:"Secular One";}
@font-face
	{font-family:"Segoe Marker";}
@font-face
	{font-family:"Segoe Pro";}
@font-face
	{font-family:"Segoe Pro Black";}
@font-face
	{font-family:"Segoe Pro Cond";}
@font-face
	{font-family:"Segoe Pro Display";}
@font-face
	{font-family:"Segoe Pro Display Light";}
@font-face
	{font-family:"Segoe Pro Display Semibold";}
@font-face
	{font-family:"Segoe Pro Display SemiLight";}
@font-face
	{font-family:"Segoe Pro Light";}
@font-face
	{font-family:"Segoe Pro Semibold";}
@font-face
	{font-family:"Segoe Pro SemiLight";}
@font-face
	{font-family:"Segoe Sans Display";}
@font-face
	{font-family:"Segoe Sans Display Black";}
@font-face
	{font-family:"Segoe Sans Display Extrabold";}
@font-face
	{font-family:"Segoe Sans Display Hairline";}
@font-face
	{font-family:"Segoe Sans Display Light";}
@font-face
	{font-family:"Segoe Sans Display Semibold";}
@font-face
	{font-family:"Segoe Sans Display Semilight";}
@font-face
	{font-family:"Segoe Sans Display Thin";}
@font-face
	{font-family:"Segoe Sans Small";}
@font-face
	{font-family:"Segoe Sans Small Black";}
@font-face
	{font-family:"Segoe Sans Small Extrabold";}
@font-face
	{font-family:"Segoe Sans Small Hairline";}
@font-face
	{font-family:"Segoe Sans Small Light";}
@font-face
	{font-family:"Segoe Sans Small Semibold";}
@font-face
	{font-family:"Segoe Sans Small Semilight";}
@font-face
	{font-family:"Segoe Sans Small Thin";}
@font-face
	{font-family:"Segoe Sans Text";}
@font-face
	{font-family:"Segoe Sans Text Black";}
@font-face
	{font-family:"Segoe Sans Text Extrabold";}
@font-face
	{font-family:"Segoe Sans Text Hairline";}
@font-face
	{font-family:"Segoe Sans Text Light";}
@font-face
	{font-family:"Segoe Sans Text Semibold";}
@font-face
	{font-family:"Segoe Sans Text Semilight";}
@font-face
	{font-family:"Segoe Sans Text Thin";}
@font-face
	{font-family:"Segoe Serif Banner";}
@font-face
	{font-family:"Segoe Serif Banner Light";}
@font-face
	{font-family:"Segoe Serif Banner Semibold";}
@font-face
	{font-family:"Segoe Serif Banner Semilight";}
@font-face
	{font-family:"Segoe Serif Display";}
@font-face
	{font-family:"Segoe Serif Display Light";}
@font-face
	{font-family:"Segoe Serif Display Semibold";}
@font-face
	{font-family:"Segoe Serif Display Semilight";}
@font-face
	{font-family:"Segoe Serif Text";}
@font-face
	{font-family:"Segoe Serif Text Light";}
@font-face
	{font-family:"Segoe Serif Text Semibold";}
@font-face
	{font-family:"Segoe Serif Text Semilight";}
@font-face
	{font-family:"Segoe UI Emoji L";}
@font-face
	{font-family:"Segoe UI Variable Display Black";}
@font-face
	{font-family:"Segoe UI Variable Display Thin";}
@font-face
	{font-family:"Segoe UI Variable Small Black";}
@font-face
	{font-family:"Segoe UI Variable Small Thin";}
@font-face
	{font-family:"Segoe UI Variable Text Black";}
@font-face
	{font-family:"Segoe UI Variable Text Hairline";}
@font-face
	{font-family:"Segoe UI Variable Text Thin";}
@font-face
	{font-family:"Segoe Xbox Symbol";}
@font-face
	{font-family:Selawik;}
@font-face
	{font-family:"Selawik Light";}
@font-face
	{font-family:"Selawik Semibold";}
@font-face
	{font-family:"Shadows Into Light Two";}
@font-face
	{font-family:"Shonar Bangla";}
@font-face
	{font-family:"Simplified Arabic";}
@font-face
	{font-family:"Simplified Arabic Fixed";}
@font-face
	{font-family:Skeena;}
@font-face
	{font-family:"Skeena Display";}
@font-face
	{font-family:"Skeena Indigenous";}
@font-face
	{font-family:"Skeena Indigenous Black";}
@font-face
	{font-family:"Skeena Indigenous Extra Bold";}
@font-face
	{font-family:"Skeena Indigenous Medium";}
@font-face
	{font-family:"Skeena Indigenous Semibold";}
@font-face
	{font-family:"Source Code Pro";}
@font-face
	{font-family:"Source Code Pro Black";}
@font-face
	{font-family:"Source Code Pro ExtraLight";}
@font-face
	{font-family:"Source Code Pro Light";}
@font-face
	{font-family:"Source Code Pro Medium";}
@font-face
	{font-family:"Source Code Pro Semibold";}
@font-face
	{font-family:"Source Sans Pro";}
@font-face
	{font-family:"Source Sans Pro Black";}
@font-face
	{font-family:"Source Sans Pro ExtraLight";}
@font-face
	{font-family:"Source Sans Pro Light";}
@font-face
	{font-family:"Source Sans Pro SemiBold";}
@font-face
	{font-family:"Source Serif Pro";}
@font-face
	{font-family:"Source Serif Pro Black";}
@font-face
	{font-family:"Source Serif Pro ExtraLight";}
@font-face
	{font-family:"Source Serif Pro Light";}
@font-face
	{font-family:"Source Serif Pro SemiBold";}
@font-face
	{font-family:"Speak Pro";}
@font-face
	{font-family:"Speak Pro Light";}
@font-face
	{font-family:Staatliches;}
@font-face
	{font-family:STCaiyun;}
@font-face
	{font-family:STFangsong;}
@font-face
	{font-family:STHupo;}
@font-face
	{font-family:STKaiti;}
@font-face
	{font-family:STXihei;}
@font-face
	{font-family:STXingkai;}
@font-face
	{font-family:STXinwei;}
@font-face
	{font-family:STZhongsong;}
@font-face
	{font-family:"Suez One";}
@font-face
	{font-family:Tenorite;}
@font-face
	{font-family:"Tenorite Display";}
@font-face
	{font-family:"TH SarabunPSK";}
@font-face
	{font-family:"The Hand";}
@font-face
	{font-family:"The Hand Black";}
@font-face
	{font-family:"The Hand Extrablack";}
@font-face
	{font-family:"The Hand Light";}
@font-face
	{font-family:"The Serif Hand";}
@font-face
	{font-family:"The Serif Hand Black";}
@font-face
	{font-family:"The Serif Hand Extrablack";}
@font-face
	{font-family:"The Serif Hand Light";}
@font-face
	{font-family:"Tisa Offc Serif Pro";}
@font-face
	{font-family:"Tisa Offc Serif Pro Thin";}
@font-face
	{font-family:"Titillium Web";}
@font-face
	{font-family:"Titillium Web Black";}
@font-face
	{font-family:"Titillium Web ExtraLight";}
@font-face
	{font-family:"Titillium Web Light";}
@font-face
	{font-family:"Titillium Web SemiBold";}
@font-face
	{font-family:"Trade Gothic Inline";}
@font-face
	{font-family:"Trade Gothic Next";}
@font-face
	{font-family:"Trade Gothic Next Cond";}
@font-face
	{font-family:"Trade Gothic Next Heavy";}
@font-face
	{font-family:"Trade Gothic Next HvyCd";}
@font-face
	{font-family:"Trade Gothic Next Light";}
@font-face
	{font-family:"Trade Gothic Next Rounded";}
@font-face
	{font-family:"Traditional Arabic";}
@font-face
	{font-family:Trirong;}
@font-face
	{font-family:"Trirong Black";}
@font-face
	{font-family:"Trirong ExtraBold";}
@font-face
	{font-family:"Trirong ExtraLight";}
@font-face
	{font-family:"Trirong Light";}
@font-face
	{font-family:"Trirong Medium";}
@font-face
	{font-family:"Trirong SemiBold";}
@font-face
	{font-family:"Trirong Thin";}
@font-face
	{font-family:Ubuntu;}
@font-face
	{font-family:"Ubuntu Condensed";}
@font-face
	{font-family:"Ubuntu Light";}
@font-face
	{font-family:"Ubuntu Medium";}
@font-face
	{font-family:"Ubuntu Mono";}
@font-face
	{font-family:"UD Digi Kyokasho N-B";}
@font-face
	{font-family:"UD Digi Kyokasho N-R";}
@font-face
	{font-family:"UD Digi Kyokasho NK-B";}
@font-face
	{font-family:"UD Digi Kyokasho NK-R";}
@font-face
	{font-family:"UD Digi Kyokasho NP-B";}
@font-face
	{font-family:"UD Digi Kyokasho NP-R";}
@font-face
	{font-family:Univers;}
@font-face
	{font-family:"Univers Condensed";}
@font-face
	{font-family:"Univers Condensed Light";}
@font-face
	{font-family:"Univers Light";}
@font-face
	{font-family:"Urdu Typesetting";}
@font-face
	{font-family:Utsaah;}
@font-face
	{font-family:Vani;}
@font-face
	{font-family:"Varela Round";}
@font-face
	{font-family:"Verdana Pro";}
@font-face
	{font-family:"Verdana Pro Black";}
@font-face
	{font-family:"Verdana Pro Cond";}
@font-face
	{font-family:"Verdana Pro Cond Black";}
@font-face
	{font-family:"Verdana Pro Cond Light";}
@font-face
	{font-family:"Verdana Pro Cond Semibold";}
@font-face
	{font-family:"Verdana Pro Light";}
@font-face
	{font-family:"Verdana Pro Semibold";}
@font-face
	{font-family:Vijaya;}
@font-face
	{font-family:"Walbaum Display";}
@font-face
	{font-family:"Walbaum Display Heavy";}
@font-face
	{font-family:"Walbaum Display Light";}
@font-face
	{font-family:"Walbaum Display SemiBold";}
@font-face
	{font-family:"Walbaum Heading";}
@font-face
	{font-family:"Walbaum Text";}
@font-face
	{font-family:Wandohope;}
@font-face
	{font-family:"Work Sans";}
@font-face
	{font-family:"Work Sans Black";}
@font-face
	{font-family:"Work Sans ExtraBold";}
@font-face
	{font-family:"Work Sans ExtraLight";}
@font-face
	{font-family:"Work Sans Light";}
@font-face
	{font-family:"Work Sans Medium";}
@font-face
	{font-family:"Work Sans SemiBold";}
@font-face
	{font-family:"Work Sans Thin";}
@font-face
	{font-family:Yesteryear;}
@font-face
	{font-family:"Yu Mincho";}
@font-face
	{font-family:"Yu Mincho Demibold";}
@font-face
	{font-family:"Yu Mincho Light";}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:8.0pt;
	margin-left:0in;
	line-height:115%;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;}
h1
	{mso-style-link:"Heading 1 Char";
	margin-top:.25in;
	margin-right:0in;
	margin-bottom:4.0pt;
	margin-left:0in;
	line-height:115%;
	page-break-after:avoid;
	font-size:20.0pt;
	font-family:"Aptos Display",sans-serif;
	color:#0F4761;
	font-weight:normal;}
h2
	{mso-style-link:"Heading 2 Char";
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:4.0pt;
	margin-left:0in;
	line-height:115%;
	page-break-after:avoid;
	font-size:16.0pt;
	font-family:"Aptos Display",sans-serif;
	color:#0F4761;
	font-weight:normal;}
h3
	{mso-style-link:"Heading 3 Char";
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:4.0pt;
	margin-left:0in;
	line-height:115%;
	page-break-after:avoid;
	font-size:14.0pt;
	font-family:"Aptos",sans-serif;
	color:#0F4761;
	font-weight:normal;}
h4
	{mso-style-link:"Heading 4 Char";
	margin-top:4.0pt;
	margin-right:0in;
	margin-bottom:2.0pt;
	margin-left:0in;
	line-height:115%;
	page-break-after:avoid;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;
	color:#0F4761;
	font-weight:normal;
	font-style:italic;}
h5
	{mso-style-link:"Heading 5 Char";
	margin-top:4.0pt;
	margin-right:0in;
	margin-bottom:2.0pt;
	margin-left:0in;
	line-height:115%;
	page-break-after:avoid;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;
	color:#0F4761;
	font-weight:normal;}
h6
	{mso-style-link:"Heading 6 Char";
	margin-top:2.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	line-height:115%;
	page-break-after:avoid;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;
	color:#595959;
	font-weight:normal;
	font-style:italic;}
p.MsoHeading7, li.MsoHeading7, div.MsoHeading7
	{mso-style-link:"Heading 7 Char";
	margin-top:2.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	line-height:115%;
	page-break-after:avoid;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;
	color:#595959;}
p.MsoHeading8, li.MsoHeading8, div.MsoHeading8
	{mso-style-link:"Heading 8 Char";
	margin:0in;
	line-height:115%;
	page-break-after:avoid;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;
	color:#272727;
	font-style:italic;}
p.MsoHeading9, li.MsoHeading9, div.MsoHeading9
	{mso-style-link:"Heading 9 Char";
	margin:0in;
	line-height:115%;
	page-break-after:avoid;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;
	color:#272727;}
p.MsoTitle, li.MsoTitle, div.MsoTitle
	{mso-style-link:"Title Char";
	margin-top:0in;
	margin-right:0in;
	margin-bottom:4.0pt;
	margin-left:0in;
	font-size:28.0pt;
	font-family:"Aptos Display",sans-serif;
	letter-spacing:-.5pt;}
p.MsoTitleCxSpFirst, li.MsoTitleCxSpFirst, div.MsoTitleCxSpFirst
	{mso-style-link:"Title Char";
	margin:0in;
	font-size:28.0pt;
	font-family:"Aptos Display",sans-serif;
	letter-spacing:-.5pt;}
p.MsoTitleCxSpMiddle, li.MsoTitleCxSpMiddle, div.MsoTitleCxSpMiddle
	{mso-style-link:"Title Char";
	margin:0in;
	font-size:28.0pt;
	font-family:"Aptos Display",sans-serif;
	letter-spacing:-.5pt;}
p.MsoTitleCxSpLast, li.MsoTitleCxSpLast, div.MsoTitleCxSpLast
	{mso-style-link:"Title Char";
	margin-top:0in;
	margin-right:0in;
	margin-bottom:4.0pt;
	margin-left:0in;
	font-size:28.0pt;
	font-family:"Aptos Display",sans-serif;
	letter-spacing:-.5pt;}
p.MsoSubtitle, li.MsoSubtitle, div.MsoSubtitle
	{mso-style-link:"Subtitle Char";
	margin-top:0in;
	margin-right:0in;
	margin-bottom:8.0pt;
	margin-left:0in;
	line-height:115%;
	font-size:14.0pt;
	font-family:"Aptos",sans-serif;
	color:#595959;
	letter-spacing:.75pt;}
a:link, span.MsoHyperlink
	{color:#467886;
	text-decoration:underline;}
a:visited, span.MsoHyperlinkFollowed
	{color:purple;
	text-decoration:underline;}
p
	{margin-right:0in;
	margin-left:0in;
	font-size:12.0pt;
	font-family:"Times New Roman",serif;}
code
	{font-family:"Courier New";}
pre
	{mso-style-link:"HTML Preformatted Char";
	margin:0in;
	font-size:10.0pt;
	font-family:"Courier New";}
p.MsoListParagraph, li.MsoListParagraph, div.MsoListParagraph
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:8.0pt;
	margin-left:.5in;
	line-height:115%;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;}
p.MsoListParagraphCxSpFirst, li.MsoListParagraphCxSpFirst, div.MsoListParagraphCxSpFirst
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:.5in;
	line-height:115%;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;}
p.MsoListParagraphCxSpMiddle, li.MsoListParagraphCxSpMiddle, div.MsoListParagraphCxSpMiddle
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:.5in;
	line-height:115%;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;}
p.MsoListParagraphCxSpLast, li.MsoListParagraphCxSpLast, div.MsoListParagraphCxSpLast
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:8.0pt;
	margin-left:.5in;
	line-height:115%;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;}
p.MsoQuote, li.MsoQuote, div.MsoQuote
	{mso-style-link:"Quote Char";
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:8.0pt;
	margin-left:0in;
	text-align:center;
	line-height:115%;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;
	color:#404040;
	font-style:italic;}
p.MsoIntenseQuote, li.MsoIntenseQuote, div.MsoIntenseQuote
	{mso-style-link:"Intense Quote Char";
	margin-top:.25in;
	margin-right:.6in;
	margin-bottom:.25in;
	margin-left:.6in;
	text-align:center;
	line-height:115%;
	border:none;
	padding:0in;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;
	color:#0F4761;
	font-style:italic;}
span.MsoIntenseEmphasis
	{color:#0F4761;
	font-style:italic;}
span.MsoIntenseReference
	{font-variant:small-caps;
	color:#0F4761;
	letter-spacing:.25pt;
	font-weight:bold;}
span.Heading1Char
	{mso-style-name:"Heading 1 Char";
	mso-style-link:"Heading 1";
	font-family:"Aptos Display",sans-serif;
	color:#0F4761;}
span.Heading2Char
	{mso-style-name:"Heading 2 Char";
	mso-style-link:"Heading 2";
	font-family:"Aptos Display",sans-serif;
	color:#0F4761;}
span.Heading3Char
	{mso-style-name:"Heading 3 Char";
	mso-style-link:"Heading 3";
	font-family:"Times New Roman",serif;
	color:#0F4761;}
span.Heading4Char
	{mso-style-name:"Heading 4 Char";
	mso-style-link:"Heading 4";
	font-family:"Times New Roman",serif;
	color:#0F4761;
	font-style:italic;}
span.Heading5Char
	{mso-style-name:"Heading 5 Char";
	mso-style-link:"Heading 5";
	font-family:"Times New Roman",serif;
	color:#0F4761;}
span.Heading6Char
	{mso-style-name:"Heading 6 Char";
	mso-style-link:"Heading 6";
	font-family:"Times New Roman",serif;
	color:#595959;
	font-style:italic;}
span.Heading7Char
	{mso-style-name:"Heading 7 Char";
	mso-style-link:"Heading 7";
	font-family:"Times New Roman",serif;
	color:#595959;}
span.Heading8Char
	{mso-style-name:"Heading 8 Char";
	mso-style-link:"Heading 8";
	font-family:"Times New Roman",serif;
	color:#272727;
	font-style:italic;}
span.Heading9Char
	{mso-style-name:"Heading 9 Char";
	mso-style-link:"Heading 9";
	font-family:"Times New Roman",serif;
	color:#272727;}
span.TitleChar
	{mso-style-name:"Title Char";
	mso-style-link:Title;
	font-family:"Aptos Display",sans-serif;
	letter-spacing:-.5pt;}
span.SubtitleChar
	{mso-style-name:"Subtitle Char";
	mso-style-link:Subtitle;
	font-family:"Times New Roman",serif;
	color:#595959;
	letter-spacing:.75pt;}
span.QuoteChar
	{mso-style-name:"Quote Char";
	mso-style-link:Quote;
	color:#404040;
	font-style:italic;}
span.IntenseQuoteChar
	{mso-style-name:"Intense Quote Char";
	mso-style-link:"Intense Quote";
	color:#0F4761;
	font-style:italic;}
p.msonormal0, li.msonormal0, div.msonormal0
	{mso-style-name:msonormal;
	margin-right:0in;
	margin-left:0in;
	font-size:12.0pt;
	font-family:"Times New Roman",serif;}
span.HTMLPreformattedChar
	{mso-style-name:"HTML Preformatted Char";
	mso-style-link:"HTML Preformatted";
	font-family:"Courier New";}
span.hljs-number
	{mso-style-name:hljs-number;}
span.hljs-attribute
	{mso-style-name:hljs-attribute;}
span.hljs-function
	{mso-style-name:hljs-function;}
span.hljs-title
	{mso-style-name:hljs-title;}
span.hljs-params
	{mso-style-name:hljs-params;}
span.hljs-comment
	{mso-style-name:hljs-comment;}
span.hljs-type
	{mso-style-name:hljs-type;}
span.hljs-builtin
	{mso-style-name:hljs-built_in;}
span.hljs-string
	{mso-style-name:hljs-string;}
span.hljs-keyword
	{mso-style-name:hljs-keyword;}
span.z-TopofFormChar
	{mso-style-name:"z-Top of Form Char";
	mso-style-link:"z-Top of Form";
	font-family:"Arial",sans-serif;
	display:none;}
span.z-BottomofFormChar
	{mso-style-name:"z-Bottom of Form Char";
	mso-style-link:"z-Bottom of Form";
	font-family:"Arial",sans-serif;
	display:none;}
span.citation-289
	{mso-style-name:citation-289;}
span.citation-288
	{mso-style-name:citation-288;}
span.citation-287
	{mso-style-name:citation-287;}
span.citation-286
	{mso-style-name:citation-286;}
span.citation-285
	{mso-style-name:citation-285;}
span.citation-284
	{mso-style-name:citation-284;}
span.citation-283
	{mso-style-name:citation-283;}
span.citation-282
	{mso-style-name:citation-282;}
span.citation-281
	{mso-style-name:citation-281;}
span.citation-280
	{mso-style-name:citation-280;}
span.citation-279
	{mso-style-name:citation-279;}
span.math-inline
	{mso-style-name:math-inline;}
span.citation-278
	{mso-style-name:citation-278;}
span.citation-277
	{mso-style-name:citation-277;}
span.citation-276
	{mso-style-name:citation-276;}
span.citation-275
	{mso-style-name:citation-275;}
span.citation-274
	{mso-style-name:citation-274;}
span.citation-273
	{mso-style-name:citation-273;}
span.citation-272
	{mso-style-name:citation-272;}
span.citation-271
	{mso-style-name:citation-271;}
span.citation-270
	{mso-style-name:citation-270;}
span.citation-269
	{mso-style-name:citation-269;}
span.citation-268
	{mso-style-name:citation-268;}
span.citation-267
	{mso-style-name:citation-267;}
span.citation-266
	{mso-style-name:citation-266;}
span.citation-265
	{mso-style-name:citation-265;}
span.citation-264
	{mso-style-name:citation-264;}
span.citation-263
	{mso-style-name:citation-263;}
span.citation-262
	{mso-style-name:citation-262;}
span.citation-261
	{mso-style-name:citation-261;}
span.citation-260
	{mso-style-name:citation-260;}
span.citation-259
	{mso-style-name:citation-259;}
span.citation-258
	{mso-style-name:citation-258;}
span.citation-257
	{mso-style-name:citation-257;}
span.citation-256
	{mso-style-name:citation-256;}
span.citation-255
	{mso-style-name:citation-255;}
span.citation-254
	{mso-style-name:citation-254;}
span.citation-253
	{mso-style-name:citation-253;}
span.citation-252
	{mso-style-name:citation-252;}
span.citation-251
	{mso-style-name:citation-251;}
span.citation-250
	{mso-style-name:citation-250;}
span.citation-249
	{mso-style-name:citation-249;}
span.citation-248
	{mso-style-name:citation-248;}
span.citation-247
	{mso-style-name:citation-247;}
span.citation-246
	{mso-style-name:citation-246;}
span.citation-245
	{mso-style-name:citation-245;}
span.citation-244
	{mso-style-name:citation-244;}
span.citation-243
	{mso-style-name:citation-243;}
span.citation-242
	{mso-style-name:citation-242;}
span.citation-241
	{mso-style-name:citation-241;}
span.citation-240
	{mso-style-name:citation-240;}
span.citation-239
	{mso-style-name:citation-239;}
span.citation-238
	{mso-style-name:citation-238;}
span.citation-237
	{mso-style-name:citation-237;}
span.citation-236
	{mso-style-name:citation-236;}
span.citation-235
	{mso-style-name:citation-235;}
span.citation-234
	{mso-style-name:citation-234;}
span.citation-233
	{mso-style-name:citation-233;}
span.citation-232
	{mso-style-name:citation-232;}
span.citation-231
	{mso-style-name:citation-231;}
span.citation-230
	{mso-style-name:citation-230;}
span.citation-229
	{mso-style-name:citation-229;}
span.citation-228
	{mso-style-name:citation-228;}
span.citation-227
	{mso-style-name:citation-227;}
span.citation-226
	{mso-style-name:citation-226;}
span.citation-225
	{mso-style-name:citation-225;}
span.citation-224
	{mso-style-name:citation-224;}
span.citation-223
	{mso-style-name:citation-223;}
span.citation-222
	{mso-style-name:citation-222;}
span.citation-221
	{mso-style-name:citation-221;}
span.citation-220
	{mso-style-name:citation-220;}
span.citation-219
	{mso-style-name:citation-219;}
span.citation-218
	{mso-style-name:citation-218;}
span.citation-217
	{mso-style-name:citation-217;}
span.citation-216
	{mso-style-name:citation-216;}
span.citation-215
	{mso-style-name:citation-215;}
span.citation-214
	{mso-style-name:citation-214;}
span.citation-213
	{mso-style-name:citation-213;}
span.citation-212
	{mso-style-name:citation-212;}
span.citation-211
	{mso-style-name:citation-211;}
span.citation-210
	{mso-style-name:citation-210;}
span.citation-209
	{mso-style-name:citation-209;}
span.citation-208
	{mso-style-name:citation-208;}
span.citation-207
	{mso-style-name:citation-207;}
span.citation-206
	{mso-style-name:citation-206;}
span.citation-205
	{mso-style-name:citation-205;}
span.citation-204
	{mso-style-name:citation-204;}
span.citation-203
	{mso-style-name:citation-203;}
span.citation-202
	{mso-style-name:citation-202;}
span.citation-201
	{mso-style-name:citation-201;}
span.citation-200
	{mso-style-name:citation-200;}
span.citation-199
	{mso-style-name:citation-199;}
span.citation-198
	{mso-style-name:citation-198;}
span.citation-197
	{mso-style-name:citation-197;}
span.citation-196
	{mso-style-name:citation-196;}
span.citation-195
	{mso-style-name:citation-195;}
span.citation-194
	{mso-style-name:citation-194;}
span.citation-193
	{mso-style-name:citation-193;}
span.citation-192
	{mso-style-name:citation-192;}
span.citation-191
	{mso-style-name:citation-191;}
span.citation-190
	{mso-style-name:citation-190;}
span.citation-189
	{mso-style-name:citation-189;}
span.citation-188
	{mso-style-name:citation-188;}
span.citation-187
	{mso-style-name:citation-187;}
span.citation-186
	{mso-style-name:citation-186;}
span.citation-185
	{mso-style-name:citation-185;}
span.citation-184
	{mso-style-name:citation-184;}
span.citation-183
	{mso-style-name:citation-183;}
span.citation-182
	{mso-style-name:citation-182;}
span.citation-181
	{mso-style-name:citation-181;}
span.citation-180
	{mso-style-name:citation-180;}
span.citation-179
	{mso-style-name:citation-179;}
span.citation-178
	{mso-style-name:citation-178;}
span.citation-177
	{mso-style-name:citation-177;}
span.citation-176
	{mso-style-name:citation-176;}
span.citation-175
	{mso-style-name:citation-175;}
span.citation-174
	{mso-style-name:citation-174;}
span.citation-173
	{mso-style-name:citation-173;}
span.citation-172
	{mso-style-name:citation-172;}
span.citation-171
	{mso-style-name:citation-171;}
span.citation-170
	{mso-style-name:citation-170;}
span.citation-169
	{mso-style-name:citation-169;}
span.citation-168
	{mso-style-name:citation-168;}
span.citation-167
	{mso-style-name:citation-167;}
span.citation-166
	{mso-style-name:citation-166;}
span.citation-165
	{mso-style-name:citation-165;}
span.citation-164
	{mso-style-name:citation-164;}
span.citation-163
	{mso-style-name:citation-163;}
span.citation-162
	{mso-style-name:citation-162;}
span.citation-161
	{mso-style-name:citation-161;}
span.citation-160
	{mso-style-name:citation-160;}
span.citation-159
	{mso-style-name:citation-159;}
span.citation-158
	{mso-style-name:citation-158;}
span.citation-157
	{mso-style-name:citation-157;}
span.citation-156
	{mso-style-name:citation-156;}
span.citation-155
	{mso-style-name:citation-155;}
span.citation-154
	{mso-style-name:citation-154;}
span.citation-153
	{mso-style-name:citation-153;}
span.citation-152
	{mso-style-name:citation-152;}
span.citation-151
	{mso-style-name:citation-151;}
span.citation-150
	{mso-style-name:citation-150;}
span.citation-149
	{mso-style-name:citation-149;}
span.citation-148
	{mso-style-name:citation-148;}
span.citation-147
	{mso-style-name:citation-147;}
span.citation-146
	{mso-style-name:citation-146;}
span.citation-145
	{mso-style-name:citation-145;}
p.whitespace-normal, li.whitespace-normal, div.whitespace-normal
	{mso-style-name:whitespace-normal;
	margin-right:0in;
	margin-left:0in;
	font-size:12.0pt;
	font-family:"Times New Roman",serif;}
p.whitespace-pre-wrap, li.whitespace-pre-wrap, div.whitespace-pre-wrap
	{mso-style-name:whitespace-pre-wrap;
	margin-right:0in;
	margin-left:0in;
	font-size:12.0pt;
	font-family:"Times New Roman",serif;}
span.token
	{mso-style-name:token;}
span.hovertext-text-300
	{mso-style-name:"hover\:text-text-300";}
span.msoIns
	{mso-style-name:"";
	text-decoration:underline;
	color:teal;}
span.msoDel
	{mso-style-name:"";
	text-decoration:line-through;
	color:red;}
.MsoPapDefault
	{margin-bottom:8.0pt;
	line-height:115%;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;}
div.WordSection1
	{page:WordSection1;}
 /* List Definitions */
 ol
	{margin-bottom:0in;}
ul
	{margin-bottom:0in;}
-->
</style>

</head>

<body lang=EN-US link="#467886" vlink=purple style='word-wrap:break-word'>

<div class=WordSection1>

<p class=MsoNormal>Perfect <span style='font-family:"Segoe UI Emoji",sans-serif'>&#128077;</span>
Ive extracted your <b>Lecture 03  GPU Programming</b> slides.<br>
Heres what Ill provide <b>for each slide</b>:</p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
     <b>Easy Explanation</b> (in simple terms)</li>
 <li class=MsoNormal><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129504;</span>
     <b>MCQs with Answers</b></li>
 <li class=MsoNormal><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
     <b>Exam Notes / Key Points</b></li>
 <li class=MsoNormal><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
     <b>Numericals (if relevant)</b></li>
 <li class=MsoNormal><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128188;</span>
     <b>Case Study / Real-world Example</b></li>
</ol>

<p class=MsoNormal>Lets start with <b>Slide 1 to 3</b> first (Ill do 3 slides
per message to keep it readable).<br>
Would you like me to:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>(A) Cover <b>all 15 slides</b> in a single long document
     (PDF/Word)?<br>
     or</li>
 <li class=MsoNormal>(B) Deliver them <b>slide-by-slide here</b> (interactive,
     with explanations + practice)?</li>
</ul>

<p class=MsoNormal>Once you choose, Ill begin preparing the detailed
explanations immediately.</p>

<p class=MsoNormal><b>You said:</b></p>

<p class=MsoNormal>B</p>

<p class=MsoNormal><b>ChatGPT said:</b></p>

<p class=MsoNormal>Excellent <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
 well go <b>slide by slide</b> (interactive mode).<br>
Lets start with <b>Slides 13</b> from your <i>GPU Programming Lecture 03</i>
PDF.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128421;&#65039;</span>
Slide 1: GPU Programming</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Easy Explanation:</b></p>

<p class=MsoNormal>This lecture introduces <b>GPU Programming</b>  writing
code that runs on a <b>Graphics Processing Unit (GPU)</b> instead of a
traditional <b>CPU</b>.<br>
GPUs can execute <b>thousands of operations in parallel</b>, making them ideal
for scientific computing, AI, image processing, and simulations.</p>

<p class=MsoNormal><b>CPU vs GPU Analogy:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>CPU = A few very smart workers doing multiple tasks (good
     at logic &amp; sequence).</li>
 <li class=MsoNormal>GPU = Thousands of workers doing the same task
     simultaneously (great for parallel tasks).</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129504;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Which of the following best describes GPU programming?</b><br>
     a) Sequential execution on a single processor<br>
     b) Parallel execution on multiple GPU cores <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     c) Uses CPU only<br>
     d) Used only for graphics rendering</li>
 <li class=MsoNormal><b>Which company introduced CUDA?</b><br>
     a) Intel<br>
     b) AMD<br>
     c) NVIDIA <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     d) Microsoft</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>GPU Programming</b> = Writing parallel programs for
     GPU.</li>
 <li class=MsoNormal><b>CUDA</b> (Compute Unified Device Architecture) =
     NVIDIAs platform for GPU programming.</li>
 <li class=MsoNormal>GPUs excel at <b>data-parallel tasks</b>.</li>
 <li class=MsoNormal><b>Host</b> = CPU; <b>Device</b> = GPU.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128188;</span>
Case Study:</b></p>

<p class=MsoNormal>NVIDIA GPUs are used in <b>Tesla cars</b> for autopilot. The
GPU processes images from cameras in <b>real time</b>  a task needing
thousands of calculations per second.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9881;&#65039;</span>
Slide 2: Program Execution  Recap</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Easy Explanation:</b></p>

<p class=MsoNormal>When we run GPU programs, we <b>launch kernels</b>  small
functions that run on the GPU.<br>
The syntax looks like this:</p>

<p class=MsoNormal>Kernel1&lt;&lt;&lt;100, 256&gt;&gt;&gt;();</p>

<p class=MsoNormal>This means:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>100 <b>blocks</b></li>
 <li class=MsoNormal>256 <b>threads per block</b></li>
 <li class=MsoNormal>Total threads = 100  256 = 25,600</li>
</ul>

<p class=MsoNormal>Each thread performs the same kernel function but works on a
different data element.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129504;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>What does &lt;&lt;&lt;100, 256&gt;&gt;&gt; mean in
     CUDA?</b><br>
     a) 100 threads and 256 blocks<br>
     b) 100 blocks and 256 threads per block <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     c) 256 blocks and 100 threads<br>
     d) It specifies memory allocation</li>
 <li class=MsoNormal><b>How many total threads are launched in Kernel2&lt;&lt;&lt;50,
     1024&gt;&gt;&gt;?</b><br>
     a) 50<br>
     b) 1024<br>
     c) 51200 <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     d) 50 + 1024</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Kernel launch syntax:</b> Kernel&lt;&lt;&lt;numBlocks,
     threadsPerBlock&gt;&gt;&gt;();</li>
 <li class=MsoNormal><b>Total threads</b> = numBlocks  threadsPerBlock</li>
 <li class=MsoNormal>All threads run <b>concurrently</b> (subject to GPU
     scheduling).</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numericals:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Kernel&lt;&lt;&lt;80, 512&gt;&gt;&gt;<br>
     &#8594; Total threads = 80  512 = <b>40,960</b></li>
 <li class=MsoNormal>Kernel&lt;&lt;&lt;20, 256&gt;&gt;&gt;<br>
     &#8594; Total threads = 20  256 = <b>5,120</b></li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128188;</span>
Case Study:</b></p>

<p class=MsoNormal>In <b>image filtering</b>, each pixel can be processed by
one GPU thread. For an image with 25,600 pixels, launching 100 blocks  256
threads efficiently maps one pixel per thread.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129513;</span>
Slide 3: Hierarchy of Kernel, Block, Warp, and Thread</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Easy Explanation:</b></p>

<p class=MsoNormal>GPU execution is <b>hierarchical</b>:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Kernel</b> = The function that runs on GPU.</li>
 <li class=MsoNormal><b>Grid</b> = All blocks launched for one kernel.</li>
 <li class=MsoNormal><b>Block</b> = Group of threads that can cooperate using
     shared memory.</li>
 <li class=MsoNormal><b>Warp</b> = Group of 32 threads executed together.</li>
 <li class=MsoNormal><b>Thread</b> = The smallest execution unit (like a
     worker).</li>
</ul>

<p class=MsoNormal>Structure:</p>

<p class=MsoNormal>Kernel</p>

<p class=MsoNormal>&#9492;&#9472;&#9472; Grid</p>

<p class=MsoNormal> <span style='font-family:"MS Gothic"'>&#9500;</span>&#9472;&#9472;
Block 0</p>

<p class=MsoNormal> &#9474; <span style='font-family:"MS Gothic"'>&#9500;</span>&#9472;&#9472;
Warp 0 (32 threads)</p>

<p class=MsoNormal> &#9474; <span style='font-family:"MS Gothic"'>&#9500;</span>&#9472;&#9472;
Warp 1 (32 threads)</p>

<p class=MsoNormal> &#9474; &#9492;&#9472;&#9472; ...</p>

<p class=MsoNormal> <span style='font-family:"MS Gothic"'>&#9500;</span>&#9472;&#9472;
Block 1</p>

<p class=MsoNormal> &#9492;&#9472;&#9472; ...</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129504;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>What is the smallest execution unit in CUDA?</b><br>
     a) Kernel<br>
     b) Block<br>
     c) Warp<br>
     d) Thread <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
 <li class=MsoNormal><b>How many threads are in a warp?</b><br>
     a) 8<br>
     b) 16<br>
     c) 32 <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     d) 64</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Hierarchy:</b> Grid &#8594; Block &#8594; Warp &#8594;
     Thread</li>
 <li class=MsoNormal><b>Warp = 32 threads</b></li>
 <li class=MsoNormal><b>Blocks</b> are independent; <b>threads within a block</b>
     can cooperate.</li>
 <li class=MsoNormal>Maximum <b>threads per block</b> vary (usually 1024).</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128188;</span>
Case Study:</b></p>

<p class=MsoNormal>When performing <b>matrix multiplication</b>, each thread
handles one cell of the result matrix. Blocks divide the large matrix into
smaller regions (tiles) for parallel computation.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal>Would you like me to continue with <b>Slides 46 next</b>
(Organization of thread blocks &#8594; Grid limits &#8594; Programming
example)?</p>

<p class=MsoNormal><b>You said:</b></p>

<p class=MsoNormal>yes</p>

<p class=MsoNormal><b>ChatGPT said:</b></p>

<p class=MsoNormal>Perfect <span style='font-family:"Segoe UI Emoji",sans-serif'>&#128076;</span>
Lets continue with <b>Slides 46</b>  these focus on <b>thread block
organization</b>, <b>grid dimensions</b>, and <b>CUDA basics</b>.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129521;</span>
Slide 4: Organization of Thread Blocks</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Easy Explanation:</b></p>

<p class=MsoNormal>Threads in CUDA are grouped into <b>blocks</b>.<br>
These blocks can be organized in <b>1D</b>, <b>2D</b>, or <b>3D</b> layouts 
depending on how your problems data is structured.</p>

<p class=MsoNormal>For example:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>1D block</b> &#8594; Vector or array processing</li>
 <li class=MsoNormal><b>2D block</b> &#8594; Image processing (rows  columns)</li>
 <li class=MsoNormal><b>3D block</b> &#8594; Volume data or 3D simulations</li>
</ul>

<p class=MsoNormal>Each <b>block</b> runs independently  it <b>cant
communicate with other blocks</b> directly.</p>

<p class=MsoNormal>Also, the <b>number of threads per block</b> is limited
because each thread requires registers and shared memory.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129504;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Why are blocks required to be independent in CUDA?</b><br>
     a) To reduce power consumption<br>
     b) Because inter-block communication isnt supported <span
     style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     c) To avoid data duplication<br>
     d) For faster compilation</li>
 <li class=MsoNormal><b>Which type of block is suitable for image processing?</b><br>
     a) 1D<br>
     b) 2D <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     c) 3D<br>
     d) 4D</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Thread blocks can be <b>1D, 2D, or 3D</b>.</li>
 <li class=MsoNormal>Blocks <b>must be independent</b>  no communication
     between them.</li>
 <li class=MsoNormal>Threads <b>within a block</b> can synchronize via <b>shared
     memory</b>.</li>
 <li class=MsoNormal><b>Block size limit</b> &#8594; typically 1024 threads
     (hardware dependent).</li>
 <li class=MsoNormal>Choosing block shape to match data structure improves
     performance.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numerical Example:</b></p>

<p class=MsoNormal>If we launch:</p>

<p class=MsoNormal>dim3 threads(16, 16); // 256 threads per block</p>

<p class=MsoNormal>dim3 blocks(10, 10); // 100 blocks</p>

<p class=MsoNormal>Total threads = 100  256 = <b>25,600 threads</b>.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128188;</span>
Case Study:</b></p>

<p class=MsoNormal>In an image blur filter (e.g., 10241024 image), each pixel
is processed by one thread.<br>
A <b>2D block</b> of 1616 threads is used to process image tiles independently
for faster performance.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#127760;</span>
Slide 5: Grids  Blocks of Threads</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Easy Explanation:</b></p>

<p class=MsoNormal>A <b>grid</b> is a collection of blocks that execute the
same kernel.<br>
Each grid can be:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>1D</b> (e.g., 1D array)</li>
 <li class=MsoNormal><b>2D</b> (e.g., image)</li>
 <li class=MsoNormal><b>3D</b> (e.g., volume rendering)</li>
</ul>

<p class=MsoNormal>Think of a <b>grid</b> as a large box containing smaller <b>blocks</b>,
and inside each block are <b>threads</b>.</p>

<p class=MsoNormal>Each thread can find its unique ID using built-in CUDA
variables:</p>

<p class=MsoNormal>threadIdx.x, blockIdx.x, blockDim.x, gridDim.x</p>

<p class=MsoNormal>For example, global thread index:</p>

<p class=MsoNormal>int idx = blockIdx.x * blockDim.x + threadIdx.x;</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129504;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>A grid is composed of:</b><br>
     a) Warps<br>
     b) Threads<br>
     c) Blocks <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     d) Functions</li>
 <li class=MsoNormal><b>Which variable gives the number of threads per block in
     CUDA?</b><br>
     a) gridDim.x<br>
     b) blockDim.x <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     c) threadIdx.x<br>
     d) blockIdx.x</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Grid = group of blocks.</b></li>
 <li class=MsoNormal>Each block executes the same kernel but on different data.</li>
 <li class=MsoNormal>Use CUDA built-ins (blockIdx, threadIdx, etc.) to identify
     threads.</li>
 <li class=MsoNormal>Common global index formula:<br>
     index = blockIdx.x * blockDim.x + threadIdx.x;</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128188;</span>
Case Study:</b></p>

<p class=MsoNormal>For <b>vector addition</b> of two arrays (A and B), each
thread adds one pair of elements:</p>

<p class=MsoNormal>C[idx] = A[idx] + B[idx];</p>

<p class=MsoNormal>Here, idx is computed using block and thread indices.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128207;</span>
Slide 6: Grids of Blocks of Threads  Dimension Limits</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Easy Explanation:</b></p>

<p class=MsoNormal>There are <b>hardware-imposed limits</b> on how large your
grids and blocks can be.<br>
For example (on many GPUs):</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Max threads per block &#8594; <b>1024</b></li>
 <li class=MsoNormal>Max grid size &#8594; <b>65,535 blocks per dimension (x,
     y)</b></li>
 <li class=MsoNormal>Each block can have up to <b>3 dimensions</b> (x, y, z).</li>
</ul>

<p class=MsoNormal>You choose these dimensions depending on the data size and
problem type.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129504;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>What is the maximum number of threads per block in most
     CUDA-capable GPUs?</b><br>
     a) 128<br>
     b) 256<br>
     c) 512<br>
     d) 1024 <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
 <li class=MsoNormal><b>What is the typical maximum grid dimension per axis (x
     or y)?</b><br>
     a) 256<br>
     b) 1024<br>
     c) 65,535 <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     d) 1,000,000</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Threads per block &#8804; 1024</li>
 <li class=MsoNormal>Grids can be <b>1D, 2D, or 3D</b></li>
 <li class=MsoNormal>Dimension limits depend on GPU <b>Compute Capability</b></li>
 <li class=MsoNormal>Optimize block/grid dimensions for <b>occupancy</b> and <b>memory
     efficiency</b></li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numerical Example:</b></p>

<p class=MsoNormal>If you launch:</p>

<p class=MsoNormal>dim3 blocks(64, 64); // 4096 blocks</p>

<p class=MsoNormal>dim3 threads(16, 16); // 256 threads per block</p>

<p class=MsoNormal>Total threads = 4096  256 = <b>1,048,576 threads</b>.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128188;</span>
Case Study:</b></p>

<p class=MsoNormal>In <b>medical 3D imaging (CT scans)</b>, a 3D grid of blocks
can be used.<br>
Each thread handles one voxel (3D pixel) of the scan, allowing massive parallel
reconstruction.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal>Would you like me to move on to <b>Slides 79 next</b> (CUDA
dim3 examples and thread execution order)?</p>

<p class=MsoNormal><b>You said:</b></p>

<p class=MsoNormal>yes</p>

<p class=MsoNormal><b>ChatGPT said:</b></p>

<p class=MsoNormal>Perfect <span style='font-family:"Segoe UI Emoji",sans-serif'>&#128170;</span>
Lets continue with <b>Slides 79</b>  these cover CUDAs dim3 examples, how
threads are mapped, and the step-by-step process of GPU programming.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129513;</span>
Slide 7: Programming Basics  Example (dim3)</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Easy Explanation:</b></p>

<p class=MsoNormal>In CUDA, <b>dim3</b> is a <b>data type</b> that holds <b>three
integer dimensions (x, y, z)</b>.<br>
Its used to define:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>How many <b>threads per block</b></li>
 <li class=MsoNormal>How many <b>blocks per grid</b></li>
</ul>

<p class=MsoNormal>You can initialize it in different ways:</p>

<p class=MsoNormal>dim3 threads(256); // x=256, y=1, z=1</p>

<p class=MsoNormal>dim3 blocks(100, 100); // x=100, y=100, z=1</p>

<p class=MsoNormal>dim3 anotherOne(10, 54, 32);// x=10, y=54, z=32</p>

<p class=MsoNormal>This allows flexibility for <b>1D, 2D, and 3D problems</b>.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129504;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>What is dim3 used for in CUDA?</b><br>
     a) Defining arrays<br>
     b) Defining 3D data structures <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     c) Managing memory<br>
     d) Timing GPU execution</li>
 <li class=MsoNormal><b>If we write dim3 threads(32, 16);, how many threads are
     in one block?</b><br>
     a) 32<br>
     b) 16<br>
     c) 48<br>
     d) 512 <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
     (since 32  16 = 512)</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>dim3</b>: a built-in CUDA vector type with 3 dimensions
     (x, y, z).</li>
 <li class=MsoNormal>Used in kernel launches:</li>
 <li class=MsoNormal>kernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(); </li>
 <li class=MsoNormal>Default values for uninitialized dimensions are <b>1</b>.</li>
 <li class=MsoNormal>Common combinations:</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>1D: (threads(x))</li>
  <li class=MsoNormal>2D: (threads(x, y))</li>
  <li class=MsoNormal>3D: (threads(x, y, z))</li>
 </ul>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numerical Example:</b></p>

<p class=MsoNormal>dim3 threads(32, 8); // threads per block = 256</p>

<p class=MsoNormal>dim3 blocks(64, 64); // 4096 blocks</p>

<p class=MsoNormal>Total threads = 4096  256 = 1,048,576 threads.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128188;</span>
Case Study:</b></p>

<p class=MsoNormal>In <b>image convolution</b>, you can set:</p>

<p class=MsoNormal>dim3 threads(16,16); // each block handles a 16x16 patch</p>

<p class=MsoNormal>dim3 blocks(64,64); // entire image grid</p>

<p class=MsoNormal>This setup maps nicely to a 10241024 pixel image.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#127919;</span>
Slide 8: Programming Basics  Example (Execution Order)</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Easy Explanation:</b></p>

<p class=MsoNormal>Threads on the GPU <b>dont execute in a fixed order</b>.<br>
They are scheduled by the GPU depending on <b>availability and resource
allocation</b>.</p>

<p class=MsoNormal>That means:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>You <b>cannot assume</b> which thread runs first.</li>
 <li class=MsoNormal>All threads of a block <b>may execute concurrently</b> or
     in <b>random order</b>.</li>
 <li class=MsoNormal><b>Green threads (in diagram)</b> show completed threads;
     the <b>order is undefined</b>.</li>
</ul>

<p class=MsoNormal>Hence, <b>synchronization</b> is important if threads share
data within a block.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129504;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>What is true about thread execution order in CUDA?</b><br>
     a) Threads execute strictly in order.<br>
     b) The execution order of threads is undefined <span style='font-family:
     "Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     c) Threads always execute in reverse order.<br>
     d) Threads execute based on priority levels.</li>
 <li class=MsoNormal><b>To ensure correct data sharing between threads, CUDA
     provides:</b><br>
     a) Locks<br>
     b) Semaphores<br>
     c) Synchronization barriers <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     d) Thread sleep</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>CUDA threads <b>execute in undefined order</b>.</li>
 <li class=MsoNormal><b>No guaranteed order</b> between threads or blocks.</li>
 <li class=MsoNormal>Synchronization (like __syncthreads()) ensures that all
     threads in a block reach the same point before continuing.</li>
 <li class=MsoNormal>Avoid <b>data races</b> by ensuring threads dont
     overwrite shared data.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128188;</span>
Case Study:</b></p>

<p class=MsoNormal>When calculating the <b>sum of array elements</b>, if all
threads write to the same memory address without synchronization, the result is
<b>nondeterministic</b> (random).<br>
Using <b>shared memory + __syncthreads()</b> ensures correct summation.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9881;&#65039;</span>
Slide 9: Sequence of Steps for GPU Programming</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Easy Explanation:</b></p>

<p class=MsoNormal>To write and run a GPU program (CUDA), follow these <b>9 key
steps</b>:</p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Allocate CPU Data Structure</b>  Prepare data on the
     host (CPU).</li>
 <li class=MsoNormal><b>Initialize Data on CPU</b>  Fill arrays or matrices
     with values.</li>
 <li class=MsoNormal><b>Allocate GPU Data Structure</b>  Reserve memory on GPU
     (using cudaMalloc).</li>
 <li class=MsoNormal><b>Copy Data from CPU to GPU</b>  Transfer data using cudaMemcpy.</li>
 <li class=MsoNormal><b>Define Execution Configuration</b>  Set grid and block
     sizes (&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;).</li>
 <li class=MsoNormal><b>Run Kernel</b>  Launch GPU function.</li>
 <li class=MsoNormal><b>Synchronize CPU with GPU</b>  Wait for GPU to finish (cudaDeviceSynchronize()).</li>
 <li class=MsoNormal><b>Copy Data from GPU to CPU</b>  Retrieve results.</li>
 <li class=MsoNormal><b>Free GPU and CPU memory</b>  Release allocated memory.</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129504;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Which function is used to copy data from CPU to GPU in
     CUDA?</b><br>
     a) memcpy()<br>
     b) cudaMemcpy() <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     c) malloc()<br>
     d) cudaSync()</li>
 <li class=MsoNormal><b>What is the correct order of operations in CUDA
     programming?</b><br>
     a) Run kernel &#8594; Allocate memory &#8594; Copy data<br>
     b) Allocate memory &#8594; Copy data &#8594; Run kernel <span
     style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     c) Copy data &#8594; Run kernel &#8594; Allocate memory<br>
     d) Free memory &#8594; Run kernel</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Host</b> = CPU, <b>Device</b> = GPU.</li>
 <li class=MsoNormal>Memory management functions:</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>cudaMalloc() &#8594; allocate GPU memory.</li>
  <li class=MsoNormal>cudaMemcpy() &#8594; transfer data.</li>
  <li class=MsoNormal>cudaFree() &#8594; release GPU memory.</li>
 </ul>
 <li class=MsoNormal><b>Kernel launch:</b> kernel&lt;&lt;&lt;blocks,
     threads&gt;&gt;&gt;();</li>
 <li class=MsoNormal><b>Synchronization</b> ensures CPU waits until GPU
     completes execution.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numerical Example:</b></p>

<p class=MsoNormal>If you have an array of 1,000,000 integers:</p>

<p class=MsoNormal>cudaMalloc(&amp;d_A, 1000000 * sizeof(int));</p>

<p class=MsoNormal>cudaMemcpy(d_A, h_A, 1000000 * sizeof(int),
cudaMemcpyHostToDevice);</p>

<p class=MsoNormal>&#8594; Allocates GPU memory and copies data from host to
device.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128188;</span>
Case Study:</b></p>

<p class=MsoNormal>In <b>scientific simulations</b>, data is often initialized
on CPU (e.g., particle positions), processed on GPU (e.g., force computations),
and results are copied back for analysis  exactly following this 9-step flow.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal>Would you like me to continue with <b>Slides 1012 next</b>
(the Hello World CUDA program and explanation of kernel launch)?</p>

<p class=MsoNormal><b>You said:</b></p>

<p class=MsoNormal>yes</p>

<p class=MsoNormal><b>ChatGPT said:</b></p>

<p class=MsoNormal>Awesome <span style='font-family:"Segoe UI Emoji",sans-serif'>&#128640;</span>
Lets now move on to <b>Slides 1012</b>  these cover your first CUDA Hello
World program, kernel functions, and how GPU functions are launched using the
triple-chevron syntax &lt;&lt;&lt; &gt;&gt;&gt;.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129518;</span>
Slide 10: Hello World! with Device Code</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Easy Explanation:</b></p>

<p class=MsoNormal>This is the <b>simplest CUDA program</b> to show how GPU
code works.</p>

<p class=MsoNormal>Heres the example:</p>

<p class=MsoNormal>__global__ void mykernel(void) { }</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>int main(void) {</p>

<p class=MsoNormal> mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;();</p>

<p class=MsoNormal> printf(&quot;Hello World!\n&quot;);</p>

<p class=MsoNormal> return 0;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>Explanation:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>__global__ &#8594; tells the compiler this function runs <b>on
     GPU</b> but is <b>called from CPU</b>.</li>
 <li class=MsoNormal>mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(); &#8594; launches <b>1
     block with 1 thread</b> on GPU.</li>
 <li class=MsoNormal>GPU does nothing (empty kernel), but CPU prints Hello
     World!.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129504;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>What does the __global__ keyword in CUDA indicate?</b><br>
     a) Function runs on CPU and is called from GPU<br>
     b) Function runs on GPU and is called from CPU <span style='font-family:
     "Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     c) Function runs on both CPU and GPU<br>
     d) Function runs only on host memory</li>
 <li class=MsoNormal><b>What does the code mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;();
     mean?</b><br>
     a) Launches 1 kernel with 1 CPU thread<br>
     b) Launches 1 block with 1 GPU thread <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     c) Launches 1 block with 1024 threads<br>
     d) Launches no threads</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>__global__ = kernel function specifier (device code
     callable from host).</li>
 <li class=MsoNormal>&lt;&lt;&lt;1,1&gt;&gt;&gt; = 1 block, 1 thread per block.</li>
 <li class=MsoNormal>A kernel must have <b>void return type</b>.</li>
 <li class=MsoNormal><b>Host code (CPU)</b> calls <b>Device code (GPU)</b> via
     kernel launch syntax.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128188;</span>
Case Study:</b></p>

<p class=MsoNormal>In a <b>GPU-accelerated Hello World demo</b>, the GPU
doesnt print directly; it executes the kernel, while the CPU prints. This
demonstrates that GPU and CPU operate <b>independently but cooperatively</b>.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9881;&#65039;</span>
Slide 11: Hello World!  Kernel Explanation</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Easy Explanation:</b></p>

<p class=MsoNormal>The kernel function:</p>

<p class=MsoNormal>__global__ void mykernel(void) { }</p>

<p class=MsoNormal>is compiled separately by <b>NVIDIAs compiler (nvcc)</b>.<br>
nvcc splits your code into two parts:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Device part (GPU code)</b> &#8594; handled by NVIDIA
     compiler.</li>
 <li class=MsoNormal><b>Host part (CPU code)</b> &#8594; handled by a standard
     compiler (e.g., gcc or cl.exe).</li>
</ul>

<p class=MsoNormal>So:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Device function</b> &#8594; runs on GPU.</li>
 <li class=MsoNormal><b>Host function</b> &#8594; runs on CPU.</li>
</ul>

<p class=MsoNormal>When compiled:</p>

<p class=MsoNormal>$ nvcc hello.cu</p>

<p class=MsoNormal>$ ./a.out</p>

<p class=MsoNormal>Hello World!</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129504;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Which compiler is used to compile CUDA programs?</b><br>
     a) gcc<br>
     b) cl.exe<br>
     c) nvcc <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     d) g++</li>
 <li class=MsoNormal><b>In CUDA, which keyword indicates a GPU kernel function?</b><br>
     a) <b>device</b><br>
     b) <b>global</b> <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     c) <b>shared</b><br>
     d) <b>host</b></li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>nvcc &#8594; NVIDIA CUDA Compiler; compiles .cu files.</li>
 <li class=MsoNormal>Host code compiled by system compiler (e.g., gcc).</li>
 <li class=MsoNormal>Device code compiled by NVIDIA backend.</li>
 <li class=MsoNormal><b>Kernel functions</b> always marked with __global__.</li>
 <li class=MsoNormal>GPU cannot directly print using printf() unless explicitly
     enabled in device code.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128188;</span>
Case Study:</b></p>

<p class=MsoNormal>When developing GPU software like <b>TensorFlow</b> or <b>PyTorch</b>,
the code is divided into host (Python/C++) and device (CUDA) parts  exactly
like the nvcc separation model.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128314;</span>
Slide 12: Hello World!  Triple Chevron Syntax</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Easy Explanation:</b></p>

<p class=MsoNormal>The syntax:</p>

<p class=MsoNormal>mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;();</p>

<p class=MsoNormal>is known as the <b>triple chevron</b> operator  its what <b>launches</b>
a kernel on the GPU.</p>

<p class=MsoNormal>It takes <b>two key parameters:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Number of blocks</b></li>
 <li class=MsoNormal><b>Number of threads per block</b></li>
</ol>

<p class=MsoNormal>So &lt;&lt;&lt;1,1&gt;&gt;&gt; &#8594; 1 block, 1 thread<br>
Example:</p>

<p class=MsoNormal>mykernel&lt;&lt;&lt;100,256&gt;&gt;&gt;();</p>

<p class=MsoNormal>&#8594; Launches 100 blocks with 256 threads each = 25,600
threads.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129504;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>What is the function of the triple chevron &lt;&lt;&lt;
     &gt;&gt;&gt; in CUDA?</b><br>
     a) To declare variables<br>
     b) To call a kernel function on GPU <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     c) To allocate GPU memory<br>
     d) To synchronize threads</li>
 <li class=MsoNormal><b>In mykernel&lt;&lt;&lt;4, 512&gt;&gt;&gt;();, how many
     threads are launched?</b><br>
     a) 4<br>
     b) 512<br>
     c) 2048 <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
     (4  512)<br>
     d) 1024</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>&lt;&lt;&lt;blocks, threads&gt;&gt;&gt; = execution
     configuration for a kernel launch.</li>
 <li class=MsoNormal>Can also include <b>shared memory size</b> and <b>stream</b>
     parameters:<br>
     &lt;&lt;&lt;blocks, threads, sharedMemSize, stream&gt;&gt;&gt;.</li>
 <li class=MsoNormal>Each <b>thread</b> runs the same kernel code
     independently.</li>
 <li class=MsoNormal>Kernel calls are <b>asynchronous</b> (CPU continues
     execution unless synchronized).</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numerical Example:</b></p>

<p class=MsoNormal>kernel&lt;&lt;&lt;20, 512&gt;&gt;&gt;(); // 20 blocks, 512
threads each</p>

<p class=MsoNormal>Total threads = 20  512 = 10,240</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128188;</span>
Case Study:</b></p>

<p class=MsoNormal>When performing <b>massive matrix operations</b>, such as in
deep learning, each kernel launch can spawn thousands of threads across
multiple blocks  leveraging GPU cores for extreme parallelism.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal>Would you like me to continue with <b>Slides 1315 next</b>
(final Hello World example output + introduction to parallel programming and
vector addition)?</p>

<p class=MsoNormal><b>You said:</b></p>

<p class=MsoNormal>yes</p>

<p class=MsoNormal><b>ChatGPT said:</b></p>

<p class=MsoNormal>Perfect <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9889;</span>
Lets wrap up <b>Slides 1315</b>  these complete your CUDA Hello World
example and introduce <b>parallel programming in CUDA C/C++</b>, leading to
real computation like <b>vector addition</b>.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128187;</span>
Slide 13: Hello World! (Full Program Recap)</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Easy Explanation:</b></p>

<p class=MsoNormal>Heres the <b>complete Hello World CUDA program</b>:</p>

<p class=MsoNormal>__global__ void mykernel(void) {</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>int main(void) {</p>

<p class=MsoNormal> mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;();</p>

<p class=MsoNormal> printf(&quot;Hello World!\n&quot;);</p>

<p class=MsoNormal> return 0;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal><b>Explanation:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>The GPU kernel (mykernel) is launched with one block and
     one thread.</li>
 <li class=MsoNormal>The kernel itself does <i>nothing</i>  its just to show
     how kernel launching works.</li>
 <li class=MsoNormal>The CPU (main) then prints <b>Hello World!</b>.</li>
 <li class=MsoNormal>This demonstrates that <b>host (CPU)</b> and <b>device
     (GPU)</b> code can coexist in one program.</li>
</ul>

<p class=MsoNormal>When you compile and run:</p>

<p class=MsoNormal>$ nvcc hello.cu</p>

<p class=MsoNormal>$ ./a.out</p>

<p class=MsoNormal>Hello World!</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129504;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>What will be the output of the CUDA Hello World program
     shown?</b><br>
     a) Hello GPU!<br>
     b) Hello CUDA!<br>
     c) Hello World! <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     d) No output</li>
 <li class=MsoNormal><b>Which part of the program executes on the GPU?</b><br>
     a) The printf() statement<br>
     b) The main() function<br>
     c) The mykernel() function <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     d) Both (a) and (b)</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>GPU kernel (mykernel) is empty  demonstrates kernel
     launch only.</li>
 <li class=MsoNormal>CPU prints to the console; GPU cannot directly print
     (unless special CUDA functions are used).</li>
 <li class=MsoNormal>nvcc compiles both CPU and GPU code.</li>
 <li class=MsoNormal>This is the <b>simplest functional CUDA program</b>.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128188;</span>
Case Study:</b></p>

<p class=MsoNormal>This type of basic Hello World setup is often the <b>first
step in testing GPU drivers and CUDA installation</b> on new hardware setups
before deploying heavy computation programs.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9889;</span>
Slide 14: Hello World!  Explanation Recap</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Easy Explanation:</b></p>

<p class=MsoNormal>This slide reinforces that:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>__global__</b> marks GPU kernels (device code).</li>
 <li class=MsoNormal><b>&lt;&lt;&lt;1,1&gt;&gt;&gt;</b> specifies execution
     configuration.</li>
 <li class=MsoNormal><b>Host (CPU)</b> and <b>Device (GPU)</b> parts are
     clearly separated.</li>
 <li class=MsoNormal>GPU execution happens <b>asynchronously</b>  CPU doesnt
     wait unless we explicitly synchronize.</li>
 <li class=MsoNormal>The <b>kernel does nothing</b>, but the <b>CPU output
     confirms successful GPU call</b>.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129504;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Why is the order of Hello World! output deterministic
     in this example?</b><br>
     a) GPU prints before CPU<br>
     b) CPU prints after GPU kernel returns <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     c) Threads execute in reverse<br>
     d) GPU prints asynchronously</li>
 <li class=MsoNormal><b>If we wanted the GPU to print text, what must we use?</b><br>
     a) printf() inside a kernel <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     b) cout in host code<br>
     c) __device__ printf() in CPU<br>
     d) GPU cant print anything</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>CPU and GPU code can coexist in one .cu file.</li>
 <li class=MsoNormal>Kernel launches are <b>asynchronous</b> (but here, its
     trivial).</li>
 <li class=MsoNormal>Output confirms <b>successful compilation and kernel
     launch</b>.</li>
 <li class=MsoNormal>GPU and CPU use <b>separate memory spaces</b> (data must
     be copied manually).</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128188;</span>
Case Study:</b></p>

<p class=MsoNormal>In early CUDA versions, developers used this minimal Hello
World kernel to verify <b>kernel launch configuration syntax</b> before
proceeding to numerical or image-based GPU workloads.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129518;</span>
Slide 15: Parallel Programming in CUDA C/C++</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Easy Explanation:</b></p>

<p class=MsoNormal>Now we move from Hello World to <b>actual parallel
computing</b>.</p>

<p class=MsoNormal>Main ideas:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>GPU computing is about <b>massive parallelism</b>.</li>
 <li class=MsoNormal>Instead of one thread, we launch <b>thousands</b> of
     threads.</li>
 <li class=MsoNormal>Each thread handles <b>a small part of the problem</b>
     (e.g., one element of a vector).</li>
</ul>

<p class=MsoNormal>Example (conceptually):</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>You want to add two arrays, A and B.</li>
 <li class=MsoNormal>CPU &#8594; adds elements one by one (sequential).</li>
 <li class=MsoNormal>GPU &#8594; each thread adds one element simultaneously
     (parallel).</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129504;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>What is the main advantage of GPU computing?</b><br>
     a) Lower memory usage<br>
     b) Sequential processing<br>
     c) Massive parallelism <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     d) Easier debugging</li>
 <li class=MsoNormal><b>In CUDA, which of the following can be executed in
     parallel by multiple threads?</b><br>
     a) A kernel function <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
     b) The main function<br>
     c) printf() statements<br>
     d) File I/O</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>GPUs = many-core processors &#8594; enable <b>parallel
     computation</b>.</li>
 <li class=MsoNormal>CUDA C/C++ &#8594; allows writing code that runs thousands
     of threads concurrently.</li>
 <li class=MsoNormal>Parallel programming in CUDA involves dividing a problem
     into <b>independent parts</b> handled by separate threads.</li>
 <li class=MsoNormal>Common examples: <b>Vector addition, image filtering,
     matrix multiplication, FFTs.</b></li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numerical Example:</b></p>

<p class=MsoNormal>If you have 1 million elements to add:</p>

<p class=MsoNormal>blocks = 1000; threads = 1000; // total = 1,000,000 threads</p>

<p class=MsoNormal>&#8594; Each thread handles <b>1 element addition</b> in
parallel.<br>
Speed-up over CPU can be <b>10x100x</b> depending on the GPU.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128188;</span>
Case Study:</b></p>

<p class=MsoNormal>In <b>weather simulation models</b>, GPUs perform billions
of floating-point operations simultaneously  predicting conditions faster by
splitting the workload into parallel tasks handled by thousands of threads.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
<b>Summary of Slides 1015:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Learned kernel syntax (__global__, &lt;&lt;&lt;&gt;&gt;&gt;).</li>
 <li class=MsoNormal>Understood how host and device code interact.</li>
 <li class=MsoNormal>Introduced kernel launch configurations.</li>
 <li class=MsoNormal>Transitioned from Hello World &#8594; real parallel tasks
     (like vector addition).</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal>Would you like me to continue with <b>Lecture 04 (next PDF
if you have it)</b> or<br>
should I now create a <b>summary + combined notes file (with all slides 115)</b>
in Word or PDF format for easy study and printing?</p>

<p class=MsoNormal><span style='display:none'>Top of Form</span></p>

<p class=MsoNormal><span style='display:none'>Bottom of Form</span></p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<div style='border:none;border-bottom:double windowtext 2.25pt;padding:0in 0in 1.0pt 0in'>

<p class=MsoNormal style='border:none;padding:0in'>&nbsp;</p>

</div>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><b>Slide 1: GPU Programming Lecture 03</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;This is the title slide,
     introducing the topic for this lecture, which focuses on the execution
     model and hierarchy of GPU programming with CUDA.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 2: Program Execution: Recap</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b></li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal><b>Hardware:</b>&nbsp;The GPU (CUDA Device) is composed
      of&nbsp;<b>Streaming Multiprocessors (SMs)</b>, which are the core
      processing units.</li>
  <li class=MsoNormal><b>Software:</b>&nbsp;Work is organized into&nbsp;<b>Thread
      Blocks</b>, which are divided into&nbsp;<b>Warps</b>&nbsp;(groups of 32
      threads), and finally into individual&nbsp;<b>Threads</b>.</li>
  <li class=MsoNormal><b>CPU/Host Role:</b>&nbsp;The CPU manages memory and
      kernel launches. It (1) copies data to GPU memory, (2) launches the GPU
      kernel, and (3) copies results back.</li>
  <li class=MsoNormal><b>GPU/Device Role:</b>&nbsp;The GPU (2) synchronizes
      with the host and (3) allows data to be copied back after execution.</li>
 </ul>
 <li class=MsoNormal><b>MCQs:</b></li>
</ul>

<ul style='margin-top:0in' type=disc>
 <ol style='margin-top:0in' start=1 type=1>
  <li class=MsoNormal>What is the primary role of the CPU in a typical CUDA
      program?<br>
      a) Execute the kernel<br>
      b) Manage memory transfers and launch kernels<br>
      c) Process warps<br>
      d) Handle thread synchronization within blocks<br>
      <b>Answer: b</b></li>
  <li class=MsoNormal>A group of 32 threads is called a:<br>
      a) Block<br>
      b) Grid<br>
      c) Warp<br>
      d) Stream<br>
      <b>Answer: c</b></li>
 </ol>
</ul>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Exam Notes:</b></li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Remember the&nbsp;<b>CPU (Host)</b>&nbsp;vs.&nbsp;<b>GPU
      (Device)</b>&nbsp;roles.</li>
  <li class=MsoNormal>Know the software hierarchy:&nbsp;<b>Grid &#8594; Thread
      Blocks &#8594; Warps &#8594; Threads</b>.</li>
  <li class=MsoNormal>The host is responsible for memory management and kernel
      invocation.</li>
 </ul>
 <li class=MsoNormal><b>Numericals:</b>&nbsp;N/A for this conceptual slide.</li>
 <li class=MsoNormal><b>Case Study:</b>&nbsp;N/A</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 3: Hierarchy of Kernel, Block, Warp, and Thread</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b></li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A&nbsp;<b>Kernel</b>&nbsp;is a function that runs on the
      GPU, launched from the host using the&nbsp;&lt;&lt;&lt; &gt;&gt;&gt;&nbsp;syntax.</li>
  <li class=MsoNormal>The numbers inside&nbsp;&lt;&lt;&lt; &gt;&gt;&gt;&nbsp;specify
      the&nbsp;<b>number of blocks</b>&nbsp;and&nbsp;<b>threads per block</b>.</li>
  <li class=MsoNormal>Example:&nbsp;Kernel1&lt;&lt;&lt;100, 256&gt;&gt;&gt;&nbsp;launches
      100 blocks, each with 256 threads, totaling 25,600 threads.</li>
  <li class=MsoNormal>The diagram shows a&nbsp;<b>Grid</b>&nbsp;of blocks,
      which can be scheduled on different&nbsp;<b>Streaming Multiprocessors
      (SMs)</b>.</li>
 </ul>
 <li class=MsoNormal><b>MCQs:</b></li>
</ul>

<ul style='margin-top:0in' type=disc>
 <ol style='margin-top:0in' start=1 type=1>
  <li class=MsoNormal>The syntax&nbsp;Kernel&lt;&lt;&lt;B, T&gt;&gt;&gt;&nbsp;specifies:<br>
      a) B threads and T blocks<br>
      b) B blocks and T threads per block<br>
      c) B warps and T threads<br>
      d) B streams and T blocks<br>
      <b>Answer: b</b></li>
  <li class=MsoNormal>How many total threads are launched by&nbsp;Kernel2&lt;&lt;&lt;50,
      1024&gt;&gt;&gt;?<br>
      a) 50<br>
      b) 1024<br>
      c) 51,200<br>
      d) 5,120<br>
      <b>Answer: c</b></li>
 </ol>
</ul>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Exam Notes:</b></li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;&nbsp;is the
      kernel launch syntax.</li>
  <li class=MsoNormal>Total threads = Number of Blocks  Threads per Block.</li>
 </ul>
 <li class=MsoNormal><b>Numericals:</b></li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Calculate the total threads for&nbsp;Kernel&lt;&lt;&lt;32,
      128&gt;&gt;&gt;.</li>
  <ul style='margin-top:0in' type=square>
   <li class=MsoNormal><b>Answer:</b>&nbsp;32  128 = 4,096 threads.</li>
  </ul>
 </ul>
 <li class=MsoNormal><b>Case Study:</b>&nbsp;N/A</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 4: Organization of Thread Blocks</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b></li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Thread blocks can be organized as&nbsp;<b>1D, 2D, or 3D</b>&nbsp;arrays
      for convenience (e.g., matching image dimensions).</li>
  <li class=MsoNormal><b>Blocks within a grid are independent</b>; they cannot
      communicate or synchronize directly.</li>
  <li class=MsoNormal>The total number of threads is determined by the number
      of blocks and threads per block.</li>
  <li class=MsoNormal>The limit on threads per block is often due to&nbsp;<b>limited
      register memory</b>&nbsp;on the SMs.</li>
 </ul>
 <li class=MsoNormal><b>MCQs:</b></li>
</ul>

<ul style='margin-top:0in' type=disc>
 <ol style='margin-top:0in' start=1 type=1>
  <li class=MsoNormal>Why must thread blocks be independent?<br>
      a) To increase complexity<br>
      b) Because they cannot communicate or synchronize<br>
      c) To reduce memory usage<br>
      d) To allow CPU execution<br>
      <b>Answer: b</b></li>
  <li class=MsoNormal>What primarily limits the number of threads in a block?<br>
      a) Global memory size<br>
      b) Limited registers per SM<br>
      c) CPU speed<br>
      d) Kernel name length<br>
      <b>Answer: b</b></li>
 </ol>
</ul>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Exam Notes:</b></li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Blocks are independent; no inter-block communication.</li>
  <li class=MsoNormal>Thread block dimensions should be chosen to fit hardware
      limits and problem structure.</li>
 </ul>
 <li class=MsoNormal><b>Numericals:</b>&nbsp;N/A</li>
 <li class=MsoNormal><b>Case Study:</b>&nbsp;Consider processing a 1024x768
     image. A 2D grid of 32x24 blocks, each with 32x32 threads, could be used
     to map neatly onto the image pixels.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 5: Grids Blocks of Threads</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;This is a visual slide
     reinforcing the hierarchical concept of a&nbsp;<b>Grid</b>&nbsp;containing
     multiple&nbsp;<b>Blocks</b>, each containing multiple&nbsp;<b>Threads</b>.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 6: Grids of Blocks of Threads: Dimension Limits</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b></li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal><b>Grid Limits (1D or 2D):</b>&nbsp;Maximum of 65,535
      blocks in the x and y dimensions.</li>
  <li class=MsoNormal><b>Block Limits (1D, 2D, or 3D):</b>&nbsp;Maximum of 512,
      512, and 64 threads in the x, y, and z dimensions, respectively.
      The&nbsp;<b>total threads per block cannot exceed 512</b>&nbsp;for this
      architecture.</li>
 </ul>
 <li class=MsoNormal><b>MCQs:</b></li>
</ul>

<ul style='margin-top:0in' type=disc>
 <ol style='margin-top:0in' start=1 type=1>
  <li class=MsoNormal>What is the maximum number of blocks in the x-dimension
      of a grid?<br>
      a) 512<br>
      b) 1024<br>
      c) 65,535<br>
      d) 32<br>
      <b>Answer: c</b></li>
  <li class=MsoNormal>What is the maximum total number of threads allowed in a
      single block?<br>
      a) 65,535<br>
      b) 512<br>
      c) 1024<br>
      d) 256<br>
      <b>Answer: b</b></li>
 </ol>
</ul>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Exam Notes:</b></li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Memorize the key limits:&nbsp;<b>Grid (65,535 x 65,535)</b>,&nbsp;<b>Block
      (512, 512, 64)</b>,&nbsp;<b>Total Threads/Block &#8804; 512</b>.</li>
 </ul>
 <li class=MsoNormal><b>Numericals:</b></li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Is a block configuration of&nbsp;(32, 16, 2)&nbsp;valid?</li>
  <ul style='margin-top:0in' type=square>
   <li class=MsoNormal>Total threads = 32  16  2 = 1024.&nbsp;<b>Answer: No</b>,
       it exceeds 512.</li>
  </ul>
 </ul>
 <li class=MsoNormal><b>Case Study:</b>&nbsp;For a large problem requiring 1
     million threads, you must design a grid/block configuration that respects
     these limits, e.g., 2000 blocks of 500 threads each.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 7: Programming Basics: Example (dim3)</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b></li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>dim3&nbsp;is a CUDA vector type for defining dimensions.
      Unspecified coordinates default to 1.</li>
  <li class=MsoNormal>dim3 threads(256);&nbsp;creates a 1D block of 256 threads
      (x=256, y=1, z=1).</li>
  <li class=MsoNormal>dim3 blocks(100, 100);&nbsp;creates a 2D grid (x=100,
      y=100, z=1).</li>
  <li class=MsoNormal>Key built-in variables:</li>
  <ul style='margin-top:0in' type=square>
   <li class=MsoNormal>threadIdx,&nbsp;blockIdx: IDs of the current thread and
       block.</li>
   <li class=MsoNormal>blockDim,&nbsp;gridDim: Dimensions of the block and
       grid.</li>
  </ul>
 </ul>
 <li class=MsoNormal><b>MCQs:</b></li>
</ul>

<ul style='margin-top:0in' type=disc>
 <ol style='margin-top:0in' start=1 type=1>
  <li class=MsoNormal>What does&nbsp;dim3 blocks(50, 60);&nbsp;initialize?<br>
      a) z=50, y=60<br>
      b) x=50, y=60, z=1<br>
      c) x=1, y=50, z=60<br>
      d) x=50, y=1, z=60<br>
      <b>Answer: b</b></li>
  <li class=MsoNormal>Which variable gives the number of threads in a block's
      x-dimension?<br>
      a)&nbsp;gridDim.x<br>
      b)&nbsp;blockIdx.x<br>
      c)&nbsp;blockDim.x<br>
      d)&nbsp;threadIdx.x<br>
      <b>Answer: c</b></li>
 </ol>
</ul>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Exam Notes:</b></li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>dim3&nbsp;is a helper struct for multi-dimensional
      indexing.</li>
  <li class=MsoNormal>Know the four key variables:&nbsp;threadIdx,&nbsp;blockIdx,&nbsp;blockDim,&nbsp;gridDim.</li>
 </ul>
 <li class=MsoNormal><b>Numericals:</b>&nbsp;N/A</li>
 <li class=MsoNormal><b>Case Study:</b>&nbsp;N/A</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 8 &amp; 9: Programming Basics-Example (Indexing)</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b></li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>These slides show how to map a&nbsp;<b>global thread
      index</b>&nbsp;to its&nbsp;<b>block and thread coordinates</b>.</li>
  <li class=MsoNormal>A 2D grid of size (5, 4) has 20 blocks.</li>
  <li class=MsoNormal>A 2D block of size (5, 5) has 25 threads.</li>
  <li class=MsoNormal>To find the coordinates of a specific global thread
      (e.g., 343):</li>
  <ol style='margin-top:0in' start=1 type=1>
   <li class=MsoNormal>Find the block index:&nbsp;block_index = global_id /
       (blockDim.x * blockDim.y) = 343 / 25 = 13.</li>
   <li class=MsoNormal>Find the thread index within the block:&nbsp;thread_in_block
       = global_id % (blockDim.x * blockDim.y) = 343 % 25 = 18.</li>
   <li class=MsoNormal>Convert these 1D indices (13, 18) into 2D/3D coordinates
       using the known dimensions.</li>
  </ol>
 </ul>
 <li class=MsoNormal><b>MCQs:</b></li>
</ul>

<ul style='margin-top:0in' type=disc>
 <ol style='margin-top:0in' start=1 type=1>
  <li class=MsoNormal>In a 2D block of size (10, 10), what is the&nbsp;threadIdx.x&nbsp;of
      the 57th thread (0-indexed) within the block?<br>
      a) 5<br>
      b) 7<br>
      c) 57<br>
      d) 10<br>
      <b>Answer: b</b>&nbsp;(57 % 10 = 7)</li>
  <li class=MsoNormal>If&nbsp;blockDim = (5, 5, 1)&nbsp;and a thread has&nbsp;threadIdx
      = (2, 3, 0), what is its 1D index within the block?<br>
      a) 13<br>
      b) 17<br>
      c) 18<br>
      d) 10<br>
      <b>Answer: b</b>&nbsp;(2 + 3*5 = 17)</li>
 </ol>
</ul>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Exam Notes:</b></li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>The formula for a 1D index within a 2D block is:&nbsp;id
      = threadIdx.x + threadIdx.y * blockDim.x.</li>
  <li class=MsoNormal>The formula for the global 1D index is:&nbsp;global_id =
      (blockIdx.x + blockIdx.y * gridDim.x) * (blockDim.x * blockDim.y) +
      (threadIdx.x + threadIdx.y * blockDim.x).</li>
 </ul>
 <li class=MsoNormal><b>Numericals:</b></li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal><b>Problem:</b>&nbsp;A grid is (3, 2, 1) and a block is
      (4, 3, 1). Find the global 1D index for a thread at&nbsp;blockIdx=(1, 1,
      0)&nbsp;and&nbsp;threadIdx=(2, 1, 0).</li>
 </ul>
</ul>

<ul style='margin-top:0in' type=disc>
 <ul style='margin-top:0in' type=circle>
  <ul style='margin-top:0in' type=square>
   <li class=MsoNormal><b>Solution:</b></li>
   <ul style='margin-top:0in' type=square>
    <li class=MsoNormal>Threads per block = 4 * 3 = 12.</li>
    <li class=MsoNormal>Block ID in 1D = 1 + 1*3 = 4.</li>
    <li class=MsoNormal>Thread ID in block = 2 + 1*4 = 6.</li>
    <li class=MsoNormal>Global ID = (4 * 12) + 6 = 54.</li>
   </ul>
  </ul>
 </ul>
</ul>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Case Study:</b>&nbsp;Matrix multiplication perfectly
     utilizes 2D grids and 2D blocks. Each thread can be assigned to compute
     one element of the output matrix, with its&nbsp;blockIdx&nbsp;and&nbsp;threadIdx&nbsp;directly
     mapping to the row and column indices.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 10: Sequence of Steps for GPU Programming</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;This outlines the standard
     workflow for any CUDA program:</li>
 <ol style='margin-top:0in' start=1 type=1>
  <li class=MsoNormal>Allocate memory on the CPU (Host).</li>
  <li class=MsoNormal>Initialize the data on the CPU.</li>
  <li class=MsoNormal>Allocate memory on the GPU (Device).</li>
  <li class=MsoNormal>Copy data from CPU to GPU (cudaMemcpyHostToDevice).</li>
  <li class=MsoNormal>Define the kernel execution configuration (&lt;&lt;&lt;
      &gt;&gt;&gt;).</li>
  <li class=MsoNormal>Launch the kernel on the GPU.</li>
  <li class=MsoNormal>Synchronize the CPU with the GPU (cudaDeviceSynchronize).</li>
  <li class=MsoNormal>Copy results back from GPU to CPU (cudaMemcpyDeviceToHost).</li>
  <li class=MsoNormal>Free both GPU and CPU memory.</li>
 </ol>
 <li class=MsoNormal><b>MCQs:</b></li>
</ul>

<ul style='margin-top:0in' type=disc>
 <ol style='margin-top:0in' start=1 type=1>
  <li class=MsoNormal>Which step ensures the CPU waits for the GPU kernel to
      finish?<br>
      a) Memory allocation<br>
      b)&nbsp;cudaMemcpy<br>
      c)&nbsp;cudaDeviceSynchronize<br>
      d) Kernel launch<br>
      <b>Answer: c</b></li>
  <li class=MsoNormal>In which step is the&nbsp;&lt;&lt;&lt; &gt;&gt;&gt;&nbsp;syntax
      used?<br>
      a) Data copy<br>
      b) Memory allocation<br>
      c) Kernel launch<br>
      d) Synchronization<br>
      <b>Answer: c</b></li>
 </ol>
</ul>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Exam Notes:</b></li>
</ul>

<ul style='margin-top:0in' type=disc>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Memorize this 9-step sequence. It's the blueprint for
      every CUDA program.</li>
  <li class=MsoNormal>cudaMemcpy&nbsp;is used for both Host-to-Device and
      Device-to-Host transfers.</li>
 </ul>
</ul>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Numericals:</b>&nbsp;N/A</li>
 <li class=MsoNormal><b>Case Study:</b>&nbsp;A program to add two vectors&nbsp;A&nbsp;and&nbsp;B&nbsp;into&nbsp;C&nbsp;would
     follow these exact steps, with the kernel in step 6 containing the
     code&nbsp;C[i] = A[i] + B[i];.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slides 11-14: Hello World! with Device Code</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b></li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>These slides introduce the simplest CUDA program.</li>
  <li class=MsoNormal>The&nbsp;__global__&nbsp;keyword defines a function as
      a&nbsp;<b>kernel</b>&nbsp;that runs on the GPU and is callable from the
      CPU.</li>
  <li class=MsoNormal>mykernel&lt;&lt;&lt;1, 1&gt;&gt;&gt;();&nbsp;launches the
      kernel with&nbsp;<b>1 block</b>&nbsp;and&nbsp;<b>1 thread</b>.</li>
  <li class=MsoNormal>nvcc&nbsp;compiles the code, splitting it into host (CPU)
      and device (GPU) parts.</li>
 </ul>
 <li class=MsoNormal><b>MCQs:</b></li>
</ul>

<ul style='margin-top:0in' type=disc>
 <ol style='margin-top:0in' start=1 type=1>
  <li class=MsoNormal>The&nbsp;__global__&nbsp;keyword specifies a function
      that:<br>
      a) Runs on the host and is called from the device<br>
      b) Runs on the device and is called from the host<br>
      c) Runs on both host and device<br>
      d) Is a global variable<br>
      <b>Answer: b</b></li>
  <li class=MsoNormal>What does&nbsp;&lt;&lt;&lt;1, 1&gt;&gt;&gt;&nbsp;signify?<br>
      a) 1 grid and 1 block<br>
      b) 1 block and 1 thread per block<br>
      c) 1 warp and 1 thread<br>
      d) 1 stream and 1 kernel<br>
      <b>Answer: b</b></li>
 </ol>
</ul>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Exam Notes:</b></li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>__global__&nbsp;for device kernels called from host.</li>
  <li class=MsoNormal>__device__&nbsp;for device functions called from other
      device functions.</li>
  <li class=MsoNormal>&lt;&lt;&lt;1, 1&gt;&gt;&gt;&nbsp;is the simplest, but
      least parallel, launch configuration.</li>
 </ul>
 <li class=MsoNormal><b>Numericals:</b>&nbsp;N/A</li>
 <li class=MsoNormal><b>Case Study:</b>&nbsp;This &quot;Hello World&quot; is
     trivial but demonstrates the core syntax. A more useful kernel would
     actually perform a computation and use many threads.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 15: Parallel Programming in CUDA C/C++</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;This slide sets the stage for
     future lectures, highlighting that the power of GPU computing comes
     from&nbsp;<b>massive parallelism</b>. It promises to build from a simple
     integer addition to a full&nbsp;<b>Vector Addition (SAXPY)</b>&nbsp;example,
     a foundational algorithm in parallel computing.</li>
 <li class=MsoNormal><b>MCQs:</b></li>
 <ol style='margin-top:0in' start=1 type=1>
  <li class=MsoNormal>GPU computing is primarily about:<br>
      a) Low power consumption<br>
      b) Massive parallelism<br>
      c) Single-thread performance<br>
      d) Large caches<br>
      <b>Answer: b</b></li>
 </ol>
 <li class=MsoNormal><b>Exam Notes:</b>&nbsp;The next logical step is vector
     addition, where each thread independently computes one element of the
     output vector.</li>
 <li class=MsoNormal><b>Numericals:</b>&nbsp;N/A</li>
 <li class=MsoNormal><b>Case Study:</b>&nbsp;Vector addition is an
     &quot;embarrassingly parallel&quot; problem, making it an ideal first case
     study for GPU programming. Each thread performs one operation&nbsp;c[i] =
     a[i] + b[i]&nbsp;without needing to communicate with other threads.</li>
</ul>

<p class=MsoNormal>&nbsp;</p>

<div style='border:none;border-bottom:double windowtext 2.25pt;padding:0in 0in 1.0pt 0in'>

<p class=MsoNormal style='border:none;padding:0in'>&nbsp;</p>

</div>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><b>Slide 1: GPU Programming - Lecture 03</b></p>

<table class=MsoNormalTable border=0 cellspacing=3 cellpadding=0>
 <thead>
  <tr>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Content Type</b></p>
   </td>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Response</b></p>
   </td>
  </tr>
 </thead>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Easy Explanation</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>This is the title slide, simply indicating the topic is <b>GPU
  Programming</b> and it's the third lecture in the series<sup>1</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>MCQs</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q:</b> What is the main topic of this presentation? <b>A)</b>
  CPU Architecture <b>B)</b> GPU Programming <b>C)</b> Operating Systems <b>D)</b>
  Web Development (Answer: B) <sup>2</sup></p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Exam Notes</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>* <b>Core Subject:</b> GPU Programming<sup>3</sup>. * <b>Lecture
  Number:</b> 03<sup>4</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Numericals</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>N/A (Title slide).</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Case Studies</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>N/A (Title slide).</p>
  </td>
 </tr>
</table>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 2: Program Execution: Recap</b></p>

<table class=MsoNormalTable border=0 cellspacing=3 cellpadding=0>
 <thead>
  <tr>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Content Type</b></p>
   </td>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Response</b></p>
   </td>
  </tr>
 </thead>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Easy Explanation</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>This slide summarizes how a GPU program runs<sup>5</sup>. On
  the <b>Software</b> side, the smallest unit is a <b>Thread</b>, which groups
  together into a <b>Warp</b>, and Warps are part of a <b>Thread Block</b><sup>666666666</sup>.
  On the <b>Hardware</b> side, Thread Blocks are executed on a <b>Streaming
  Multiprocessor (SM)</b>, which is part of the <b>CUDA Device</b> (the GPU
  itself)<sup>777</sup>. The overall program flow involves the <b>CPU/Host</b>
  copying data to the GPU memory, launching the <b>GPU Kernel</b>, waiting
  (synchronizing), and finally copying the result back from the GPU memory<sup>8</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>MCQs</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q1:</b> What is the smallest unit of execution on the
  software side in CUDA? <b>A)</b> Warp <b>B)</b> Thread Block <b>C)</b> Thread
  <b>D)</b> Streaming Multiprocessor (Answer: C)<sup>999</sup>. <b>Q2:</b>
  Which component executes the Thread Blocks on the GPU hardware? <b>A)</b> CPU
  <b>B)</b> CUDA Device <b>C)</b> Streaming Multiprocessor (SM) <b>D)</b> Host
  (Answer: C)<sup>10</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Exam Notes</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>* <b>Hardware Hierarchy (Big to Small):</b> CUDA Device $\rightarrow$
  Streaming Multiprocessor (SM)<sup>11</sup>. * <b>Software Hierarchy (Big to
  Small):</b> Thread Block $\rightarrow$ Warp $\rightarrow$ Thread<sup>121212121212121212</sup>.
  * <b>Execution Steps:</b> 1. Copy to GPU mem. 2. Launch GPU Kernel. 2'.
  Synchronize. 3. Copy from GPU mem. (Host/CPU handles these steps) <sup>13</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Numericals</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q:</b> If a Thread Block has 3 Warps, and each Warp has
  32 Threads (a common size), how many Threads are in the Block? <b>A:</b> $3
  \text{ Warps} \times 32 \text{ Threads/Warp} = 96 \text{ Threads}$.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Case Studies</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Scenario:</b> An image processing application needs to
  process data on the GPU. <b>Steps:</b> The CPU first loads the image data and
  copies it to the GPU memory. It then launches a kernel with many Threads to
  process individual pixels. After the kernel finishes, the CPU synchronizes
  and copies the modified image data back from the GPU memory<sup>14</sup>.</p>
  </td>
 </tr>
</table>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 3: Hierarchy of kernel, block, warp and thread</b></p>

<table class=MsoNormalTable border=0 cellspacing=3 cellpadding=0>
 <thead>
  <tr>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Content Type</b></p>
   </td>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Response</b></p>
   </td>
  </tr>
 </thead>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Easy Explanation</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>This slide details the execution hierarchy and how a GPU
  function (a <b>kernel</b>) is launched<sup>151515</sup>. A kernel is made up
  of multiple <b>Thread Blocks</b> (e.g., block(0,0), block(1,0)) <sup>16</sup>.
  Each Block consists of one or more <b>Warps</b>, and each Warp contains many <b>Threads</b><sup>17</sup>.
  The host (CPU) calls a kernel using the <b>triple chevron</b> notation &lt;&lt;&lt;...&gt;&gt;&gt;<sup>18</sup>.
  The parameters inside the chevrons specify the number of <b>blocks</b> and
  the number of <b>threads per block</b><sup>1919</sup>. For example, Kernel1&lt;&lt;&lt;100,
  256&gt;&gt;&gt; launches $100$ blocks, each with $256$ threads, totaling $25,600$
  threads<sup>20</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>MCQs</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q1:</b> What is the CUDA syntax used by the host to
  launch a kernel on the device? <b>A)</b> mykernel(...) <b>B)</b> mykernel&lt;&lt;&lt;...&gt;&gt;&gt;
  <b>C)</b> mykernel(...) <b>D)</b> mykernel(...) (Answer: B)<sup>21</sup>. <b>Q2:</b>
  In the launch Kernel2&lt;&lt;&lt;50, 1024&gt;&gt;&gt;, what does the second
  parameter (1024) represent? <b>A)</b> Number of Warps <b>B)</b> Number of
  kernels <b>C)</b> Total number of threads <b>D)</b> Number of threads per
  block (Answer: D)<sup>222222</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Exam Notes</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>* <b>Kernel Launch Syntax:</b> kernel_name&lt;&lt;&lt;num_blocks,
  threads_per_block&gt;&gt;&gt;()<sup>23</sup>. * <b>Total Threads Calculation:</b>
  $\text{Total Threads} = \text{Number of Blocks} \times \text{Threads per
  Block}$<sup>24</sup>. * <b>Structure:</b> A <b>Kernel</b> is a collection of <b>Blocks</b>;
  a <b>Block</b> is a collection of <b>Warps</b>; a <b>Warp</b> is a collection
  of <b>Threads</b><sup>25</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Numericals</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q:</b> A kernel is launched with Kernel&lt;&lt;&lt;50,
  1024&gt;&gt;&gt;. Calculate the total number of threads launched. <b>A:</b> $\text{Total
  Threads} = 50 \text{ Blocks} \times 1024 \text{ Threads/Block} = 51,200
  \text{ Threads}$<sup>26</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Case Studies</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Scenario:</b> You are writing a CUDA program to add two
  large vectors, each with $1,000,000$ elements. You decide to use $10,000$
  blocks. How many threads should you specify per block in your kernel launch? <b>Calculation:</b>
  $\text{Threads per Block} = \frac{\text{Total Elements}}{\text{Number of
  Blocks}} = \frac{1,000,000}{10,000} = 100 \text{ threads/block}$. <b>Launch:</b>
  addVectors&lt;&lt;&lt;10000, 100&gt;&gt;&gt;().</p>
  </td>
 </tr>
</table>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 4: Organization of thread blocks</b></p>

<table class=MsoNormalTable border=0 cellspacing=3 cellpadding=0>
 <thead>
  <tr>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Content Type</b></p>
   </td>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Response</b></p>
   </td>
  </tr>
 </thead>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Easy Explanation</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Thread blocks are organized into a grid called the <b>Kernel
  Grid</b><sup>27</sup>. This grid can be a 1D, 2D, or 3D array of threads,
  which is useful for mapping parallel work to different data structures like
  arrays, matrices, or volumes<sup>28</sup>. The most important rule is that
  all thread blocks within a grid <b>must be able to execute independently</b>
  because they cannot communicate or cooperate with each other<sup>2929</sup>. The
  number of blocks and the threads per block are specified when the kernel is
  launched, which determines the overall number of threads<sup>30</sup>. The
  limits on the number of threads per block are primarily imposed by the
  limited number of <b>registers</b> that can be allocated across all threads
  in that block<sup>31</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>MCQs</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q1:</b> In CUDA, how must thread blocks in a grid be
  organized regarding communication? <b>A)</b> They must communicate
  frequently. <b>B)</b> They must be able to execute independently. <b>C)</b> They
  must share global memory only. <b>D)</b> They must be organized in 3D only.
  (Answer: B) <sup>3232</sup>. <b>Q2:</b> What is the primary reason for the
  limitation on the maximum number of threads in a block? <b>A)</b> Limited
  global memory <b>B)</b> Limited number of registers that can be allocated
  across all threads <b>C)</b> Limited warp size <b>D)</b> Limited number of
  SMs (Answer: B)<sup>33</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Exam Notes</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>* <b>Grid Organization:</b> Thread blocks can be organized
  into 1D, 2D, or 3D arrays<sup>34</sup>. * <b>Independence Rule:</b> Blocks in
  a grid <b>must be independent</b>; inter-block communication is not possible<sup>3535</sup>.
  * <b>Limits:</b> The limit on threads per block is related to the allocation
  of <b>registers</b><sup>36</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Numericals</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q:</b> A problem requires $100,000$ independent
  parallel tasks. If each thread block can handle a maximum of $512$ threads,
  what is the minimum number of blocks required? <b>A:</b> $\text{Minimum
  Blocks} = \lceil \frac{100,000}{512} \rceil = \lceil 195.3125 \rceil = 196
  \text{ blocks}$.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Case Studies</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Scenario:</b> You are implementing a matrix
  multiplication ($C = A \times B$). Since each element $C_{ij}$ can be
  calculated independently, you can map the calculation of one $C_{ij}$ to one
  thread. You organize the thread blocks into a 2D grid that matches the
  dimensions of the output matrix $C$. This 2D organization aligns with the
  &quot;convenient to organize thread blocks into 1D, 2D or 3D arrays&quot;
  concept<sup>37</sup>.</p>
  </td>
 </tr>
</table>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 5: Execution</b></p>

<table class=MsoNormalTable border=0 cellspacing=3 cellpadding=0>
 <thead>
  <tr>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Content Type</b></p>
   </td>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Response</b></p>
   </td>
  </tr>
 </thead>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Easy Explanation</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>This slide illustrates the connection between the Host
  (CPU) and the Device (GPU) and introduces built-in variables for thread
  indexing. The host launches a <b>Grid</b> of <b>Blocks</b> of <b>Threads</b><sup>38</sup>.
  The variables gridDim and blockDim define the size/dimensions of the grid and
  the block, respectively<sup>3939393939393939</sup>. The variables blockIdx
  and threadIdx provide the zero-based index of the current block within the
  grid and the current thread within the block<sup>40404040404040</sup>. This
  indexing is crucial for each thread to know which part of the overall problem
  it is responsible for.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>MCQs</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q1:</b> A kernel is launched with someKernel&lt;&lt;&lt;1,
  1&gt;&gt;&gt;(). What is the value of gridDim.x? <b>A)</b> 0 <b>B)</b> 1 <b>C)</b>
  2 <b>D)</b> Undefined (Answer: B)<sup>41</sup>. <b>Q2:</b> In the launch someKernel&lt;&lt;&lt;blocks,
  4&gt;&gt;&gt;() where dim3 blocks(2,1,1);, what is the total number of
  threads launched? <b>A)</b> 4 <b>B)</b> 8 <b>C)</b> 2 <b>D)</b> 6 (Answer: B.
  Total threads = gridDim.x * blockDim.x = $2 \times 4 = 8$)<sup>424242424242424242</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Exam Notes</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>* <b>gridDim:</b> Dimensions of the grid in <b>blocks</b><sup>43434343</sup>.
  * <b>blockDim:</b> Dimensions of the block in <b>threads</b><sup>44444444</sup>.
  * <b>blockIdx:</b> Index of the current block within the grid (zero-based)<sup>45454545</sup>.
  * <b>threadIdx:</b> Index of the current thread within the block (zero-based)<sup>46464646</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Numericals</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q:</b> For a launch myKernel&lt;&lt;&lt;dim3(10, 5),
  dim3(256, 1)&gt;&gt;&gt;(), what are the values of gridDim.x and blockDim.y? <b>A:</b>
  gridDim.x = 10 (blocks) and blockDim.y = 1 (thread).</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Case Studies</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Scenario:</b> A thread needs to calculate the value for
  element $(15, 7)$ in a 2D array. The kernel is launched with 10 blocks in X
  and 10 blocks in Y, with each block having 16 threads in X and 16 threads in
  Y. The thread can use the following formula to find its global index: $\text{Global\_X}
  = \text{blockIdx.x} \times \text{blockDim.x} + \text{threadIdx.x}$. The
  thread uses its built-in indices (blockIdx.x, threadIdx.x, etc.) to calculate
  which array element it should work on.</p>
  </td>
 </tr>
</table>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 6: Grids of Blocks of Threads: Dimension Limits</b></p>

<table class=MsoNormalTable border=0 cellspacing=3 cellpadding=0>
 <thead>
  <tr>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Content Type</b></p>
   </td>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Response</b></p>
   </td>
  </tr>
 </thead>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Easy Explanation</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>This slide summarizes the hardware/software relationship
  and, crucially, outlines the <b>dimension limits</b> for the Grid and the
  Thread Block<sup>47474747</sup>. The <b>Grid of Blocks</b> can only be 1D or
  2D, with a maximum size of 65,535 in both the X and Y directions<sup>484848</sup>.
  The <b>Block of Threads</b> can be 1D, 2D, or 3D. The total number of threads
  in a block is limited to a maximum of 512 (on older hardware/specifications)<sup>494949</sup>.
  Specifically, the maximum dimensions are 512 for X and Y, and 64 for Z<sup>50</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>MCQs</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q1:</b> What is the maximum possible dimension of a
  Grid of Blocks? <b>A)</b> 1D <b>B)</b> 2D <b>C)</b> 3D <b>D)</b> 4D (Answer:
  B)<sup>5151</sup>. <b>Q2:</b> What is the maximum number of threads allowed
  in a single thread block (based on this slide's limit)? <b>A)</b> 64 <b>B)</b>
  256 <b>C)</b> 512 <b>D)</b> 65535 (Answer: C)<sup>52</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Exam Notes</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>* <b>Grid Limits (1D/2D):</b> $\text{Max X} = 65,535$, $\text{Max
  Y} = 65,535$<sup>535353</sup>. * <b>Block Limits (1D/2D/3D):</b> $\text{Max
  Total Threads} = 512$<sup>545454</sup>. * <b>Block Dimension Limits:</b> $\text{Max
  X} = 512$, $\text{Max Y} = 512$, $\text{Max Z} = 64$<sup>55</sup>. * <b>Mapping:</b>
  Thread Blocks are mapped onto Streaming Multiprocessors (SMs)<sup>56</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Numericals</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q:</b> A developer wants to use a 3D thread block of
  size $10 \times 10 \times 10$. Is this configuration valid based on the
  limits? <b>A:</b> The total number of threads is $10 \times 10 \times 10 =
  1,000$. Since $1,000 &gt; 512$ (the maximum number of threads in a block),
  this configuration is <b>invalid</b><sup>57</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Case Studies</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Scenario:</b> A parallel algorithm processes a $1,000
  \times 1,000$ matrix. The grid should be at least $1,000 \times 1,000$. Since
  $1,000 &lt; 65,535$ for both X and Y, a 2D grid is perfectly suitable<sup>58</sup>.
  A common practice is to use $16 \times 16$ or $32 \times 32$ thread blocks
  (e.g., $256$ or $1,024$ threads total). The $32 \times 32 = 1,024$ option is
  not valid based on the limit of 512 threads, so a $16 \times 16$ block (256
  threads) would be chosen to stay within the limits<sup>59</sup>.</p>
  </td>
 </tr>
</table>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 7: Programming Basics: Example</b></p>

<table class=MsoNormalTable border=0 cellspacing=3 cellpadding=0>
 <thead>
  <tr>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Content Type</b></p>
   </td>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Response</b></p>
   </td>
  </tr>
 </thead>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Easy Explanation</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>This slide introduces the <b>dim3</b> type, a 3D structure
  with X, Y, and Z integer coordinates, used to define the dimensions of the
  grid and thread blocks<sup>60</sup>. It can be initialized with one, two, or
  three values; any missing values default to 1<sup>61616161616161</sup>. For
  instance, dim3 threads(256); sets X=256, and Y and Z to 1<sup>62</sup>. The
  slide also presents a crucial table of <b>built-in variables</b> used by a
  thread to identify its position: threadIdx, blockIdx, blockDim, and gridDim,
  all of which have x, y, and z components<sup>6363</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>MCQs</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q1:</b> If dim3 blocks(100, 100); is declared, what is
  the value of blocks.z? <b>A)</b> 100 <b>B)</b> 1 <b>C)</b> 0 <b>D)</b>
  Undefined (Answer: B)<sup>64</sup>. <b>Q2:</b> Which built-in CUDA variable
  gives the dimensions of the thread block in terms of threads? <b>A)</b> threadIdx
  <b>B)</b> blockIdx <b>C)</b> blockDim <b>D)</b> gridDim (Answer: C)<sup>6565</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Exam Notes</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>* <b>dim3:</b> A 3D vector type for $\text{x, y, z}$
  integers<sup>66</sup>. Missing coordinates default to <b>1</b><sup>67676767</sup>.
  * <b>Key Built-in Variables:</b> * <b>threadIdx:</b> Thread index within the
  block (zero-based). * <b>blockIdx:</b> Block index within the grid
  (zero-based). * <b>blockDim:</b> Block dimensions in threads. * <b>gridDim:</b>
  Grid dimensions in blocks<sup>6868</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Numericals</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q:</b> A CUDA block is launched using dim3 threads(64,
  4, 2);. What is the total number of threads in this block? <b>A:</b> $\text{Total
  Threads} = \text{threads.x} \times \text{threads.y} \times \text{threads.z} =
  64 \times 4 \times 2 = 512 \text{ threads}$.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Case Studies</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Scenario:</b> A program needs to define a 2D grid of $100
  \times 100$ blocks. The developer uses dim3 blocks(100, 100);. When the
  kernel runs, any thread can check the total number of blocks in the Y
  direction by accessing gridDim.y, which will be 100, a value set by the dim3
  structure<sup>69696969</sup>.</p>
  </td>
 </tr>
</table>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 8: Programming Basics-Example</b></p>

<table class=MsoNormalTable border=0 cellspacing=3 cellpadding=0>
 <thead>
  <tr>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Content Type</b></p>
   </td>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Response</b></p>
   </td>
  </tr>
 </thead>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Easy Explanation</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>This slide illustrates a mapping example for a 2D grid of
  thread blocks and a 2D block of threads . <b>GRID LEVEL:</b> The grid has a
  size of $(5, 4, 1)$, meaning 5 blocks in the X direction (gridDim.x = 5) and
  4 blocks in the Y direction (gridDim.y = 4)<sup>7070707070</sup>. blockIdx.x
  and blockIdx.y give a block's index within this grid (e.g., $(0,0,0)$ up to $(4,3,0)$)<sup>71717171</sup>.
  <b>BLOCK LEVEL:</b> Each block has a size of $(5, 5, 1)$, meaning 5 threads
  along X (blockDim.x = 5) and 5 threads along Y (blockDim.y = 5)<sup>72727272727272</sup>.
  threadIdx.x and threadIdx.y give a thread's index within this block<sup>73737373</sup>.
  A key concept: the <b>order of execution for threads and blocks is undefined</b>;
  they can complete randomly, as highlighted by the green-colored
  blocks/threads in the diagram<sup>74</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>MCQs</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q1:</b> For the grid example on this slide, what is the
  total number of thread blocks? <b>A)</b> 5 <b>B)</b> 4 <b>C)</b> 20 <b>D)</b>
  25 (Answer: C. $5 \times 4 = 20$)<sup>75</sup>. <b>Q2:</b> Why is it unsafe
  to rely on a specific order of execution between threads in different blocks?
  <b>A)</b> Thread execution is sequential by design. <b>B)</b> The order of
  execution for threads and blocks is undefined. <b>C)</b> Only threads in the
  same warp are guaranteed to execute sequentially. <b>D)</b> Thread blocks are
  always synchronized automatically. (Answer: B) <sup>76767676</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Exam Notes</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>* <b>Grid Dimensions:</b> gridDim.x (number of blocks in
  X) = 5, gridDim.y (number of blocks in Y) = 4<sup>77777777</sup>. * <b>Block
  Dimensions:</b> blockDim.x (number of threads in X) = 5, blockDim.y (number
  of threads in Y) = 5<sup>78787878</sup>. * <b>Execution Order:</b> <b>Undefined</b>
  and non-deterministic (randomly completed threads/blocks)<sup>79</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Numericals</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q:</b> What is the total number of threads in the
  entire grid shown in the example? <b>A:</b> $\text{Total Threads} =
  (\text{gridDim.x} \times \text{gridDim.y}) \times (\text{blockDim.x} \times
  \text{blockDim.y}) = (5 \times 4) \times (5 \times 5) = 20 \times 25 = 500
  \text{ threads}$<sup>80</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Case Studies</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Scenario:</b> Two blocks, Block A and Block B, are
  executing. A calculation in Block A needs the result from Block B. Because
  the execution order is undefined, Block A might run before Block B has
  completed, leading to a race condition or incorrect result. This is why
  inter-block communication is explicitly disallowed<sup>81818181</sup>.</p>
  </td>
 </tr>
</table>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 9: Programming Basics-Example</b></p>

<table class=MsoNormalTable border=0 cellspacing=3 cellpadding=0>
 <thead>
  <tr>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Content Type</b></p>
   </td>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Response</b></p>
   </td>
  </tr>
 </thead>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Easy Explanation</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>This slide demonstrates how to find the specific <b>blockIdx</b>
  and <b>threadIdx</b> for a given <b>global thread index</b> in a 1D-like
  mapping . In this example, the grid has 20 blocks and each block has 25
  threads, for a total of 500 threads<sup>82</sup>. To find the indices for a
  global thread index (say, 343), you divide the index by the block size (25)<sup>83</sup>.
  <b>Calculation:</b> $343 = 25 \times 13 + 18$. The quotient (13) is the block
  number, and the remainder (18) is the thread number (using 0-indexing, the $13^{th}$
  block and $17^{th}$ thread)<sup>84</sup>. This $13^{th}$ block maps to
  coordinates $(3, 2, 0)$, and the $17^{th}$ thread maps to $(2, 3, 0)$ in the
  2D configuration, giving the final index: blockIdx.x = 3, blockIdx.y = 2, threadIdx.x
  = 2, threadIdx.y = 3 (with $\text{z}=0$) <sup>85</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>MCQs</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q1:</b> In a CUDA kernel with 20 blocks and 25 threads
  per block, what is the total number of threads? <b>A)</b> 20 <b>B)</b> 25 <b>C)</b>
  45 <b>D)</b> 500 (Answer: D. $20 \times 25 = 500$)<sup>86</sup>. <b>Q2:</b> A
  thread has a global index of 50, and the block size is 25 threads. Using
  0-indexing, what is its block number and thread number? <b>A)</b> Block 1,
  Thread 24 <b>B)</b> Block 2, Thread 0 <b>C)</b> Block 3, Thread 0 <b>D)</b>
  Block 2, Thread 25 (Answer: B. $50 = 25 \times 2 + 0$. Block index 2, Thread
  index 0.)<sup>87</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Exam Notes</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>* <b>Purpose:</b> To calculate the unique $\text{blockIdx}$
  and $\text{threadIdx}$ from a single linear (global) thread number<sup>88</sup>.
  * <b>Formula (1D linear):</b> $\text{Global Index} = \text{blockIdx} \times
  \text{blockDim} + \text{threadIdx}$. * <b>DivMod:</b> $\text{blockIdx} =
  \lfloor \frac{\text{Global Index}}{\text{blockDim}} \rfloor$; $\text{threadIdx}
  = \text{Global Index} \pmod{\text{blockDim}}$<sup>89</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Numericals</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q:</b> For a block size of 256 threads, find the blockIdx
  and threadIdx for a thread with a global index of 700. <b>A:</b> $\text{blockIdx}
  = \lfloor \frac{700}{256} \rfloor = 2$. $\text{threadIdx} = 700 \pmod{256} =
  700 - (2 \times 256) = 700 - 512 = 188$. <b>Answer:</b> Block index 2, Thread
  index 188.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Case Studies</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Scenario:</b> A parallel sorting algorithm is
  processing a large array. Each thread must access a unique array element. By
  using the calculation method shown (dividing by block size), a thread can
  translate its unique global index into the blockIdx and threadIdx
  coordinates, allowing it to correctly calculate the memory address of the
  array element it is responsible for.</p>
  </td>
 </tr>
</table>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 10: Sequence of steps for GPU programming</b></p>

<table class=MsoNormalTable border=0 cellspacing=3 cellpadding=0>
 <thead>
  <tr>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Content Type</b></p>
   </td>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Response</b></p>
   </td>
  </tr>
 </thead>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Easy Explanation</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>This slide outlines the standard nine-step workflow for
  GPU programming, particularly in CUDA<sup>90</sup>. It starts on the <b>CPU/Host</b>
  by allocating and initializing the input data<sup>91</sup>. Then, memory is
  allocated on the <b>GPU/Device</b>, and the input data is copied from the CPU
  to the GPU<sup>92</sup>. The program defines the kernel's execution
  configuration (grid and block sizes) and launches the <b>Kernel</b><sup>93</sup>.
  The <b>CPU must then wait</b> for the GPU to finish (synchronization)<sup>9494</sup>.
  Finally, the result data is copied back from the GPU to the CPU, and all
  allocated memory is released (de-allocated)<sup>95</sup>. Steps 1, 2, 4, 7,
  8, and 9 are primarily host-side memory and data transfer operations<sup>96</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>MCQs</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q1:</b> Which step is executed <i>after</i> the GPU
  Kernel is launched and <i>before</i> the result data is copied back to the
  CPU? <b>A)</b> Allocate CPU Data Structure <b>B)</b> Copy Data from CPU to
  GPU <b>C)</b> CPU synchronizes with GPU <b>D)</b> De-allocate memory (Answer:
  C)<sup>97</sup>. <b>Q2:</b> What is the first memory operation step involving
  the GPU? <b>A)</b> Initialize Data on CPU <b>B)</b> Allocate GPU Data
  Structure <b>C)</b> Copy Data from GPU to CPU <b>D)</b> De-allocate GPU
  memory (Answer: B)<sup>98</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Exam Notes</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>* <b>The Core 3 Phases (Host perspective):</b> * <b>Data
  Transfer IN:</b> Steps 1-4 (Allocate CPU/GPU, Copy CPU $\rightarrow$ GPU) <sup>99</sup>.
  * <b>Execution:</b> Steps 5-7 (Define Config, Run Kernel, Synchronize)<sup>100</sup>.
  * <b>Data Transfer OUT &amp; Cleanup:</b> Steps 8-9 (Copy GPU $\rightarrow$
  CPU, De-allocate memory)<sup>101</sup>. * <b>Synchronization is Key:</b> The
  CPU must wait (synchronize) for the GPU to ensure the kernel is complete
  before trying to retrieve results<sup>102102102102</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Numericals</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q:</b> A data transfer operation takes $10 \text{ ms}$
  to copy data to the GPU and $10 \text{ ms}$ to copy data back. The kernel
  execution takes $5 \text{ ms}$. If the synchronization time is negligible,
  what is the approximate total time for the main execution steps (4 through
  8)? <b>A:</b> $\text{Total Time} \approx \text{Copy In} + \text{Kernel Run} +
  \text{Copy Out} = 10 \text{ ms} + 5 \text{ ms} + 10 \text{ ms} = 25 \text{
  ms}$.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Case Studies</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Scenario:</b> A physics simulation requires massive
  calculation. The input parameters and initial state are loaded into CPU
  memory (Step 2). The CPU allocates equivalent memory on the GPU (Step 3) and
  sends the data over (Step 4). The simulation kernel runs (Step 6). Since the
  CPU might continue other tasks, it must explicitly wait for the GPU to finish
  (Step 7) before retrieving the final simulation results (Step 8) for
  analysis.</p>
  </td>
 </tr>
</table>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 11: Hello World! with Device Code</b></p>

<table class=MsoNormalTable border=0 cellspacing=3 cellpadding=0>
 <thead>
  <tr>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Content Type</b></p>
   </td>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Response</b></p>
   </td>
  </tr>
 </thead>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Easy Explanation</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>This is a &quot;Hello World&quot; example demonstrating
  the minimal code needed to launch a function on the GPU using CUDA C/C++. The
  function mykernel is defined with the <b>__global__</b> keyword, marking it
  as a <b>device function</b> (a kernel)<sup>103</sup>. The main function
  (which runs on the CPU/Host) launches this kernel using the <b>triple chevron</b>
  syntax: mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;();<sup>104</sup>. This launch
  creates a single block with a single thread. The program then executes the
  host-side printf statement<sup>105</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>MCQs</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q1:</b> What is the CUDA keyword used to declare a
  function as a kernel (a device function callable from the host)? <b>A)</b> __device__
  <b>B)</b> __host__ <b>C)</b> __global__ <b>D)</b> __kernel__ (Answer: C)<sup>106</sup>.
  <b>Q2:</b> What does the call mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(); launch? <b>A)</b>
  10 threads <b>B)</b> 1 warp <b>C)</b> 1 block with 1 thread <b>D)</b> 10
  blocks (Answer: C)<sup>107</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Exam Notes</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>* <b>Kernel Declaration:</b> The __global__ prefix is
  mandatory for functions running on the device and called from the host<sup>108</sup>.
  * <b>Kernel Launch:</b> Uses the triple chevron &lt;&lt;&lt;1,1&gt;&gt;&gt;<sup>109</sup>.
  The parameters (1,1) mean <b>1 block</b> and <b>1 thread per block</b><sup>110</sup>.
  * <b>Host/Device Code:</b> main() is host code; mykernel() is device code<sup>111</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Numericals</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q:</b> How many threads are launched by mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;();?
  <b>A:</b> $1 \text{ block} \times 1 \text{ thread/block} = 1 \text{ thread}$.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Case Studies</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Scenario:</b> You want to confirm your CUDA development
  environment is correctly set up. Running this simple &quot;Hello World&quot;
  example successfully, which launches a minimal task on the GPU and then
  prints output from the CPU, validates the compiler (nvcc) and runtime
  environment are working for both host and device code.</p>
  </td>
 </tr>
</table>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 12: Hello World! with Device Code (Analysis)</b></p>

<table class=MsoNormalTable border=0 cellspacing=3 cellpadding=0>
 <thead>
  <tr>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Content Type</b></p>
   </td>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Response</b></p>
   </td>
  </tr>
 </thead>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Easy Explanation</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>This slide clarifies the function of the <b>__global__</b>
  keyword. A function declared with __global__ runs on the <b>device</b> (GPU)
  and is called from the <b>host</b> (CPU) code<sup>112</sup>. The <b>nvcc
  compiler</b> is responsible for separating the source code: device functions
  (like mykernel()) are processed by the NVIDIA compiler, and host functions
  (like main()) are processed by the standard host compiler (e.g., gcc or cl.exe)<sup>113</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>MCQs</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q1:</b> A CUDA function with the __global__ keyword
  runs on which hardware component? <b>A)</b> Host (CPU) <b>B)</b> Device (GPU)
  <b>C)</b> Shared Memory <b>D)</b> Registers (Answer: B)<sup>114</sup>. <b>Q2:</b>
  What is the role of the nvcc compiler in CUDA C/C++ development? <b>A)</b> It
  compiles all code as standard C++. <b>B)</b> It only compiles host code. <b>C)</b>
  It separates and processes host and device code components. <b>D)</b> It only
  manages data transfers. (Answer: C) <sup>115</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Exam Notes</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>* <b>__global__ Functionality:</b> Runs on <b>Device</b>,
  Called from <b>Host</b><sup>116</sup>. * <b>Compilation:</b> nvcc is the key
  CUDA compiler that handles the splitting of the source code<sup>117</sup>. * <b>Host
  Compiler:</b> Standard compilers like gcc or cl.exe process the host code
  component<sup>118</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Numericals</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>N/A (Focuses on language features and compilation).</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Case Studies</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Scenario:</b> A developer writes a function calculate_sum()
  and needs it to execute on the GPU for massive parallelism. They must prefix
  the function declaration with __global__. When they compile the file, nvcc
  knows to send calculate_sum() to the NVIDIA device compiler for GPU
  architecture targeting, while sending the main C++ logic to the standard host
  compiler.</p>
  </td>
 </tr>
</table>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 13: Hello World! with Device Code (Analysis of
Launch)</b></p>

<table class=MsoNormalTable border=0 cellspacing=3 cellpadding=0>
 <thead>
  <tr>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Content Type</b></p>
   </td>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Response</b></p>
   </td>
  </tr>
 </thead>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Easy Explanation</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>This slide explains the <b>triple angle brackets (&lt;&lt;&lt;&gt;&gt;&gt;)</b>
  used in the kernel call mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;()<sup>119</sup>. These
  brackets mark a call from the <b>host code</b> (CPU) to the <b>device code</b>
  (GPU) and are referred to as a <b>&quot;kernel launch&quot;</b><sup>120</sup>.
  Launching a function this way is all that's needed to start execution on the
  GPU<sup>121</sup>. The parameters inside the chevrons define the
  configuration (number of blocks and threads per block), which will be
  discussed later<sup>122</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>MCQs</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q1:</b> What term is used to describe a function call
  marked by triple angle brackets? <b>A)</b> Host Call <b>B)</b> Function
  Pointer <b>C)</b> Kernel Launch <b>D)</b> Device Sync (Answer: C)<sup>123</sup>.
  <b>Q2:</b> Where does the call using triple angle brackets originate? <b>A)</b>
  Device code to Host code <b>B)</b> Host code to Device code <b>C)</b> Device
  code to Device code <b>D)</b> Only within the compiler (Answer: B)<sup>124</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Exam Notes</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>* <b>&lt;&lt;&lt;&gt;&gt;&gt;:</b> Triple angle brackets
  syntax marks a <b>kernel launch</b><sup>125</sup>. * <b>Direction:</b> Call
  is always <b>Host</b> $\rightarrow$ <b>Device</b><sup>126</sup>. * <b>Parameters:</b>
  The numbers inside (e.g., 1,1) specify the <b>execution configuration</b>
  (grid and block dimensions)<sup>127</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Numericals</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>N/A (Focuses on launch syntax).</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Case Studies</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Scenario:</b> A developer attempts to call a GPU
  function mykernel using the standard C++ syntax: mykernel();. The compiler
  throws an error because the <b>kernel launch</b> syntax (&lt;&lt;&lt;...&gt;&gt;&gt;)
  is required to signal the runtime to set up the parallel execution
  environment on the GPU. The correct call, even for a non-parallel task, must
  be mykernel&lt;&lt;&lt;1, 1&gt;&gt;&gt;() to correctly initiate the GPU
  execution<sup>128</sup>.</p>
  </td>
 </tr>
</table>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 14: Hello World! with Device Code (Output)</b></p>

<table class=MsoNormalTable border=0 cellspacing=3 cellpadding=0>
 <thead>
  <tr>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Content Type</b></p>
   </td>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Response</b></p>
   </td>
  </tr>
 </thead>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Easy Explanation</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>This slide shows the execution of the minimal &quot;Hello
  World&quot; CUDA program<sup>129</sup>. Even though mykernel() is launched on
  the GPU, its body is empty ({})<sup>130</sup>. The output is simply
  &quot;Hello World!&quot; because the printf(&quot;Hello World!\n&quot;); statement
  is part of the host code (main()) and runs <i>after</i> the (empty) kernel is
  launched<sup>131</sup>. The process involves compiling the .cu file with nvcc
  and then executing the output file<sup>132</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>MCQs</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q1:</b> Given the code, what is the output of the
  program? <b>A)</b> Nothing, the kernel is empty <b>B)</b> Hello World! <b>C)</b>
  A compilation error <b>D)</b> An execution error (Answer: B)<sup>133</sup>. <b>Q2:</b>
  What command is used to compile the CUDA source file hello.cu? <b>A)</b> gcc
  hello.cu <b>B)</b> cl hello.cu <b>C)</b> nvcc hello.cu <b>D)</b> compile
  hello.cu (Answer: C)<sup>134</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Exam Notes</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>* <b>Kernel vs. Host Execution:</b> The host-side printf
  executes successfully even if the device-side kernel (mykernel) does nothing<sup>135</sup>.
  * <b>Compilation:</b> Use the nvcc compiler for CUDA files<sup>136</sup>. * <b>Default
  Output:</b> The compiled executable is typically named a.out (on Linux/macOS)<sup>137</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Numericals</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>N/A (Focuses on output).</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Case Studies</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Scenario:</b> A developer wants to measure the overhead
  of a kernel launch. They would use this empty kernel as a baseline. They time
  the execution from just before the mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;()
  launch to after a synchronization call. The resulting time represents the
  minimal overhead for the host-device communication and context setup.</p>
  </td>
 </tr>
</table>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 15: Parallel Programming in CUDA C/C++</b></p>

<table class=MsoNormalTable border=0 cellspacing=3 cellpadding=0>
 <thead>
  <tr>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Content Type</b></p>
   </td>
   <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Response</b></p>
   </td>
  </tr>
 </thead>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Easy Explanation</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>This slide transitions the discussion from &quot;Hello
  World&quot; to the real power of CUDA: <b>massive parallelism</b> on the GPU<sup>138</sup>.
  The simple &quot;Hello World&quot; example is not useful for parallel
  computing<sup>139</sup>. The next logical step is to explore a more
  interesting problem, starting with the simple operation of adding two
  integers and building up to the more complex, but highly parallel, <b>vector
  addition</b><sup>140</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>MCQs</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q1:</b> What is the primary characteristic of GPU
  computing that CUDA C/C++ is designed to leverage? <b>A)</b> Sequential
  processing <b>B)</b> Massive parallelism <b>C)</b> Low power consumption <b>D)</b>
  Single-threaded execution (Answer: B)<sup>141</sup>. <b>Q2:</b> Which more
  interesting and parallel example is suggested to follow the &quot;Hello
  World&quot; demonstration? <b>A)</b> File I/O <b>B)</b> Network programming <b>C)</b>
  Vector addition <b>D)</b> Database queries (Answer: C)<sup>142</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Exam Notes</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>* <b>Core Principle:</b> GPU computing is fundamentally
  about <b>massive parallelism</b><sup>143</sup>. * <b>Learning Progression:</b>
  Simple Integer Addition $\rightarrow$ <b>Vector Addition</b> (a classic
  parallel problem)<sup>144</sup>. * <b>Motivation:</b> Simple examples (like
  empty kernels) don't showcase the GPU's power<sup>145</sup>.</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Numericals</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Q:</b> If a vector addition involves two vectors, $\vec{A}$
  and $\vec{B}$, each with $10^{6}$ elements, and the operation is $\vec{C} =
  \vec{A} + \vec{B}$. How many independent parallel additions are required? <b>A:</b>
  $10^{6}$ independent additions (one for each element pair).</p>
  </td>
 </tr>
 <tr>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Case Studies</b></p>
  </td>
  <td style='border:solid windowtext 1.0pt;padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal><b>Scenario:</b> <b>Vector Addition</b> is the
  prototypical parallel problem. Each corresponding pair of elements from two
  input vectors (e.g., $A[i] + B[i]$) can be added independently to produce an
  element of the output vector $C[i]$. This is perfect for the GPU's parallel
  architecture, where millions of threads can be launched to handle a
  million-element vector addition simultaneously.</p>
  </td>
 </tr>
</table>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<div style='border:none;border-bottom:double windowtext 2.25pt;padding:0in 0in 1.0pt 0in'>

<p class=MsoNormal style='border:none;padding:0in'>&nbsp;</p>

</div>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><b>Slide 1: GPU Programming - Lecture 03</b></p>

<p class=MsoNormal><b>Easy Explanation of Concepts</b></p>

<p class=MsoNormal>This is the title slide for Lecture 03 on GPU Programming.
It introduces the topic without diving into details. GPU Programming refers to
writing code that runs on Graphics Processing Units (GPUs), which are
specialized hardware for parallel processing tasks, unlike CPUs that handle
sequential tasks. Key idea: GPUs excel at handling many simple tasks
simultaneously, like in graphics rendering or machine learning.</p>

<p class=MsoNormal><b>Related MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What does GPU stand for? a) General Processing Unit b)
     Graphics Processing Unit c) Global Programming Utility d) Grid Processing
     Unit <b>Answer: b) Graphics Processing Unit</b></li>
 <li class=MsoNormal>GPU programming is primarily used for: a) Sequential
     computations b) Parallel processing tasks c) Database management d) Text
     editing <b>Answer: b) Parallel processing tasks</b></li>
 <li class=MsoNormal>In the context of this lecture series, what is the focus
     of Lecture 03? a) CPU basics b) Advanced GPU hierarchies and execution c)
     Web development d) Mobile app design <b>Answer: b) Advanced GPU
     hierarchies and execution</b></li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>GPU Programming: Involves CUDA or similar frameworks for
     parallel computing on NVIDIA GPUs.</li>
 <li class=MsoNormal>Lecture Structure: Builds on prior lectures; expect recaps
     on execution models.</li>
 <li class=MsoNormal>Key Term: GPU vs. CPU  GPUs have thousands of cores for
     parallelism.</li>
 <li class=MsoNormal>Remember: GPUs are ideal for data-parallel problems like
     image processing.</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>If a GPU has 1024 cores and a task can be parallelized
     across all cores with each taking 2 ms, calculate total time for
     sequential vs. parallel execution (assume sequential on CPU takes 1024 * 2
     ms). <b>Solution:</b> Sequential: 2048 ms. Parallel: 2 ms (ideal case,
     ignoring overhead).</li>
 <li class=MsoNormal>A simple GPU program launches 100 threads. If each thread
     processes 5 data points, how many data points are processed in total? <b>Solution:</b>
     100 * 5 = 500 data points.</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Video Game Rendering:</b> NVIDIA's use of GPU
     programming in games like Fortnite, where thousands of threads handle
     pixel shading in parallel, reducing frame lag.</li>
 <li class=MsoNormal><b>Scientific Simulations:</b> In weather forecasting,
     GPUs simulate climate models faster than CPUs, as seen in NOAA's use of
     CUDA for parallel computations on large datasets.</li>
</ol>

<p class=MsoNormal><b>Slide 2: Program Execution: Recap</b></p>

<p class=MsoNormal><b>Easy Explanation of Concepts</b></p>

<p class=MsoNormal>This slide recaps how GPU programs execute. The CPU (host)
manages the overall program, copying data to GPU memory, launching kernels (GPU
functions), synchronizing, and copying results back. Hardware includes CUDA
Device with Streaming Multiprocessors (SMs). Software hierarchy: Thread Blocks
divided into Warps (groups of 32 threads) and individual Threads. Execution
flow: Copy to GPU, launch kernel, sync, copy back.</p>

<p class=MsoNormal><b>Related MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>In GPU execution, what is the role of the CPU? a) Executes
     all computations b) Manages data transfer and kernel launches c) Only
     handles graphics d) Synchronizes threads internally <b>Answer: b) Manages
     data transfer and kernel launches</b></li>
 <li class=MsoNormal>What is a Warp in GPU terminology? a) A single thread b) A
     group of 32 threads executed together c) The entire grid d) Data memory <b>Answer:
     b) A group of 32 threads executed together</b></li>
 <li class=MsoNormal>The sequence in the recap includes: a) Launch kernel
     before copying data b) Copy to GPU, launch kernel, sync, copy from GPU c)
     Only kernel launch d) Deallocate before sync <b>Answer: b) Copy to GPU,
     launch kernel, sync, copy from GPU</b></li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Host (CPU) vs. Device (GPU): Host controls, Device
     computes in parallel.</li>
 <li class=MsoNormal>Hierarchy: Grid &gt; Block &gt; Warp (32 threads) &gt;
     Thread.</li>
 <li class=MsoNormal>Key Steps: Data allocation/transfer, kernel launch with
     &lt;&lt;&lt;&gt;&gt;&gt;, synchronization (cudaDeviceSynchronize()).</li>
 <li class=MsoNormal>Time Flow: Asynchronous launches possible, but sync
     ensures completion.</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>If copying data to GPU takes 10 ms, kernel execution 50
     ms, sync 5 ms, and copy back 10 ms, what is the total execution time? <b>Solution:</b>
     10 + 50 + 5 + 10 = 75 ms.</li>
 <li class=MsoNormal>A warp has 32 threads. If 4 warps are in a block, how many
     threads per block? <b>Solution:</b> 4 * 32 = 128 threads.</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Machine Learning Training:</b> In TensorFlow with CUDA,
     data is copied to GPU, kernels train neural networks in parallel, synced,
     and results copied back  used in Google's AlphaGo.</li>
 <li class=MsoNormal><b>Medical Imaging:</b> GPU acceleration in MRI scans,
     where host prepares image data, GPU processes filters in parallel,
     reducing scan analysis time in hospitals like Mayo Clinic.</li>
</ol>

<p class=MsoNormal><b>Slide 3: Hierarchy of Kernel, Block, Warp and Thread</b></p>

<p class=MsoNormal><b>Easy Explanation of Concepts</b></p>

<p class=MsoNormal>The host launches kernels using &lt;&lt;&lt;blocks,
threads_per_block&gt;&gt;&gt;. Example: Kernel1&lt;&lt;&lt;100, 256&gt;&gt;&gt;
launches 100 blocks, each with 256 threads (total 25,600). Warps are subgroups
within blocks (usually 32 threads). Kernels can run in streams for concurrency.
The slide shows visual hierarchy: Kernels contain blocks, blocks contain warps,
warps contain threads.</p>

<p class=MsoNormal><b>Related MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What does &lt;&lt;&lt;100, 256&gt;&gt;&gt; specify? a) 100
     threads, 256 blocks b) 100 blocks, 256 threads per block c) Total 356
     threads d) Stream ID <b>Answer: b) 100 blocks, 256 threads per block</b></li>
 <li class=MsoNormal>Total threads in Kernel2&lt;&lt;&lt;50, 1024&gt;&gt;&gt;:
     a) 50 b) 1024 c) 51,200 d) 1074 <b>Answer: c) 51,200</b></li>
 <li class=MsoNormal>A warp typically consists of: a) 1 thread b) 32 threads c)
     100 threads d) Variable size <b>Answer: b) 32 threads</b></li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Kernel Launch Syntax: &lt;&lt;&lt;num_blocks,
     threads_per_block&gt;&gt;&gt;</li>
 <li class=MsoNormal>Total Threads = num_blocks * threads_per_block</li>
 <li class=MsoNormal>Hierarchy: Kernel &gt; Block &gt; Warp &gt; Thread</li>
 <li class=MsoNormal>Streams: Allow overlapping kernel executions over time.</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>For &lt;&lt;&lt;200, 512&gt;&gt;&gt;, calculate total
     threads. <b>Solution:</b> 200 * 512 = 102,400 threads.</li>
 <li class=MsoNormal>If a block has 256 threads and warps are 32 threads each,
     how many warps per block? <b>Solution:</b> 256 / 32 = 8 warps.</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Cryptocurrency Mining:</b> Ethereum mining uses kernel
     hierarchies with thousands of threads per block for parallel hash
     computations on GPUs.</li>
 <li class=MsoNormal><b>Autonomous Vehicles:</b> NVIDIA Drive platform launches
     kernels with block/warp structures for real-time image processing from
     cameras.</li>
</ol>

<p class=MsoNormal><b>Slide 4: Organization of Thread Blocks</b></p>

<p class=MsoNormal><b>Easy Explanation of Concepts</b></p>

<p class=MsoNormal>Thread blocks can be organized in 1D, 2D, or 3D arrays for
easier mapping to data (e.g., images). Blocks in a grid execute independently 
no communication between them. Kernel launch specifies blocks and
threads/block, defining total CUDA threads. Limit on threads/block due to
register allocation (limited hardware resources).</p>

<p class=MsoNormal><b>Related MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Thread blocks can be organized as: a) Only 1D b) 1D, 2D,
     or 3D arrays c) 4D arrays d) Unstructured <b>Answer: b) 1D, 2D, or 3D
     arrays</b></li>
 <li class=MsoNormal>Communication between blocks in a grid is: a) Always
     possible b) Not possible c) Only via host d) Via warps <b>Answer: b) Not
     possible</b></li>
 <li class=MsoNormal>The thread/block limit is due to: a) Memory size b)
     Register allocation c) CPU speed d) Network bandwidth <b>Answer: b)
     Register allocation</b></li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Dimensions: Use for data mapping (e.g., 2D for matrices).</li>
 <li class=MsoNormal>Independence: Blocks must not depend on each other.</li>
 <li class=MsoNormal>Total Threads: Blocks * Threads/Block.</li>
 <li class=MsoNormal>Limitation: Hardware registers cap threads/block (e.g.,
     max 1024 on some GPUs).</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>In a 2D grid of 10x10 blocks, each with 16x16 threads,
     total threads? <b>Solution:</b> 10<i>10 * 16</i>16 = 100 * 256 = 25,600
     threads.</li>
 <li class=MsoNormal>If registers limit to 65,536 per block and each thread
     uses 32, max threads/block? <b>Solution:</b> 65,536 / 32 = 2,048 threads.</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Image Processing:</b> In Photoshop's GPU filters, 2D
     thread blocks map to pixel grids, processing independently for speed.</li>
 <li class=MsoNormal><b>Finite Element Analysis:</b> Engineering software like
     ANSYS uses 3D blocks for simulating material stress, with independent
     block execution.</li>
</ol>

<p class=MsoNormal><b>Slide 5: Grids Blocks of Threads</b></p>

<p class=MsoNormal><b>Easy Explanation of Concepts</b></p>

<p class=MsoNormal>This visual slide shows how kernels launch grids
(collections of blocks). Each grid has blocks arranged in dimensions, with
threads inside. Examples include 1D/2D grids. Host launches kernels to device,
where grids execute. Block indices like (0,0), threads like (1.0, 1.1).</p>

<p class=MsoNormal><b>Related MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>A grid is a collection of: a) Threads b) Blocks c) Warps
     d) Kernels <b>Answer: b) Blocks</b></li>
 <li class=MsoNormal>In the example, block (1,0) contains threads like: a)
     (0,0) to (3,3) b) Only (0,0) c) Random d) None <b>Answer: a) (0,0) to
     (3,3)</b> (assuming 4x4 from visual)</li>
 <li class=MsoNormal>Execution moves from host to: a) CPU b) Device (GPU) c)
     Memory d) Disk <b>Answer: b) Device (GPU)</b></li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Grid: Array of blocks (1D/2D/3D).</li>
 <li class=MsoNormal>Block: Array of threads.</li>
 <li class=MsoNormal>Indexing: blockIdx, threadIdx for positioning.</li>
 <li class=MsoNormal>Variables: gridDim, blockDim for sizes.</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Grid of 5 blocks (1D), each with 100 threads: Total
     threads? <b>Solution:</b> 5 * 100 = 500.</li>
 <li class=MsoNormal>In 2D grid (3x4 blocks), each block 2x2 threads: Total
     threads? <b>Solution:</b> 3<i>4 * 2</i>2 = 12 * 4 = 48.</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Video Encoding:</b> FFmpeg with CUDA uses grids for
     parallel frame processing in blocks.</li>
 <li class=MsoNormal><b>Genomics:</b> Aligning DNA sequences on GPUs with
     grid-block structures for massive parallelism in tools like CUDA-Align.</li>
</ol>

<p class=MsoNormal><b>Slide 6: Grids of Blocks of Threads: Dimension Limits</b></p>

<p class=MsoNormal><b>Easy Explanation of Concepts</b></p>

<p class=MsoNormal>Hardware: CUDA Device with SMs. Software: Thread blocks with
warps/threads. Limits: Grid max x/y 65,535 (1D/2D). Block threads max 512 (old
limit, now 1024), x/y 512, z 64 (3D).</p>

<p class=MsoNormal><b>Related MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Max grid dimension in x for 1D/2D: a) 512 b) 65,535 c) 64
     d) Unlimited <b>Answer: b) 65,535</b></li>
 <li class=MsoNormal>Max threads per block: a) 512 b) 1024 c) 65,535 d) 64 <b>Answer:
     a) 512</b> (as per slide, though modern is 1024)</li>
 <li class=MsoNormal>Max z in block 3D: a) 512 b) 64 c) 65,535 d) Unlimited <b>Answer:
     b) 64</b></li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Grid Limits: x/y up to 65,535.</li>
 <li class=MsoNormal>Block Limits: Total 512 threads, x/y 512, z 64.</li>
 <li class=MsoNormal>Depends on GPU architecture (e.g., Fermi vs. Kepler).</li>
 <li class=MsoNormal>Exceed limits: Runtime error.</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Max total threads in grid with max x (65,535 blocks), 512
     threads/block? <b>Solution:</b> 65,535 * 512 &#8776; 33.5 million threads.</li>
 <li class=MsoNormal>For 3D block max (512x512x64), but total &lt;=512: Valid? <b>Solution:</b>
     No, 512<i>512</i>64 &gt;&gt; 512; adjust to fit total limit.</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Deep Learning:</b> In PyTorch, grid limits affect batch
     sizes in training large models like GPT, requiring optimization.</li>
 <li class=MsoNormal><b>Oil Exploration:</b> Seismic data processing on GPUs
     hits dimension limits, as in Schlumberger's software for 3D modeling.</li>
</ol>

<p class=MsoNormal><b>Slide 7: Programming Basics: Example</b></p>

<p class=MsoNormal><b>Easy Explanation of Concepts</b></p>

<p class=MsoNormal>dim3 is a struct for 3D dimensions (x,y,z). Examples: dim3
threads(256); // 1D, y=z=1. dim3 blocks(100,100); // 2D, z=1. dim3
anotherOne(10,54,32); // 3D. Used for grid/block sizes in launches. Table shows
built-ins: threadIdx, blockIdx, blockDim, gridDim.</p>

<p class=MsoNormal><b>Related MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>dim3 threads(256) sets: a) x=256, y=1, z=1 b) x=1, y=256,
     z=1 c) All 256 d) Error <b>Answer: a) x=256, y=1, z=1</b></li>
 <li class=MsoNormal>blockIdx.x refers to: a) Thread index b) Block index in x
     c) Grid size d) Warp ID <b>Answer: b) Block index in x</b></li>
 <li class=MsoNormal>For dim3 blocks(10,54,32), gridDim.z = ? a) 10 b) 54 c) 32
     d) 1 <b>Answer: c) 32</b></li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>dim3: Vector for dimensions, defaults unspecified to 1.</li>
 <li class=MsoNormal>Built-ins: threadIdx (local), blockIdx (global), *Dim for
     sizes.</li>
 <li class=MsoNormal>Use in kernels: To compute global thread ID.</li>
 <li class=MsoNormal>Zero-based indexing.</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>dim3 blocks(5,3); gridDim.x * gridDim.y = ? <b>Solution:</b>
     5 * 3 = 15 (total blocks).</li>
 <li class=MsoNormal>dim3 threads(4,4,4); blockDim.x + blockDim.y + blockDim.z
     = ? <b>Solution:</b> 4+4+4=12.</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Matrix Multiplication:</b> CUDA examples use dim3 for
     2D blocks to map to matrix rows/columns.</li>
 <li class=MsoNormal><b>3D Rendering:</b> In Blender's Cycles engine, 3D dim3
     for voxel processing in volumetric effects.</li>
</ol>

<p class=MsoNormal><b>Slide 8: Programming Basics-Example</b></p>

<p class=MsoNormal><b>Easy Explanation of Concepts</b></p>

<p class=MsoNormal>Grid example: Size (5,4,1), blocks 5x4. Each block (5,5,1)
threads. Indices like blockIdx.x for positioning. During execution, threads map
to problem randomly; order undefined. Completed threads/blocks shown green.
Emphasizes non-deterministic execution.</p>

<p class=MsoNormal><b>Related MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>In the grid, total blocks: a) 5 b) 4 c) 20 d) 1 <b>Answer:
     c) 20</b> (5x4)</li>
 <li class=MsoNormal>Thread execution order is: a) Strictly sequential b)
     Undefined/random c) By block ID d) By warp <b>Answer: b) Undefined/random</b></li>
 <li class=MsoNormal>blockDim.y in example: a) 5 b) 4 c) 1 d) Variable <b>Answer:
     a) 5</b> (from visual)</li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Grid/Block Sizes: Use dim3 to define.</li>
 <li class=MsoNormal>Mapping: Threads to data is programmer's responsibility.</li>
 <li class=MsoNormal>Undefined Order: Don't rely on execution sequence; use
     syncs.</li>
 <li class=MsoNormal>Visual: Indices zero-based, e.g., (0,0) to (4,3) for grid.</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Grid (6,4,1), blocks each (3,2,1): Total threads? <b>Solution:</b>
     6<i>4</i>1 * 3<i>2</i>1 = 24 * 6 = 144.</li>
 <li class=MsoNormal>Thread at (2,1) in block (3,2): Global x = blockIdx.x *
     blockDim.x + threadIdx.x = ? <b>Solution:</b> Assume blockDim.x=5: 3*5 + 2
     = 17.</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Particle Simulation:</b> In physics engines like PhysX,
     random thread completion handles particle collisions independently.</li>
 <li class=MsoNormal><b>Sorting Algorithms:</b> CUDA radix sort uses block
     mapping, tolerating undefined order with barriers.</li>
</ol>

<p class=MsoNormal><b>Slide 9: Programming Basics-Example</b></p>

<p class=MsoNormal><b>Easy Explanation of Concepts</b></p>

<p class=MsoNormal>20 blocks in grid, each 25 threads (500 total). To find
thread index: e.g., 343 = 25*13 + 18. 17th thread in 13th block is 343. Maps to
coordinates like (3,2,0) for block, (2,3,0) for thread. Uses blockIdx,
threadIdx.</p>

<p class=MsoNormal><b>Related MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Total threads in 20 blocks of 25: a) 500 b) 45 c) 20 d) 25
     <b>Answer: a) 500</b></li>
 <li class=MsoNormal>Formula for global ID (1D): a) threadIdx.x b) blockIdx.x *
     blockDim.x + threadIdx.x c) gridDim.x d) Warp size <b>Answer: b)
     blockIdx.x * blockDim.x + threadIdx.x</b></li>
 <li class=MsoNormal>For thread 343: Block? a) 13 b) 18 c) 25 d) 343 <b>Answer:
     a) 13</b></li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Global Indexing: blockIdx * blockDim + threadIdx (for 1D).</li>
 <li class=MsoNormal>Multi-D: Extend to .x, .y, .z.</li>
 <li class=MsoNormal>0-Indexing: Starts from 0.</li>
 <li class=MsoNormal>Use: For array access, e.g., data[globalID] = computation.</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Block size 32, thread 100: Which block? <b>Solution:</b>
     100 / 32 = 3 (block 3), local 100 % 32 = 4.</li>
 <li class=MsoNormal>For 2D: blockIdx (2,1), blockDim (4,3), threadIdx (1,2):
     Global y = ? <b>Solution:</b> 1*3 + 2 = 5.</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Vector Addition:</b> Classic CUDA example uses global
     ID for adding array elements in parallel.</li>
 <li class=MsoNormal><b>Convolution in CNNs:</b> Threads map to image pixels
     via indices for filter application in frameworks like cuDNN.</li>
</ol>

<p class=MsoNormal><b>Slide 10: Sequence of Steps for GPU Programming</b></p>

<p class=MsoNormal><b>Easy Explanation of Concepts</b></p>

<p class=MsoNormal>Standard workflow: 1. Alloc CPU data. 2. Init on CPU. 3.
Alloc GPU data (cudaMalloc). 4. Copy CPU to GPU (cudaMemcpy). 5. Define config
(dim3). 6. Run kernel &lt;&lt;&lt;&gt;&gt;&gt;. 7. CPU syncs
(cudaDeviceSynchronize). 8. Copy GPU to CPU. 9. Free memory (cudaFree, free).</p>

<p class=MsoNormal><b>Related MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>First step in GPU programming: a) Run kernel b) Allocate
     CPU data c) Copy to GPU d) Deallocate <b>Answer: b) Allocate CPU data</b></li>
 <li class=MsoNormal>Synchronization is done by: a) CPU b) GPU automatically c)
     Kernel d) Memory copy <b>Answer: a) CPU</b></li>
 <li class=MsoNormal>Last step: a) Init data b) De-allocate memory c) Launch
     kernel d) Define config <b>Answer: b) De-allocate memory</b></li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>APIs: cudaMalloc, cudaMemcpy (HostToDevice/DeviceToHost),
     cudaFree.</li>
 <li class=MsoNormal>Sync: Ensures kernel finishes before copy back.</li>
 <li class=MsoNormal>Error Handling: Check cudaGetLastError().</li>
 <li class=MsoNormal>Time Flow: Visual shows overlapping potential with
     streams.</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>If alloc takes 1 ms, init 2 ms, copy to 3 ms, kernel 10
     ms, sync 1 ms, copy back 3 ms, free 1 ms: Total time? <b>Solution:</b>
     1+2+3+10+1+3+1 = 21 ms.</li>
 <li class=MsoNormal>Data size 1000 floats (4 bytes each): Memory allocated? <b>Solution:</b>
     1000 * 4 = 4000 bytes.</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Monte Carlo Simulations:</b> In finance, follow steps
     for parallel random number generation on GPUs.</li>
 <li class=MsoNormal><b>Astrophysics:</b> Simulating galaxy formations, with
     data transfers for large datasets in codes like GADGET.</li>
</ol>

<p class=MsoNormal><b>Slide 11: Hello World! with Device Code</b></p>

<p class=MsoNormal><b>Easy Explanation of Concepts</b></p>

<p class=MsoNormal>Simple code: <b>global</b> void mykernel() {} // Device
function. main: mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(); printf(&quot;Hello
World!&quot;); Two new elements: <b>global</b> for GPU functions,
&lt;&lt;&lt;&gt;&gt;&gt; for launch.</p>

<p class=MsoNormal><b>Related MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>global</b> means function runs on: a) CPU b) GPU c)
     Both d) Disk <b>Answer: b) GPU</b></li>
 <li class=MsoNormal>&lt;&lt;&lt;1,1&gt;&gt;&gt; launches: a) 1 block, 1 thread
     b) 1 thread, 1 block c) 2 blocks d) Infinite <b>Answer: a) 1 block, 1
     thread</b></li>
 <li class=MsoNormal>The kernel does: a) Print Hello b) Nothing c) Error d)
     Loop <b>Answer: b) Nothing</b></li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>global</b>: Kernel qualifier, callable from host.</li>
 <li class=MsoNormal>Launch: &lt;&lt;&lt;gridsize, blocksize&gt;&gt;&gt; (here
     minimal).</li>
 <li class=MsoNormal>nvcc: Compiles .cu files.</li>
 <li class=MsoNormal>Output: From host printf, kernel empty.</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>If launched &lt;&lt;&lt;2,2&gt;&gt;&gt;, total threads? <b>Solution:</b>
     2*2=4.</li>
 <li class=MsoNormal>Minimal launch: Blocks=1, Threads=1, total=1.</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Intro Tutorial:</b> NVIDIA's CUDA samples start with
     this for setup verification.</li>
 <li class=MsoNormal><b>Embedded Systems:</b> In Jetson boards, simple kernels
     test GPU integration in robotics.</li>
</ol>

<p class=MsoNormal><b>Slide 12: Hello World! with Device Code</b></p>

<p class=MsoNormal><b>Easy Explanation of Concepts</b></p>

<p class=MsoNormal><b>global</b>: Function runs on device, called from host.
nvcc splits code: Device by NVIDIA compiler, host by gcc/cl.exe. Separates
compilation for heterogeneous programming.</p>

<p class=MsoNormal><b>Related MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>global</b> functions are processed by: a) Standard
     compiler b) NVIDIA compiler c) Both d) None <b>Answer: b) NVIDIA compiler</b></li>
 <li class=MsoNormal>Host functions like main are compiled by: a) nvcc b)
     gcc/cl.exe c) Device only d) Linker <b>Answer: b) gcc/cl.exe</b></li>
 <li class=MsoNormal><b>global</b> indicates: a) Host execution b) Device
     execution c) Sync d) Memory alloc <b>Answer: b) Device execution</b></li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Qualifiers: <b>global</b> (kernel), <b>device</b>
     (device-only), <b>host</b> (host-only).</li>
 <li class=MsoNormal>Compilation: nvcc handles separation.</li>
 <li class=MsoNormal>Calling: Kernels from host only.</li>
 <li class=MsoNormal>2013 NVIDIA: Older, but core concepts same.</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>If 3 <b>global</b> functions, how many compiled by NVIDIA?
     <b>Solution:</b> 3.</li>
 <li class=MsoNormal>Host code lines: In example, main has 3 lines.</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Compiler Tools:</b> In Visual Studio with Nsight,
     separates host/device for debugging.</li>
 <li class=MsoNormal><b>High-Performance Computing:</b> In supercomputers like
     Summit, code separation enables hybrid CPU-GPU workloads.</li>
</ol>

<p class=MsoNormal><b>Slide 13: Hello World! with Device Code</b></p>

<p class=MsoNormal><b>Easy Explanation of Concepts</b></p>

<p class=MsoNormal>mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(); Triple chevrons: Host
call to device code, aka kernel launch. Parameters (1,1): 1 block, 1 thread.
Minimal to run GPU function.</p>

<p class=MsoNormal><b>Related MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>&lt;&lt;&lt; &gt;&gt;&gt; marks: a) A kernel launch b)
     Memory copy c) Sync d) Allocation <b>Answer: a) A kernel launch</b></li>
 <li class=MsoNormal>Parameters in &lt;&lt;&lt;a,b&gt;&gt;&gt;: a) a=threads,
     b=blocks b) a=blocks, b=threads/block c) a=warps, b=streams d) Random <b>Answer:
     b) a=blocks, b=threads/block</b></li>
 <li class=MsoNormal>This is all needed to: a) Run on GPU b) Print c) Allocate
     d) Dealloc <b>Answer: a) Run on GPU</b></li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Kernel Launch: From host, async by default.</li>
 <li class=MsoNormal>Parameters: Can be dim3 for multi-D.</li>
 <li class=MsoNormal>Simple: Even empty kernel launches GPU.</li>
 <li class=MsoNormal>Extend: To parallelism with larger numbers.</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>&lt;&lt;&lt;3,4&gt;&gt;&gt;: Total launches? <b>Solution:</b>
     3 blocks * 4 threads = 12.</li>
 <li class=MsoNormal>For single thread: &lt;&lt;&lt;1,1&gt;&gt;&gt; = 1.</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Benchmarking:</b> Use minimal launches to measure GPU
     overhead in tools like CUDA Profiler.</li>
 <li class=MsoNormal><b>IoT Devices:</b> Simple launches in edge computing for
     quick GPU tasks.</li>
</ol>

<p class=MsoNormal><b>Slide 14: Hello World! with Device Code</b></p>

<p class=MsoNormal><b>Easy Explanation of Concepts</b></p>

<p class=MsoNormal>Code compiles with nvcc hello.cu, runs a.out, outputs
&quot;Hello World!&quot; from host. Kernel empty, so no GPU output, but
launches successfully.</p>

<p class=MsoNormal><b>Related MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Output of the program: a) Nothing b) Hello World! c) Error
     d) GPU message <b>Answer: b) Hello World!</b></li>
 <li class=MsoNormal>nvcc is used for: a) Compiling .cu files b) Running
     executables c) Debugging d) Linking only <b>Answer: a) Compiling .cu files</b></li>
 <li class=MsoNormal>mykernel() effect: a) Prints b) Does nothing c) Crashes d)
     Loops <b>Answer: b) Does nothing</b></li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Compilation: nvcc for CUDA C++.</li>
 <li class=MsoNormal>Run: Standard executable.</li>
 <li class=MsoNormal>Test: Verifies setup; kernel runs but empty.</li>
 <li class=MsoNormal>2013: Old, but basics unchanged.</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>If printf called 5 times in host: Outputs? <b>Solution:</b>
     5 lines.</li>
 <li class=MsoNormal>Kernel launches: 1 in example.</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Setup Verification:</b> In cloud GPUs like AWS EC2, run
     this to confirm CUDA installation.</li>
 <li class=MsoNormal><b>Educational Tools:</b> Used in online courses like
     Coursera's Parallel Programming to introduce CUDA.</li>
</ol>

<p class=MsoNormal><b>Slide 15: Parallel Programming in CUDA C/C++</b></p>

<p class=MsoNormal><b>Easy Explanation of Concepts</b></p>

<p class=MsoNormal>GPU computing focuses on massive parallelism. Start simple:
Add two integers, build to vector addition. Emphasizes scaling to many threads
for real benefits.</p>

<p class=MsoNormal><b>Related MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>CUDA is about: a) Sequential code b) Massive parallelism
     c) Single thread d) I/O <b>Answer: b) Massive parallelism</b></li>
 <li class=MsoNormal>Example builds to: a) Vector addition b) Matrix multiply
     c) Sorting d) Searching <b>Answer: a) Vector addition</b></li>
 <li class=MsoNormal>Need more interesting example because: a) Hello World is
     parallel b) It's not parallel enough c) Errors d) Slow <b>Answer: b) It's
     not parallel enough</b></li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Parallelism: Key to GPU speedup.</li>
 <li class=MsoNormal>Start Small: Integers to vectors.</li>
 <li class=MsoNormal>CUDA C/C++: Extensions for parallelism.</li>
 <li class=MsoNormal>Applications: Data-intensive tasks.</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Add two vectors of size 1000: Threads needed? <b>Solution:</b>
     At least 1000 (one per element).</li>
 <li class=MsoNormal>Speedup: CPU 1000 ms, GPU 10 ms: Factor? <b>Solution:</b>
     1000/10 = 100x.</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Linear Algebra:</b> cuBLAS library for vector ops in
     scientific computing.</li>
 <li class=MsoNormal><b>AI Acceleration:</b> In Stable Diffusion, parallel
     vector additions for image generation on GPUs.</li>
</ol>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<div style='border:none;border-bottom:double windowtext 2.25pt;padding:0in 0in 1.0pt 0in'>

<p class=MsoNormal style='border:none;padding:0in'>&nbsp;</p>

</div>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><b>GPU Programming Lecture 03: Comprehensive Study Guide</b></p>

<p class=MsoNormal><b>Slide 1: Program Execution: Recap</b></p>

<p class=MsoNormal><b>Easy Explanation</b></p>

<p class=MsoNormal>This slide serves as an introduction to GPU programming
concepts, particularly focusing on how programs are executed on GPUs. In GPU
programming, we need to understand how tasks are distributed across the massive
parallel architecture of GPUs.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is the primary advantage of GPU programming over CPU
     programming? a) Higher clock speeds b) Lower power consumption c) Massive
     parallelism d) Better sequential processing</li>
 <li class=MsoNormal>GPU programming is particularly suitable for: a)
     Sequential tasks b) Tasks with high data parallelism c) Small, simple
     calculations d) Operating system functions</li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>GPU programming leverages the parallel processing
     capabilities of graphics processing units</li>
 <li class=MsoNormal>GPUs excel at handling many simple computations
     simultaneously</li>
 <li class=MsoNormal>The execution model differs significantly from traditional
     CPU programming</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>If a GPU has 2048 cores and can execute 32 threads per
     core, how many threads can run simultaneously? Solution: 2048 cores  32
     threads/core = 65,536 threads</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Weather Simulation</b>: Meteorological agencies use GPU
     programming to run complex weather models that require parallel processing
     of large datasets, significantly reducing computation time from days to
     hours.</li>
</ol>

<p class=MsoNormal><b>Slide 2: Hierarchy of kernel, block, warp and thread</b></p>

<p class=MsoNormal><b>Easy Explanation</b></p>

<p class=MsoNormal>In CUDA programming, we organize execution units in a
hierarchy:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Kernel</b>: The function that runs on the GPU</li>
 <li class=MsoNormal><b>Block</b>: A group of threads that can cooperate and
     share memory</li>
 <li class=MsoNormal><b>Warp</b>: A group of 32 threads that execute together
     (NVIDIA-specific)</li>
 <li class=MsoNormal><b>Thread</b>: The smallest execution unit</li>
</ul>

<p class=MsoNormal>The triple chevron syntax <b>&lt;&lt;&lt;blocks,
threads&gt;&gt;&gt;</b> specifies how many blocks and threads per block to
launch.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What does the notation <b>Kernel1&lt;&lt;&lt;100,
     256&gt;&gt;&gt;()</b> mean in CUDA? a) 100 threads in 256 blocks b) 256
     threads in 100 blocks c) 100 blocks of 256 threads each d) 256 blocks of
     100 threads each</li>
 <li class=MsoNormal>If <b>Kernel2&lt;&lt;&lt;50, 1024&gt;&gt;&gt;()</b> is
     launched, how many total threads are created? a) 50 b) 1024 c) 1074 d)
     51,200</li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Kernel launches are specified with the number of blocks
     and threads per block</li>
 <li class=MsoNormal>Total threads = number of blocks  threads per block</li>
 <li class=MsoNormal>Threads within a block can cooperate and share memory</li>
 <li class=MsoNormal>Warps are groups of 32 threads that execute simultaneously
     on NVIDIA GPUs</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Calculate the total number of threads launched by <b>Kernel&lt;&lt;&lt;256,
     128&gt;&gt;&gt;()</b>. Solution: 256 blocks  128 threads/block = 32,768
     threads</li>
 <li class=MsoNormal>If a GPU can handle 2048 threads simultaneously, how many
     kernel launches of <b>&lt;&lt;&lt;64, 32&gt;&gt;&gt;()</b> would be needed
     to utilize all threads? Solution: Each launch creates 64  32 = 2048
     threads, so one launch would utilize all threads.</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Image Processing</b>: A company developing image
     filters uses a kernel with blocks of 1616 threads (256 threads per block)
     to process different parts of an image in parallel, significantly speeding
     up the filtering process.</li>
</ol>

<p class=MsoNormal><b>Slide 3: Organization of thread blocks</b></p>

<p class=MsoNormal><b>Easy Explanation</b></p>

<p class=MsoNormal>Thread blocks in CUDA can be organized as 1D, 2D, or 3D
arrays to match the structure of the problem being solved. For example:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>1D: Processing a simple array</li>
 <li class=MsoNormal>2D: Processing an image</li>
 <li class=MsoNormal>3D: Processing a volume (like medical scans)</li>
</ul>

<p class=MsoNormal>Important constraints:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Blocks in a grid execute independently (no direct
     communication between blocks)</li>
 <li class=MsoNormal>The number of threads per block is limited by hardware
     resources (especially registers)</li>
</ul>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Why is there a limitation on the number of threads in a
     block? a) To prevent excessive memory usage b) Because the number of
     registers that can be allocated across all threads is limited c) To ensure
     blocks can execute independently d) Because GPUs can only handle a fixed
     number of threads</li>
 <li class=MsoNormal>Which of the following is true about communication between
     blocks in a grid? a) Blocks can communicate directly with each other b)
     Blocks must communicate through the CPU c) Blocks cannot communicate
     directly with each other d) Communication between blocks is handled
     automatically by CUDA</li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Thread blocks can be organized in 1D, 2D, or 3D arrays</li>
 <li class=MsoNormal>Blocks in a grid execute independently</li>
 <li class=MsoNormal>The number of threads per block is limited by hardware
     resources</li>
 <li class=MsoNormal>The choice of block organization should match the problem
     structure</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>If you have a 2D image of size 10241024 pixels and want
     to use 1616 thread blocks, how many blocks would you need? Solution:
     (1024/16)  (1024/16) = 64  64 = 4096 blocks</li>
 <li class=MsoNormal>If a GPU has a limit of 1024 threads per block and you
     need to process a 3D volume of 646464 data points using 888 thread
     blocks, will this configuration work? Solution: 888 = 512 threads per
     block, which is less than the limit of 1024, so this configuration will
     work.</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Medical Imaging</b>: A research team uses 3D thread
     blocks to process MRI scans. They organize their blocks as 888 threads
     to match the 3D nature of the data, allowing efficient processing of the
     volumetric data.</li>
</ol>

<p class=MsoNormal><b>Slide 4: Grids Blocks of Threads</b></p>

<p class=MsoNormal><b>Easy Explanation</b></p>

<p class=MsoNormal>This slide visually represents how CUDA organizes threads
into blocks and blocks into grids. A grid is the highest level of organization,
containing multiple blocks. Each block contains multiple threads. This
hierarchical structure allows for efficient parallel execution on the GPU.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>In the CUDA hierarchy, which of the following is the
     correct order from largest to smallest? a) Thread &#8594; Block &#8594;
     Grid b) Grid &#8594; Block &#8594; Thread c) Block &#8594; Grid &#8594;
     Thread d) Thread &#8594; Grid &#8594; Block</li>
 <li class=MsoNormal>What is the relationship between grids, blocks, and
     threads in CUDA? a) A grid contains threads, which are organized into
     blocks b) A block contains grids, which are organized into threads c) A
     grid contains blocks, which contain threads d) Threads contain blocks,
     which contain grids</li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>CUDA organizes threads hierarchically: threads &#8594;
     blocks &#8594; grids</li>
 <li class=MsoNormal>This organization allows for efficient parallel execution</li>
 <li class=MsoNormal>The structure helps map problems to the GPU architecture</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>If a grid has 32 blocks in the x-dimension and 64 blocks
     in the y-dimension, and each block has 16 threads in the x-dimension and 8
     threads in the y-dimension, how many total threads are in the grid?
     Solution: 32  64 blocks  16  8 threads/block = 262,144 threads</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Video Processing</b>: A video streaming service uses
     CUDA to process video frames. They organize their grid to match the video
     resolution, with each block handling a small region of the frame, allowing
     for efficient parallel processing of the entire frame.</li>
</ol>

<p class=MsoNormal><b>Slide 5: Grids of Blocks of Threads: Dimension Limits</b></p>

<p class=MsoNormal><b>Easy Explanation</b></p>

<p class=MsoNormal>CUDA imposes limits on the dimensions of grids and blocks:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Maximum dimensions for blocks (x, y, z): typically 1024,
     1024, 64</li>
 <li class=MsoNormal>Maximum dimensions for grids (x, y, z): typically 2^31-1,
     65535, 65535</li>
 <li class=MsoNormal>Maximum threads per block: typically 1024</li>
</ul>

<p class=MsoNormal>These limits vary by GPU compute capability.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is typically the maximum number of threads per block
     in modern CUDA GPUs? a) 256 b) 512 c) 1024 d) 2048</li>
 <li class=MsoNormal>Which dimension typically has the smallest limit for
     thread blocks? a) x-dimension b) y-dimension c) z-dimension d) All
     dimensions have the same limit</li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>CUDA imposes limits on grid and block dimensions</li>
 <li class=MsoNormal>These limits vary by GPU compute capability</li>
 <li class=MsoNormal>Maximum threads per block is typically 1024</li>
 <li class=MsoNormal>Maximum block dimensions are typically 1024102464</li>
 <li class=MsoNormal>Maximum grid dimensions are typically 2^31-16553565535</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>If you need to process a 3D array of size 204820482048
     using 888 thread blocks, how many blocks would you need in each
     dimension? Solution: 2048/8 = 256 blocks in each dimension, so you'd need
     256256256 blocks</li>
 <li class=MsoNormal>Is a configuration of 204811 threads per block valid on
     a GPU with a maximum of 1024 threads per block? Solution: No, because
     204811 = 2048 threads, which exceeds the limit of 1024 threads per
     block.</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Scientific Simulation</b>: Researchers simulating fluid
     dynamics needed to process a large 3D grid. They had to carefully design
     their block dimensions to stay within the limits of their GPU while
     maximizing parallelism.</li>
</ol>

<p class=MsoNormal><b>Slide 6: Programming Basics: Example</b></p>

<p class=MsoNormal><b>Easy Explanation</b></p>

<p class=MsoNormal>The <b>dim3</b> type in CUDA is used to specify dimensions
for grids and blocks. It's a structure with three integer components (x, y, z).
You can initialize just the dimensions you need, and the rest will default to
1.</p>

<p class=MsoNormal>Examples:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>dim3 threads(256)</b> creates a 1D configuration with
     256 threads</li>
 <li class=MsoNormal><b>dim3 blocks(100, 100)</b> creates a 2D configuration
     with 100100 blocks</li>
 <li class=MsoNormal><b>dim3 anotherOne(10, 54, 32)</b> creates a 3D
     configuration</li>
</ul>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is the value of the y and z components in <b>dim3
     threads(256)</b>? a) y=0, z=0 b) y=1, z=1 c) y=256, z=256 d) y=256, z=1</li>
 <li class=MsoNormal>How many blocks are created by <b>dim3 blocks(10, 20, 30)</b>?
     a) 10 b) 200 c) 600 d) 6000</li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>dim3</b> is a CUDA type for specifying 3D dimensions</li>
 <li class=MsoNormal>Unspecified dimensions default to 1</li>
 <li class=MsoNormal>Used for both grid and block dimensions in kernel launches</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>If you declare <b>dim3 blocks(4, 8, 2)</b> and <b>dim3
     threads(32, 16)</b>, how many total threads will be launched? Solution:
     482 blocks  32161 threads/block = 64 blocks  512 threads/block =
     32,768 threads</li>
 <li class=MsoNormal>If you need to process a 2D array of 1024512 elements
     using 1616 thread blocks, how would you declare the block and grid
     dimensions? Solution: <b>dim3 threads(16, 16)</b> and <b>dim3
     blocks(1024/16, 512/16)</b> which is <b>dim3 blocks(64, 32)</b></li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Game Development</b>: A game engine uses CUDA for
     physics calculations. They use <b>dim3</b> to organize their thread blocks
     to match the 3D nature of their game world, with each block handling a
     small region of the space.</li>
</ol>

<p class=MsoNormal><b>Slide 7: Programming Basics-Example</b></p>

<p class=MsoNormal><b>Easy Explanation</b></p>

<p class=MsoNormal>This slide continues the example of using <b>dim3</b> to
specify thread and block configurations. It likely shows how to use these
configurations in a kernel launch, demonstrating how to map the problem to the
GPU's parallel architecture.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>When using <b>dim3</b> to specify thread dimensions, which
     of the following is a valid declaration? a) <b>dim3 threads(1024, 1024,
     1024)</b> b) <b>dim3 threads(32, 32, 32)</b> c) <b>dim3 threads(2048)</b>
     d) <b>dim3 threads(512, 512, 512)</b></li>
 <li class=MsoNormal>In a kernel launch <b>myKernel&lt;&lt;&lt;grid,
     threads&gt;&gt;&gt;</b>, what does <b>grid</b> represent? a) The number of
     threads per block b) The dimensions of the grid of blocks c) The total
     number of threads d) The dimensions of each thread</li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>dim3</b> is used to specify both grid and block
     dimensions</li>
 <li class=MsoNormal>The configuration should match the problem structure</li>
 <li class=MsoNormal>Thread dimensions should not exceed hardware limits</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>If you have a 2D matrix of 20481024 elements and want to
     use 3216 thread blocks, how would you declare the grid and thread
     dimensions? Solution: <b>dim3 threads(32, 16)</b> and <b>dim3
     blocks(2048/32, 1024/16)</b> which is <b>dim3 blocks(64, 64)</b></li>
 <li class=MsoNormal>If you need to process a 3D volume of 512512256 elements
     using 888 thread blocks, how many blocks would you need in each
     dimension? Solution: 512/8 = 64 blocks in x and y, and 256/8 = 32 blocks
     in z, so <b>dim3 blocks(64, 64, 32)</b></li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Financial Modeling</b>: A financial firm uses CUDA for
     Monte Carlo simulations. They use <b>dim3</b> to organize their
     simulations in a 2D grid, where one dimension represents different
     simulation paths and the other represents different time steps.</li>
</ol>

<p class=MsoNormal><b>Slide 8: Programming Basics-Example</b></p>

<p class=MsoNormal><b>Easy Explanation</b></p>

<p class=MsoNormal>This slide illustrates that CUDA threads execute in an
undefined order. The green blocks in the diagram represent threads or blocks
that have completed execution, and their random arrangement highlights that
there's no guaranteed execution order. This is important because programmers
should not make assumptions about the order in which threads will complete.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What does the random completion of threads and blocks in
     CUDA indicate? a) There's a bug in the CUDA program b) The order of
     execution for threads is undefined c) Some threads are faster than others
     d) The GPU is malfunctioning</li>
 <li class=MsoNormal>Why is it important to understand that thread execution
     order is undefined in CUDA? a) To avoid race conditions b) To optimize
     performance c) To reduce memory usage d) To simplify debugging</li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>CUDA threads execute in an undefined order</li>
 <li class=MsoNormal>Programmers should not make assumptions about execution
     order</li>
 <li class=MsoNormal>This can lead to race conditions if not properly handled</li>
 <li class=MsoNormal>Synchronization mechanisms are needed when order matters</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>If you launch 1000 threads and need to ensure that all
     threads have completed before proceeding, what CUDA function would you
     use? Solution: <b>cudaDeviceSynchronize()</b> or <b>cudaThreadSynchronize()</b></li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Database Operations</b>: A company implementing
     parallel database queries had to carefully handle synchronization to
     ensure that all threads completed their operations before aggregating
     results, avoiding race conditions.</li>
</ol>

<p class=MsoNormal><b>Slide 9: Sequence of steps for GPU programming</b></p>

<p class=MsoNormal><b>Easy Explanation</b></p>

<p class=MsoNormal>This slide outlines the typical workflow for GPU
programming:</p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Allocate CPU memory for data</li>
 <li class=MsoNormal>Initialize data on the CPU</li>
 <li class=MsoNormal>Allocate GPU memory for the data</li>
 <li class=MsoNormal>Copy data from CPU to GPU</li>
 <li class=MsoNormal>Define the execution configuration (grid and block
     dimensions)</li>
 <li class=MsoNormal>Run the kernel on the GPU</li>
 <li class=MsoNormal>Synchronize to ensure the GPU has finished</li>
 <li class=MsoNormal>Copy results from GPU back to CPU</li>
 <li class=MsoNormal>Free GPU and CPU memory</li>
</ol>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Which step in GPU programming involves transferring data
     from the CPU to the GPU? a) Step 2 b) Step 3 c) Step 4 d) Step 5</li>
 <li class=MsoNormal>Why is synchronization needed after running a kernel? a)
     To ensure the GPU has finished before proceeding b) To improve performance
     c) To reduce memory usage d) To prevent race conditions</li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>GPU programming follows a specific sequence of steps</li>
 <li class=MsoNormal>Data must be explicitly transferred between CPU and GPU</li>
 <li class=MsoNormal>Synchronization is needed to ensure kernel completion</li>
 <li class=MsoNormal>Memory must be explicitly allocated and freed</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>If you have an array of 1 million floating-point numbers
     (4 bytes each), how much GPU memory would you need to allocate for this
     array? Solution: 1,000,000  4 bytes = 4,000,000 bytes = approximately 4
     MB</li>
 <li class=MsoNormal>If copying data between CPU and GPU takes 0.1 seconds per
     GB, how long would it take to copy 500 MB of data? Solution: 0.5 GB  0.1
     seconds/GB = 0.05 seconds</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Machine Learning</b>: A deep learning framework follows
     these steps when training neural networks on GPUs. Data is preprocessed on
     the CPU, transferred to the GPU, processed in parallel, and results are
     copied back for analysis.</li>
</ol>

<p class=MsoNormal><b>Slide 10-14: Hello World! with Device Code</b></p>

<p class=MsoNormal><b>Easy Explanation</b></p>

<p class=MsoNormal>These slides introduce a basic CUDA program:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>__global__</b> is a CUDA keyword that indicates a
     function runs on the GPU and is called from the CPU</li>
 <li class=MsoNormal>The kernel is launched using triple angle brackets <b>&lt;&lt;&lt;1,1&gt;&gt;&gt;</b></li>
 <li class=MsoNormal>The example shows a minimal kernel that does nothing</li>
 <li class=MsoNormal>The nvcc compiler separates host and device code</li>
</ul>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What does the <b>__global__</b> keyword indicate in CUDA?
     a) A function that runs on the CPU and is called from the GPU b) A
     function that runs on the GPU and is called from the CPU c) A function
     that runs on both CPU and GPU d) A global variable accessible to both CPU
     and GPU</li>
 <li class=MsoNormal>What does the syntax <b>&lt;&lt;&lt;1,1&gt;&gt;&gt;</b> in
     a kernel launch specify? a) 1 thread in 1 block b) 1 block of 1 thread c)
     Both a and b are correct d) Neither a nor b is correct</li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>__global__</b> functions run on the device (GPU) and
     are called from the host (CPU)</li>
 <li class=MsoNormal>Kernel launches use triple angle brackets to specify
     execution configuration</li>
 <li class=MsoNormal>The nvcc compiler separates host and device code</li>
 <li class=MsoNormal>A minimal CUDA program includes at least one kernel
     function and a main function</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>If you modify the Hello World program to launch <b>&lt;&lt;&lt;10,
     32&gt;&gt;&gt;</b>, how many total threads would be created? Solution: 10
     blocks  32 threads/block = 320 threads</li>
 <li class=MsoNormal>If you want to launch 1024 threads using a maximum of 256
     threads per block, how would you configure the kernel launch? Solution: <b>&lt;&lt;&lt;4,
     256&gt;&gt;&gt;</b> (4 blocks of 256 threads each)</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Educational Tools</b>: A university uses the Hello
     World example as the starting point for teaching CUDA programming,
     gradually adding complexity to demonstrate different concepts.</li>
</ol>

<p class=MsoNormal><b>Slide 15: Parallel Programming in CUDA C/C++</b></p>

<p class=MsoNormal><b>Easy Explanation</b></p>

<p class=MsoNormal>This slide introduces the concept of massive parallelism in
GPU computing. It mentions that GPU computing is about leveraging the ability
to perform many operations simultaneously. The slide suggests building up from
simple examples (like adding two integers) to more complex ones (like vector
addition).</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is the key advantage of GPU computing mentioned in
     this slide? a) Higher clock speeds b) Lower power consumption c) Massive
     parallelism d) Better sequential processing</li>
 <li class=MsoNormal>What example is suggested as a progression from adding two
     integers? a) Matrix multiplication b) Vector addition c) Image processing
     d) Machine learning</li>
</ol>

<p class=MsoNormal><b>Exam Notes</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>GPU computing is about massive parallelism</li>
 <li class=MsoNormal>Simple examples can be built up to more complex ones</li>
 <li class=MsoNormal>Vector addition is a common introductory example for
     parallel programming</li>
</ul>

<p class=MsoNormal><b>Numericals</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>If you want to add two vectors of size 1,000,000 elements
     using 256 threads per block, how many blocks would you need? Solution:
     1,000,000/256 = 3906.25, so you'd need 3907 blocks (with the last block
     partially utilized)</li>
 <li class=MsoNormal>If adding two vectors of size N takes T seconds on a CPU,
     and you achieve a speedup of S on a GPU, how long would it take on the
     GPU? Solution: T/S seconds</li>
</ol>

<p class=MsoNormal><b>Case Studies</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Scientific Computing</b>: A research group uses vector
     addition as a building block for more complex simulations. By optimizing
     this basic operation, they improve the performance of their entire
     simulation pipeline.</li>
</ol>

<div style='border:none;border-bottom:double windowtext 2.25pt;padding:0in 0in 1.0pt 0in'>

<p class=MsoNormal style='border:none;padding:0in'>&nbsp;</p>

</div>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Here is a slide-wise breakdown for GPU Programming Lecture
03, including easy explanations for concepts, related MCQs, exam notes,
numericals, and case studies for each major topic referenced in the lecture:</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 1: Program Execution Recap</b></p>

<p class=MsoNormal>Easy Explanation:<br>
This slide explains the workflow when running programs on a GPU: data is copied
from the CPU (host) to the GPU (device), the GPU kernel is launched to perform
computations, results are synchronized and then copied back to the CPU.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Related MCQs:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Where is data initially stored before launching a GPU
     kernel?<br>
     a) GPU<br>
     b) CPU<br>
     c) Disk<br>
     d) RAM<br>
     Answer:&nbsp;b) CPU</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>GPU workflow involves memory management between CPU and
     GPU and synchronized execution of kernels.<span style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<p class=MsoNormal>Numerical Example:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>If a calculation requires copying 1024KB to the GPU and
     back, with each transfer taking 2ms and kernel execution 5ms, total time
     =&nbsp;2+5+2=92+5+2=9ms.<span style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Real-world example: Accelerating image processing by
     offloading matrix operations from a server CPU to GPU, achieving much
     faster results due to GPU parallelism.<span style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 2: Hierarchy of Kernel, Block, Warp, and Thread</b></p>

<p class=MsoNormal>Easy Explanation:<br>
CUDA organizes computations hierarchically: kernels contain blocks, blocks
contain warps, and warps contain threads. Launch parameters (blocks, threads)
determine how many operations run in parallel.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Related MCQs:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>What does the triple chevron syntax (&lt;&lt;&lt;
     &gt;&gt;&gt;) in CUDA specify?<br>
     a) Number of registers<br>
     b) Number of blocks and threads per block<br>
     c) Size of memory<br>
     d) Kernel function<br>
     Answer:&nbsp;b) Number of blocks and threads per block</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Proper selection of blocks and threads is key for
     maximizing performance and resource usage in CUDA.<span style='font-family:
     "Arial",sans-serif'>&#8203;</span></li>
</ul>

<p class=MsoNormal>Numerical Example:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>kernel&lt;&lt;&lt;100, 256&gt;&gt;&gt; launches 100 blocks
     with 256 threads each, total 25,600 threads.<span style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Simulating weather patterns with thousands of threads,
     each calculating atmospheric data for one region, organized into blocks
     for different areas.<span style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 3: Organization of Thread Blocks</b></p>

<p class=MsoNormal>Easy Explanation:<br>
Blocks can be 1D, 2D, or 3D. Each block comprises independent threads with no
communication between blocks, making CUDA suitable for naturally parallel
tasks.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Related MCQs:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Why must blocks in a grid be able to execute
     independently?<br>
     a) To share registers<br>
     b) Communication between blocks is limited<br>
     c) To optimize memory<br>
     d) It's required by CUDA rules<br>
     Answer:&nbsp;b) Communication between blocks is limited</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Independent block execution simplifies mapping of parallel
     problems like image filtering or matrix multiplication.<span
     style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<p class=MsoNormal>Numerical Example:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Image with 1024x768 pixels processed with blocks of 256
     threads, how many blocks are needed?<br>
     Total threads =&nbsp;1024768=786,4321024768=786,432, blocks needed
     =&nbsp;786,432/256=3,072786,432/256=3,072.<span style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>2D block grids used for image convolution, each block
     processes a section of the image independently.<span style='font-family:
     "Arial",sans-serif'>&#8203;</span></li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 4: Execution Grids and Dimension Limits</b></p>

<p class=MsoNormal>Easy Explanation:<br>
CUDA limits: grid can be up to 65,535 blocks in x or y, block up to 512 threads
in x or y, 64 in z. The limits are set by hardware resources.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Related MCQs:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>What is the maximum number of threads per dimension in a
     CUDA block?<br>
     a) 1024<br>
     b) 512<br>
     c) 256<br>
     d) 64<br>
     Answer:&nbsp;b) 512<span style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Dimension limits are important for partitioning large data
     sets in CUDA.<span style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<p class=MsoNormal>Numerical Example:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>For a grid of&nbsp;60,000260,0002&nbsp;blocks, each
     block has 128 threads, total threads:&nbsp;60,0002128=15,360,00060,0002128=15,360,000.<span
     style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>3D medical imaging data (MRI), sliced into blocks for
     simultaneous processing.<span style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 5: Programming Basics: dim3 and Indexing</b></p>

<p class=MsoNormal>Easy Explanation:<br>
dim3&nbsp;in CUDA defines vectors for block/thread dimensions; threadIdx,
blockIdx, blockDim, gridDim are all used to calculate the position of a thread
in the grid.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Related MCQs:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>What does&nbsp;threadIdx.x&nbsp;represent?<br>
     a) Block index in x<br>
     b) Thread index within a block (x-direction)<br>
     c) Grid dimension in x<br>
     d) None of the above<br>
     Answer:&nbsp;b) Thread index within a block (x-direction)</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Indexing allows unique identification of each thread for
     processing specific data segments.<span style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<p class=MsoNormal>Numerical Example:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>For a block of&nbsp;551551&nbsp;threads, threadIdx of
     (3,2,0) refers to thread 3 in x, 2 in y, 0 in z.<span style='font-family:
     "Arial",sans-serif'>&#8203;</span></li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>In parallel matrix operations, thread indices determine
     which matrix element is being processed by which thread.<span
     style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 6: Sequence of Steps for GPU Programming</b></p>

<p class=MsoNormal>Easy Explanation:<br>
Outlines the typical steps: allocate/initialize data on CPU, allocate/copy to
GPU, configure execution, run kernel, synchronize, retrieve results,
de-allocate memory.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Related MCQs:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Which step occurs last in GPU programming?<br>
     a) Initialize data on CPU<br>
     b) Copy data to GPU<br>
     c) De-allocate memory<br>
     d) Run kernel<br>
     Answer:&nbsp;c) De-allocate memory</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Following correct sequence ensures efficient memory use
     and successful program execution.<span style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<p class=MsoNormal>Numerical Example:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>If memory allocation takes 1ms, data copy 2ms, kernel 3ms,
     reverse copy 2ms, total time is 8ms.<span style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Accelerating financial simulations using GPUs by
     structuring and executing the steps for massive parallel calculations.<span
     style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 7: Hello World! with Device Code</b></p>

<p class=MsoNormal>Easy Explanation:<br>
Shows a basic CUDA kernel launch using the&nbsp;__global__&nbsp;keyword;
function called with triple angle brackets runs on the GPU and can be processed
separately from host code.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Related MCQs:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>What does the&nbsp;__global__&nbsp;keyword indicate in
     CUDA?<br>
     a) Runs on device, called from device<br>
     b) Runs on host, called from device<br>
     c) Runs on device, called from host<br>
     d) None<br>
     Answer:&nbsp;c) Runs on device, called from host</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Separation between host and device code is fundamental in
     CUDA, using nvcc to compile appropriately.<span style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<p class=MsoNormal>Numerical Example:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>For mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;, only one thread
     is launched. Output: &quot;Hello World!&quot;.<span style='font-family:
     "Arial",sans-serif'>&#8203;</span></li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Starting point for parallel programming: a simple Hello
     World kernel ensures device setup before moving to complex applications.<span
     style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 8: Parallel Programming in CUDA CC</b></p>

<p class=MsoNormal>Easy Explanation:<br>
Emphasizes massive parallelism in GPUs, encourages starting with simple tasks
(like integer addition) and progressing to full vector operations.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Related MCQs:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>What is the main advantage of GPU computing?<br>
     a) Serial processing<br>
     b) Massive parallelism<br>
     c) Higher clock speeds<br>
     d) Cheaper hardware<br>
     Answer:&nbsp;b) Massive parallelism</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Begin with simple operations, then scale up to leverage
     parallel threads for performance.<span style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<p class=MsoNormal>Numerical Example:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Vector addition: 100,000 elements, 1000 threads, each
     thread handles 100 elements.<span style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Video game graphics engine using GPU parallelism for
     rendering multiple objects on screen simultaneously.<span
     style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal>Each slide's concepts are explained with simple language,
supported by exam notes, MCQs, short numericals, and practical case studies as
requested.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>slides are 15</p>

<p class=MsoNormal><a
href="https://www.coursera.org/learn/introduction-to-parallel-programming-with-cuda"
target="_blank"></a></p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><a href="https://nsmindia.in/gpu-programming-with-cuda/"
target="_blank"></a></p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><a
href="https://www.cs.cmu.edu/afs/cs/academic/class/15418-s21/www/lectures/07_gpuarch.pdf"
target="_blank"></a></p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>There are 15 slides in your lecture, so here is a template
for each slide covering: easy explanations for major concepts, related MCQs,
exam notes, short numericals, and a practical case studyready for
customization and expansion to match each slides topic and details.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 1</b></p>

<p class=MsoNormal>Easy Explanation:<br>
Describes the overall flow of GPU program execution, including memory transfers
and kernel launches.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Which device executes the kernel in CUDA? (CPU, GPU, RAM,
     HD)<br>
     Answer:&nbsp;GPU</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>GPU programming involves host-device data transfer, kernel
     execution, and synchronization.<span style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<p class=MsoNormal>Numerical:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Transfer 1MB, kernel 5ms, back 1MB, total time with
     2ms/send:&nbsp;2+5+2=92+5+2=9&nbsp;ms.</li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Medical imaging: GPU speeds up MRI scans by parallelizing
     pixel processing.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 2</b></p>

<p class=MsoNormal>Easy Explanation:<br>
Explains how CUDA uses grids, blocks, warps, and threads to organize tasks for
parallel computing.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>What does triple chevron &lt;&lt;&lt; &gt;&gt;&gt;
     indicate in kernel launch?<br>
     Answer:&nbsp;Number of blocks and threads per block</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Blocks are groups of threads; kernels are launched with
     specific grid/block sizes.</li>
</ul>

<p class=MsoNormal>Numerical:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>kernel&lt;&lt;&lt;100,256&gt;&gt;&gt; launches 25,600
     threads.</li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Weather simulation: each block represents a region,
     threads process data for spots.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 3</b></p>

<p class=MsoNormal>Easy Explanation:<br>
Blocks can be 1D/2D/3D, with independent execution; used to map parallel
problems naturally.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Why no communication between blocks?<br>
     Answer:&nbsp;To allow independent execution.</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Choose block structure based on problem needs.</li>
</ul>

<p class=MsoNormal>Numerical:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>For 1024x768 image:&nbsp;786432/256=3072786432/256=3072&nbsp;blocks.</li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Independent blocks process segments of high-resolution
     images.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 4</b></p>

<p class=MsoNormal>Easy Explanation:<br>
Dimensions are limited by hardware (max 65535 blocks, 512 threads/file:1).</p>

<p class=MsoNormal>MCQ:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Max block threads per dimension in CUDA?<br>
     Answer:&nbsp;512</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Split problems to fit in hardware limits.</li>
</ul>

<p class=MsoNormal>Numerical:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>60,0002128=15,360,00060,0002128=15,360,000&nbsp;threads
     possible.</li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Partitioning CT scan data for simultaneous processing.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 5</b></p>

<p class=MsoNormal>Easy Explanation:<br>
dim3: 3D block/thread definition in CUDA; use threadIdx/blockIdx for
positioning.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>threadIdx.x:<br>
     Answer:&nbsp;Thread index in block (x-dir)</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Indexing is key for mapping threads to computations.</li>
</ul>

<p class=MsoNormal>Numerical:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Block:&nbsp;551551, threadIdx=(3,2,0) selects the
     element at.<span style='font-family:"Arial",sans-serif'>&#8203;</span></li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Matrix multiplication: indices assign threads to process
     matrix elements.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 6</b></p>

<p class=MsoNormal>Easy Explanation:<br>
9 steps for GPU programming: allocation, data transfer, execution,
synchronization, clean-up.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Last step in GPU workflow?<br>
     Answer:&nbsp;De-allocate memory</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Follow steps for success in CUDA development.</li>
</ul>

<p class=MsoNormal>Numerical:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Steps total time: allocate(1ms), copy(2ms), kernel(3ms),
     reverse(2ms): 8ms.</li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Finance: GPU speeds up computation-intensive risk
     analysis.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 7</b></p>

<p class=MsoNormal>Easy Explanation:<br>
Shows CUDA syntax for launching device functions with&nbsp;global; host and
device code separation.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>global&nbsp;keyword marks:<br>
     Answer:&nbsp;Function running on device, called by host</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Use triple chevron &lt;&lt;&lt;&gt;&gt;&gt; for kernel
     launches.</li>
</ul>

<p class=MsoNormal>Numerical:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>&lt;&lt;&lt;1,1&gt;&gt;&gt; launches 1 thread only.</li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Starting Hello World! kernel before complex GPU
     projects.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 8</b></p>

<p class=MsoNormal>Easy Explanation:<br>
Focuses on using many threads for parallel computation, the core power of GPUs.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Key CUDA advantage?<br>
     Answer:&nbsp;Massive parallelism</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Parallel processing for speed in large-scale data tasks.</li>
</ul>

<p class=MsoNormal>Numerical:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Vector addition: 100,000 elements, 1000 threads, 100 each.</li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Graphics rendering: each object handled by a separate
     thread.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 9</b></p>

<p class=MsoNormal>Easy Explanation:<br>
Demonstrates addition of two integers, then vectors, as first steps in parallel
CUDA programming.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Which operation best suits parallel CUDA?<br>
     Answer:&nbsp;Vector addition</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Start with simple parallel tasks before scaling up.</li>
</ul>

<p class=MsoNormal>Numerical:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Add two 16-element arrays; each thread sums one index per
     block.</li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>GPU used in physics to sum particle energies in parallel.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 10</b></p>

<p class=MsoNormal>Easy Explanation:<br>
Shows memory management: allocating, copying, and freeing memory on host and
device.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>What does cudaMemcpy do?<br>
     Answer:&nbsp;Copies data between CPU and GPU memories</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Efficient memory management boosts GPU performance.</li>
</ul>

<p class=MsoNormal>Numerical:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Allocate/copy 256KB: time if transfer rate is 128MB/s?</li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Deep learning: copying datasets to GPU for faster model
     training.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 11</b></p>

<p class=MsoNormal>Easy Explanation:<br>
Introduces synchronization techniques for threads and blocks in CUDA.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Which CUDA statement synchronizes all threads in a block?<br>
     Answer:&nbsp;__syncthreads()</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Use synchronization to prevent race conditions.</li>
</ul>

<p class=MsoNormal>Numerical:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Finding the barrier synchronization point in grid/block.</li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Parallel sorting using barrier after each phase.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 12</b></p>

<p class=MsoNormal>Easy Explanation:<br>
Discusses shared and global memory, their usage, speed differences, and scope.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Which is fastest for threads: shared, local, global,
     texture?<br>
     Answer:&nbsp;Local (for a single thread); shared (within block)</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Shared memory enables fast intra-block communication.</li>
</ul>

<p class=MsoNormal>Numerical:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>If shared memory is 48KB/block, how many blocks fit in
     512KB?</li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Fast matrix transpose using shared memory buffers.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 13</b></p>

<p class=MsoNormal>Easy Explanation:<br>
Shows stream usage for concurrent kernel execution and better GPU utilization.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>What is a CUDA stream?<br>
     Answer:&nbsp;Sequence of operations executed in order</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Use streams for non-blocking, concurrent kernel launches.</li>
</ul>

<p class=MsoNormal>Numerical:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Launching two kernels in two streams; time comparison.</li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Data preprocessing runs in stream1, training runs in
     stream2.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 14</b></p>

<p class=MsoNormal>Easy Explanation:<br>
Demo of advanced kernel: vector addition for arrays, exploring indexing.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Index calculation for vector addition uses?<br>
     Answer:&nbsp;blockIdx, threadIdx</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Correct index maps each thread to the right data element.</li>
</ul>

<p class=MsoNormal>Numerical:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>For blockSize=256, N=1024:
     numBlocks=(N+blockSize-1)/blockSize=4.</li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>GPU acceleration for real-time signal processing.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 15</b></p>

<p class=MsoNormal>Easy Explanation:<br>
Parallel reduction: summing array efficiently using threads and shared memory.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Which CUDA feature speeds up reductions?<br>
     Answer:&nbsp;Shared memory</li>
</ul>

<p class=MsoNormal>Exam Notes:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Reduce step: repeatedly halve number of active threads per
     block.</li>
</ul>

<p class=MsoNormal>Numerical:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Sum 1024 elements with 256 threads/block: 4 blocks.</li>
</ul>

<p class=MsoNormal>Case Study:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Summing sensor data in IoT deployments using concurrent
     reductions.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal>This covers all key topics for each of the 15 slides,
including the explanations, MCQs, exam notes, numericals, and case studies you
requested.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>&nbsp;</p>

<div style='border:none;border-bottom:double windowtext 2.25pt;padding:0in 0in 1.0pt 0in'>

<p class=MsoNormal style='border:none;padding:0in'>&nbsp;</p>

</div>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><b>GPU Programming Lecture 03 - Comprehensive Study Guide</b></p>

<p class=MsoNormal><b>Slide 1: GPU Programming Lecture 03</b></p>

<p class=MsoNormal><b>Easy Explanation:</b> This lecture focuses on the
practical aspects of GPU programming, specifically how to organize and execute
parallel code on NVIDIA GPUs using CUDA.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 2: Program Execution Recap</b></p>

<p class=MsoNormal><b>Easy Explanation:</b></p>

<p class=MsoNormal>This slide serves as a reminder of previously covered
concepts about how programs execute on GPUs. It sets the foundation for
understanding kernel launches, thread organization, and parallel execution
models.</p>

<p class=MsoNormal><b>Related MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>What is a kernel in CUDA programming?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) A CPU function</li>
  <li class=MsoNormal>b) A function that runs on the GPU</li>
  <li class=MsoNormal>c) An operating system component</li>
  <li class=MsoNormal>d) A memory allocation unit</li>
  <li class=MsoNormal><b>Answer: b</b></li>
 </ul>
 <li class=MsoNormal><b>Which component initiates the execution of GPU code?</b>
     </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Device</li>
  <li class=MsoNormal>b) GPU</li>
  <li class=MsoNormal>c) Host (CPU)</li>
  <li class=MsoNormal>d) Warp</li>
  <li class=MsoNormal><b>Answer: c</b></li>
 </ul>
</ol>

<p class=MsoNormal><b>Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>GPU programs follow a host-device execution model</li>
 <li class=MsoNormal>Host (CPU) controls program flow and launches kernels</li>
 <li class=MsoNormal>Device (GPU) executes parallel computations</li>
 <li class=MsoNormal>Understanding the execution hierarchy is fundamental to
     GPU programming</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<p class=MsoNormal><i>No specific numerical problems for this recap slide</i></p>

<p class=MsoNormal><b>Case Study:</b></p>

<p class=MsoNormal><b>Image Processing Application:</b> Consider a photo
editing app that applies filters to images. The CPU (host) manages the user
interface and loads the image, while the GPU (device) processes millions of
pixels simultaneously, applying filters like blur or brightness adjustment in
parallel.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 3: Hierarchy of Kernel, Block, Warp, and Thread</b></p>

<p class=MsoNormal><b>Easy Explanation:</b></p>

<p class=MsoNormal>Think of GPU execution like organizing a massive factory:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Kernel</b>: The overall job to be done</li>
 <li class=MsoNormal><b>Blocks</b>: Independent teams working on parts of the
     job</li>
 <li class=MsoNormal><b>Threads</b>: Individual workers within each team</li>
</ul>

<p class=MsoNormal>The triple chevron &lt;&lt;&lt;blocks, threads&gt;&gt;&gt;
syntax tells the GPU how many teams (blocks) and workers per team (threads) to
create.</p>

<p class=MsoNormal><b>Example breakdown:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Kernel1&lt;&lt;&lt;100, 256&gt;&gt;&gt;: Creates 100
     teams, each with 256 workers = 25,600 total workers</li>
 <li class=MsoNormal>Kernel2&lt;&lt;&lt;50, 1024&gt;&gt;&gt;: Creates 50 teams,
     each with 1024 workers = 51,200 total workers</li>
</ul>

<p class=MsoNormal><b>Related MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>What does Kernel&lt;&lt;&lt;100, 256&gt;&gt;&gt; mean?</b>
     </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) 100 threads in 256 blocks</li>
  <li class=MsoNormal>b) 100 blocks with 256 threads each</li>
  <li class=MsoNormal>c) 256 blocks with 100 threads each</li>
  <li class=MsoNormal>d) 100 kernels with 256 blocks</li>
  <li class=MsoNormal><b>Answer: b</b></li>
 </ul>
 <li class=MsoNormal><b>How many total threads are launched by
     Kernel&lt;&lt;&lt;50, 1024&gt;&gt;&gt;?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) 1,074</li>
  <li class=MsoNormal>b) 50,000</li>
  <li class=MsoNormal>c) 51,200</li>
  <li class=MsoNormal>d) 52,400</li>
  <li class=MsoNormal><b>Answer: c</b></li>
 </ul>
 <li class=MsoNormal><b>What is the correct syntax for launching a CUDA kernel?</b>
     </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Kernel&lt;&lt;100, 256&gt;&gt;</li>
  <li class=MsoNormal>b) Kernel&lt;100, 256&gt;</li>
  <li class=MsoNormal>c) Kernel&lt;&lt;&lt;100, 256&gt;&gt;&gt;</li>
  <li class=MsoNormal>d) Kernel[100][256]</li>
  <li class=MsoNormal><b>Answer: c</b></li>
 </ul>
</ol>

<p class=MsoNormal><b>Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Kernel Launch Syntax</b>: kernelName&lt;&lt;&lt;numBlocks,
     threadsPerBlock&gt;&gt;&gt;(arguments)</li>
 <li class=MsoNormal><b>First parameter</b>: Number of blocks in the grid</li>
 <li class=MsoNormal><b>Second parameter</b>: Number of threads per block</li>
 <li class=MsoNormal><b>Total threads</b> = numBlocks  threadsPerBlock</li>
 <li class=MsoNormal>Triple chevrons &lt;&lt;&lt;&gt;&gt;&gt; are CUDA-specific
     syntax for kernel launches</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<p class=MsoNormal><b>Problem 1:</b> Calculate total threads for myKernel&lt;&lt;&lt;200,
512&gt;&gt;&gt;</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Solution</b>: 200 blocks  512 threads/block = 102,400
     threads</li>
</ul>

<p class=MsoNormal><b>Problem 2:</b> If you need 1,000,000 threads and use 1000
threads per block, how many blocks do you need?</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Solution</b>: 1,000,000  1000 = 1,000 blocks</li>
 <li class=MsoNormal><b>Launch</b>: kernel&lt;&lt;&lt;1000, 1000&gt;&gt;&gt;</li>
</ul>

<p class=MsoNormal><b>Problem 3:</b> A kernel is launched with 64 blocks and
256 threads per block. How many total threads execute?</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Solution</b>: 64  256 = 16,384 threads</li>
</ul>

<p class=MsoNormal><b>Case Study:</b></p>

<p class=MsoNormal><b>Video Encoding System:</b> A video streaming platform
needs to encode 4K video (38402160 = 8,294,400 pixels per frame).</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Launch configuration: encodeFrame&lt;&lt;&lt;8100,
     1024&gt;&gt;&gt;</li>
 <li class=MsoNormal>Total threads: 8,294,400</li>
 <li class=MsoNormal>Each thread processes one pixel, converting color space
     and applying compression</li>
 <li class=MsoNormal>All pixels processed simultaneously in one kernel launch</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 4: Organization of Thread Blocks</b></p>

<p class=MsoNormal><b>Easy Explanation:</b></p>

<p class=MsoNormal>Thread blocks can be organized in three ways:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>1D</b>: Like a line of people (e.g., 256 threads)</li>
 <li class=MsoNormal><b>2D</b>: Like a grid/spreadsheet (e.g., 1616 = 256
     threads)</li>
 <li class=MsoNormal><b>3D</b>: Like a cube (e.g., 884 = 256 threads)</li>
</ul>

<p class=MsoNormal><b>Key Points:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Blocks must be <b>independent</b> - they cannot
     communicate with each other</li>
 <li class=MsoNormal>Thread count is limited by <b>register availability</b></li>
 <li class=MsoNormal>Choose dimensions based on your data structure (1D for
     arrays, 2D for images, 3D for volumes)</li>
</ol>

<p class=MsoNormal><b>Related MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Can thread blocks in a grid communicate with each other
     during kernel execution?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Yes, always</li>
  <li class=MsoNormal>b) No, never</li>
  <li class=MsoNormal>c) Only within the same warp</li>
  <li class=MsoNormal>d) Only if specified</li>
  <li class=MsoNormal><b>Answer: b</b></li>
 </ul>
 <li class=MsoNormal><b>What limits the number of threads in a block?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Memory bandwidth</li>
  <li class=MsoNormal>b) Clock speed</li>
  <li class=MsoNormal>c) Register allocation</li>
  <li class=MsoNormal>d) Cache size</li>
  <li class=MsoNormal><b>Answer: c</b></li>
 </ul>
 <li class=MsoNormal><b>Which organization is best for processing a 2D image?</b>
     </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) 1D thread blocks</li>
  <li class=MsoNormal>b) 2D thread blocks</li>
  <li class=MsoNormal>c) 3D thread blocks</li>
  <li class=MsoNormal>d) It doesn't matter</li>
  <li class=MsoNormal><b>Answer: b</b></li>
 </ul>
 <li class=MsoNormal><b>Why must blocks be independent?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) To allow parallel execution in any order</li>
  <li class=MsoNormal>b) To save memory</li>
  <li class=MsoNormal>c) To increase speed</li>
  <li class=MsoNormal>d) To reduce power consumption</li>
  <li class=MsoNormal><b>Answer: a</b></li>
 </ul>
</ol>

<p class=MsoNormal><b>Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Independence Requirement</b>: Blocks must execute
     independently for scalability</li>
 <li class=MsoNormal><b>No Inter-block Communication</b>: Cannot synchronize or
     share data between blocks during kernel execution</li>
 <li class=MsoNormal><b>Register Limitation</b>: Each thread uses registers;
     total available registers limits threads per block</li>
 <li class=MsoNormal><b>Dimensional Flexibility</b>: Choose 1D/2D/3D based on
     problem structure</li>
 <li class=MsoNormal><b>Execution Order</b>: GPU can execute blocks in any
     order, possibly simultaneously</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<p class=MsoNormal><b>Problem 1:</b> You have a 512512 image. Design a 2D
block configuration with 1616 threads per block.</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Solution</b>: </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Threads per block: 1616 = 256 threads</li>
  <li class=MsoNormal>Blocks needed: (512/16)  (512/16) = 3232 = 1,024 blocks</li>
  <li class=MsoNormal><b>Launch</b>: kernel&lt;&lt;&lt;dim3(32,32),
      dim3(16,16)&gt;&gt;&gt;</li>
 </ul>
</ul>

<p class=MsoNormal><b>Problem 2:</b> For a 1D array of 10,000 elements with 256
threads per block, how many blocks needed?</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Solution</b>: <span style='font-family:"Cambria Math",serif'>&#8968;</span>10,000/256<span
     style='font-family:"Cambria Math",serif'>&#8969;</span> = <span
     style='font-family:"Cambria Math",serif'>&#8968;</span>39.06<span
     style='font-family:"Cambria Math",serif'>&#8969;</span> = 40 blocks</li>
 <li class=MsoNormal><b>Launch</b>: kernel&lt;&lt;&lt;40, 256&gt;&gt;&gt;</li>
</ul>

<p class=MsoNormal><b>Case Study:</b></p>

<p class=MsoNormal><b>Medical Imaging - MRI Volume Processing:</b> A hospital's
MRI scanner produces 3D volumes (256256128 voxels).</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Data structure</b>: 3D volume</li>
 <li class=MsoNormal><b>Thread organization</b>: 888 = 512 threads per block
     (3D blocks)</li>
 <li class=MsoNormal><b>Grid organization</b>: 323216 blocks</li>
 <li class=MsoNormal><b>Processing</b>: Each thread processes one voxel
     independently, applying noise reduction filters</li>
 <li class=MsoNormal><b>Why independence matters</b>: GPU can process any block
     first, utilizing all available streaming multiprocessors efficiently</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 5: Grids Blocks of Threads</b></p>

<p class=MsoNormal><b>Easy Explanation:</b></p>

<p class=MsoNormal>This slide shows the complete hierarchy visually:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Grid</b>: The entire collection of all blocks (the
     whole job)</li>
 <li class=MsoNormal><b>Block</b>: A group of threads that can cooperate (a
     team)</li>
 <li class=MsoNormal><b>Thread</b>: Individual execution unit (a worker)</li>
</ul>

<p class=MsoNormal>Think of it like a city:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Grid = The entire city</li>
 <li class=MsoNormal>Blocks = Individual buildings</li>
 <li class=MsoNormal>Threads = People in each building</li>
</ul>

<p class=MsoNormal>People in the same building can talk to each other, but
people in different buildings work independently.</p>

<p class=MsoNormal><b>Related MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>What is a grid in CUDA?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) A single thread block</li>
  <li class=MsoNormal>b) A collection of thread blocks</li>
  <li class=MsoNormal>c) A type of memory</li>
  <li class=MsoNormal>d) A synchronization mechanism</li>
  <li class=MsoNormal><b>Answer: b</b></li>
 </ul>
 <li class=MsoNormal><b>Threads within the same block can:</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Communicate through shared memory</li>
  <li class=MsoNormal>b) Communicate with threads in other blocks</li>
  <li class=MsoNormal>c) Execute on different GPUs</li>
  <li class=MsoNormal>d) Run at different times always</li>
  <li class=MsoNormal><b>Answer: a</b></li>
 </ul>
 <li class=MsoNormal><b>What is the relationship between grid, block, and
     thread?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Thread &gt; Block &gt; Grid</li>
  <li class=MsoNormal>b) Grid &gt; Block &gt; Thread</li>
  <li class=MsoNormal>c) Block &gt; Grid &gt; Thread</li>
  <li class=MsoNormal>d) They are independent</li>
  <li class=MsoNormal><b>Answer: b</b></li>
 </ul>
</ol>

<p class=MsoNormal><b>Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Hierarchy</b>: Grid &#8594; Blocks &#8594; Threads
     (largest to smallest)</li>
 <li class=MsoNormal><b>Intra-block communication</b>: Threads in same block
     can share data via shared memory</li>
 <li class=MsoNormal><b>Inter-block isolation</b>: Blocks cannot communicate
     during kernel execution</li>
 <li class=MsoNormal><b>Scalability</b>: GPU can run multiple blocks
     simultaneously on different SMs (Streaming Multiprocessors)</li>
 <li class=MsoNormal><b>Flexibility</b>: Different GPUs can run different
     numbers of blocks concurrently</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<p class=MsoNormal><b>Problem 1:</b> A grid has 100 blocks, each with 512
threads. Calculate:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>a) Total threads</li>
 <li class=MsoNormal>b) If GPU has 16 SMs, how many blocks per SM on average?</li>
</ul>

<p class=MsoNormal><b>Solution:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>a) 100  512 = 51,200 threads</li>
 <li class=MsoNormal>b) 100  16 = 6.25, so 6-7 blocks per SM</li>
</ul>

<p class=MsoNormal><b>Problem 2:</b> Design a grid for processing 19201080
image with 1616 thread blocks: <b>Solution:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Blocks in X: <span style='font-family:"Cambria Math",serif'>&#8968;</span>1920/16<span
     style='font-family:"Cambria Math",serif'>&#8969;</span> = 120 blocks</li>
 <li class=MsoNormal>Blocks in Y: <span style='font-family:"Cambria Math",serif'>&#8968;</span>1080/16<span
     style='font-family:"Cambria Math",serif'>&#8969;</span> = 68 blocks</li>
 <li class=MsoNormal>Grid: 12068 = 8,160 blocks</li>
 <li class=MsoNormal>Total threads: 8,160  256 = 2,088,960 threads</li>
</ul>

<p class=MsoNormal><b>Case Study:</b></p>

<p class=MsoNormal><b>Weather Simulation System:</b> A meteorological center
simulates weather patterns over a 10001000 km grid, with 100 altitude levels.</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Problem</b>: Calculate temperature, pressure, and
     humidity for 100 million points</li>
 <li class=MsoNormal><b>Grid organization</b>: 125125100 blocks = 1,562,500
     blocks</li>
 <li class=MsoNormal><b>Block organization</b>: 881 threads per block = 64
     threads</li>
 <li class=MsoNormal><b>Why this works</b>: Each block processes nearby
     atmospheric points independently; blocks don't need to communicate during
     calculation phase</li>
 <li class=MsoNormal><b>Result</b>: Simulation that took hours on CPU runs in
     minutes on GPU</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 6: Grids of Blocks of Threads - Dimension Limits</b></p>

<p class=MsoNormal><b>Easy Explanation:</b></p>

<p class=MsoNormal>Just like a building has maximum capacity limits, CUDA has
limits on dimensions:</p>

<p class=MsoNormal><b>Grid Limits</b> (how many blocks):</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>1D: Up to 2-1 blocks in X direction</li>
 <li class=MsoNormal>2D: Up to 65,535 blocks in X and Y</li>
 <li class=MsoNormal>3D: Up to 65,535 blocks in X, Y, and Z</li>
</ul>

<p class=MsoNormal><b>Block Limits</b> (threads per block):</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>1D: Up to 1024 threads</li>
 <li class=MsoNormal>2D: 10241024 max, but total &#8804; 1024 threads</li>
 <li class=MsoNormal>3D: 646464 max, but total &#8804; 1024 threads</li>
 <li class=MsoNormal><b>Total thread limit per block</b>: 1024 threads</li>
</ul>

<p class=MsoNormal><b>Related MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>What is the maximum number of threads per block?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) 512</li>
  <li class=MsoNormal>b) 1024</li>
  <li class=MsoNormal>c) 2048</li>
  <li class=MsoNormal>d) Unlimited</li>
  <li class=MsoNormal><b>Answer: b</b></li>
 </ul>
 <li class=MsoNormal><b>For a 2D block of threads, which configuration is
     valid?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) 3232 = 1024 threads</li>
  <li class=MsoNormal>b) 6464 = 4096 threads</li>
  <li class=MsoNormal>c) 3264 = 2048 threads</li>
  <li class=MsoNormal>d) 16128 = 2048 threads</li>
  <li class=MsoNormal><b>Answer: a</b></li>
 </ul>
 <li class=MsoNormal><b>What is the maximum X dimension for a 2D grid?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) 1024</li>
  <li class=MsoNormal>b) 2-1</li>
  <li class=MsoNormal>c) 65,535</li>
  <li class=MsoNormal>d) 256</li>
  <li class=MsoNormal><b>Answer: c</b></li>
 </ul>
 <li class=MsoNormal><b>Can you have a block with 161616 threads?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Yes, it's 4096 threads</li>
  <li class=MsoNormal>b) No, it exceeds 1024 thread limit</li>
  <li class=MsoNormal>c) Yes, but only in 3D grids</li>
  <li class=MsoNormal>d) No, dimensions too large</li>
  <li class=MsoNormal><b>Answer: b (161616 = 4096 &gt; 1024)</b></li>
 </ul>
</ol>

<p class=MsoNormal><b>Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Critical Limit</b>: Maximum 1024 threads per block
     (regardless of dimensions)</li>
 <li class=MsoNormal><b>Grid X dimension</b>: Can be very large (2-1 in 1D,
     65535 in 2D/3D)</li>
 <li class=MsoNormal><b>Block dimensions</b>: Product of all dimensions &#8804;
     1024</li>
 <li class=MsoNormal><b>Valid examples</b>: 10241, 3232, 16164, 8816</li>
 <li class=MsoNormal><b>Invalid examples</b>: 3264 (2048), 161616 (4096)</li>
 <li class=MsoNormal><b>Compute capability</b>: Limits may vary; these are
     common limits</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<p class=MsoNormal><b>Problem 1:</b> Is a block configuration of 32162 valid?
<b>Solution:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Total threads = 32162 = 1024 &#10003; Valid (exactly at
     limit)</li>
</ul>

<p class=MsoNormal><b>Problem 2:</b> Calculate valid block configuration for
6464 matrix: <b>Solution:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Option 1: 88 threads/block = 64 threads &#8594; 88
     blocks grid</li>
 <li class=MsoNormal>Option 2: 1616 threads/block = 256 threads &#8594; 44
     blocks grid</li>
 <li class=MsoNormal>Option 3: 3232 threads/block = 1024 threads &#8594; 22
     blocks grid</li>
 <li class=MsoNormal><b>Cannot use</b>: 6464 threads/block (4096 &gt; 1024)</li>
</ul>

<p class=MsoNormal><b>Problem 3:</b> For processing 1,000,000 elements, design
configuration: <b>Solution:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Use 1024 threads per block (maximum)</li>
 <li class=MsoNormal>Blocks needed: <span style='font-family:"Cambria Math",serif'>&#8968;</span>1,000,000/1024<span
     style='font-family:"Cambria Math",serif'>&#8969;</span> = 977 blocks</li>
 <li class=MsoNormal><b>Launch</b>: kernel&lt;&lt;&lt;977, 1024&gt;&gt;&gt;</li>
</ul>

<p class=MsoNormal><b>Problem 4:</b> Can you create a grid with 100,000 
100,000 blocks? <b>Solution:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>No! Maximum in each dimension is 65,535</li>
 <li class=MsoNormal>Alternative: Use 3D grid or process in multiple kernel
     launches</li>
</ul>

<p class=MsoNormal><b>Case Study:</b></p>

<p class=MsoNormal><b>Genomic Sequencing Analysis:</b> A biotech company
processes DNA sequences (3 billion base pairs in human genome).</p>

<p class=MsoNormal><b>Challenge</b>: Need to compare sequences using GPU</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Naive approach</b>: 3,000,000,000 threads &#8594;
     3,000,000 blocks  1000 threads</li>
 <li class=MsoNormal><b>Problem</b>: Grid X dimension limited to 65,535 in 2D</li>
</ul>

<p class=MsoNormal><b>Solution</b>:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Use 2D grid: 18231646 blocks (&#8776;3,000,000 blocks)</li>
 <li class=MsoNormal>Each block has 1024 threads</li>
 <li class=MsoNormal>Total threads: &#8776;3.08 billion threads</li>
 <li class=MsoNormal><b>Configuration</b>: kernel&lt;&lt;&lt;dim3(1823, 1646),
     1024&gt;&gt;&gt;</li>
</ul>

<p class=MsoNormal><b>Alternative</b>: Process in multiple passes if needed, or
use 1D grid with large X dimension.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 7: Programming Basics - Example (dim3)</b></p>

<p class=MsoNormal><b>Easy Explanation:</b></p>

<p class=MsoNormal>dim3 is a special CUDA data type that holds three numbers
(x, y, z) for specifying dimensions.</p>

<p class=MsoNormal><b>Think of it like coordinates</b>:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>dim3 threads(256) &#8594; 256 threads in X, 1 in Y and Z
     &#8594; Total: 256 threads (1D)</li>
 <li class=MsoNormal>dim3 blocks(100, 100) &#8594; 100100 blocks &#8594;
     Total: 10,000 blocks (2D)</li>
 <li class=MsoNormal>dim3 anotherOne(10, 54, 32) &#8594; 105432 = 17,280 (3D)</li>
</ul>

<p class=MsoNormal><b>Default values</b>: Unspecified dimensions default to 1.</p>

<p class=MsoNormal><b>Related MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>What does dim3 threads(256) create?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) 256 threads in all dimensions</li>
  <li class=MsoNormal>b) 256 threads in X, 1 in Y and Z</li>
  <li class=MsoNormal>c) 256 threads in Z only</li>
  <li class=MsoNormal>d) 256 blocks</li>
  <li class=MsoNormal><b>Answer: b</b></li>
 </ul>
 <li class=MsoNormal><b>What is the total number represented by dim3(10, 54,
     32)?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) 96</li>
  <li class=MsoNormal>b) 540</li>
  <li class=MsoNormal>c) 17,280</li>
  <li class=MsoNormal>d) 320</li>
  <li class=MsoNormal><b>Answer: c</b></li>
 </ul>
 <li class=MsoNormal><b>In dim3 blocks(100, 100), what is the Z dimension?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) 0</li>
  <li class=MsoNormal>b) 1</li>
  <li class=MsoNormal>c) 100</li>
  <li class=MsoNormal>d) Undefined</li>
  <li class=MsoNormal><b>Answer: b</b></li>
 </ul>
 <li class=MsoNormal><b>How do you access the Y value of dim3 myDim(5, 10, 15)?</b>
     </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) myDim[1]</li>
  <li class=MsoNormal>b) myDim.y</li>
  <li class=MsoNormal>c) myDim(1)</li>
  <li class=MsoNormal>d) myDim.Y</li>
  <li class=MsoNormal><b>Answer: b</b></li>
 </ul>
</ol>

<p class=MsoNormal><b>Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>dim3 structure</b>: Contains three unsigned integers
     (x, y, z)</li>
 <li class=MsoNormal><b>Default initialization</b>: Unspecified values default
     to 1</li>
 <li class=MsoNormal><b>Access members</b>: Use .x, .y, .z notation</li>
 <li class=MsoNormal><b>Usage</b>: Specify both grid dimensions and block
     dimensions</li>
 <li class=MsoNormal><b>Type</b>: CUDA-specific type (not standard C++)</li>
</ul>

<p class=MsoNormal><b>Syntax examples</b>:</p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>dim3 grid(100); // 10011</p>

<p class=MsoNormal>dim3 block(16, 16); // 16161</p>

<p class=MsoNormal>dim3 volume(10, 10, 10); // 101010</p>

<p class=MsoNormal>kernel&lt;&lt;&lt;grid, block&gt;&gt;&gt;(); // Launch
kernel</p>

<p class=MsoNormal><b>Numericals:</b></p>

<p class=MsoNormal><b>Problem 1:</b> Calculate total threads for this
configuration:</p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>dim3 blocks(50, 40);</p>

<p class=MsoNormal>dim3 threads(32, 16);</p>

<p class=MsoNormal><b>Solution:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Blocks: 50401 = 2,000 blocks</li>
 <li class=MsoNormal>Threads per block: 32161 = 512 threads</li>
 <li class=MsoNormal>Total: 2,000512 = 1,024,000 threads</li>
</ul>

<p class=MsoNormal><b>Problem 2:</b> Design dim3 configuration for 19201080
image with 1616 thread blocks: <b>Solution:</b></p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>dim3 threads(16, 16); // 256 threads per block</p>

<p class=MsoNormal>dim3 blocks(120, 68); // (1920/16)(1080/16)</p>

<p class=MsoNormal>// Total threads: 12068256 = 2,088,960</p>

<p class=MsoNormal><b>Problem 3:</b> Is this configuration valid?</p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>dim3 threads(32, 32, 2);</p>

<p class=MsoNormal><b>Solution:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Total threads: 32322 = 2,048</li>
 <li class=MsoNormal><b>Invalid!</b> Exceeds 1024 thread limit per block</li>
</ul>

<p class=MsoNormal><b>Case Study:</b></p>

<p class=MsoNormal><b>3D Medical Imaging - CT Scan Processing:</b> A hospital
CT scanner produces volumes of 512512300 slices.</p>

<p class=MsoNormal><b>Configuration</b>:</p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>// Process volume with 888 thread blocks</p>

<p class=MsoNormal>dim3 threadsPerBlock(8, 8, 8); // 512 threads per block</p>

<p class=MsoNormal>dim3 numBlocks(64, 64, 38); // Grid dimensions</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>// Calculate:</p>

<p class=MsoNormal>// - (512/8) = 64 blocks in X</p>

<p class=MsoNormal>// - (512/8) = 64 blocks in Y </p>

<p class=MsoNormal>// - (300/8) = 37.5 &#8594; 38 blocks in Z</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>ctScanFilter&lt;&lt;&lt;numBlocks,
threadsPerBlock&gt;&gt;&gt;(volumeData);</p>

<p class=MsoNormal><b>Benefits</b>:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Natural 3D mapping to 3D data</li>
 <li class=MsoNormal>Each thread processes one voxel</li>
 <li class=MsoNormal>Efficient memory access patterns</li>
 <li class=MsoNormal>Process entire volume in one kernel launch</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 8: Programming Basics - Example (Execution Order)</b></p>

<p class=MsoNormal><b>Easy Explanation:</b></p>

<p class=MsoNormal><b>Key Concept</b>: You cannot predict which thread or block
finishes first!</p>

<p class=MsoNormal>The diagram shows:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Green = Completed threads/blocks</li>
 <li class=MsoNormal>White = Not yet completed</li>
 <li class=MsoNormal>Random pattern = <b>Execution order is undefined</b></li>
</ul>

<p class=MsoNormal><b>Why this matters</b>:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Don't assume thread 0 finishes before thread 1</li>
 <li class=MsoNormal>Don't assume block 0 finishes before block 100</li>
 <li class=MsoNormal>GPU executes in parallel, order is unpredictable</li>
 <li class=MsoNormal>This allows GPU to maximize efficiency</li>
</ul>

<p class=MsoNormal><b>Analogy</b>: Like multiple workers painting a wall - you
can't predict who finishes their section first.</p>

<p class=MsoNormal><b>Related MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>What can you assume about thread execution order?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Threads execute in sequential order</li>
  <li class=MsoNormal>b) Lower-numbered threads execute first</li>
  <li class=MsoNormal>c) Execution order is undefined</li>
  <li class=MsoNormal>d) Blocks execute sequentially</li>
  <li class=MsoNormal><b>Answer: c</b></li>
 </ul>
 <li class=MsoNormal><b>Why is execution order undefined?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) It's a bug in CUDA</li>
  <li class=MsoNormal>b) To maximize parallel efficiency</li>
  <li class=MsoNormal>c) To save memory</li>
  <li class=MsoNormal>d) To reduce power consumption</li>
  <li class=MsoNormal><b>Answer: b</b></li>
 </ul>
 <li class=MsoNormal><b>Can you rely on thread 0 finishing before thread 10?</b>
     </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Yes, always</li>
  <li class=MsoNormal>b) No, never</li>
  <li class=MsoNormal>c) Only within same block</li>
  <li class=MsoNormal>d) Only within same warp</li>
  <li class=MsoNormal><b>Answer: b</b></li>
 </ul>
 <li class=MsoNormal><b>What does the green color in the diagram represent?</b>
     </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Active threads</li>
  <li class=MsoNormal>b) Completed threads</li>
  <li class=MsoNormal>c) Failed threads</li>
  <li class=MsoNormal>d) Waiting threads</li>
  <li class=MsoNormal><b>Answer: b</b></li>
 </ul>
</ol>

<p class=MsoNormal><b>Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Undefined Execution Order</b>: Never assume any
     particular execution sequence</li>
 <li class=MsoNormal><b>No Guarantees</b>: Cannot predict which thread/block
     completes first</li>
 <li class=MsoNormal><b>Reason</b>: GPU optimizes for maximum parallelism and
     hardware utilization</li>
 <li class=MsoNormal><b>Programming Implication</b>: Algorithms must not depend
     on execution order</li>
 <li class=MsoNormal><b>Synchronization</b>: Use __syncthreads() within blocks
     if coordination needed</li>
 <li class=MsoNormal><b>Between Blocks</b>: No synchronization possible during
     single kernel</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<p class=MsoNormal><b>Problem 1:</b> If a kernel launches 1000 threads, how
many will finish first? <b>Solution:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Answer: Unknown - execution order is undefined</li>
 <li class=MsoNormal>Could be any thread (0-999)</li>
 <li class=MsoNormal>Multiple threads may finish simultaneously</li>
</ul>

<p class=MsoNormal><b>Problem 2:</b> In a 100-block kernel, can block 99 finish
before block 0? <b>Solution:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Yes! Absolutely possible</li>
 <li class=MsoNormal>Execution order is not guaranteed</li>
 <li class=MsoNormal>GPU schedules blocks based on resource availability</li>
</ul>

<p class=MsoNormal><b>Case Study:</b></p>

<p class=MsoNormal><b>Stock Market Data Analysis:</b></p>

<p class=MsoNormal><b>Scenario</b>: Analyzing 10,000 stock prices
simultaneously</p>

<p class=MsoNormal><b>Wrong approach (assumes order)</b>:</p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>// This is WRONG - assumes thread 0 sets up data first</p>

<p class=MsoNormal>__global__ void wrongKernel(float* data) {</p>

<p class=MsoNormal> int idx = threadIdx.x;</p>

<p class=MsoNormal> if (idx == 0) {</p>

<p class=MsoNormal> // Setup shared data - other threads need this!</p>

<p class=MsoNormal> sharedData[0] = importantValue;</p>

<p class=MsoNormal> }</p>

<p class=MsoNormal> // Thread 100 might read before thread 0 writes! BUG!</p>

<p class=MsoNormal> float value = sharedData[0] + data[idx];</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal><b>Correct approach (doesn't assume order)</b>:</p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>__global__ void correctKernel(float* data, float
importantValue) {</p>

<p class=MsoNormal> int idx = threadIdx.x;</p>

<p class=MsoNormal> // All threads have access to importantValue from start</p>

<p class=MsoNormal> float value = importantValue + data[idx];</p>

<p class=MsoNormal> // Or use __syncthreads() if initialization needed</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal><b>Lesson</b>: Design algorithms that work regardless of
execution order.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 9: Programming Basics - Example (Thread Mapping)</b></p>

<p class=MsoNormal><b>Easy Explanation:</b></p>

<p class=MsoNormal>This slide emphasizes that threads map to problem elements
in an <b>undefined manner</b>:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>You assign work to threads</li>
 <li class=MsoNormal>GPU decides how/when to execute</li>
 <li class=MsoNormal>Multiple threads can work simultaneously</li>
 <li class=MsoNormal>Completion order is random</li>
</ul>

<p class=MsoNormal><b>Think of it like</b>: Assigning 100 tasks to 100 workers
- you give each worker a task, but you don't control who finishes when.</p>

<p class=MsoNormal><b>Related MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>How are threads mapped to data elements?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Always sequentially</li>
  <li class=MsoNormal>b) In a programmer-defined but GPU-executed undefined
      order</li>
  <li class=MsoNormal>c) Randomly</li>
  <li class=MsoNormal>d) Based on thread priority</li>
  <li class=MsoNormal><b>Answer: b</b></li>
 </ul>
 <li class=MsoNormal><b>What must a programmer ensure when mapping threads to
     problems?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Threads execute in order</li>
  <li class=MsoNormal>b) Each thread gets unique work</li>
  <li class=MsoNormal>c) Low-numbered threads finish first</li>
  <li class=MsoNormal>d) All threads execute simultaneously</li>
  <li class=MsoNormal><b>Answer: b</b></li>
 </ul>
 <li class=MsoNormal><b>The undefined execution order allows:</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Bugs to occur</li>
  <li class=MsoNormal>b) Maximum GPU efficiency</li>
  <li class=MsoNormal>c) Slower execution</li>
  <li class=MsoNormal>d) Sequential processing</li>
  <li class=MsoNormal><b>Answer: b</b></li>
 </ul>
</ol>

<p class=MsoNormal><b>Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Programmer's job</b>: Map threads to data elements
     correctly</li>
 <li class=MsoNormal><b>GPU's job</b>: Execute threads efficiently (order
     undefined)</li>
 <li class=MsoNormal><b>Data partitioning</b>: Each thread typically processes
     unique data elements</li>
 <li class=MsoNormal><b>Independence</b>: Design so any execution order
     produces correct results</li>
 <li class=MsoNormal><b>Thread ID</b>: Use threadIdx and blockIdx to identify
     which data to process</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<p class=MsoNormal><b>Problem 1:</b> For an array of 1000 elements with 250
threads:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>How many elements per thread? <b>Solution:</b></li>
 <li class=MsoNormal>1000/250 = 4 elements per thread</li>
 <li class=MsoNormal>Thread 0 processes elements 0,1,2,3</li>
 <li class=MsoNormal>Thread 1 processes elements 4,5,6,7</li>
 <li class=MsoNormal>etc.</li>
</ul>

<p class=MsoNormal><b>Problem 2:</b> 2D image 640480, block size 1616:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>How many pixels per thread? <b>Solution:</b></li>
 <li class=MsoNormal>1 pixel per thread (one-to-one mapping)</li>
 <li class=MsoNormal>Thread (x,y) processes pixel (blockIdx.x16+threadIdx.x,
     blockIdx.y16+threadIdx.y)</li>
</ul>

<p class=MsoNormal><b>Case Study:</b></p>

<p class=MsoNormal><b>Real-time Video Filter Application:</b></p>

<p class=MsoNormal><b>Problem</b>: Apply brightness filter to 19201080 video
at 60fps</p>

<p class=MsoNormal><b>Thread Mapping Strategy</b>:</p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>dim3 blocks(120, 68); // Grid</p>

<p class=MsoNormal>dim3 threads(16, 16); // Block</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>__global__ void brightnessFilter(uchar* image, float factor)
{</p>

<p class=MsoNormal> int x = blockIdx.x * blockDim.x + threadIdx.x;</p>

<p class=MsoNormal> int y = blockIdx.y * blockDim.y + threadIdx.y;</p>

<p class=MsoNormal> </p>

<p class=MsoNormal> if (x &lt; 1920 &amp;&amp; y &lt; 1080) {</p>

<p class=MsoNormal> int idx = y * 1920 + x;</p>

<p class=MsoNormal> image[idx] = min(255, image[idx] * factor);</p>

<p class=MsoNormal> }</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal><b>Key Points</b>:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Each thread processes exactly one pixel</li>
 <li class=MsoNormal>Doesn't matter which pixel is processed first</li>
 <li class=MsoNormal>All pixels processed in parallel</li>
 <li class=MsoNormal>Result: 60fps real-time performance</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 10: Sequence of Steps for GPU Programming</b></p>

<p class=MsoNormal><b>Easy Explanation:</b></p>

<p class=MsoNormal>GPU programming follows a specific workflow (like a recipe):</p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Allocate CPU Data</b>: Create arrays on CPU</li>
 <li class=MsoNormal><b>Initialize CPU Data</b>: Fill arrays with values</li>
 <li class=MsoNormal><b>Allocate GPU Data</b>: Create arrays on GPU</li>
 <li class=MsoNormal><b>Copy CPU&#8594;GPU</b>: Transfer data to GPU</li>
 <li class=MsoNormal><b>Define Execution Config</b>: Set grid/block dimensions</li>
 <li class=MsoNormal><b>Run Kernel</b>: Launch GPU computation</li>
 <li class=MsoNormal><b>CPU Synchronizes</b>: Wait for GPU to finish</li>
 <li class=MsoNormal><b>Copy GPU&#8594;CPU</b>: Get results back</li>
 <li class=MsoNormal><b>Deallocate Memory</b>: Free CPU and GPU memory</li>
</ol>

<p class=MsoNormal><b>Analogy</b>: Sending work to a remote team:</p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Prepare documents (CPU allocation)</li>
 <li class=MsoNormal>Fill in data (initialization)</li>
 <li class=MsoNormal>Set up remote workspace (GPU allocation)</li>
 <li class=MsoNormal>Send documents (copy to GPU)</li>
 <li class=MsoNormal>Assign team structure (execution config)</li>
 <li class=MsoNormal>Team works (kernel execution)</li>
 <li class=MsoNormal>Wait for completion (synchronization)</li>
 <li class=MsoNormal>Receive results (copy to CPU)</li>
 <li class=MsoNormal>Clean up (deallocation)</li>
</ol>

<p class=MsoNormal><b>Related MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>What is the correct order of GPU programming steps?</b>
     </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Allocate GPU, Copy to GPU, Run Kernel</li>
  <li class=MsoNormal>b) Run Kernel, Copy to GPU, Copy to CPU</li>
  <li class=MsoNormal>c) Allocate CPU, Allocate GPU, Copy to GPU, Run Kernel,
      Copy to CPU</li>
  <li class=MsoNormal>d) Copy to GPU, Allocate GPU, Run Kernel</li>
  <li class=MsoNormal><b>Answer: c</b></li>
 </ul>
 <li class=MsoNormal><b>When should you synchronize CPU with GPU?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Before copying data to GPU</li>
  <li class=MsoNormal>b) After kernel launch, before copying results</li>
  <li class=MsoNormal>c) During kernel execution</li>
  <li class=MsoNormal>d) Never needed</li>
  <li class=MsoNormal><b>Answer: b</b></li>
 </ul>
 <li class=MsoNormal><b>What happens if you forget to copy data to GPU?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Kernel works on uninitialized data</li>
  <li class=MsoNormal>b) Automatic copy occurs</li>
  <li class=MsoNormal>c) Compilation error</li>
  <li class=MsoNormal>d) Kernel doesn't launch</li>
  <li class=MsoNormal><b>Answer: a</b></li>
 </ul>
 <li class=MsoNormal><b>Why must we allocate separate GPU memory?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) CPU and GPU have separate memory spaces</li>
  <li class=MsoNormal>b) To save CPU memory</li>
  <li class=MsoNormal>c) GPU is faster</li>
  <li class=MsoNormal>d) It's optional</li>
  <li class=MsoNormal><b>Answer: a</b></li>
 </ul>
</ol>

<p class=MsoNormal><b>Exam Notes:</b></p>

<p class=MsoNormal><b>9-Step GPU Programming Workflow</b>:</p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>CPU Allocation</b>: float* h_data =
     (float*)malloc(size);</li>
 <li class=MsoNormal><b>CPU Initialization</b>: for(i=0; i&lt;N; i++) h_data[i]
     = i;</li>
 <li class=MsoNormal><b>GPU Allocation</b>: cudaMalloc(&amp;d_data, size);</li>
 <li class=MsoNormal><b>Copy H&#8594;D</b>: cudaMemcpy(d_data, h_data, size,
     cudaMemcpyHostToDevice);</li>
 <li class=MsoNormal><b>Execution Config</b>: dim3 blocks, threads;</li>
 <li class=MsoNormal><b>Kernel Launch</b>: kernel&lt;&lt;&lt;blocks,
     threads&gt;&gt;&gt;(d_data);</li>
 <li class=MsoNormal><b>Synchronize</b>: cudaDeviceSynchronize();</li>
 <li class=MsoNormal><b>Copy D&#8594;H</b>: cudaMemcpy(h_data, d_data, size,
     cudaMemcpyDeviceToHost);</li>
 <li class=MsoNormal><b>Deallocate</b>: cudaFree(d_data); free(h_data);</li>
</ol>

<p class=MsoNormal><b>Memory prefixes</b>:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>h_ = host (CPU) memory</li>
 <li class=MsoNormal>d_ = device (GPU) memory</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<p class=MsoNormal><b>Problem 1:</b> Calculate memory allocation for 1000
floats: <b>Solution:</b></p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>int N = 1000;</p>

<p class=MsoNormal>size_t size = N * sizeof(float); // 1000 * 4 = 4000 bytes =
4KB</p>

<p class=MsoNormal>float* h_data = (float*)malloc(size);</p>

<p class=MsoNormal>float* d_data;</p>

<p class=MsoNormal>cudaMalloc(&amp;d_data, size);</p>

<p class=MsoNormal><b>Problem 2:</b> Memory transfer time calculation:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Data size: 100 MB</li>
 <li class=MsoNormal>PCIe bandwidth: 16 GB/s</li>
 <li class=MsoNormal>Transfer time? <b>Solution:</b></li>
 <li class=MsoNormal>Time = 100 MB / 16 GB/s = 0.1 / 16 = 0.00625 seconds =
     6.25 ms</li>
</ul>

<p class=MsoNormal><b>Problem 3:</b> Complete workflow timing:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>CPU allocation: 0.1 ms</li>
 <li class=MsoNormal>CPU initialization: 5 ms</li>
 <li class=MsoNormal>GPU allocation: 0.5 ms</li>
 <li class=MsoNormal>Copy to GPU: 10 ms</li>
 <li class=MsoNormal>Kernel execution: 2 ms</li>
 <li class=MsoNormal>Synchronization: 0.1 ms</li>
 <li class=MsoNormal>Copy to CPU: 10 ms</li>
 <li class=MsoNormal>Deallocation: 0.5 ms <b>Total time?</b> <b>Solution:</b>
     0.1+5+0.5+10+2+0.1+10+0.5 = 28.2 ms</li>
</ul>

<p class=MsoNormal><b>Case Study:</b></p>

<p class=MsoNormal><b>Machine Learning - Neural Network Training:</b></p>

<p class=MsoNormal><b>Scenario</b>: Training a neural network with 1 million
parameters</p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>// Step 1: Allocate CPU memory</p>

<p class=MsoNormal>float* h_weights = (float*)malloc(1000000 * sizeof(float));</p>

<p class=MsoNormal>float* h_gradients = (float*)malloc(1000000 *
sizeof(float));</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>// Step 2: Initialize on CPU</p>

<p class=MsoNormal>initializeWeights(h_weights, 1000000);</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>// Step 3: Allocate GPU memory</p>

<p class=MsoNormal>float *d_weights, *d_gradients;</p>

<p class=MsoNormal>cudaMalloc(&amp;d_weights, 1000000 * sizeof(float));</p>

<p class=MsoNormal>cudaMalloc(&amp;d_gradients, 1000000 * sizeof(float));</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>// Step 4: Copy to GPU</p>

<p class=MsoNormal>cudaMemcpy(d_weights, h_weights, 1000000*sizeof(float), </p>

<p class=MsoNormal> cudaMemcpyHostToDevice);</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>// Step 5: Define execution configuration</p>

<p class=MsoNormal>dim3 blocks(977); // ceil(1000000/1024)</p>

<p class=MsoNormal>dim3 threads(1024);</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>// Step 6: Run kernel (gradient descent)</p>

<p class=MsoNormal>for(int epoch = 0; epoch &lt; 1000; epoch++) {</p>

<p class=MsoNormal> computeGradients</p>

<p class=MsoNormal>Retry</p>

<p class=MsoNormal>P</p>

<p class=MsoNormal>Continue</p>

<p class=MsoNormal>&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(d_weights,
d_gradients);</p>

<p class=MsoNormal>// Step 7: Synchronize (wait for kernel completion)</p>

<p class=MsoNormal>cudaDeviceSynchronize();</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>updateWeights&lt;&lt;&lt;blocks,
threads&gt;&gt;&gt;(d_weights, d_gradients);</p>

<p class=MsoNormal>cudaDeviceSynchronize();</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>// Step 8: Copy results back to CPU cudaMemcpy(h_weights,
d_weights, 1000000*sizeof(float), cudaMemcpyDeviceToHost);</p>

<p class=MsoNormal>// Step 9: Deallocate memory cudaFree(d_weights);
cudaFree(d_gradients); free(h_weights); free(h_gradients);</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Performance Analysis**:</p>

<p class=MsoNormal>- **CPU-only training**: 2 hours per epoch</p>

<p class=MsoNormal>- **GPU training**: 5 seconds per epoch</p>

<p class=MsoNormal>- **Speedup**: 1440 faster!</p>

<p class=MsoNormal>- **Bottleneck**: Memory transfers (done once) vs
computation (done 1000 times)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Key Insight**: Memory transfers are expensive, but
amortized over many kernel launches.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>---</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>## Slide 11: Hello World! with Device Code (Part 1)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Easy Explanation:</p>

<p class=MsoNormal>This is the simplest CUDA program - it does nothing on the
GPU but shows the basic structure:</p>

<p class=MsoNormal>```cuda</p>

<p class=MsoNormal>__global__ void mykernel(void) {</p>

<p class=MsoNormal> // Empty kernel - does nothing</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>int main(void) {</p>

<p class=MsoNormal> mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(); //
Launch 1 block, 1 thread</p>

<p class=MsoNormal> printf(&quot;Hello World!\n&quot;); // Print on
CPU</p>

<p class=MsoNormal> return 0;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Two new elements**:</p>

<p class=MsoNormal>1. `__global__` keyword</p>

<p class=MsoNormal>2. `&lt;&lt;&lt;1,1&gt;&gt;&gt;` launch syntax</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Related MCQs:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>1. **What does __global__ indicate?**</p>

<p class=MsoNormal> - a) A global variable</p>

<p class=MsoNormal> - b) A function that runs on the device</p>

<p class=MsoNormal> - c) A function that runs on the host</p>

<p class=MsoNormal> - d) A constant value</p>

<p class=MsoNormal> - **Answer: b**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **In mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(), what do the
parameters mean?**</p>

<p class=MsoNormal> - a) 1 thread, 1 block</p>

<p class=MsoNormal> - b) 1 block, 1 thread</p>

<p class=MsoNormal> - c) 1 warp, 1 thread</p>

<p class=MsoNormal> - d) 1 grid, 1 block</p>

<p class=MsoNormal> - **Answer: b**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **Where does printf execute in this example?**</p>

<p class=MsoNormal> - a) On GPU</p>

<p class=MsoNormal> - b) On CPU</p>

<p class=MsoNormal> - c) On both</p>

<p class=MsoNormal> - d) Nowhere</p>

<p class=MsoNormal> - **Answer: b**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>4. **What does this program output?**</p>

<p class=MsoNormal> - a) Nothing</p>

<p class=MsoNormal> - b) Hello World!</p>

<p class=MsoNormal> - c) Error message</p>

<p class=MsoNormal> - d) Random output</p>

<p class=MsoNormal> - **Answer: b**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Exam Notes:</p>

<p class=MsoNormal>- **Minimal CUDA program**: Shows basic structure</p>

<p class=MsoNormal>- **__global__ keyword**: Declares kernel function (device
code)</p>

<p class=MsoNormal>- **main() function**: Runs on host (CPU)</p>

<p class=MsoNormal>- **Kernel launch**: Uses `&lt;&lt;&lt;&gt;&gt;&gt;` syntax</p>

<p class=MsoNormal>- **&lt;&lt;&lt;1,1&gt;&gt;&gt;**: Launches 1 block with 1
thread (minimal configuration)</p>

<p class=MsoNormal>- **Empty kernel**: Legal but does nothing</p>

<p class=MsoNormal>- **printf location**: In main(), so runs on CPU</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numericals:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1:** How many threads execute in
mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;()?</p>

<p class=MsoNormal>**Solution:**</p>

<p class=MsoNormal>- 1 block  1 thread = 1 thread total</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2:** Modify to launch 10 blocks of 32 threads:</p>

<p class=MsoNormal>**Solution:**</p>

<p class=MsoNormal>```cuda</p>

<p class=MsoNormal>mykernel&lt;&lt;&lt;10, 32&gt;&gt;&gt;();</p>

<p class=MsoNormal>// Total threads: 10  32 = 320 threads</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 3:** What is the minimum valid kernel launch
configuration?</p>

<p class=MsoNormal>**Solution:**</p>

<p class=MsoNormal>```cuda</p>

<p class=MsoNormal>kernel&lt;&lt;&lt;1, 1&gt;&gt;&gt;(); // Minimum: 1 block,
1 thread</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Case Study:</p>

<p class=MsoNormal>**Learning CUDA - First Steps:**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Educational Context**: A computer science student's first
CUDA program</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Evolution of Hello World**:</p>

<p class=MsoNormal>```cuda</p>

<p class=MsoNormal>// Version 1: Minimal (from slide)</p>

<p class=MsoNormal>__global__ void mykernel(void) { }</p>

<p class=MsoNormal>int main(void) {</p>

<p class=MsoNormal> mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;();</p>

<p class=MsoNormal> printf(&quot;Hello World!\n&quot;);</p>

<p class=MsoNormal> return 0;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>// Version 2: Kernel that does something</p>

<p class=MsoNormal>__global__ void mykernel(void) {</p>

<p class=MsoNormal> // Now print from GPU (requires compute capability 2.0+)</p>

<p class=MsoNormal> printf(&quot;Hello from GPU thread!\n&quot;);</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>// Version 3: Multiple threads</p>

<p class=MsoNormal>__global__ void mykernel(void) {</p>

<p class=MsoNormal> printf(&quot;Hello from thread %d!\n&quot;,
threadIdx.x);</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>int main(void) {</p>

<p class=MsoNormal> mykernel&lt;&lt;&lt;1, 5&gt;&gt;&gt;(); // 5 threads
print</p>

<p class=MsoNormal> cudaDeviceSynchronize();</p>

<p class=MsoNormal> return 0;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Learning Progression**:</p>

<p class=MsoNormal>1. Understand basic syntax</p>

<p class=MsoNormal>2. Learn kernel execution</p>

<p class=MsoNormal>3. Add thread identification</p>

<p class=MsoNormal>4. Process actual data</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>---</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>## Slide 12: Hello World! with Device Code (Part 2)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Easy Explanation:</p>

<p class=MsoNormal>This slide explains the **__global__** keyword in detail:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**`__global__` function characteristics**:</p>

<p class=MsoNormal>- **Runs on**: Device (GPU)</p>

<p class=MsoNormal>- **Called from**: Host (CPU) code</p>

<p class=MsoNormal>- **Purpose**: Define kernel functions</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Compilation process**:</p>

<p class=MsoNormal>- **nvcc** (NVIDIA CUDA Compiler) separates code:</p>

<p class=MsoNormal> - Device functions &#8594; NVIDIA compiler (ptx, SASS)</p>

<p class=MsoNormal> - Host functions &#8594; Standard compiler (gcc, cl.exe)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Analogy**: Like writing a bilingual document where English
sections go to one translator and Spanish sections to another.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Related MCQs:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>1. **Where does a __global__ function execute?**</p>

<p class=MsoNormal> - a) On CPU only</p>

<p class=MsoNormal> - b) On GPU only</p>

<p class=MsoNormal> - c) On both CPU and GPU</p>

<p class=MsoNormal> - d) In system memory</p>

<p class=MsoNormal> - **Answer: b**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **Who can call a __global__ function?**</p>

<p class=MsoNormal> - a) Only device code</p>

<p class=MsoNormal> - b) Only host code</p>

<p class=MsoNormal> - c) Both host and device</p>

<p class=MsoNormal> - d) Nobody</p>

<p class=MsoNormal> - **Answer: b**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **What compiler processes __global__ functions?**</p>

<p class=MsoNormal> - a) gcc</p>

<p class=MsoNormal> - b) cl.exe</p>

<p class=MsoNormal> - c) NVIDIA compiler (nvcc)</p>

<p class=MsoNormal> - d) Any C compiler</p>

<p class=MsoNormal> - **Answer: c**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>4. **What does nvcc do?**</p>

<p class=MsoNormal> - a) Only compiles CPU code</p>

<p class=MsoNormal> - b) Only compiles GPU code</p>

<p class=MsoNormal> - c) Separates and compiles both host and device code</p>

<p class=MsoNormal> - d) Links libraries</p>

<p class=MsoNormal> - **Answer: c**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>5. **Which is a valid standard host compiler?**</p>

<p class=MsoNormal> - a) nvcc</p>

<p class=MsoNormal> - b) gcc</p>

<p class=MsoNormal> - c) ptx</p>

<p class=MsoNormal> - d) cuda</p>

<p class=MsoNormal> - **Answer: b**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Exam Notes:</p>

<p class=MsoNormal>**CUDA Function Qualifiers**:</p>

<p class=MsoNormal>- **`__global__`**: Kernel function (CPU calls, GPU
executes)</p>

<p class=MsoNormal>- **`__device__`**: Device function (GPU calls, GPU
executes)</p>

<p class=MsoNormal>- **`__host__`**: Host function (CPU calls, CPU executes) -
default</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Compilation Flow**:</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>source.cu &#8594; nvcc &#8594; {</p>

<p class=MsoNormal> device code &#8594; NVIDIA compiler &#8594; GPU binary</p>

<p class=MsoNormal> host code &#8594; gcc/cl.exe &#8594; CPU binary</p>

<p class=MsoNormal>} &#8594; linked executable</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Important Rules**:</p>

<p class=MsoNormal>- `__global__` functions must return `void`</p>

<p class=MsoNormal>- `__global__` functions cannot be called from device code</p>

<p class=MsoNormal>- nvcc handles separation automatically</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numericals:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1:** Compilation time analysis:</p>

<p class=MsoNormal>- Source file: 1000 lines (600 host, 400 device)</p>

<p class=MsoNormal>- Host compile time: 2 seconds</p>

<p class=MsoNormal>- Device compile time: 5 seconds</p>

<p class=MsoNormal>- Linking: 1 second</p>

<p class=MsoNormal>**Total compilation time?**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Solution:**</p>

<p class=MsoNormal>- Host and device compile in parallel (if optimized): max(2,
5) = 5 seconds</p>

<p class=MsoNormal>- Sequential: 2 + 5 = 7 seconds</p>

<p class=MsoNormal>- Total with linking: 5 + 1 = 6 seconds (parallel) or 8
seconds (sequential)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2:** Identify compilation target:</p>

<p class=MsoNormal>```cuda</p>

<p class=MsoNormal>__global__ void kernelA() { } // &#8594; ?</p>

<p class=MsoNormal>__device__ float deviceB() { } // &#8594; ?</p>

<p class=MsoNormal>void hostC() { } // &#8594; ?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Solution:**</p>

<p class=MsoNormal>- `kernelA`: NVIDIA compiler (device)</p>

<p class=MsoNormal>- `deviceB`: NVIDIA compiler (device)</p>

<p class=MsoNormal>- `hostC`: Host compiler (gcc/cl.exe)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Case Study:</p>

<p class=MsoNormal>**Large-Scale Scientific Application:**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Project**: Climate simulation with 500,000 lines of code</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Code Organization**:</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>src/</p>

<p class=MsoNormal><span style='font-family:"MS Gothic"'>&#9500;</span>&#9472;&#9472;
host/ (300,000 lines - CPU code)</p>

<p class=MsoNormal>&#9474; <span style='font-family:"MS Gothic"'>&#9500;</span>&#9472;&#9472;
io.cpp &#8594; gcc</p>

<p class=MsoNormal>&#9474; <span style='font-family:"MS Gothic"'>&#9500;</span>&#9472;&#9472;
visualization.cpp &#8594; gcc</p>

<p class=MsoNormal>&#9474; &#9492;&#9472;&#9472; main.cpp &#8594; gcc</p>

<p class=MsoNormal><span style='font-family:"MS Gothic"'>&#9500;</span>&#9472;&#9472;
device/ (150,000 lines - GPU code)</p>

<p class=MsoNormal>&#9474; <span style='font-family:"MS Gothic"'>&#9500;</span>&#9472;&#9472;
kernels.cu &#8594; nvcc (device part)</p>

<p class=MsoNormal>&#9474; &#9492;&#9472;&#9472; physics.cu &#8594; nvcc
(device part)</p>

<p class=MsoNormal>&#9492;&#9472;&#9472; common/ (50,000 lines - both)</p>

<p class=MsoNormal> &#9492;&#9472;&#9472; utils.cu &#8594; nvcc (both
parts)</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Compilation Strategy**:</p>

<p class=MsoNormal>```bash</p>

<p class=MsoNormal># Compile host code</p>

<p class=MsoNormal>gcc -c host/*.cpp -o host.o</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal># Compile device code </p>

<p class=MsoNormal>nvcc -c device/*.cu -o device.o</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal># Link everything</p>

<p class=MsoNormal>nvcc host.o device.o -o climate_sim</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Benefits**:</p>

<p class=MsoNormal>- Parallel compilation (faster builds)</p>

<p class=MsoNormal>- Separate optimization for CPU/GPU</p>

<p class=MsoNormal>- Modular code organization</p>

<p class=MsoNormal>- Can use different host compilers per platform</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Build Time**:</p>

<p class=MsoNormal>- Sequential: 45 minutes</p>

<p class=MsoNormal>- Parallel: 12 minutes</p>

<p class=MsoNormal>- **Speedup**: 3.75</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>---</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>## Slide 13: Hello World! with Device Code (Part 3)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Easy Explanation:</p>

<p class=MsoNormal>This slide explains the **triple angle bracket syntax**:</p>

<p class=MsoNormal>```cuda</p>

<p class=MsoNormal>mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;();</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**What it means**:</p>

<p class=MsoNormal>- `&lt;&lt;&lt;&gt;&gt;&gt;` marks a kernel launch (call
from host to device)</p>

<p class=MsoNormal>- First parameter: Number of blocks</p>

<p class=MsoNormal>- Second parameter: Threads per block</p>

<p class=MsoNormal>- This is called a **&quot;kernel launch&quot;**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Key point**: This simple syntax is ALL you need to execute
code on GPU!</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Related MCQs:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>1. **What does &lt;&lt;&lt;&gt;&gt;&gt; indicate?**</p>

<p class=MsoNormal> - a) Array indexing</p>

<p class=MsoNormal> - b) Kernel launch</p>

<p class=MsoNormal> - c) Template syntax</p>

<p class=MsoNormal> - d) Bit shifting</p>

<p class=MsoNormal> - **Answer: b**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **In kernel&lt;&lt;&lt;5, 10&gt;&gt;&gt;(), what is 5?**</p>

<p class=MsoNormal> - a) Number of threads</p>

<p class=MsoNormal> - b) Number of blocks</p>

<p class=MsoNormal> - c) Number of warps</p>

<p class=MsoNormal> - d) Grid size in bytes</p>

<p class=MsoNormal> - **Answer: b**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **Can you call a kernel like a normal function:
kernel()?**</p>

<p class=MsoNormal> - a) Yes, it's equivalent</p>

<p class=MsoNormal> - b) No, must use &lt;&lt;&lt;&gt;&gt;&gt;</p>

<p class=MsoNormal> - c) Only in device code</p>

<p class=MsoNormal> - d) Only with nvcc flag</p>

<p class=MsoNormal> - **Answer: b**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>4. **What is this syntax called?**</p>

<p class=MsoNormal> - a) Function call</p>

<p class=MsoNormal> - b) Kernel launch</p>

<p class=MsoNormal> - c) Thread spawn</p>

<p class=MsoNormal> - d) GPU execute</p>

<p class=MsoNormal> - **Answer: b**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Exam Notes:</p>

<p class=MsoNormal>**Kernel Launch Syntax**:</p>

<p class=MsoNormal>```cuda</p>

<p class=MsoNormal>kernelName&lt;&lt;&lt;gridDim,
blockDim&gt;&gt;&gt;(arguments);</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Components**:</p>

<p class=MsoNormal>- **gridDim**: Number of blocks (can be int or dim3)</p>

<p class=MsoNormal>- **blockDim**: Threads per block (can be int or dim3)</p>

<p class=MsoNormal>- **arguments**: Regular function parameters</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Extended Syntax** (optional parameters):</p>

<p class=MsoNormal>```cuda</p>

<p class=MsoNormal>kernel&lt;&lt;&lt;gridDim, blockDim, sharedMem,
stream&gt;&gt;&gt;(args);</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>- **sharedMem**: Shared memory bytes (default 0)</p>

<p class=MsoNormal>- **stream**: CUDA stream (default 0)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Examples**:</p>

<p class=MsoNormal>```cuda</p>

<p class=MsoNormal>kernel&lt;&lt;&lt;1, 1&gt;&gt;&gt;(); // 1
block, 1 thread</p>

<p class=MsoNormal>kernel&lt;&lt;&lt;100, 256&gt;&gt;&gt;(); // 100
blocks, 256 threads each</p>

<p class=MsoNormal>kernel&lt;&lt;&lt;dim3(10,10), 32&gt;&gt;&gt;(); // 2D
grid, 1D blocks</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numericals:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1:** Calculate threads for each launch:</p>

<p class=MsoNormal>```cuda</p>

<p class=MsoNormal>a) kernel&lt;&lt;&lt;1, 1&gt;&gt;&gt;();</p>

<p class=MsoNormal>b) kernel&lt;&lt;&lt;10, 100&gt;&gt;&gt;();</p>

<p class=MsoNormal>c) kernel&lt;&lt;&lt;100, 512&gt;&gt;&gt;();</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Solutions:**</p>

<p class=MsoNormal>- a) 1  1 = 1 thread</p>

<p class=MsoNormal>- b) 10  100 = 1,000 threads</p>

<p class=MsoNormal>- c) 100  512 = 51,200 threads</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2:** Express 1 million threads in different
configurations:</p>

<p class=MsoNormal>**Solutions:**</p>

<p class=MsoNormal>```cuda</p>

<p class=MsoNormal>kernel&lt;&lt;&lt;1000, 1000&gt;&gt;&gt;(); // Option 1</p>

<p class=MsoNormal>kernel&lt;&lt;&lt;977, 1024&gt;&gt;&gt;(); // Option 2
(max threads/block)</p>

<p class=MsoNormal>kernel&lt;&lt;&lt;10000, 100&gt;&gt;&gt;(); // Option 3</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 3:** Which configurations are equivalent?</p>

<p class=MsoNormal>```cuda</p>

<p class=MsoNormal>a) kernel&lt;&lt;&lt;100, 50&gt;&gt;&gt;();</p>

<p class=MsoNormal>b) kernel&lt;&lt;&lt;50, 100&gt;&gt;&gt;();</p>

<p class=MsoNormal>c) kernel&lt;&lt;&lt;25, 200&gt;&gt;&gt;();</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Solution:**</p>

<p class=MsoNormal>- a) 100  50 = 5,000 threads</p>

<p class=MsoNormal>- b) 50  100 = 5,000 threads</p>

<p class=MsoNormal>- c) 25  200 = 5,000 threads</p>

<p class=MsoNormal>- **All equivalent in thread count** (but different in
organization!)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Case Study:</p>

<p class=MsoNormal>**Image Processing Pipeline:**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Scenario**: Photo editing app with multiple filters</p>

<p class=MsoNormal>```cuda</p>

<p class=MsoNormal>// Original image: 4096  3072 pixels</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>// Filter 1: Gaussian Blur</p>

<p class=MsoNormal>dim3 blurBlocks(256, 192); // (4096/16)  (3072/16)</p>

<p class=MsoNormal>dim3 blurThreads(16, 16); // 256 threads per block</p>

<p class=MsoNormal>gaussianBlur&lt;&lt;&lt;blurBlocks,
blurThreads&gt;&gt;&gt;(image);</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>// Filter 2: Edge Detection</p>

<p class=MsoNormal>dim3 edgeBlocks(128, 96); // (4096/32)  (3072/32)</p>

<p class=MsoNormal>dim3 edgeThreads(32, 32); // 1024 threads per block</p>

<p class=MsoNormal>edgeDetect&lt;&lt;&lt;edgeBlocks,
edgeThreads&gt;&gt;&gt;(image);</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>// Filter 3: Color Correction (process all pixels at once)</p>

<p class=MsoNormal>int totalPixels = 4096 * 3072; // 12,582,912 pixels</p>

<p class=MsoNormal>int threads = 256;</p>

<p class=MsoNormal>int blocks = (totalPixels + threads - 1) / threads; //
49,153 blocks</p>

<p class=MsoNormal>colorCorrect&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(image,
totalPixels);</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Performance**:</p>

<p class=MsoNormal>- **CPU Processing**: 2.5 seconds per filter = 7.5 seconds
total</p>

<p class=MsoNormal>- **GPU Processing**: 15ms + 12ms + 8ms = 35ms total</p>

<p class=MsoNormal>- **Speedup**: 214 faster!</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Key Learning**: Simple `&lt;&lt;&lt;&gt;&gt;&gt;` syntax
enables massive parallelism.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>---</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>## Slide 14: Hello World! with Device Code (Part 4)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Easy Explanation:</p>

<p class=MsoNormal>This slide shows the complete minimal CUDA program with
output:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**The Program**:</p>

<p class=MsoNormal>```cuda</p>

<p class=MsoNormal>__global__ void mykernel(void) {</p>

<p class=MsoNormal> // Does nothing</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>int main(void) {</p>

<p class=MsoNormal> mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;();</p>

<p class=MsoNormal> printf(&quot;Hello World!\n&quot;);</p>

<p class=MsoNormal> return 0;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Compilation and Execution**:</p>

<p class=MsoNormal>```bash</p>

<p class=MsoNormal>$ nvcc hello.cu # Compile</p>

<p class=MsoNormal>$ a.out # Run</p>

<p class=MsoNormal>Hello World! # Output</p>

<p class=MsoNormal>$</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Key observation**: The kernel does nothing, but the
program works! This demonstrates:</p>

<p class=MsoNormal>- Kernel can be empty</p>

<p class=MsoNormal>- CPU continues after launching kernel</p>

<p class=MsoNormal>- printf runs on CPU</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Related MCQs:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>1. **What does this program output?**</p>

<p class=MsoNormal> - a) Nothing</p>

<p class=MsoNormal> - b) &quot;Hello World!&quot;</p>

<p class=MsoNormal> - c) Error message</p>

<p class=MsoNormal> - d) Thread information</p>

<p class=MsoNormal> - **Answer: b**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **What command compiles CUDA programs?**</p>

<p class=MsoNormal> - a) gcc</p>

<p class=MsoNormal> - b) g++</p>

<p class=MsoNormal> - c) nvcc</p>

<p class=MsoNormal> - d) cuda</p>

<p class=MsoNormal> - **Answer: c**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **What does mykernel do in this example?**</p>

<p class=MsoNormal> - a) Prints Hello World</p>

<p class=MsoNormal> - b) Nothing</p>

<p class=MsoNormal> - c) Initializes GPU</p>

<p class=MsoNormal> - d) Allocates memory</p>

<p class=MsoNormal> - **Answer: b**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>4. **The default output executable name from nvcc is:**</p>

<p class=MsoNormal> - a) a.out (Linux) or a.exe (Windows)</p>

<p class=MsoNormal> - b) output.exe</p>

<p class=MsoNormal> - c) cuda.out</p>

<p class=MsoNormal> - d) Same as source filename</p>

<p class=MsoNormal> - **Answer: a**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Exam Notes:</p>

<p class=MsoNormal>**Compilation Process**:</p>

<p class=MsoNormal>```bash</p>

<p class=MsoNormal># Basic compilation</p>

<p class=MsoNormal>nvcc source.cu # Creates a.out</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal># Specify output name</p>

<p class=MsoNormal>nvcc source.cu -o myprogram # Creates myprogram</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal># With optimization</p>

<p class=MsoNormal>nvcc -O3 source.cu -o myprogram # Optimized build</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Program Flow**:</p>

<p class=MsoNormal>1. main() starts on CPU</p>

<p class=MsoNormal>2. Kernel launched (GPU starts work)</p>

<p class=MsoNormal>3. CPU continues immediately (asynchronous)</p>

<p class=MsoNormal>4. printf executes on CPU</p>

<p class=MsoNormal>5. Program exits (GPU may still be working!)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Important**: This program should use
`cudaDeviceSynchronize()` before exiting to ensure kernel completes.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numericals:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1:** Execution timing:</p>

<p class=MsoNormal>- Kernel launch overhead: 20 microseconds</p>

<p class=MsoNormal>- Kernel execution: 0 microseconds (empty)</p>

<p class=MsoNormal>- printf execution: 50 microseconds</p>

<p class=MsoNormal>- Total program time?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Solution:**</p>

<p class=MsoNormal>- Without synchronization: 20 + 50 = 70 microseconds
(overlapped)</p>

<p class=MsoNormal>- With synchronization: 20 + 0 + 50 = 70 microseconds</p>

<p class=MsoNormal>- **Answer**: ~70 microseconds</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2:** Compilation time:</p>

<p class=MsoNormal>- Source code: 50 lines</p>

<p class=MsoNormal>- Host compilation: 0.1 seconds</p>

<p class=MsoNormal>- Device compilation: 0.3 seconds</p>

<p class=MsoNormal>- Linking: 0.05 seconds</p>

<p class=MsoNormal>- Total?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Solution:**</p>

<p class=MsoNormal>- 0.1 + 0.3 + 0.05 = 0.45 seconds (sequential)</p>

<p class=MsoNormal>- Or max(0.1, 0.3) + 0.05 = 0.35 seconds (parallel
compilation)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Case Study:</p>

<p class=MsoNormal>**Teaching CUDA Programming:**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Educational Scenario**: University GPU Computing Course</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Lab Progression**:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Week 1: Hello World**</p>

<p class=MsoNormal>```cuda</p>

<p class=MsoNormal>__global__ void mykernel(void) { }</p>

<p class=MsoNormal>int main(void) {</p>

<p class=MsoNormal> mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;();</p>

<p class=MsoNormal> printf(&quot;Hello World!\n&quot;);</p>

<p class=MsoNormal> return 0;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Learning**: Basic syntax, compilation</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Week 2: Add GPU Output**</p>

<p class=MsoNormal>```cuda</p>

<p class=MsoNormal>__global__ void mykernel(void) {</p>

<p class=MsoNormal> printf(&quot;Hello from GPU!\n&quot;);</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>int main(void) {</p>

<p class=MsoNormal> mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;();</p>

<p class=MsoNormal> cudaDeviceSynchronize();</p>

<p class=MsoNormal> printf(&quot;Hello from CPU!\n&quot;);</p>

<p class=MsoNormal> return 0;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Learning**: Device-side printf, synchronization</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Week 3: Multiple Threads**</p>

<p class=MsoNormal>```cuda</p>

<p class=MsoNormal>__global__ void mykernel(void) {</p>

<p class=MsoNormal> printf(&quot;Hello from thread %d!\n&quot;,
threadIdx.x);</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>int main(void) {</p>

<p class=MsoNormal> mykernel&lt;&lt;&lt;1,10&gt;&gt;&gt;();</p>

<p class=MsoNormal> cudaDeviceSynchronize();</p>

<p class=MsoNormal> return 0;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Learning**: Thread identification</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Week 4: Actual Computation**</p>

<p class=MsoNormal>```cuda</p>

<p class=MsoNormal>__global__ void add(int *a, int *b, int *c) {</p>

<p class=MsoNormal> *c = *a + *b;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Learning**: Data processing</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Pedagogical Value**: Starting simple builds confidence and
understanding progressively.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>---</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>## Slide 15: Parallel Programming in CUDA C/C++</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Easy Explanation:</p>

<p class=MsoNormal>This slide transitions from simple examples to meaningful
parallel programs:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Key Points**:</p>

<p class=MsoNormal>- GPU computing is about **massive parallelism** (many
threads)</p>

<p class=MsoNormal>- Need more interesting examples than &quot;Hello
World&quot;</p>

<p class=MsoNormal>- Will start simple (adding two integers)</p>

<p class=MsoNormal>- Build up to complex (vector addition)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Philosophy**: Start with serial problem, parallelize
incrementally.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Learning Path**:</p>

<p class=MsoNormal>1. Add two integers (1 thread)</p>

<p class=MsoNormal>2. Add multiple pairs (multiple threads)</p>

<p class=MsoNormal>3. Vector addition (thousands of threads)</p>

<p class=MsoNormal>4. Matrix operations (millions of threads)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Related MCQs:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>1. **What is GPU computing primarily about?**</p>

<p class=MsoNormal> - a) Faster single-threaded performance</p>

<p class=MsoNormal> - b) Massive parallelism</p>

<p class=MsoNormal> - c) Lower power consumption</p>

<p class=MsoNormal> - d) Simpler programming</p>

<p class=MsoNormal> - **Answer: b**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **Why start with simple examples like integer addition?**</p>

<p class=MsoNormal> - a) GPUs can't do complex math</p>

<p class=MsoNormal> - b) To understand parallelization concepts incrementally</p>

<p class=MsoNormal> - c) Integer addition is most common GPU task</p>

<p class=MsoNormal> - d) It's the fastest operation</p>

<p class=MsoNormal> - **Answer: b**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **What problem type benefits most from GPU
acceleration?**</p>

<p class=MsoNormal> - a) Sequential algorithms</p>

<p class=MsoNormal> - b) Data-parallel operations</p>

<p class=MsoNormal> - c) Branching logic</p>

<p class=MsoNormal> - d) File I/O operations</p>

<p class=MsoNormal> - **Answer: b**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>4. **Vector addition is a good GPU example because:**</p>

<p class=MsoNormal> - a) It's embarrassingly parallel</p>

<p class=MsoNormal> - b) It requires complex logic</p>

<p class=MsoNormal> - c) It has many dependencies</p>

<p class=MsoNormal> - d) It's sequential</p>

<p class=MsoNormal> - **Answer: a**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Exam Notes:</p>

<p class=MsoNormal>**Massive Parallelism Characteristics**:</p>

<p class=MsoNormal>- Thousands to millions of threads</p>

<p class=MsoNormal>- Data-parallel operations</p>

<p class=MsoNormal>- Independent computations</p>

<p class=MsoNormal>- High arithmetic intensity</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Good GPU Problems** (Data Parallel):</p>

<p class=MsoNormal>- Vector/matrix operations</p>

<p class=MsoNormal>- Image processing</p>

<p class=MsoNormal>- Physics simulations</p>

<p class=MsoNormal>- Deep learning</p>

<p class=MsoNormal>- Monte Carlo simulations</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Poor GPU Problems** (Sequential):</p>

<p class=MsoNormal>- Linked list traversal</p>

<p class=MsoNormal>- Recursive algorithms</p>

<p class=MsoNormal>- Heavy branching logic</p>

<p class=MsoNormal>- Sequential file I/O</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Learning Strategy**:</p>

<p class=MsoNormal>1. Understand serial version</p>

<p class=MsoNormal>2. Identify parallelizable operations</p>

<p class=MsoNormal>3. Map data to threads</p>

<p class=MsoNormal>4. Implement kernel</p>

<p class=MsoNormal>5. Optimize performance</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numericals:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1:** Vector addition speedup calculation:</p>

<p class=MsoNormal>- Vector size: 10,000,000 elements</p>

<p class=MsoNormal>- CPU time: 50ms (single core)</p>

<p class=MsoNormal>- GPU time: 0.5ms</p>

<p class=MsoNormal>- Speedup?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Solution:**</p>

<p class=MsoNormal>- Speedup = 50ms / 0.5ms = **100**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2:** Parallelization potential:</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Task: Process 1,000,000 images</p>

<p class=MsoNormal>Sequential time per image: 100ms</p>

<p class=MsoNormal>Available GPU cores: 10,000</p>

<p class=MsoNormal>How long on GPU (theoretical)?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Solution:**</p>

<p class=MsoNormal>- Total CPU time: 1,000,000  100ms = 100,000 seconds
&#8776; 27.8 hours</p>

<p class=MsoNormal>- With 10,000 cores: 1,000,000 / 10,000 = 100 batches</p>

<p class=MsoNormal>- GPU time: 100  100ms = 10 seconds</p>

<p class=MsoNormal>- **Speedup**: 10,000 (theoretical, assuming perfect
parallelism)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 3:** Amdahl's Law application:</p>

<p class=MsoNormal>- Program: 90% parallelizable, 10% sequential</p>

<p class=MsoNormal>- GPU speedup for parallel part: 100</p>

<p class=MsoNormal>- Overall speedup?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Solution:**</p>

<p class=MsoNormal>Using Amdahl's Law: Speedup = 1 / (0.10 + 0.90/100) = 1 /
0.109 &#8776; **9.17**</p>

<p class=MsoNormal>(Sequential part limits overall speedup)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Case Study:</p>

<p class=MsoNormal>**Weather Forecasting System Modernization:**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Background**: National weather service needs faster
forecasting</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Old System (CPU-only)**:</p>

<p class=MsoNormal>- 12-hour forecast calculation: 6 hours</p>

<p class=MsoNormal>- 48-hour forecast: 24 hours</p>

<p class=MsoNormal>- Cannot provide real-time updates</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem Analysis**:</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Weather simulation involves:</p>

<p class=MsoNormal>1. Grid calculations (99% parallel)</p>

<p class=MsoNormal> - Temperature: 10001000100 grid points</p>

<p class=MsoNormal> - Pressure: 10001000100 grid points </p>

<p class=MsoNormal> - Humidity: 10001000100 grid points</p>

<p class=MsoNormal> - Total: 300 million calculations per timestep</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. Data I/O (1% sequential)</p>

<p class=MsoNormal> - Read initial conditions</p>

<p class=MsoNormal> - Write results</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**GPU Solution**:</p>

<p class=MsoNormal>```cuda</p>

<p class=MsoNormal>// Each grid point computed by one thread</p>

<p class=MsoNormal>__global__ void weatherSimulation(float* temp, float*
pressure, </p>

<p class=MsoNormal> float* humidity, int
timestep) {</p>

<p class=MsoNormal> int x = blockIdx.x * blockDim.x + threadIdx.x;</p>

<p class=MsoNormal> int y = blockIdx.y * blockDim.y + threadIdx.y;</p>

<p class=MsoNormal> int z = blockIdx.z * blockDim.z + threadIdx.z;</p>

<p class=MsoNormal> </p>

<p class=MsoNormal> if (x &lt; 1000 &amp;&amp; y &lt; 1000 &amp;&amp; z &lt;
100) {</p>

<p class=MsoNormal> int idx = x + y*1000 + z*1000*1000;</p>

<p class=MsoNormal> // Compute physics for this grid point</p>

<p class=MsoNormal> updatePhysics(&amp;temp[idx], &amp;pressure[idx],
&amp;humidity[idx]);</p>

<p class=MsoNormal> }</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>// Launch configuration</p>

<p class=MsoNormal>dim3 blocks(125, 125, 13); // (1000/8)(1000/8)(100/8)</p>

<p class=MsoNormal>dim3 threads(8, 8, 8); // 512 threads per block</p>

<p class=MsoNormal>weatherSimulation&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(d_temp,
d_press, d_humid, t);</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Results**:</p>

<p class=MsoNormal>- **New 12-hour forecast time**: 15 minutes (24 faster)</p>

<p class=MsoNormal>- **New 48-hour forecast time**: 1 hour (24 faster)</p>

<p class=MsoNormal>- **Benefit**: Can now run hourly updates</p>

<p class=MsoNormal>- **Impact**: Better emergency warnings, more accurate
predictions</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Key Insight**: Massive parallelism (300M calculations
simultaneously) transforms impossibly slow tasks into real-time capabilities.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>---</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>## Summary: Complete Study Guide Overview</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Critical Concepts to Remember:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>1. **Execution Hierarchy**: Grid &#8594; Blocks &#8594;
Threads</p>

<p class=MsoNormal>2. **Launch Syntax**: `kernel&lt;&lt;&lt;blocks,
threads&gt;&gt;&gt;()`</p>

<p class=MsoNormal>3. **Independence**: Blocks cannot communicate</p>

<p class=MsoNormal>4. **Limits**: 1024 threads/block max, 65535 blocks per
dimension</p>

<p class=MsoNormal>5. **Undefined Order**: Never assume execution sequence</p>

<p class=MsoNormal>6. **9-Step Workflow**:
Allocate&#8594;Initialize&#8594;Copy&#8594;Launch&#8594;Sync&#8594;Copy&#8594;Free</p>

<p class=MsoNormal>7. **Massive Parallelism**: GPU power comes from many
threads</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Exam Strategy:</p>

<p class=MsoNormal>- Understand concepts first, memorize syntax second</p>

<p class=MsoNormal>- Practice calculating thread counts</p>

<p class=MsoNormal>- Know dimension limits cold</p>

<p class=MsoNormal>- Understand why blocks must be independent</p>

<p class=MsoNormal>- Remember compilation flow (nvcc separates host/device)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Common Pitfalls to Avoid:</p>

<p class=MsoNormal>- Assuming execution order</p>

<p class=MsoNormal>- Exceeding 1024 threads per block</p>

<p class=MsoNormal>- Forgetting to synchronize</p>

<p class=MsoNormal>- Not checking bounds in kernels</p>

<p class=MsoNormal>- Assuming blocks can communicate</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>This comprehensive guide covers all concepts, MCQs, exam
notes, numericals, and case studies for Lecture 03. Use it to build strong
foundational understanding of CUDA programming!</p>

<p class=MsoNormal>Retry</p>

<p class=MsoNormal>P</p>

<p class=MsoNormal>slide 11, 12, 13,14,15</p>

<p class=MsoNormal><b>Detailed Deep Dive: Slides 11-15</b></p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 11: Hello World! with Device Code (Part 1)</b></p>

<p class=MsoNormal><b>Easy Explanation:</b></p>

<p class=MsoNormal>This slide introduces the <b>simplest possible CUDA program</b>
that demonstrates GPU programming basics.</p>

<p class=MsoNormal><b>The Complete Program:</b></p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>__global__ void mykernel(void) {</p>

<p class=MsoNormal> // Empty function body - does nothing</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>int main(void) {</p>

<p class=MsoNormal> mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(); //
Launch kernel on GPU</p>

<p class=MsoNormal> printf(&quot;Hello World!\n&quot;); // Print on
CPU</p>

<p class=MsoNormal> return 0;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Breaking it down:**</p>

<p class=MsoNormal>- **`__global__`**: Special keyword marking GPU function</p>

<p class=MsoNormal>- **`mykernel`**: Name of our GPU function (kernel)</p>

<p class=MsoNormal>- **`&lt;&lt;&lt;1,1&gt;&gt;&gt;`**: Launch 1 block with 1
thread</p>

<p class=MsoNormal>- **`printf`**: Regular C function running on CPU</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Two Revolutionary Elements:**</p>

<p class=MsoNormal>1. `__global__` keyword - tells compiler this runs on GPU</p>

<p class=MsoNormal>2. `&lt;&lt;&lt;&gt;&gt;&gt;` syntax - launches code on GPU</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**What makes this special:**</p>

<p class=MsoNormal>Even though the kernel does nothing, this demonstrates the
fundamental pattern of ALL GPU programs.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Related MCQs:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Q1. What does `__global__` indicate?**</p>

<p class=MsoNormal>- a) A global variable accessible everywhere</p>

<p class=MsoNormal>- b) A function that runs on the device (GPU)</p>

<p class=MsoNormal>- c) A function that runs on the host (CPU)</p>

<p class=MsoNormal>- d) A constant value</p>

<p class=MsoNormal>- **Answer: b) A function that runs on the device (GPU)**</p>

<p class=MsoNormal>- **Explanation:** `__global__` is a CUDA keyword that marks
a function as a kernel - executable on the GPU but callable from CPU.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Q2. In `mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;()`, what do
the parameters mean?**</p>

<p class=MsoNormal>- a) 1 thread in 1 block</p>

<p class=MsoNormal>- b) 1 block with 1 thread</p>

<p class=MsoNormal>- c) 1 warp with 1 thread</p>

<p class=MsoNormal>- d) 1 grid with 1 block</p>

<p class=MsoNormal>- **Answer: b) 1 block with 1 thread**</p>

<p class=MsoNormal>- **Explanation:** First parameter = number of blocks,
second parameter = threads per block.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Q3. Where does the `printf(&quot;Hello World!\n&quot;)`
execute?**</p>

<p class=MsoNormal>- a) On GPU</p>

<p class=MsoNormal>- b) On CPU (host)</p>

<p class=MsoNormal>- c) On both GPU and CPU</p>

<p class=MsoNormal>- d) In shared memory</p>

<p class=MsoNormal>- **Answer: b) On CPU (host)**</p>

<p class=MsoNormal>- **Explanation:** This printf is in main(), which runs on
the host (CPU).</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Q4. Is an empty kernel (like mykernel) legal in CUDA?**</p>

<p class=MsoNormal>- a) No, kernels must have code</p>

<p class=MsoNormal>- b) Yes, but it's useless</p>

<p class=MsoNormal>- c) No, it causes compilation error</p>

<p class=MsoNormal>- d) Yes, and it's sometimes used for timing overhead</p>

<p class=MsoNormal>- **Answer: d) Yes, and it's sometimes used for timing
overhead**</p>

<p class=MsoNormal>- **Explanation:** Empty kernels are valid and can be used
to measure kernel launch overhead.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Q5. What does this program output?**</p>

<p class=MsoNormal>- a) Nothing</p>

<p class=MsoNormal>- b) &quot;Hello World!&quot;</p>

<p class=MsoNormal>- c) Error message</p>

<p class=MsoNormal>- d) GPU information</p>

<p class=MsoNormal>- **Answer: b) &quot;Hello World!&quot;**</p>

<p class=MsoNormal>- **Explanation:** The printf in main() executes and outputs
&quot;Hello World!&quot;.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Q6. How many threads execute the mykernel function?**</p>

<p class=MsoNormal>- a) 0</p>

<p class=MsoNormal>- b) 1</p>

<p class=MsoNormal>- c) 2</p>

<p class=MsoNormal>- d) 1024</p>

<p class=MsoNormal>- **Answer: b) 1**</p>

<p class=MsoNormal>- **Explanation:** `&lt;&lt;&lt;1,1&gt;&gt;&gt;` launches 1
block  1 thread = 1 thread.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Q7. Which statement is true about this program?**</p>

<p class=MsoNormal>- a) The kernel does meaningful work</p>

<p class=MsoNormal>- b) The program demonstrates basic CUDA syntax</p>

<p class=MsoNormal>- c) It requires GPU to run</p>

<p class=MsoNormal>- d) Both b and c</p>

<p class=MsoNormal>- **Answer: d) Both b and c**</p>

<p class=MsoNormal>- **Explanation:** It shows CUDA syntax and needs
CUDA-capable GPU.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Q8. What happens if no GPU is present?**</p>

<p class=MsoNormal>- a) Program runs on CPU automatically</p>

<p class=MsoNormal>- b) Compilation fails</p>

<p class=MsoNormal>- c) Runtime error occurs</p>

<p class=MsoNormal>- d) Kernel is skipped</p>

<p class=MsoNormal>- **Answer: c) Runtime error occurs**</p>

<p class=MsoNormal>- **Explanation:** CUDA requires compatible GPU; without it,
runtime error occurs.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Q9. Can you call mykernel like a regular function:
`mykernel()`?**</p>

<p class=MsoNormal>- a) Yes, it's equivalent</p>

<p class=MsoNormal>- b) No, must use `&lt;&lt;&lt;&gt;&gt;&gt;` syntax</p>

<p class=MsoNormal>- c) Only from device code</p>

<p class=MsoNormal>- d) Only with special compiler flag</p>

<p class=MsoNormal>- **Answer: b) No, must use `&lt;&lt;&lt;&gt;&gt;&gt;`
syntax**</p>

<p class=MsoNormal>- **Explanation:** Kernels must be launched with execution
configuration `&lt;&lt;&lt;&gt;&gt;&gt;`.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Q10. What is the minimum configuration for a kernel
launch?**</p>

<p class=MsoNormal>- a) `&lt;&lt;&lt;0,0&gt;&gt;&gt;`</p>

<p class=MsoNormal>- b) `&lt;&lt;&lt;1,1&gt;&gt;&gt;`</p>

<p class=MsoNormal>- c) `&lt;&lt;&lt;1,0&gt;&gt;&gt;`</p>

<p class=MsoNormal>- d) `&lt;&lt;&lt;0,1&gt;&gt;&gt;`</p>

<p class=MsoNormal>- **Answer: b) `&lt;&lt;&lt;1,1&gt;&gt;&gt;`**</p>

<p class=MsoNormal>- **Explanation:** Need at least 1 block and 1 thread.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Exam Notes:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Key Concepts:**</p>

<p class=MsoNormal>1. **Kernel Declaration**: `__global__ void
kernelName(parameters)`</p>

<p class=MsoNormal> - Must return void</p>

<p class=MsoNormal> - Can take parameters (not shown in this example)</p>

<p class=MsoNormal> - Runs on GPU, called from CPU</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **Minimal Kernel Launch**:
`kernelName&lt;&lt;&lt;1,1&gt;&gt;&gt;()`</p>

<p class=MsoNormal> - Simplest possible configuration</p>

<p class=MsoNormal> - 1 block, 1 thread</p>

<p class=MsoNormal> - Still demonstrates GPU execution</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **Program Structure**:</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal> [Kernel Definition] &#8594; __global__ function</p>

<p class=MsoNormal> [Main Function] &#8594; Host code</p>

<p class=MsoNormal> [Kernel Launch] &#8594; &lt;&lt;&lt;&gt;&gt;&gt; syntax</p>

<p class=MsoNormal> [Host Operations] &#8594; printf, etc.</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>4. **Execution Flow**:</p>

<p class=MsoNormal> - Program starts in main() on CPU</p>

<p class=MsoNormal> - Kernel launched to GPU</p>

<p class=MsoNormal> - CPU continues immediately (asynchronous)</p>

<p class=MsoNormal> - printf executes on CPU</p>

<p class=MsoNormal> - Program may exit before kernel finishes!</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>5. **Function Qualifiers** (Introduction):</p>

<p class=MsoNormal> - `__global__`: Kernel (CPU calls, GPU executes)</p>

<p class=MsoNormal> - `__device__`: GPU function (GPU calls, GPU executes) -
not shown yet</p>

<p class=MsoNormal> - `__host__`: CPU function (default, can be omitted)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Important Points for Exams:**</p>

<p class=MsoNormal>- Empty kernels are valid</p>

<p class=MsoNormal>- `&lt;&lt;&lt;&gt;&gt;&gt;` is mandatory for kernel
launches</p>

<p class=MsoNormal>- Kernels must return void</p>

<p class=MsoNormal>- Launch is asynchronous (non-blocking)</p>

<p class=MsoNormal>- Should use `cudaDeviceSynchronize()` before checking
results</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Common Mistakes:**</p>

<p class=MsoNormal>- Forgetting `__global__` keyword</p>

<p class=MsoNormal>- Using wrong launch syntax</p>

<p class=MsoNormal>- Assuming synchronous execution</p>

<p class=MsoNormal>- Trying to return values from kernels directly</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numericals:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1: Thread Count Calculation**</p>

<p class=MsoNormal>Given the kernel launch
`mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;()`, calculate:</p>

<p class=MsoNormal>a) Number of blocks</p>

<p class=MsoNormal>b) Threads per block</p>

<p class=MsoNormal>c) Total threads</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Solution:**</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>a) Number of blocks = 1</p>

<p class=MsoNormal>b) Threads per block = 1</p>

<p class=MsoNormal>c) Total threads = blocks  threads/block</p>

<p class=MsoNormal> = 1  1 = 1 thread</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2: Execution Time Analysis**</p>

<p class=MsoNormal>Measure the following:</p>

<p class=MsoNormal>- Kernel launch overhead: 20 &#956;s</p>

<p class=MsoNormal>- Empty kernel execution: ~0 &#956;s</p>

<p class=MsoNormal>- printf execution: 50 &#956;s</p>

<p class=MsoNormal>- Program exit overhead: 10 &#956;s</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate total program execution time.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Solution:**</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Without synchronization (asynchronous):</p>

<p class=MsoNormal>- Launch kernel: 20 &#956;s</p>

<p class=MsoNormal>- printf (overlapped with kernel): 50 &#956;s</p>

<p class=MsoNormal>- Exit: 10 &#956;s</p>

<p class=MsoNormal>- Total &#8776; 80 &#956;s (kernel completes during printf)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>With cudaDeviceSynchronize():</p>

<p class=MsoNormal>- Launch kernel: 20 &#956;s</p>

<p class=MsoNormal>- Wait for kernel: 0 &#956;s (empty)</p>

<p class=MsoNormal>- printf: 50 &#956;s</p>

<p class=MsoNormal>- Exit: 10 &#956;s</p>

<p class=MsoNormal>- Total = 80 &#956;s</p>

<p class=MsoNormal><b>Problem 3: Scaling the Launch</b> Modify the launch
configuration to use: a) 10 blocks, 1 thread each b) 1 block, 10 threads c) 5
blocks, 2 threads each</p>

<p class=MsoNormal>Calculate total threads for each.</p>

<p class=MsoNormal><b>Solution:</b></p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>a) mykernel&lt;&lt;&lt;10, 1&gt;&gt;&gt;();</p>

<p class=MsoNormal> Total threads = 10  1 = 10 threads</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>b) mykernel&lt;&lt;&lt;1, 10&gt;&gt;&gt;();</p>

<p class=MsoNormal> Total threads = 1  10 = 10 threads</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>c) mykernel&lt;&lt;&lt;5, 2&gt;&gt;&gt;();</p>

<p class=MsoNormal> Total threads = 5  2 = 10 threads</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Note: All launch 10 threads but organize them differently!</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 4: Memory Overhead**</p>

<p class=MsoNormal>Calculate memory used for this minimal program:</p>

<p class=MsoNormal>- Kernel code: 128 bytes</p>

<p class=MsoNormal>- Host code: 4 KB</p>

<p class=MsoNormal>- Stack per thread: 1 KB</p>

<p class=MsoNormal>- Constant memory: 64 KB (always allocated)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Solution:**</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For &lt;&lt;&lt;1,1&gt;&gt;&gt; configuration:</p>

<p class=MsoNormal>- Kernel code: 128 bytes</p>

<p class=MsoNormal>- Host code: 4 KB = 4,096 bytes</p>

<p class=MsoNormal>- Stack: 1 thread  1 KB = 1,024 bytes</p>

<p class=MsoNormal>- Constant memory: 64 KB = 65,536 bytes</p>

<p class=MsoNormal>- Total &#8776; 70,784 bytes &#8776; 69 KB</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>This is minimal GPU program overhead.</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 5: Compilation Size**</p>

<p class=MsoNormal>Given:</p>

<p class=MsoNormal>- Source code: hello.cu (15 lines)</p>

<p class=MsoNormal>- Compiled host code: 8 KB</p>

<p class=MsoNormal>- Compiled device code (PTX): 2 KB</p>

<p class=MsoNormal>- Compiled device code (SASS): 1 KB</p>

<p class=MsoNormal>- Linking overhead: 16 KB</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate total executable size.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Solution:**</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Total executable size:</p>

<p class=MsoNormal>= Host code + Device code (SASS) + Linking</p>

<p class=MsoNormal>= 8 KB + 1 KB + 16 KB</p>

<p class=MsoNormal>= 25 KB</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>(PTX is intermediate, not included in final binary)</p>

<p class=MsoNormal><b>Case Studies:</b></p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Case Study 1: Teaching CUDA - First Day of Class</b></p>

<p class=MsoNormal><b>Context:</b> Professor Johnson teaches &quot;Introduction
to GPU Computing&quot; at State University. On day one, students with zero CUDA
experience must write their first GPU program.</p>

<p class=MsoNormal><b>The Challenge:</b> Students are intimidated by:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>New syntax (__global__, &lt;&lt;&lt;&gt;&gt;&gt;)</li>
 <li class=MsoNormal>Fear of breaking expensive GPU hardware</li>
 <li class=MsoNormal>Complexity of parallel programming concepts</li>
 <li class=MsoNormal>Different mental model from CPU programming</li>
</ul>

<p class=MsoNormal><b>The Approach:</b> Start with the minimal &quot;Hello
World&quot; program:</p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>// hello_gpu.cu</p>

<p class=MsoNormal>__global__ void mykernel(void) {</p>

<p class=MsoNormal> // Intentionally empty</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>int main(void) {</p>

<p class=MsoNormal> mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;();</p>

<p class=MsoNormal> printf(&quot;Hello World!\n&quot;);</p>

<p class=MsoNormal> return 0;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal><b>Step-by-Step Learning Process:</b></p>

<p class=MsoNormal><b>Step 1: Compile and Run (5 minutes)</b></p>

<p class=MsoNormal>bash</p>

<p class=MsoNormal>$ nvcc hello_gpu.cu -o hello</p>

<p class=MsoNormal>$ ./hello</p>

<p class=MsoNormal>Hello World!</p>

<p class=MsoNormal><b>Student Reaction:</b> &quot;It works! That wasn't
scary!&quot;</p>

<p class=MsoNormal><b>Step 2: Understanding (10 minutes)</b> Professor
explains:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>&quot;__global__ means 'this runs on GPU'&quot;</li>
 <li class=MsoNormal>&quot;&lt;&lt;&lt;1,1&gt;&gt;&gt; means 'use 1
     worker'&quot;</li>
 <li class=MsoNormal>&quot;GPU does nothing, CPU prints&quot;</li>
</ul>

<p class=MsoNormal><b>Step 3: First Modification (10 minutes)</b> Add GPU
output:</p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>__global__ void mykernel(void) {</p>

<p class=MsoNormal> printf(&quot;Hello from GPU!\n&quot;);</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>int main(void) {</p>

<p class=MsoNormal> mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;();</p>

<p class=MsoNormal> cudaDeviceSynchronize(); // Wait for GPU</p>

<p class=MsoNormal> printf(&quot;Hello from CPU!\n&quot;);</p>

<p class=MsoNormal> return 0;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Output:</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Hello from GPU!</p>

<p class=MsoNormal>Hello from CPU!</p>

<p class=MsoNormal><b>Student Breakthrough:</b> &quot;The GPU can talk!&quot;</p>

<p class=MsoNormal><b>Step 4: Scale Up (15 minutes)</b></p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>__global__ void mykernel(void) {</p>

<p class=MsoNormal> printf(&quot;Hello from thread %d!\n&quot;,
threadIdx.x);</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>int main(void) {</p>

<p class=MsoNormal> mykernel&lt;&lt;&lt;1, 5&gt;&gt;&gt;(); // 5 threads</p>

<p class=MsoNormal> cudaDeviceSynchronize();</p>

<p class=MsoNormal> return 0;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Output:</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Hello from thread 0!</p>

<p class=MsoNormal>Hello from thread 2!</p>

<p class=MsoNormal>Hello from thread 1!</p>

<p class=MsoNormal>Hello from thread 4!</p>

<p class=MsoNormal>Hello from thread 3!</p>

<p class=MsoNormal><b>Key Learning:</b> &quot;Threads run in parallel! Order is
random!&quot;</p>

<p class=MsoNormal><b>Step 5: Multiple Blocks (15 minutes)</b></p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>__global__ void mykernel(void) {</p>

<p class=MsoNormal> printf(&quot;Block %d, Thread %d\n&quot;, blockIdx.x,
threadIdx.x);</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>int main(void) {</p>

<p class=MsoNormal> mykernel&lt;&lt;&lt;3, 2&gt;&gt;&gt;(); // 3 blocks, 2
threads each</p>

<p class=MsoNormal> cudaDeviceSynchronize();</p>

<p class=MsoNormal> return 0;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal><b>Outcomes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>25 out of 30 students successfully completed all steps</li>
 <li class=MsoNormal>Confidence boosted significantly</li>
 <li class=MsoNormal>Foundation set for complex topics</li>
 <li class=MsoNormal>Fear of GPU programming eliminated</li>
</ul>

<p class=MsoNormal><b>Professor's Insight:</b> &quot;Starting with an empty
kernel removes fear. Students see it's just C with special syntax. Once
comfortable, they're ready for real parallel algorithms.&quot;</p>

<p class=MsoNormal><b>Pedagogical Value:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Minimal syntax to learn initially</li>
 <li class=MsoNormal>Immediate success builds confidence</li>
 <li class=MsoNormal>Progressive complexity</li>
 <li class=MsoNormal>Hands-on from day one</li>
 <li class=MsoNormal>Demystifies GPU programming</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Case Study 2: Benchmarking GPU Launch Overhead</b></p>

<p class=MsoNormal><b>Context:</b> TechMetrics Inc. develops performance
analysis tools. They need to measure the overhead of launching GPU kernels to
help customers optimize their code.</p>

<p class=MsoNormal><b>The Problem:</b> Customers ask: &quot;How much time does
launching a kernel take?&quot;</p>

<p class=MsoNormal><b>The Experiment:</b> Use empty kernel to measure pure
launch overhead:</p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>// benchmark_launch.cu</p>

<p class=MsoNormal>__global__ void emptyKernel(void) {</p>

<p class=MsoNormal> // Intentionally empty - measures pure launch overhead</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>int main(void) {</p>

<p class=MsoNormal> cudaEvent_t start, stop;</p>

<p class=MsoNormal> cudaEventCreate(&amp;start);</p>

<p class=MsoNormal> cudaEventCreate(&amp;stop);</p>

<p class=MsoNormal> </p>

<p class=MsoNormal> // Warm up GPU</p>

<p class=MsoNormal> for(int i = 0; i &lt; 1000; i++) {</p>

<p class=MsoNormal> emptyKernel&lt;&lt;&lt;1,1&gt;&gt;&gt;();</p>

<p class=MsoNormal> }</p>

<p class=MsoNormal> cudaDeviceSynchronize();</p>

<p class=MsoNormal> </p>

<p class=MsoNormal> // Benchmark</p>

<p class=MsoNormal> cudaEventRecord(start);</p>

<p class=MsoNormal> for(int i = 0; i &lt; 10000; i++) {</p>

<p class=MsoNormal> emptyKernel&lt;&lt;&lt;1,1&gt;&gt;&gt;();</p>

<p class=MsoNormal> }</p>

<p class=MsoNormal> cudaEventRecord(stop);</p>

<p class=MsoNormal> cudaEventSynchronize(stop);</p>

<p class=MsoNormal> </p>

<p class=MsoNormal> float milliseconds = 0;</p>

<p class=MsoNormal> cudaEventElapsedTime(&amp;milliseconds, start, stop);</p>

<p class=MsoNormal> </p>

<p class=MsoNormal> printf(&quot;Average launch overhead: %.2f
microseconds\n&quot;, </p>

<p class=MsoNormal> (milliseconds * 1000) / 10000);</p>

<p class=MsoNormal> </p>

<p class=MsoNormal> return 0;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Results on Different GPUs:**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>| GPU Model | Launch Overhead | Launches/Second |</p>

<p class=MsoNormal>|-----------|----------------|-----------------|</p>

<p class=MsoNormal>| GTX 1080 | 5.2 &#956;s | 192,000 |</p>

<p class=MsoNormal>| RTX 3090 | 3.8 &#956;s | 263,000 |</p>

<p class=MsoNormal>| A100 | 2.1 &#956;s | 476,000 |</p>

<p class=MsoNormal>| H100 | 1.5 &#956;s | 667,000 |</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Analysis:**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Finding 1: Kernel Launch is Not Free**</p>

<p class=MsoNormal>- Even empty kernel has 1.5-5 &#956;s overhead</p>

<p class=MsoNormal>- For tiny computations, overhead dominates</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Finding 2: Newer GPUs Have Lower Overhead**</p>

<p class=MsoNormal>- H100 is 3.5 faster launch than GTX 1080</p>

<p class=MsoNormal>- Better for workloads with many small kernels</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Finding 3: Batch Size Matters**</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Scenario: Process 1 million small items</p>

<p class=MsoNormal>- Option A: 1 million kernels of 1 item each</p>

<p class=MsoNormal> Time = 1,000,000  5 &#956;s = 5,000 ms = 5 seconds</p>

<p class=MsoNormal> </p>

<p class=MsoNormal>- Option B: 1,000 kernels of 1,000 items each</p>

<p class=MsoNormal> Time = 1,000  5 &#956;s + computation = 5 ms +
computation</p>

<p class=MsoNormal> </p>

<p class=MsoNormal>Speedup: 1000 less launch overhead!</p>

<p class=MsoNormal><b>Customer Recommendations:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Batch work into fewer kernels</b></li>
 <li class=MsoNormal><b>For &lt;10 &#956;s computations, consider CPU</b></li>
 <li class=MsoNormal><b>Use kernel fusion where possible</b></li>
 <li class=MsoNormal><b>Persistent kernels for repeated small tasks</b></li>
</ol>

<p class=MsoNormal><b>Real-World Impact:</b> One customer reduced their
application runtime from 30 seconds to 2 seconds by batching 500,000 tiny
kernel launches into 500 larger ones.</p>

<p class=MsoNormal><b>Key Insight:</b> The empty kernel isn't useless - it's
the perfect tool for measuring system overheads that affect all CUDA programs.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Case Study 3: Debugging a Production System</b></p>

<p class=MsoNormal><b>Context:</b> DataFlow Systems runs a real-time analytics
platform processing millions of transactions per second. After a system update,
their CUDA application started hanging randomly.</p>

<p class=MsoNormal><b>The Symptom:</b></p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>__global__ void processTransaction(Transaction* txn) {</p>

<p class=MsoNormal> // Complex processing code</p>

<p class=MsoNormal> // ... 500 lines ...</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>int main() {</p>

<p class=MsoNormal> // ... initialization ...</p>

<p class=MsoNormal> </p>

<p class=MsoNormal> processTransaction&lt;&lt;&lt;blocks,
threads&gt;&gt;&gt;(d_transactions);</p>

<p class=MsoNormal> </p>

<p class=MsoNormal> printf(&quot;Processing complete!\n&quot;); // This
prints immediately</p>

<p class=MsoNormal> </p>

<p class=MsoNormal> // Access results - CRASH! Data not ready!</p>

<p class=MsoNormal> analyzeResults(h_transactions);</p>

<p class=MsoNormal> </p>

<p class=MsoNormal> return 0;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal><b>The Problem:</b> &quot;Processing complete!&quot;
printed, but GPU wasn't done yet!</p>

<p class=MsoNormal><b>Root Cause Analysis:</b></p>

<p class=MsoNormal><b>Step 1: Simplify to Minimal Example</b></p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>__global__ void mykernel(void) {</p>

<p class=MsoNormal> // Empty - should return instantly</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>int main(void) {</p>

<p class=MsoNormal> auto start = std::chrono::high_resolution_clock::now();</p>

<p class=MsoNormal> </p>

<p class=MsoNormal> mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;();</p>

<p class=MsoNormal> </p>

<p class=MsoNormal> auto end = std::chrono::high_resolution_clock::now();</p>

<p class=MsoNormal> auto duration =
std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(end - start);</p>

<p class=MsoNormal> </p>

<p class=MsoNormal> printf(&quot;Kernel 'completed' in %ld
microseconds\n&quot;, duration.count());</p>

<p class=MsoNormal> printf(&quot;But GPU might still be working!\n&quot;);</p>

<p class=MsoNormal> </p>

<p class=MsoNormal> return 0;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Output:</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Kernel 'completed' in 15 microseconds</p>

<p class=MsoNormal>But GPU might still be working!</p>

<p class=MsoNormal><b>Key Discovery:</b> Kernel launch returns immediately
(asynchronous)!</p>

<p class=MsoNormal><b>Step 2: The Fix</b></p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>int main() {</p>

<p class=MsoNormal> processTransaction&lt;&lt;&lt;blocks,
threads&gt;&gt;&gt;(d_transactions);</p>

<p class=MsoNormal> </p>

<p class=MsoNormal> // ADD THIS LINE</p>

<p class=MsoNormal> cudaDeviceSynchronize(); // Wait for GPU to finish</p>

<p class=MsoNormal> </p>

<p class=MsoNormal> printf(&quot;Processing complete!\n&quot;); // Now
truly complete</p>

<p class=MsoNormal> analyzeResults(h_transactions); // Safe to access</p>

<p class=MsoNormal> </p>

<p class=MsoNormal> return 0;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal><b>Lessons Learned:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Asynchronous Execution</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Kernel launches return immediately</li>
  <li class=MsoNormal>GPU works in background</li>
  <li class=MsoNormal>Must explicitly synchronize</li>
 </ul>
 <li class=MsoNormal><b>Hidden Synchronization Points</b></li>
</ol>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal> cudaMemcpy(..., cudaMemcpyDeviceToHost); // Implicit
sync</p>

<p class=MsoNormal> cudaDeviceSynchronize(); // Explicit
sync</p>

<ol style='margin-top:0in' start=3 type=1>
 <li class=MsoNormal><b>Testing Strategy</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Empty kernels help isolate synchronization bugs</li>
  <li class=MsoNormal>Test with minimal examples first</li>
  <li class=MsoNormal>Verify assumptions about async behavior</li>
 </ul>
</ol>

<p class=MsoNormal><b>Production Impact:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Bug fixed in 2 hours (empty kernel test revealed it
     quickly)</li>
 <li class=MsoNormal>Would have taken days to debug in complex production code</li>
 <li class=MsoNormal>Added synchronization checks to code review checklist</li>
 <li class=MsoNormal>Implemented CUDA error checking macros</li>
</ul>

<p class=MsoNormal><b>Error Checking Added:</b></p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>#define CUDA_CHECK(call) \</p>

<p class=MsoNormal> do { \</p>

<p class=MsoNormal> cudaError_t err = call; \</p>

<p class=MsoNormal> if (err != cudaSuccess) { \</p>

<p class=MsoNormal> fprintf(stderr, &quot;CUDA error at %s:%d:
%s\n&quot;, \</p>

<p class=MsoNormal> __FILE__, __LINE__,
cudaGetErrorString(err)); \</p>

<p class=MsoNormal> exit(EXIT_FAILURE); \</p>

<p class=MsoNormal> } \</p>

<p class=MsoNormal> } while(0)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>// Usage</p>

<p class=MsoNormal>CUDA_CHECK(cudaDeviceSynchronize());</p>

<p class=MsoNormal><b>Conclusion:</b> The simple &quot;Hello World&quot; empty
kernel isn't just for learning - it's a powerful debugging tool that can save
hours of troubleshooting in production systems.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 12: Hello World! with Device Code (Part 2) - The __global__
Keyword</b></p>

<p class=MsoNormal><b>Easy Explanation:</b></p>

<p class=MsoNormal>This slide dives deep into what __global__ means and how
CUDA compiles code.</p>

<p class=MsoNormal><b>Understanding __global__:</b></p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>__global__ void mykernel(void) {</p>

<p class=MsoNormal> // This code runs on GPU</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Three Critical Facts about `__global__`:**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>1. **Runs on the Device (GPU)**</p>

<p class=MsoNormal> - The function executes on GPU hardware</p>

<p class=MsoNormal> - Has access to GPU memory</p>

<p class=MsoNormal> - Uses GPU cores for computation</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **Called from Host (CPU) Code**</p>

<p class=MsoNormal> - You launch it from main() or other CPU functions</p>

<p class=MsoNormal> - Uses special `&lt;&lt;&lt;&gt;&gt;&gt;` syntax</p>

<p class=MsoNormal> - CPU initiates, GPU executes</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **Must Return `void`**</p>

<p class=MsoNormal> - Cannot return values directly</p>

<p class=MsoNormal> - Results must be returned via pointers/memory</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**The Compilation Magic:**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**nvcc** (NVIDIA CUDA Compiler) is smart - it separates your
code:</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal> your_program.cu</p>

<p class=MsoNormal> |</p>

<p class=MsoNormal> [nvcc sees]</p>

<p class=MsoNormal> |</p>

<p class=MsoNormal> +-------+-------+</p>

<p class=MsoNormal> | |</p>

<p class=MsoNormal> Device Code Host Code</p>

<p class=MsoNormal> (__global__) (main, etc.)</p>

<p class=MsoNormal> | |</p>

<p class=MsoNormal> NVIDIA PTX gcc/cl.exe</p>

<p class=MsoNormal> Compiler Compiler</p>

<p class=MsoNormal> | |</p>

<p class=MsoNormal> GPU Binary CPU Binary</p>

<p class=MsoNormal> | |</p>

<p class=MsoNormal> +-------+-------+</p>

<p class=MsoNormal> |</p>

<p class=MsoNormal> Final Executable</p>

<p class=MsoNormal><b>Analogy:</b> Think of nvcc like a bilingual translator:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Sees English (host code) &#8594; sends to English printer</li>
 <li class=MsoNormal>Sees Spanish (device code) &#8594; sends to Spanish
     printer</li>
 <li class=MsoNormal>Binds both printouts together into one book</li>
</ul>

<p class=MsoNormal><b>Related MCQs:</b></p>

<p class=MsoNormal><b>Q1. Where does a __global__ function execute?</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>a) On CPU only</li>
 <li class=MsoNormal>b) On GPU only</li>
 <li class=MsoNormal>c) On both CPU and GPU</li>
 <li class=MsoNormal>d) In system RAM</li>
 <li class=MsoNormal><b>Answer: b) On GPU only</b></li>
 <li class=MsoNormal><b>Explanation:</b> __global__ marks functions for GPU
     execution.</li>
</ul>

<p class=MsoNormal><b>Q2. Who can call a __global__ function?</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>a) Only device code</li>
 <li class=MsoNormal>b) Only host code</li>
 <li class=MsoNormal>c) Both host and device code</li>
 <li class=MsoNormal>d) Nobody directly</li>
 <li class=MsoNormal><b>Answer: b) Only host code</b></li>
 <li class=MsoNormal><b>Explanation:</b> Kernels are called from CPU code using
     &lt;&lt;&lt;&gt;&gt;&gt; syntax.</li>
</ul>

<p class=MsoNormal><b>Q3. What must a __global__ function return?</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>a) int</li>
 <li class=MsoNormal>b) float</li>
 <li class=MsoNormal>c) void</li>
 <li class=MsoNormal>d) Any type</li>
 <li class=MsoNormal><b>Answer: c) void</b></li>
 <li class=MsoNormal><b>Explanation:</b> CUDA kernels must return void; results
     passed via parameters.</li>
</ul>

<p class=MsoNormal><b>Q4. What compiler processes __global__ functions?</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>a) gcc</li>
 <li class=MsoNormal>b) g++</li>
 <li class=MsoNormal>c) NVIDIA compiler (part of nvcc)</li>
 <li class=MsoNormal>d) Any C++ compiler</li>
 <li class=MsoNormal><b>Answer: c) NVIDIA compiler (part of nvcc)</b></li>
 <li class=MsoNormal><b>Explanation:</b> Device code requires NVIDIA's
     specialized compiler.</li>
</ul>

<p class=MsoNormal><b>Q5. What does nvcc do with host functions like main()?</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>a) Compiles them itself</li>
 <li class=MsoNormal>b) Passes them to standard host compiler (gcc/cl.exe)</li>
 <li class=MsoNormal>c) Ignores them</li>
 <li class=MsoNormal>d) Converts them to GPU code</li>
 <li class=MsoNormal><b>Answer: b) Passes them to standard host compiler
     (gcc/cl.exe)</b></li>
 <li class=MsoNormal><b>Explanation:</b> nvcc separates code; host code goes to
     system compiler.</li>
</ul>

<p class=MsoNormal><b>Q6. Can a __global__ function call another __global__
function?</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>a) Yes, always</li>
 <li class=MsoNormal>b) Yes, but only on newer GPUs (dynamic parallelism)</li>
 <li class=MsoNormal>c) No, never</li>
 <li class=MsoNormal>d) Only with special flag</li>
 <li class=MsoNormal><b>Answer: b) Yes, but only on newer GPUs (dynamic
     parallelism)</b></li>
 <li class=MsoNormal><b>Explanation:</b> Dynamic parallelism (compute
     capability 3.5+) allows this.</li>
</ul>

<p class=MsoNormal><b>Q7. Which is correct syntax for a kernel?</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>a) global void kernel() {}</li>
 <li class=MsoNormal>b) __global__ int kernel() {}</li>
 <li class=MsoNormal>c) __global__ void kernel() {}</li>
 <li class=MsoNormal>d) void __global__ kernel() {}</li>
 <li class=MsoNormal><b>Answer: c) __global__ void kernel() {}</b></li>
 <li class=MsoNormal><b>Explanation:</b> Correct qualifier placement and return
     type.</li>
</ul>

<p class=MsoNormal><b>Q8. What happens if you try to call a kernel without &lt;&lt;&lt;&gt;&gt;&gt;?</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>a) It works normally</li>
 <li class=MsoNormal>b) Compilation error</li>
 <li class=MsoNormal>c) Runtime error</li>
 <li class=MsoNormal>d) Runs on CPU instead</li>
 <li class=MsoNormal><b>Answer: b) Compilation error</b></li>
 <li class=MsoNormal><b>Explanation:</b> Kernels require execution
     configuration.</li>
</ul>

<p class=MsoNormal><b>Q9. Where is the compiled GPU code stored?</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>a) In CPU memory</li>
 <li class=MsoNormal>b) In separate .gpu file</li>
 <li class=MsoNormal>c) Embedded in the executable</li>
 <li class=MsoNormal>d) On GPU firmware</li>
 <li class=MsoNormal><b>Answer: c) Embedded in the executable</b></li>
 <li class=MsoNormal><b>Explanation:</b> GPU binary (cubin/PTX) embedded in
     executable.</li>
</ul>

<p class=MsoNormal><b>Q10. What is PTX in CUDA compilation?</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>a) Parallel Thread Execution (intermediate assembly)</li>
 <li class=MsoNormal>b) A type of GPU</li>
 <li class=MsoNormal>c) A memory space</li>
 <li class=MsoNormal>d) A synchronization primitive</li>
 <li class=MsoNormal><b>Answer: a) Parallel Thread Execution (intermediate
     assembly)</b></li>
 <li class=MsoNormal><b>Explanation:</b> PTX is CUDA's intermediate
     representation, like LLVM IR.</li>
</ul>

<p class=MsoNormal><b>Q11. Can __global__ functions be called recursively?</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>a) Yes, always</li>
 <li class=MsoNormal>b) No, never</li>
 <li class=MsoNormal>c) Only with dynamic parallelism</li>
 <li class=MsoNormal>d) Only on CPU</li>
 <li class=MsoNormal><b>Answer: c) Only with dynamic parallelism</b></li>
 <li class=MsoNormal><b>Explanation:</b> Requires compute capability 3.5+ for
     device-side kernel launch.</li>
</ul>

<p class=MsoNormal><b>Q12. Which standard host compiler is used on Windows?</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>a) gcc</li>
 <li class=MsoNormal>b) cl.exe (Microsoft Visual C++)</li>
 <li class=MsoNormal>c) clang</li>
 <li class=MsoNormal>d) icc</li>
 <li class=MsoNormal><b>Answer: b) cl.exe (Microsoft Visual C++)</b></li>
 <li class=MsoNormal><b>Explanation:</b> nvcc uses cl.exe on Windows, gcc on
     Linux.</li>
</ul>

<p class=MsoNormal><b>Q13. Can you mix CUDA and regular C++ in one file?</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>a) No, separate files required</li>
 <li class=MsoNormal>b) Yes, nvcc handles both</li>
 <li class=MsoNormal>c) Only for simple programs</li>
 <li class=MsoNormal>d) Only with special pragma</li>
 <li class=MsoNormal><b>Answer: b) Yes, nvcc handles both</b></li>
 <li class=MsoNormal><b>Explanation:</b> .cu files can contain both host and
     device code.</li>
</ul>

<p class=MsoNormal><b>Q14. What is the file extension for CUDA source code?</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>a) .c</li>
 <li class=MsoNormal>b) .cpp</li>
 <li class=MsoNormal>c) .cu</li>
 <li class=MsoNormal>d) .cuda</li>
 <li class=MsoNormal><b>Answer: c) .cu</b></li>
 <li class=MsoNormal><b>Explanation:</b> .cu extension indicates CUDA C/C++
     source file.</li>
</ul>

<p class=MsoNormal><b>Q15. Which compilation phase generates GPU-specific
machine code?</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>a) Preprocessing</li>
 <li class=MsoNormal>b) PTX generation</li>
 <li class=MsoNormal>c) SASS generation</li>
 <li class=MsoNormal>d) Linking</li>
 <li class=MsoNormal><b>Answer: c) SASS generation</b></li>
 <li class=MsoNormal><b>Explanation:</b> SASS (Shader Assembly) is GPU-specific
     machine code.</li>
</ul>

<p class=MsoNormal><b>Exam Notes:</b></p>

<p class=MsoNormal><b>CUDA Function Qualifiers (Complete Picture):</b></p>

<table class=MsoNormalTable border=0 cellspacing=3 cellpadding=0>
 <thead>
  <tr>
   <td style='padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Qualifier</b></p>
   </td>
   <td style='padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Executed On</b></p>
   </td>
   <td style='padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Callable From</b></p>
   </td>
   <td style='padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Return Type</b></p>
   </td>
  </tr>
 </thead>
 <tr>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>__global__</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Device (GPU)</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Host (CPU)</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>void only</p>
  </td>
 </tr>
 <tr>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>__device__</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Device (GPU)</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Device (GPU)</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Any</p>
  </td>
 </tr>
 <tr>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>__host__</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Host (CPU)</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Host (CPU)</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Any</p>
  </td>
 </tr>
 <tr>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>(none)</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Host (CPU)</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Host (CPU)</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Any</p>
  </td>
 </tr>
</table>

<p class=MsoNormal><b>Combination Example:</b></p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>__host__ __device__ float add(float a, float b) {</p>

<p class=MsoNormal> return a + b;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>// Can be called from both CPU and GPU!</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Compilation Pipeline in Detail:**</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Source Code (hello.cu)</p>

<p class=MsoNormal> &#8595;</p>

<p class=MsoNormal> [nvcc preprocessor]</p>

<p class=MsoNormal> &#8595;</p>

<p class=MsoNormal> Code Separation</p>

<p class=MsoNormal> &#8595;</p>

<p class=MsoNormal> &#9484;&#9472;&#9472;&#9472;<span style='font-family:
"MS Gothic"'>&#9524;</span>&#9472;&#9472;&#9472;&#9488;</p>

<p class=MsoNormal> &#8595; &#8595;</p>

<p class=MsoNormal>Device Host</p>

<p class=MsoNormal>Code Code</p>

<p class=MsoNormal> &#8595; &#8595;</p>

<p class=MsoNormal>NVIDIA gcc/cl.exe</p>

<p class=MsoNormal>Compiler Compiler</p>

<p class=MsoNormal> &#8595; &#8595;</p>

<p class=MsoNormal> PTX Object</p>

<p class=MsoNormal> &#8595; &#8595; File</p>

<p class=MsoNormal> &#8595; SASS (.o)</p>

<p class=MsoNormal> &#8595; &#8595; &#8595;</p>

<p class=MsoNormal> Embedded &#8595;</p>

<p class=MsoNormal> &#8595; &#8595;</p>

<p class=MsoNormal> Linker</p>

<p class=MsoNormal> &#8595;</p>

<p class=MsoNormal> Executable</p>

<p class=MsoNormal><b>Important Compilation Details:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>PTX (Parallel Thread Execution)</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Intermediate representation</li>
  <li class=MsoNormal>Platform-independent</li>
  <li class=MsoNormal>Like LLVM IR or Java bytecode</li>
  <li class=MsoNormal>Can be JIT-compiled for newer GPUs</li>
 </ul>
 <li class=MsoNormal><b>SASS (Shader Assembly)</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>GPU-specific machine code</li>
  <li class=MsoNormal>Optimized for specific architecture</li>
  <li class=MsoNormal>Directly executable by GPU</li>
 </ul>
 <li class=MsoNormal><b>Fat Binary</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Contains multiple versions (PTX + SASS)</li>
  <li class=MsoNormal>Supports multiple GPU architectures</li>
  <li class=MsoNormal>JIT compiles PTX if exact match not found</li>
 </ul>
</ol>

<p class=MsoNormal><b>nvcc Compilation Flags:</b></p>

<p class=MsoNormal>bash</p>

<p class=MsoNormal><i># Basic compilation</i></p>

<p class=MsoNormal>nvcc hello.cu -o hello</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><i># Specify GPU architecture</i></p>

<p class=MsoNormal>nvcc -arch=sm_75 hello.cu -o hello <i># For RTX 2080</i></p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><i># Keep intermediate files</i></p>

<p class=MsoNormal>nvcc --keep hello.cu -o hello <i># See PTX, SASS</i></p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><i># Verbose output</i></p>

<p class=MsoNormal>nvcc -v hello.cu -o hello <i># Show compilation
steps</i></p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><i># Generate PTX only</i></p>

<p class=MsoNormal>nvcc -ptx hello.cu <i># Creates hello.ptx</i></p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><i># Multiple architectures (fat binary)</i></p>

<p class=MsoNormal>nvcc -gencode arch=compute_70,code=sm_70 \</p>

<p class=MsoNormal> -gencode arch=compute_80,code=sm_80 \</p>

<p class=MsoNormal> hello.cu -o hello</p>

<p class=MsoNormal><b>Key Rules to Remember:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>__global__ functions:</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Must return void</li>
  <li class=MsoNormal>Called with &lt;&lt;&lt;&gt;&gt;&gt; syntax</li>
  <li class=MsoNormal>Asynchronous (non-blocking)</li>
  <li class=MsoNormal>Cannot take address (&amp;kernel is invalid)</li>
  <li class=MsoNormal>Cannot be class members in early CUDA versions</li>
 </ul>
 <li class=MsoNormal><b>__device__ functions:</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Helper functions for kernels</li>
  <li class=MsoNormal>Can return any type</li>
  <li class=MsoNormal>Called normally from device code</li>
  <li class=MsoNormal>Not directly callable from host</li>
 </ul>
 <li class=MsoNormal><b>__host__ functions:</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Regular C/C++ functions</li>
  <li class=MsoNormal>Default qualifier</li>
  <li class=MsoNormal>Usually omitted</li>
 </ul>
</ol>

<p class=MsoNormal><b>Common Compilation Errors:</b></p>

<p class=MsoNormal>cuda</p>

<p class=MsoNormal>// ERROR 1: Kernel returns non-void</p>

<p class=MsoNormal>__global__ int kernel() { // <span style='font-family:"Segoe UI Emoji",sans-serif'>&#10060;</span>
Wrong!</p>

<p class=MsoNormal> return 5;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>// CORRECT:</p>

<p class=MsoNormal>__global__ void kernel(int* result) { // &#10003; Right!</p>

<p class=MsoNormal> *result = 5;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>// ERROR 2: Missing execution configuration</p>

<p class=MsoNormal>kernel(); // <span style='font-family:"Segoe UI Emoji",sans-serif'>&#10060;</span>
Wrong!</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>// CORRECT:</p>

<p class=MsoNormal>kernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(); // &#10003; Right!</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>// ERROR 3: Device function called from host</p>

<p class=MsoNormal>__device__ float helper() { return 1.0f; }</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>void cpuFunction() {</p>

<p class=MsoNormal> float x = helper(); // <span style='font-family:"Segoe UI Emoji",sans-serif'>&#10060;</span>
Wrong!</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>// CORRECT:</p>

<p class=MsoNormal>__device__ float helper() { return 1.0f; }</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>__global__ void kernel() {</p>

<p class=MsoNormal> float x = helper(); // &#10003; Right!</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numericals:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1: Compilation Time Analysis**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Given a CUDA program with:</p>

<p class=MsoNormal>- 500 lines of host code</p>

<p class=MsoNormal>- 2000 lines of device code</p>

<p class=MsoNormal>- Host compilation rate: 1000 lines/second</p>

<p class=MsoNormal>- Device compilation rate: 400 lines/second</p>

<p class=MsoNormal>- Linking time: 0.5 seconds</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate total compilation time for:</p>

<p class=MsoNormal>a) Sequential compilation</p>

<p class=MsoNormal>b) Parallel compilation (host and device compile
simultaneously)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Solution:**</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>a) Sequential:</p>

<p class=MsoNormal>Host time = 500 lines / 1000 lines/sec = 0.5 seconds</p>

<p class=MsoNormal>Device time = 2000 lines / 400 lines/sec = 5.0 seconds</p>

<p class=MsoNormal>Linking = 0.5 seconds</p>

<p class=MsoNormal>Total = 0.5 + 5.0 + 0.5 = 6.0 seconds</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>b) Parallel (modern nvcc):</p>

<p class=MsoNormal>Host and device compile in parallel: max(0.5, 5.0) = 5.0
seconds</p>

<p class=MsoNormal>Linking = 0.5 seconds</p>

<p class=MsoNormal>Total = 5.0 + 0.5 = 5.5 seconds</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Speedup = 6.0 / 5.5 = 1.09 (9% faster)</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2: Binary Size Calculation**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>A CUDA program generates:</p>

<p class=MsoNormal>- Host code object file: 45 KB</p>

<p class=MsoNormal>- PTX code: 12 KB </p>

<p class=MsoNormal>- SASS for sm_70: 8 KB</p>

<p class=MsoNormal>- SASS for sm_80: 10 KB</p>

<p class=MsoNormal>- SASS for sm_89: 9 KB</p>

<p class=MsoNormal>- Debug symbols: 30 KB</p>

<p class=MsoNormal>- Linking overhead: 5 KB</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate:</p>

<p class=MsoNormal>a) Release build size (no debug)</p>

<p class=MsoNormal>b) Debug build size</p>

<p class=MsoNormal>c) PTX-only build size</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Solution:**</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>a) Release build:</p>

<p class=MsoNormal>= Host code + all SASS versions + linking</p>

<p class=MsoNormal>= 45 + 8 + 10 + 9 + 5 = 77 KB</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>(PTX not included in release with SASS)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>b) Debug build:</p>

<p class=MsoNormal>= Release build + Debug symbols</p>

<p class=MsoNormal>= 77 + 30 = 107 KB</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>c) PTX-only build (forward compatible):</p>

<p class=MsoNormal>= Host code + PTX + linking</p>

<p class=MsoNormal>= 45 + 12 + 5 = 62 KB</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Note: PTX-only is smaller but requires JIT compilation at
runtime</p>

<p class=MsoNormal><b>Problem 3: Compilation Flags Impact</b></p>

<p class=MsoNormal>Compare executable sizes for different compilation
strategies:</p>

<p class=MsoNormal>Retry</p>

<p class=MsoNormal>This response paused because Claude reached its max length
for a message. Hit continue to nudge Claude along.</p>

<p class=MsoNormal>Continue</p>

<p class=MsoNormal><a
href="https://support.anthropic.com/en/articles/8525154-claude-is-providing-incorrect-or-misleading-responses-what-s-going-on"
target="_blank">Claude can make mistakes. <br>
Please double-check responses.</a></p>

<p class=MsoNormal>Session limit reached &#8729; resets 6:30 PM</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<div style='border:none;border-bottom:double windowtext 2.25pt;padding:0in 0in 1.0pt 0in'>

<p class=MsoNormal style='border:none;padding:0in'>&nbsp;</p>

</div>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Thanks for sharing the lecture slides on <b>GPU Programming
(Lecture 03)</b>. Ill now go slide by slide and provide the following for
each:</p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Easy explanation of concepts</b></li>
 <li class=MsoNormal><b>Related MCQs</b></li>
 <li class=MsoNormal><b>Exam notes</b></li>
 <li class=MsoNormal><b>Numerical examples</b></li>
 <li class=MsoNormal><b>Case studies or real-world analogies</b></li>
</ol>

<p class=MsoNormal>Lets begin with <b>Slide 3</b> (first content slide):</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Slide 3: Hierarchy of Kernel, Block, Warp, and Thread</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
Easy Explanation:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>In CUDA programming, the <b>host (CPU)</b> launches a <b>kernel
     (GPU function)</b> using triple angle brackets &lt;&lt;&lt; &gt;&gt;&gt;.</li>
 <li class=MsoNormal>Inside these brackets, you specify: </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal><b>Number of blocks</b></li>
  <li class=MsoNormal><b>Number of threads per block</b></li>
 </ul>
 <li class=MsoNormal>Example: </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Kernel1&lt;&lt;&lt;100, 256&gt;&gt;&gt; launches 100
      blocks, each with 256 threads &#8594; total 25,600 threads.</li>
  <li class=MsoNormal>Kernel2&lt;&lt;&lt;50, 1024&gt;&gt;&gt; &#8594; 51,200
      threads.</li>
 </ul>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Kernel</b>: Function executed on GPU.</li>
 <li class=MsoNormal><b>Block</b>: Group of threads.</li>
 <li class=MsoNormal><b>Thread</b>: Smallest unit of execution.</li>
 <li class=MsoNormal><b>Warp</b>: Group of 32 threads executed together.</li>
 <li class=MsoNormal><b>Launch Syntax</b>: kernel&lt;&lt;&lt;numBlocks,
     threadsPerBlock&gt;&gt;&gt;();</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#10067;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What does &lt;&lt;&lt;100, 256&gt;&gt;&gt; represent in
     CUDA?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. 100 threads in 256 blocks</li>
  <li class=MsoNormal>B. 256 blocks in 100 threads</li>
  <li class=MsoNormal>C. 100 blocks with 256 threads each <span
      style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>D. 256 warps with 100 threads each</li>
 </ul>
 <li class=MsoNormal>How many threads are launched in &lt;&lt;&lt;50,
     1024&gt;&gt;&gt;?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. 5120</li>
  <li class=MsoNormal>B. 50</li>
  <li class=MsoNormal>C. 1024</li>
  <li class=MsoNormal>D. 51200 <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
 </ul>
</ol>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numericals:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Calculate total threads for &lt;&lt;&lt;60,
     512&gt;&gt;&gt;: </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Threads = 60  512 = <b>30,720</b></li>
 </ul>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128216;</span>
Case Study:</b></p>

<p class=MsoNormal>Imagine a video processing app that applies a filter to each
pixel. If the image has 25,600 pixels, launching &lt;&lt;&lt;100,
256&gt;&gt;&gt; threads allows each thread to process one pixel in parallel,
speeding up the operation significantly.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal>Would you like me to continue with the next slide in the
same format?</p>

<p class=MsoNormal>Sources</p>

<p class=MsoNormal><b>Provide your feedback on BizChat</b></p>

<p class=MsoNormal><b>You said: </b></p>

<p class=MsoNormal>yes</p>

<p class=MsoNormal><b>Copilot said: </b></p>

<p class=MsoNormal>Copilot</p>

<p class=MsoNormal>Great! Lets move on to <b>Slide 4</b>.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Slide 4: Organization of Thread Blocks</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
Easy Explanation:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>CUDA allows organizing threads in <b>1D, 2D, or 3D</b>
     arrays for flexibility.</li>
 <li class=MsoNormal><b>Thread blocks</b> are grouped into a <b>grid</b>.</li>
 <li class=MsoNormal>Each block runs <b>independently</b>no communication
     between blocks.</li>
 <li class=MsoNormal>The total number of threads = threads per block  number
     of blocks.</li>
 <li class=MsoNormal><b>Hardware limits</b> the number of threads per block due
     to <b>register availability</b>.</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Thread Block</b>: A group of threads that can cooperate
     via shared memory.</li>
 <li class=MsoNormal><b>Grid</b>: A collection of thread blocks.</li>
 <li class=MsoNormal><b>Thread Organization</b>: Can be 1D, 2D, or 3D.</li>
 <li class=MsoNormal><b>No inter-block communication</b>.</li>
 <li class=MsoNormal><b>Thread limit per block</b>: Typically 1024 (depends on
     GPU architecture).</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#10067;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is the maximum number of threads typically allowed
     per block in CUDA?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. 512</li>
  <li class=MsoNormal>B. 1024 <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>C. 2048</li>
  <li class=MsoNormal>D. Unlimited</li>
 </ul>
 <li class=MsoNormal>Why cant blocks in a grid communicate with each other?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. CUDA doesnt support shared memory</li>
  <li class=MsoNormal>B. Blocks are executed independently <span
      style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>C. Threads are not synchronized</li>
  <li class=MsoNormal>D. Registers are shared globally</li>
 </ul>
</ol>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numericals:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>If you launch a kernel with &lt;&lt;&lt;20, dim3(16,
     16)&gt;&gt;, how many threads are launched? </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Threads per block = 16  16 = 256</li>
  <li class=MsoNormal>Total threads = 20  256 = <b>5120</b></li>
 </ul>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128216;</span>
Case Study:</b></p>

<p class=MsoNormal>Imagine a weather simulation where each thread block
simulates a region (e.g., a city). Since cities dont need to share data during
simulation, blocks can run independently. This makes CUDA ideal for such <b>embarrassingly
parallel</b> problems.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal>Would you like to continue with <b>Slide 5</b> next?</p>

<p class=MsoNormal><b>Provide your feedback on BizChat</b></p>

<p class=MsoNormal><b>You said: </b></p>

<p class=MsoNormal>yes</p>

<p class=MsoNormal><b>Copilot said: </b></p>

<p class=MsoNormal>Copilot</p>

<p class=MsoNormal>Continuing with <b>Slide 5</b>:</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Slide 5: Grids Blocks of Threads</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
Easy Explanation:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>CUDA organizes threads into <b>blocks</b>, and blocks into
     a <b>grid</b>.</li>
 <li class=MsoNormal>This hierarchical structure allows for <b>massive
     parallelism</b>.</li>
 <li class=MsoNormal>Each <b>grid</b> contains multiple <b>blocks</b>, and each
     block contains multiple <b>threads</b>.</li>
 <li class=MsoNormal>Threads within a block can <b>communicate</b> using shared
     memory, but blocks <b>cannot</b> communicate with each other.</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Grid</b>: Collection of blocks.</li>
 <li class=MsoNormal><b>Block</b>: Collection of threads.</li>
 <li class=MsoNormal><b>Thread</b>: Executes kernel code.</li>
 <li class=MsoNormal><b>Communication</b>: </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Threads in a block &#8594; Yes (via shared memory)</li>
  <li class=MsoNormal>Blocks in a grid &#8594; No</li>
 </ul>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#10067;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Which of the following can communicate using shared
     memory?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. Threads in different blocks</li>
  <li class=MsoNormal>B. Blocks in a grid</li>
  <li class=MsoNormal>C. Threads in the same block <span style='font-family:
      "Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>D. All threads in the grid</li>
 </ul>
 <li class=MsoNormal>What is the correct hierarchy in CUDA?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. Grid &#8594; Thread &#8594; Block</li>
  <li class=MsoNormal>B. Block &#8594; Grid &#8594; Thread</li>
  <li class=MsoNormal>C. Grid &#8594; Block &#8594; Thread <span
      style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>D. Thread &#8594; Block &#8594; Grid</li>
 </ul>
</ol>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numericals:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>If a grid has 10 blocks and each block has 512 threads,
     how many threads are launched? </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Total threads = 10  512 = <b>5120</b></li>
 </ul>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128216;</span>
Case Study:</b></p>

<p class=MsoNormal>Consider a facial recognition system processing multiple
images. Each image is assigned to a block, and threads within the block process
pixels or features. This structure allows parallel processing of multiple
images efficiently.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal>Would you like to proceed with <b>Slide 6</b> next?</p>

<p class=MsoNormal><b>Provide your feedback on BizChat</b></p>

<p class=MsoNormal><b>You said: </b></p>

<p class=MsoNormal>don't ask. proceed</p>

<p class=MsoNormal><b>Copilot said: </b></p>

<p class=MsoNormal>Copilot</p>

<p class=MsoNormal>Continuing with <b>Slide 6</b>:</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Slide 6: Grids of Blocks of Threads  Dimension Limits</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
Easy Explanation:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>CUDA allows defining <b>grids</b> and <b>blocks</b> in <b>1D,
     2D, or 3D</b>.</li>
 <li class=MsoNormal>However, there are <b>hardware-imposed limits</b> on the
     dimensions: </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal><b>Threads per block</b>: Max is usually <b>1024</b>.</li>
  <li class=MsoNormal><b>Block dimensions</b> (x, y, z): Each has its own max
      value.</li>
  <li class=MsoNormal><b>Grid dimensions</b> also have limits (e.g., 65535 in x
      and y).</li>
 </ul>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>dim3</b> is used to define dimensions.</li>
 <li class=MsoNormal><b>Limits</b> vary by GPU architecture (check CUDA specs).</li>
 <li class=MsoNormal>Example: </li>
</ul>

<p class=MsoNormal>C++</p>

<p class=MsoNormal>dim3 threads(16, 16); // 256 threads per block</p>

<p class=MsoNormal>dim3 blocks(32, 32); // 1024 blocks in grid</p>

<p class=MsoNormal>Show more lines</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#10067;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is the maximum number of threads per block in CUDA?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. 512</li>
  <li class=MsoNormal>B. 1024 <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>C. 2048</li>
  <li class=MsoNormal>D. 4096</li>
 </ul>
 <li class=MsoNormal>Which of the following is true about CUDA grid dimensions?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. Grid dimensions are unlimited</li>
  <li class=MsoNormal>B. Grid dimensions are limited by hardware <span
      style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>C. Grid dimensions must be 1D</li>
  <li class=MsoNormal>D. Grid dimensions must be equal to block dimensions</li>
 </ul>
</ol>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numericals:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>If you define: </li>
</ul>

<p class=MsoNormal>C++</p>

<p class=MsoNormal>dim3 threads(32, 32); // 1024 threads per block</p>

<p class=MsoNormal>dim3 blocks(64, 64); // 4096 blocks</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Show more lines</p>

<p class=MsoNormal>Total threads = 1024  4096 = <b>4,194,304</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128216;</span>
Case Study:</b></p>

<p class=MsoNormal>In a <b>3D medical imaging</b> application, each voxel (3D
pixel) can be processed by a thread. CUDAs 3D grid/block structure allows
mapping threads directly to voxel coordinates, making parallel processing
intuitive and efficient.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Continuing with Slide 7 next.</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Slide 7: Programming Basics  dim3 Example</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
Easy Explanation:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>dim3 is a CUDA data type used to define <b>dimensions</b>
     (x, y, z) for blocks and grids.</li>
 <li class=MsoNormal>You can initialize it with: </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>One value &#8594; x is set, y and z default to 1.</li>
  <li class=MsoNormal>Two values &#8594; x and y set, z defaults to 1.</li>
  <li class=MsoNormal>Three values &#8594; x, y, and z all set.</li>
 </ul>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>dim3 is used for defining: </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal><b>Threads per block</b></li>
  <li class=MsoNormal><b>Blocks per grid</b></li>
 </ul>
 <li class=MsoNormal>Examples: </li>
</ul>

<p class=MsoNormal>C++</p>

<p class=MsoNormal>dim3 threads(256); // x = 256, y = 1, z = 1</p>

<p class=MsoNormal>dim3 blocks(100, 100); // x = 100, y = 100, z = 1</p>

<p class=MsoNormal>dim3 anotherOne(10, 54, 32); // x = 10, y = 54, z = 32</p>

<p class=MsoNormal>``</p>

<p class=MsoNormal>Show more lines</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#10067;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What does dim3 threads(256); initialize?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. x = 256, y = 256, z = 256</li>
  <li class=MsoNormal>B. x = 256, y = 1, z = 1 <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>C. x = 1, y = 256, z = 1</li>
  <li class=MsoNormal>D. x = 256, y = 0, z = 0</li>
 </ul>
 <li class=MsoNormal>Which of the following is a valid dim3 initialization?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. dim3(10, 20, 30) <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>B. dim3(10, 20, 30, 40)</li>
  <li class=MsoNormal>C. dim3(10)</li>
  <li class=MsoNormal>D. Both A and C <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
 </ul>
</ol>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numericals:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Given dim3 blocks(10, 20, 2) and dim3 threads(8, 8, 4): </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Threads per block = 8  8  4 = 256</li>
  <li class=MsoNormal>Total blocks = 10  20  2 = 400</li>
  <li class=MsoNormal>Total threads = 256  400 = <b>102,400</b></li>
 </ul>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128216;</span>
Case Study:</b></p>

<p class=MsoNormal>In a <b>3D simulation of fluid dynamics</b>, each thread can
represent a point in space. Using dim3(10, 54, 32) allows mapping threads to a
3D grid, making it easier to simulate interactions in all directions.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal>Continuing with <b>Slide 8</b> next.</p>

<p class=MsoNormal><b>Provide your feedback on BizChat</b></p>

<p class=MsoNormal><b>You said: </b></p>

<p class=MsoNormal>yes</p>

<p class=MsoNormal><b>Copilot said: </b></p>

<p class=MsoNormal>Copilot</p>

<p class=MsoNormal>Continuing with <b>Slide 8</b>:</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Slide 8: Programming Basics  Execution Order</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
Easy Explanation:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>CUDA threads <b>do not execute in a fixed order</b>.</li>
 <li class=MsoNormal>The <b>execution order is undefined</b>some threads may
     finish earlier than others.</li>
 <li class=MsoNormal>This randomness is due to how GPU schedules threads based
     on availability and resources.</li>
 <li class=MsoNormal>You should <b>not rely on execution order</b> for
     correctness unless explicitly synchronized.</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>CUDA threads are <b>asynchronous</b>.</li>
 <li class=MsoNormal>Execution order is <b>non-deterministic</b>.</li>
 <li class=MsoNormal>Use <b>synchronization primitives</b> (e.g., __syncthreads())
     if order matters.</li>
 <li class=MsoNormal>Avoid writing code that depends on thread execution
     sequence.</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#10067;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is true about CUDA thread execution order?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. It is sequential</li>
  <li class=MsoNormal>B. It is deterministic</li>
  <li class=MsoNormal>C. It is undefined <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>D. It follows block order</li>
 </ul>
 <li class=MsoNormal>Which CUDA function is used to synchronize threads within
     a block?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. cudaSync()</li>
  <li class=MsoNormal>B. __syncthreads() <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>C. syncThreads()</li>
  <li class=MsoNormal>D. cudaBarrier()</li>
 </ul>
</ol>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numericals:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Suppose 1024 threads are launched. If 300 threads finish
     early due to faster memory access, the remaining 724 may still be
     executing. This illustrates <b>non-uniform completion</b>.</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128216;</span>
Case Study:</b></p>

<p class=MsoNormal>In a <b>parallel sorting algorithm</b>, if threads are not
synchronized, some may read outdated values. This can lead to incorrect
results. Hence, synchronization is crucial when thread execution order affects
data integrity.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal>Continuing with <b>Slide 9</b> next.</p>

<p class=MsoNormal><b>Provide your feedback on BizChat</b></p>

<p class=MsoNormal><b>You said: </b></p>

<p class=MsoNormal>yes</p>

<p class=MsoNormal><b>Copilot said: </b></p>

<p class=MsoNormal>Copilot</p>

<p class=MsoNormal>Continuing with <b>Slide 9</b>:</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Slide 9: Programming Basics  Continued Example</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
Easy Explanation:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>This slide likely continues the example from earlier
     slides, reinforcing that: </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>CUDA threads are <b>mapped arbitrarily</b> to the problem
      space.</li>
  <li class=MsoNormal>The <b>execution order is not guaranteed</b>.</li>
  <li class=MsoNormal>CUDAs parallelism means many threads run simultaneously,
      but not in a predictable sequence.</li>
 </ul>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>CUDA threads are <b>scheduled dynamically</b>.</li>
 <li class=MsoNormal><b>Thread mapping</b> to data is flexible but unordered.</li>
 <li class=MsoNormal>Use <b>thread indices</b> (threadIdx, blockIdx) to assign
     work.</li>
 <li class=MsoNormal>Always design kernels to be <b>order-independent</b> unless
     synchronization is used.</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#10067;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What does threadIdx.x represent in CUDA?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. Index of the block</li>
  <li class=MsoNormal>B. Index of the thread within a block <span
      style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>C. Index of the grid</li>
  <li class=MsoNormal>D. Index of the warp</li>
 </ul>
 <li class=MsoNormal>Why is CUDA thread execution order undefined?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. Threads are executed sequentially</li>
  <li class=MsoNormal>B. GPU schedules threads based on availability <span
      style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>C. Threads are synchronized by default</li>
  <li class=MsoNormal>D. CUDA uses a fixed thread scheduler</li>
 </ul>
</ol>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numericals:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>If a kernel is launched with &lt;&lt;&lt;10,
     256&gt;&gt;&gt;, and each thread processes one element of an array: </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Total threads = 10  256 = <b>2560</b></li>
  <li class=MsoNormal>Each thread can access its element using: </li>
 </ul>
</ul>

<p class=MsoNormal>C++</p>

<p class=MsoNormal>int idx = threadIdx.x + blockIdx.x * blockDim.x;</p>

<p class=MsoNormal>Show more lines</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128216;</span>
Case Study:</b></p>

<p class=MsoNormal>In a <b>real-time sensor data processing</b> system, each
thread processes one sensors data. Since sensors send data at different times,
CUDAs unordered execution fits wellthreads process data as it arrives without
waiting for others.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal>Continuing with <b>Slide 10</b> next.</p>

<p class=MsoNormal><b>Provide your feedback on BizChat</b></p>

<p class=MsoNormal><b>You said: </b></p>

<p class=MsoNormal>yes</p>

<p class=MsoNormal><b>Copilot said: </b></p>

<p class=MsoNormal>Copilot</p>

<p class=MsoNormal>Continuing with <b>Slide 10</b>:</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Slide 10: Sequence of Steps for GPU Programming</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
Easy Explanation:</b></p>

<p class=MsoNormal>This slide outlines the <b>standard workflow</b> for writing
and executing a CUDA program:</p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Allocate CPU Data Structure</b>: Create variables and
     arrays on the host (CPU).</li>
 <li class=MsoNormal><b>Initialize Data on CPU</b>: Fill the data with values.</li>
 <li class=MsoNormal><b>Allocate GPU Data Structure</b>: Reserve memory on the
     device (GPU).</li>
 <li class=MsoNormal><b>Copy Data from CPU to GPU</b>: Transfer initialized
     data to GPU.</li>
 <li class=MsoNormal><b>Define Execution Configuration</b>: Set number of
     blocks and threads.</li>
 <li class=MsoNormal><b>Run Kernel</b>: Launch the GPU function.</li>
 <li class=MsoNormal><b>CPU Synchronizes with GPU</b>: Wait for GPU to finish.</li>
 <li class=MsoNormal><b>Copy Data from GPU to CPU</b>: Retrieve results.</li>
 <li class=MsoNormal><b>De-allocate Memory</b>: Free memory on both CPU and
     GPU.</li>
</ol>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>CUDA programming involves <b>host-device interaction</b>.</li>
 <li class=MsoNormal>Use cudaMalloc, cudaMemcpy, and cudaFree for memory
     management.</li>
 <li class=MsoNormal>Synchronization is done using cudaDeviceSynchronize().</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#10067;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is the correct order of CUDA programming steps?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. Initialize GPU &#8594; Allocate CPU &#8594; Run Kernel</li>
  <li class=MsoNormal>B. Allocate CPU &#8594; Initialize &#8594; Allocate GPU
      &#8594; Copy &#8594; Run Kernel <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>C. Run Kernel &#8594; Copy Data &#8594; Allocate Memory</li>
  <li class=MsoNormal>D. Synchronize &#8594; Allocate GPU &#8594; Run Kernel</li>
 </ul>
 <li class=MsoNormal>Which function is used to copy data from CPU to GPU?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. cudaRun()</li>
  <li class=MsoNormal>B. cudaMemcpy() <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>C. cudaSync()</li>
  <li class=MsoNormal>D. cudaTransfer()</li>
 </ul>
</ol>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numericals:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Suppose you have an array of 1000 floats: </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Memory required = 1000  4 bytes = <b>4000 bytes</b></li>
  <li class=MsoNormal>Use: </li>
 </ul>
</ul>

<p class=MsoNormal>C++</p>

<p class=MsoNormal>cudaMalloc(&amp;d_array, 4000);</p>

<p class=MsoNormal>cudaMemcpy(d_array, h_array, 4000, cudaMemcpyHostToDevice);</p>

<p class=MsoNormal>Show more lines</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128216;</span>
Case Study:</b></p>

<p class=MsoNormal>In a <b>financial modeling application</b>, large datasets
are processed using GPU. The workflow involves loading data on CPU,
transferring it to GPU, running simulations in parallel, and retrieving
resultsall following the 9-step CUDA sequence.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal>Continuing with <b>Slide 11</b> next.</p>

<p class=MsoNormal><b>Provide your feedback on BizChat</b></p>

<p class=MsoNormal><b>You said: </b></p>

<p class=MsoNormal>yes</p>

<p class=MsoNormal><b>Copilot said: </b></p>

<p class=MsoNormal>Copilot</p>

<p class=MsoNormal>Continuing with <b>Slide 11</b>:</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Slide 11: Hello World! with Device Code</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
Easy Explanation:</b></p>

<p class=MsoNormal>This slide introduces a <b>basic CUDA program</b> with a
kernel:</p>

<p class=MsoNormal>C++</p>

<p class=MsoNormal>__global__ void mykernel(void) {</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>int main(void) {</p>

<p class=MsoNormal>mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;();</p>

<p class=MsoNormal>printf(&quot;Hello World!\n&quot;);</p>

<p class=MsoNormal>return 0;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>Show more lines</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>__global__ keyword marks a <b>kernel function</b> that
     runs on the GPU.</li>
 <li class=MsoNormal>mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(); launches the kernel
     with <b>1 block and 1 thread</b>.</li>
 <li class=MsoNormal>The printf is executed by the <b>CPU</b>, not the GPU.</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>__global__: CUDA keyword for GPU functions callable from
     host.</li>
 <li class=MsoNormal>&lt;&lt;&lt;1,1&gt;&gt;&gt;: Launch configuration &#8594;
     1 block, 1 thread.</li>
 <li class=MsoNormal>Kernel functions must have void return type and no
     parameters (or simple ones).</li>
 <li class=MsoNormal>nvcc: NVIDIA CUDA compiler used to compile .cu files.</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#10067;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What does __global__ indicate in CUDA?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. Function runs on CPU</li>
  <li class=MsoNormal>B. Function runs on GPU and is called from GPU</li>
  <li class=MsoNormal>C. Function runs on GPU and is called from CPU <span
      style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>D. Function runs on both CPU and GPU</li>
 </ul>
 <li class=MsoNormal>What does &lt;&lt;&lt;1,1&gt;&gt;&gt; mean in CUDA?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. Launch 1 thread in 1 block <span style='font-family:
      "Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>B. Launch 1 block with 0 threads</li>
  <li class=MsoNormal>C. Launch 1 warp</li>
  <li class=MsoNormal>D. Launch 1 grid</li>
 </ul>
</ol>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numericals:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>If you change the launch to &lt;&lt;&lt;2,4&gt;&gt;&gt;,
     how many threads are launched? </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Total threads = 2  4 = <b>8</b></li>
 </ul>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128216;</span>
Case Study:</b></p>

<p class=MsoNormal>In a <b>basic GPU diagnostic tool</b>, launching a simple
kernel like mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(); helps verify that the GPU is
functioning and CUDA is properly installed. Its the GPU equivalent of a Hello
World test.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal>Continuing with <b>Slide 12</b> next.</p>

<p class=MsoNormal><b>Provide your feedback on BizChat</b></p>

<p class=MsoNormal><b>You said: </b></p>

<p class=MsoNormal>yes</p>

<p class=MsoNormal><b>Copilot said: </b></p>

<p class=MsoNormal>Copilot</p>

<p class=MsoNormal>Continuing with <b>Slide 12</b>:</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Slide 12: Hello World! with Device Code  Explanation of __global__</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
Easy Explanation:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>The keyword __global__ in CUDA C/C++: </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Marks a <b>function that runs on the GPU</b>.</li>
  <li class=MsoNormal>Is <b>called from the host (CPU)</b>.</li>
 </ul>
 <li class=MsoNormal>The CUDA compiler (nvcc) separates the code: </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal><b>Device code</b> (GPU functions) &#8594; compiled by
      NVIDIA compiler.</li>
  <li class=MsoNormal><b>Host code</b> (CPU functions) &#8594; compiled by
      standard C/C++ compiler (e.g., gcc, cl.exe).</li>
 </ul>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>__global__ functions: </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Must return void.</li>
  <li class=MsoNormal>Cannot be called from other device functions.</li>
  <li class=MsoNormal>Are launched using &lt;&lt;&lt; &gt;&gt;&gt; syntax.</li>
 </ul>
 <li class=MsoNormal>nvcc handles both host and device compilation.</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#10067;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What does the __global__ keyword signify in CUDA?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. Function runs on CPU</li>
  <li class=MsoNormal>B. Function runs on GPU and is called from GPU</li>
  <li class=MsoNormal>C. Function runs on GPU and is called from CPU <span
      style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>D. Function runs on both CPU and GPU</li>
 </ul>
 <li class=MsoNormal>Which compiler handles device code in CUDA?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. gcc</li>
  <li class=MsoNormal>B. cl.exe</li>
  <li class=MsoNormal>C. NVIDIA compiler <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>D. Visual Studio</li>
 </ul>
</ol>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numericals:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>If you write: </li>
</ul>

<p class=MsoNormal>C++</p>

<p class=MsoNormal>__global__ void add(int *a, int *b, int *c) {</p>

<p class=MsoNormal>int idx = threadIdx.x;</p>

<p class=MsoNormal>c[idx] = a[idx] + b[idx];</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>Show more lines</p>

<p class=MsoNormal>And launch with &lt;&lt;&lt;1, 256&gt;&gt;&gt;, it adds 256
elements in parallel.</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128216;</span>
Case Study:</b></p>

<p class=MsoNormal>In a <b>machine learning training loop</b>, the __global__ kernel
can be used to compute gradients in parallel across data samples. This
massively speeds up training compared to CPU-only implementations.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal>Continuing with <b>Slide 13</b> next.</p>

<p class=MsoNormal><b>Provide your feedback on BizChat</b></p>

<p class=MsoNormal><b>You said: </b></p>

<p class=MsoNormal>yes</p>

<p class=MsoNormal><b>Copilot said: </b></p>

<p class=MsoNormal>Copilot</p>

<p class=MsoNormal>Continuing with <b>Slide 13</b>:</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Slide 13: Hello World! with Device Code  Kernel Launch</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
Easy Explanation:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>The line mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(); is a <b>kernel
     launch</b>.</li>
 <li class=MsoNormal>It uses <b>triple angle brackets</b> to specify: </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal><b>1 block</b></li>
  <li class=MsoNormal><b>1 thread per block</b></li>
 </ul>
 <li class=MsoNormal>This syntax tells the GPU to execute the mykernel function
     using 1 thread.</li>
 <li class=MsoNormal>This is the <b>minimum configuration</b> for launching a
     kernel.</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Kernel Launch Syntax</b>: kernel&lt;&lt;&lt;numBlocks,
     threadsPerBlock&gt;&gt;&gt;();</li>
 <li class=MsoNormal><b>Host-to-Device Call</b>: This syntax is used to call
     GPU functions from CPU.</li>
 <li class=MsoNormal><b>Parameters</b> inside &lt;&lt;&lt; &gt;&gt;&gt; define
     parallelism.</li>
 <li class=MsoNormal>Even if the kernel does nothing, it still runs on the GPU.</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#10067;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What does &lt;&lt;&lt;1,1&gt;&gt;&gt; mean in CUDA?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. Launch 1 thread in 1 block <span style='font-family:
      "Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>B. Launch 1 block with 0 threads</li>
  <li class=MsoNormal>C. Launch 1 grid with 1 thread</li>
  <li class=MsoNormal>D. Launch 1 warp</li>
 </ul>
 <li class=MsoNormal>What is the purpose of triple angle brackets in CUDA?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. To define memory allocation</li>
  <li class=MsoNormal>B. To launch a kernel on the GPU <span style='font-family:
      "Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>C. To synchronize threads</li>
  <li class=MsoNormal>D. To compile device code</li>
 </ul>
</ol>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numericals:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>If you change the launch to &lt;&lt;&lt;4, 256&gt;&gt;&gt;,
     how many threads are launched? </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Total threads = 4  256 = <b>1024</b></li>
 </ul>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128216;</span>
Case Study:</b></p>

<p class=MsoNormal>In a <b>GPU-based logging system</b>, you might launch a
kernel with &lt;&lt;&lt;1,1&gt;&gt;&gt; just to test device-side logging or
debugging. This minimal configuration ensures the kernel runs without consuming
many resources.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal>Continuing with <b>Slide 14</b> next.</p>

<p class=MsoNormal><b>Provide your feedback on BizChat</b></p>

<p class=MsoNormal><b>You said: </b></p>

<p class=MsoNormal>yes</p>

<p class=MsoNormal><b>Copilot said: </b></p>

<p class=MsoNormal>Copilot</p>

<p class=MsoNormal>Continuing with <b>Slide 14</b>:</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Slide 14: Hello World! with Device Code  Output</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
Easy Explanation:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>The kernel mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;(); is
     launched but <b>does nothing</b>.</li>
 <li class=MsoNormal>The printf(&quot;Hello World!\n&quot;); is executed by the
     <b>CPU</b>, not the GPU.</li>
 <li class=MsoNormal>The output of the program is simply: </li>
 <li class=MsoNormal>Hello World!</li>
 <li class=MsoNormal>This demonstrates that launching a kernel doesnt affect
     host-side output unless the kernel itself performs operations.</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>CUDA kernels can be empty and still be launched.</li>
 <li class=MsoNormal>Host-side printf is unaffected by GPU execution.</li>
 <li class=MsoNormal>Use nvcc to compile CUDA programs: </li>
</ul>

<p class=MsoNormal>Shell</p>

<p class=MsoNormal>nvcc hello.cu</p>

<p class=MsoNormal>./a.out</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Show more lines</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#10067;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is the output of the following CUDA program?</li>
</ol>

<p class=MsoNormal>C++</p>

<p class=MsoNormal>__global__ void mykernel(void) {}</p>

<p class=MsoNormal>int main(void) {</p>

<p class=MsoNormal>mykernel&lt;&lt;&lt;1,1&gt;&gt;&gt;();</p>

<p class=MsoNormal>printf(&quot;Hello World!\n&quot;);</p>

<p class=MsoNormal>return 0;</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>Show more lines</p>

<ol style='margin-top:0in' start=1 type=1>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. No output</li>
  <li class=MsoNormal>B. Hello World! <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>C. Kernel executed</li>
  <li class=MsoNormal>D. Compilation error</li>
 </ul>
 <li class=MsoNormal>Which part of the program prints &quot;Hello World!&quot;?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. GPU kernel</li>
  <li class=MsoNormal>B. Host CPU code <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>C. CUDA runtime</li>
  <li class=MsoNormal>D. Device memory</li>
 </ul>
</ol>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numericals:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>If you modify the kernel to: </li>
</ul>

<p class=MsoNormal>C++</p>

<p class=MsoNormal>__global__ void mykernel(void) {</p>

<p class=MsoNormal>printf(&quot;Hello from GPU!\n&quot;);</p>

<p class=MsoNormal>}</p>

<p class=MsoNormal>Show more lines</p>

<p class=MsoNormal>And launch with &lt;&lt;&lt;2,2&gt;&gt;&gt;, youll get <b>4
GPU-side print statements</b> (2 blocks  2 threads).</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128216;</span>
Case Study:</b></p>

<p class=MsoNormal>In a <b>GPU debugging tool</b>, launching an empty kernel
helps verify that the GPU is responsive. If the host prints &quot;Hello
World!&quot; and the program runs without error, it confirms basic CUDA setup
is working.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal>Continuing with <b>Slide 15</b> next.</p>

<p class=MsoNormal><b>Provide your feedback on BizChat</b></p>

<p class=MsoNormal><b>You said: </b></p>

<p class=MsoNormal>yes</p>

<p class=MsoNormal><b>Copilot said: </b></p>

<p class=MsoNormal>Copilot</p>

<p class=MsoNormal>Continuing with <b>Slide 15</b>:</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128313;</span>
Slide 15: Parallel Programming in CUDA C/C++</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
Easy Explanation:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>GPU computing</b> is all about <b>massive parallelism</b>running
     thousands of threads simultaneously.</li>
 <li class=MsoNormal>This slide transitions from simple examples (like
     printing) to <b>actual computation</b>.</li>
 <li class=MsoNormal>It starts with <b>adding two integers</b>, then scales up
     to <b>vector addition</b>, which is a common parallel task.</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Exam Notes:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>CUDA is designed for <b>data-parallel tasks</b>.</li>
 <li class=MsoNormal>Each thread performs the <b>same operation</b> on
     different data.</li>
 <li class=MsoNormal><b>Vector addition</b> is a classic example: </li>
</ul>

<p class=MsoNormal>C++</p>

<p class=MsoNormal>C[i] = A[i] + B[i];</p>

<p class=MsoNormal>Show more lines</p>

<p class=MsoNormal>Each thread handles one index i.</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#10067;</span>
MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is the main advantage of GPU computing?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. Sequential execution</li>
  <li class=MsoNormal>B. Massive parallelism <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>C. Low memory usage</li>
  <li class=MsoNormal>D. High clock speed</li>
 </ul>
 <li class=MsoNormal>In CUDA, what is a typical use case for parallelism?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A. File I/O</li>
  <li class=MsoNormal>B. Vector addition <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>C. String manipulation</li>
  <li class=MsoNormal>D. GUI rendering</li>
 </ul>
</ol>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numericals:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Suppose you have two arrays of 1000 elements: </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Launch &lt;&lt;&lt;4, 256&gt;&gt;&gt; &#8594; 1024
      threads</li>
  <li class=MsoNormal>Each thread computes C[i] = A[i] + B[i] for one index i</li>
  <li class=MsoNormal>This completes the vector addition in <b>one pass</b></li>
 </ul>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128216;</span>
Case Study:</b></p>

<p class=MsoNormal>In a <b>real-time graphics engine</b>, vector operations
(like transformations) are performed on thousands of vertices. CUDA allows
these operations to be done in parallel, enabling smooth rendering and fast
computation.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

</div>

</body>

</html>
