<html>

<head>
<meta http-equiv=Content-Type content="text/html; charset=windows-1252">
<meta name=Generator content="Microsoft Word 15 (filtered)">
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:Helvetica;
	panose-1:2 11 6 4 2 2 2 2 2 4;}
@font-face
	{font-family:Courier;
	panose-1:2 7 4 9 2 2 5 2 4 4;}
@font-face
	{font-family:"Tms Rmn";
	panose-1:2 2 6 3 4 5 5 2 3 4;}
@font-face
	{font-family:Helv;
	panose-1:2 11 6 4 2 2 2 3 2 4;}
@font-face
	{font-family:"New York";
	panose-1:2 4 5 3 6 5 6 2 3 4;}
@font-face
	{font-family:System;
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:Wingdings;
	panose-1:5 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"MS Mincho";
	panose-1:2 2 6 9 4 2 5 8 3 4;}
@font-face
	{font-family:Batang;
	panose-1:2 3 6 0 0 1 1 1 1 1;}
@font-face
	{font-family:SimSun;
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:PMingLiU;
	panose-1:2 1 6 1 0 1 1 1 1 1;}
@font-face
	{font-family:"MS Gothic";
	panose-1:2 11 6 9 7 2 5 8 2 4;}
@font-face
	{font-family:Dotum;
	panose-1:2 11 6 0 0 1 1 1 1 1;}
@font-face
	{font-family:SimHei;
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:MingLiU;
	panose-1:2 1 6 9 0 1 1 1 1 1;}
@font-face
	{font-family:Mincho;
	panose-1:2 2 6 9 4 3 5 8 3 5;}
@font-face
	{font-family:Gulim;
	panose-1:2 11 6 0 0 1 1 1 1 1;}
@font-face
	{font-family:Century;
	panose-1:2 4 6 4 5 5 5 2 3 4;}
@font-face
	{font-family:"Angsana New";
	panose-1:2 2 6 3 5 4 5 2 3 4;}
@font-face
	{font-family:"Cordia New";
	panose-1:2 11 3 4 2 2 2 2 2 4;}
@font-face
	{font-family:Mangal;
	panose-1:0 0 4 0 0 0 0 0 0 0;}
@font-face
	{font-family:Latha;
	panose-1:2 0 4 0 0 0 0 0 0 0;}
@font-face
	{font-family:Sylfaen;
	panose-1:1 10 5 2 5 3 6 3 3 3;}
@font-face
	{font-family:Vrinda;
	panose-1:0 0 4 0 0 0 0 0 0 0;}
@font-face
	{font-family:Raavi;
	panose-1:2 0 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:Shruti;
	panose-1:2 0 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:Sendnya;
	panose-1:0 0 4 0 0 0 0 0 0 0;}
@font-face
	{font-family:Gautami;
	panose-1:2 0 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:Tunga;
	panose-1:0 0 4 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Estrangelo Edessa";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:"Yu Gothic";
	panose-1:2 11 4 0 0 0 0 0 0 0;}
@font-face
	{font-family:DengXian;
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
@font-face
	{font-family:"Calibri Light";
	panose-1:2 15 3 2 2 2 4 3 2 4;}
@font-face
	{font-family:"Palatino Linotype";
	panose-1:2 4 5 2 5 5 5 3 3 4;}
@font-face
	{font-family:Verdana;
	panose-1:2 11 6 4 3 5 4 4 2 4;}
@font-face
	{font-family:"Arial Unicode MS";
	panose-1:2 11 6 4 2 2 2 2 2 4;}
@font-face
	{font-family:Aptos;}
@font-face
	{font-family:"Aptos Display";}
@font-face
	{font-family:"Segoe UI Emoji";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:Consolas;
	panose-1:2 11 6 9 2 2 4 3 2 4;}
@font-face
	{font-family:"Segoe UI";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:KaTeX_Math;
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:KaTeX_Size1;
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:KaTeX_Main;
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:Marlett;
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Arial Black";
	panose-1:2 11 10 4 2 1 2 2 2 4;}
@font-face
	{font-family:"Bahnschrift Light";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Bahnschrift SemiLight";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:Bahnschrift;
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Bahnschrift SemiBold";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Bahnschrift Light SemiCondensed";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Bahnschrift SemiLight SemiConde";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Bahnschrift SemiCondensed";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Bahnschrift SemiBold SemiConden";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Bahnschrift Light Condensed";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Bahnschrift SemiLight Condensed";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Bahnschrift Condensed";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Bahnschrift SemiBold Condensed";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:Cambria;
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:Candara;
	panose-1:2 14 5 2 3 3 3 2 2 4;}
@font-face
	{font-family:"Candara Light";
	panose-1:2 14 5 2 3 3 3 2 2 4;}
@font-face
	{font-family:"Comic Sans MS";
	panose-1:3 15 7 2 3 3 2 2 2 4;}
@font-face
	{font-family:Constantia;
	panose-1:2 3 6 2 5 3 6 3 3 3;}
@font-face
	{font-family:Corbel;
	panose-1:2 11 5 3 2 2 4 2 2 4;}
@font-face
	{font-family:"Corbel Light";
	panose-1:2 11 3 3 2 2 4 2 2 4;}
@font-face
	{font-family:Ebrima;
	panose-1:2 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Franklin Gothic Medium";
	panose-1:2 11 6 3 2 1 2 2 2 4;}
@font-face
	{font-family:Gabriola;
	panose-1:4 4 6 5 5 16 2 2 13 2;}
@font-face
	{font-family:Gadugi;
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:Georgia;
	panose-1:2 4 5 2 5 4 5 2 3 3;}
@font-face
	{font-family:Impact;
	panose-1:2 11 8 6 3 9 2 5 2 4;}
@font-face
	{font-family:"Ink Free";
	panose-1:3 8 4 2 0 5 0 0 0 0;}
@font-face
	{font-family:"Javanese Text";
	panose-1:2 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Leelawadee UI";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Leelawadee UI Semilight";
	panose-1:2 11 4 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Lucida Console";
	panose-1:2 11 6 9 4 5 4 2 2 4;}
@font-face
	{font-family:"Lucida Sans Unicode";
	panose-1:2 11 6 2 3 5 4 2 2 4;}
@font-face
	{font-family:"Malgun Gothic";
	panose-1:2 11 5 3 2 0 0 2 0 4;}
@font-face
	{font-family:"\@Malgun Gothic";}
@font-face
	{font-family:"Malgun Gothic Semilight";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"\@Malgun Gothic Semilight";}
@font-face
	{font-family:"Microsoft Himalaya";
	panose-1:1 1 1 0 1 1 1 1 1 1;}
@font-face
	{font-family:"Microsoft JhengHei";
	panose-1:2 11 6 4 3 5 4 4 2 4;}
@font-face
	{font-family:"\@Microsoft JhengHei";}
@font-face
	{font-family:"Microsoft JhengHei UI";
	panose-1:2 11 6 4 3 5 4 4 2 4;}
@font-face
	{font-family:"\@Microsoft JhengHei UI";}
@font-face
	{font-family:"Microsoft JhengHei Light";
	panose-1:2 11 3 4 3 5 4 4 2 4;}
@font-face
	{font-family:"\@Microsoft JhengHei Light";}
@font-face
	{font-family:"Microsoft JhengHei UI Light";
	panose-1:2 11 3 4 3 5 4 4 2 4;}
@font-face
	{font-family:"\@Microsoft JhengHei UI Light";}
@font-face
	{font-family:"Microsoft New Tai Lue";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Microsoft PhagsPa";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Microsoft Sans Serif";
	panose-1:2 11 6 4 2 2 2 2 2 4;}
@font-face
	{font-family:"Microsoft Tai Le";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Microsoft YaHei";
	panose-1:2 11 5 3 2 2 4 2 2 4;}
@font-face
	{font-family:"\@Microsoft YaHei";}
@font-face
	{font-family:"Microsoft YaHei UI";
	panose-1:2 11 5 3 2 2 4 2 2 4;}
@font-face
	{font-family:"\@Microsoft YaHei UI";}
@font-face
	{font-family:"Microsoft YaHei Light";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"\@Microsoft YaHei Light";}
@font-face
	{font-family:"Microsoft YaHei UI Light";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"\@Microsoft YaHei UI Light";}
@font-face
	{font-family:"Microsoft Yi Baiti";
	panose-1:3 0 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:MingLiU-ExtB;
	panose-1:2 2 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@MingLiU-ExtB";}
@font-face
	{font-family:PMingLiU-ExtB;
	panose-1:2 2 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@PMingLiU-ExtB";}
@font-face
	{font-family:MingLiU_HKSCS-ExtB;
	panose-1:2 2 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@MingLiU_HKSCS-ExtB";}
@font-face
	{font-family:MingLiU_MSCS-ExtB;
	panose-1:2 2 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@MingLiU_MSCS-ExtB";}
@font-face
	{font-family:"Mongolian Baiti";
	panose-1:3 0 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@MS Gothic";
	panose-1:2 11 6 9 7 2 5 8 2 4;}
@font-face
	{font-family:"MS UI Gothic";
	panose-1:2 11 6 0 7 2 5 8 2 4;}
@font-face
	{font-family:"\@MS UI Gothic";}
@font-face
	{font-family:"MS PGothic";
	panose-1:2 11 6 0 7 2 5 8 2 4;}
@font-face
	{font-family:"\@MS PGothic";}
@font-face
	{font-family:"MV Boli";
	panose-1:2 0 5 0 3 2 0 9 0 0;}
@font-face
	{font-family:"Myanmar Text";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Nirmala UI";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Nirmala UI Semilight";
	panose-1:2 11 4 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Nirmala Text";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Nirmala Text Semilight";
	panose-1:2 11 4 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Sans Serif Collection";
	panose-1:2 11 5 2 4 5 4 2 2 4;}
@font-face
	{font-family:"Segoe Fluent Icons";
	panose-1:5 10 1 2 1 1 1 1 1 1;}
@font-face
	{font-family:"Segoe MDL2 Assets";
	panose-1:5 10 1 2 1 1 1 1 1 1;}
@font-face
	{font-family:"Segoe Print";
	panose-1:2 0 6 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe Script";
	panose-1:3 11 5 4 2 0 0 0 0 3;}
@font-face
	{font-family:"Segoe UI Black";
	panose-1:2 11 10 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Segoe UI Historic";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Segoe UI Light";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Segoe UI Semibold";
	panose-1:2 11 7 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Segoe UI Semilight";
	panose-1:2 11 4 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Segoe UI Symbol";
	panose-1:2 11 5 2 4 2 4 2 2 3;}
@font-face
	{font-family:"Segoe UI Variable Small Light";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Small Semilig";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Small";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Small Semibol";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Text Light";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Text Semiligh";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Text";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Text Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Display Light";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Display Semil";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Display";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Segoe UI Variable Display Semib";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@SimSun";
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:NSimSun;
	panose-1:2 1 6 9 3 1 1 1 1 1;}
@font-face
	{font-family:"\@NSimSun";}
@font-face
	{font-family:SimSun-ExtB;
	panose-1:2 1 6 9 6 1 1 1 1 1;}
@font-face
	{font-family:"\@SimSun-ExtB";}
@font-face
	{font-family:"Sitka Small";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Small Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Text";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Text Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Subheading";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Subheading Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Heading";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Heading Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Display";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Display Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Banner";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Sitka Banner Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:Tahoma;
	panose-1:2 11 6 4 3 5 4 4 2 4;}
@font-face
	{font-family:"Trebuchet MS";
	panose-1:2 11 6 3 2 2 2 2 2 4;}
@font-face
	{font-family:Webdings;
	panose-1:5 3 1 2 1 5 9 6 7 3;}
@font-face
	{font-family:"\@Yu Gothic";
	panose-1:2 11 4 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Yu Gothic UI";
	panose-1:2 11 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@Yu Gothic UI";}
@font-face
	{font-family:"Yu Gothic UI Semibold";
	panose-1:2 11 7 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@Yu Gothic UI Semibold";}
@font-face
	{font-family:"Yu Gothic Light";
	panose-1:2 11 3 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@Yu Gothic Light";}
@font-face
	{font-family:"Yu Gothic UI Light";
	panose-1:2 11 3 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@Yu Gothic UI Light";}
@font-face
	{font-family:"Yu Gothic Medium";
	panose-1:2 11 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@Yu Gothic Medium";}
@font-face
	{font-family:"Yu Gothic UI Semilight";
	panose-1:2 11 4 0 0 0 0 0 0 0;}
@font-face
	{font-family:"\@Yu Gothic UI Semilight";}
@font-face
	{font-family:SimSun-ExtG;
	panose-1:2 1 6 9 6 1 1 1 1 1;}
@font-face
	{font-family:"\@SimSun-ExtG";}
@font-face
	{font-family:"Agency FB";
	panose-1:2 11 5 3 2 2 2 2 2 4;}
@font-face
	{font-family:Algerian;
	panose-1:4 2 7 5 4 10 2 6 7 2;}
@font-face
	{font-family:"Book Antiqua";
	panose-1:2 4 6 2 5 3 5 3 3 4;}
@font-face
	{font-family:"Arial Narrow";
	panose-1:2 11 6 6 2 2 2 3 2 4;}
@font-face
	{font-family:"Arial Rounded MT Bold";
	panose-1:2 15 7 4 3 5 4 3 2 4;}
@font-face
	{font-family:"Baskerville Old Face";
	panose-1:2 2 6 2 8 5 5 2 3 3;}
@font-face
	{font-family:"Bauhaus 93";
	panose-1:4 3 9 5 2 11 2 2 12 2;}
@font-face
	{font-family:"Bell MT";
	panose-1:2 2 5 3 6 3 5 2 3 3;}
@font-face
	{font-family:"Bernard MT Condensed";
	panose-1:2 5 8 6 6 9 5 2 4 4;}
@font-face
	{font-family:"Bodoni MT";
	panose-1:2 7 6 3 8 6 6 2 2 3;}
@font-face
	{font-family:"Bodoni MT Black";
	panose-1:2 7 10 3 8 6 6 2 2 3;}
@font-face
	{font-family:"Bodoni MT Condensed";
	panose-1:2 7 6 6 8 6 6 2 2 3;}
@font-face
	{font-family:"Bodoni MT Poster Compressed";
	panose-1:2 7 7 6 8 6 1 5 2 4;}
@font-face
	{font-family:"Bookman Old Style";
	panose-1:2 5 6 4 5 5 5 2 2 4;}
@font-face
	{font-family:"Bradley Hand ITC";
	panose-1:3 7 4 2 5 3 2 3 2 3;}
@font-face
	{font-family:"Britannic Bold";
	panose-1:2 11 9 3 6 7 3 2 2 4;}
@font-face
	{font-family:"Berlin Sans FB";
	panose-1:2 14 6 2 2 5 2 2 3 6;}
@font-face
	{font-family:"Berlin Sans FB Demi";
	panose-1:2 14 8 2 2 5 2 2 3 6;}
@font-face
	{font-family:Broadway;
	panose-1:4 4 9 5 8 11 2 2 5 2;}
@font-face
	{font-family:"Brush Script MT";
	panose-1:3 6 8 2 4 4 6 7 3 4;}
@font-face
	{font-family:"Bookshelf Symbol 7";
	panose-1:5 1 1 1 1 1 1 1 1 1;}
@font-face
	{font-family:"Californian FB";
	panose-1:2 7 4 3 6 8 11 3 2 4;}
@font-face
	{font-family:"Calisto MT";
	panose-1:2 4 6 3 5 5 5 3 3 4;}
@font-face
	{font-family:Castellar;
	panose-1:2 10 4 2 6 4 6 1 3 1;}
@font-face
	{font-family:"Century Schoolbook";
	panose-1:2 4 6 4 5 5 5 2 3 4;}
@font-face
	{font-family:Centaur;
	panose-1:2 3 5 4 5 2 5 2 3 4;}
@font-face
	{font-family:Chiller;
	panose-1:4 2 4 4 3 16 7 2 6 2;}
@font-face
	{font-family:"Colonna MT";
	panose-1:4 2 8 5 6 2 2 3 2 3;}
@font-face
	{font-family:"Cooper Black";
	panose-1:2 8 9 4 4 3 11 2 4 4;}
@font-face
	{font-family:"Copperplate Gothic Bold";
	panose-1:2 14 7 5 2 2 6 2 4 4;}
@font-face
	{font-family:"Copperplate Gothic Light";
	panose-1:2 14 5 7 2 2 6 2 4 4;}
@font-face
	{font-family:"Curlz MT";
	panose-1:4 4 4 4 5 7 2 2 2 2;}
@font-face
	{font-family:Dubai;
	panose-1:2 11 5 3 3 4 3 3 2 4;}
@font-face
	{font-family:"Dubai Light";
	panose-1:2 11 3 3 3 4 3 3 2 4;}
@font-face
	{font-family:"Dubai Medium";
	panose-1:2 11 6 3 3 4 3 3 2 4;}
@font-face
	{font-family:Elephant;
	panose-1:2 2 9 4 9 5 5 2 3 3;}
@font-face
	{font-family:"Engravers MT";
	panose-1:2 9 7 7 8 5 5 2 3 4;}
@font-face
	{font-family:"Eras Bold ITC";
	panose-1:2 11 9 7 3 5 4 2 2 4;}
@font-face
	{font-family:"Eras Demi ITC";
	panose-1:2 11 8 5 3 5 4 2 8 4;}
@font-face
	{font-family:"Eras Light ITC";
	panose-1:2 11 4 2 3 5 4 2 8 4;}
@font-face
	{font-family:"Eras Medium ITC";
	panose-1:2 11 6 2 3 5 4 2 8 4;}
@font-face
	{font-family:"Felix Titling";
	panose-1:4 6 5 5 6 2 2 2 10 4;}
@font-face
	{font-family:Forte;
	panose-1:3 6 9 2 4 5 2 7 2 3;}
@font-face
	{font-family:"Franklin Gothic Book";
	panose-1:2 11 5 3 2 1 2 2 2 4;}
@font-face
	{font-family:"Franklin Gothic Demi";
	panose-1:2 11 7 3 2 1 2 2 2 4;}
@font-face
	{font-family:"Franklin Gothic Demi Cond";
	panose-1:2 11 7 6 3 4 2 2 2 4;}
@font-face
	{font-family:"Franklin Gothic Heavy";
	panose-1:2 11 9 3 2 1 2 2 2 4;}
@font-face
	{font-family:"Franklin Gothic Medium Cond";
	panose-1:2 11 6 6 3 4 2 2 2 4;}
@font-face
	{font-family:"Freestyle Script";
	panose-1:3 8 4 2 3 2 5 11 4 4;}
@font-face
	{font-family:"French Script MT";
	panose-1:3 2 4 2 4 6 7 4 6 5;}
@font-face
	{font-family:"Footlight MT Light";
	panose-1:2 4 6 2 6 3 10 2 3 4;}
@font-face
	{font-family:Garamond;
	panose-1:2 2 4 4 3 3 1 1 8 3;}
@font-face
	{font-family:Gigi;
	panose-1:4 4 5 4 6 16 7 2 13 2;}
@font-face
	{font-family:"Gill Sans MT";
	panose-1:2 11 5 2 2 1 4 2 2 3;}
@font-face
	{font-family:"Gill Sans MT Condensed";
	panose-1:2 11 5 6 2 1 4 2 2 3;}
@font-face
	{font-family:"Gill Sans Ultra Bold Condensed";
	panose-1:2 11 10 6 2 1 4 2 2 3;}
@font-face
	{font-family:"Gill Sans Ultra Bold";
	panose-1:2 11 10 2 2 1 4 2 2 3;}
@font-face
	{font-family:"Gloucester MT Extra Condensed";
	panose-1:2 3 8 8 2 6 1 1 1 1;}
@font-face
	{font-family:"Gill Sans MT Ext Condensed Bold";
	panose-1:2 11 9 2 2 1 4 2 2 3;}
@font-face
	{font-family:"Century Gothic";
	panose-1:2 11 5 2 2 2 2 2 2 4;}
@font-face
	{font-family:"Goudy Old Style";
	panose-1:2 2 5 2 5 3 5 2 3 3;}
@font-face
	{font-family:"Goudy Stout";
	panose-1:2 2 9 4 7 3 11 2 4 1;}
@font-face
	{font-family:"Harlow Solid Italic";
	panose-1:4 3 6 4 2 15 2 2 13 2;}
@font-face
	{font-family:Harrington;
	panose-1:4 4 5 5 5 10 2 2 7 2;}
@font-face
	{font-family:Haettenschweiler;
	panose-1:2 11 7 6 4 9 2 6 2 4;}
@font-face
	{font-family:"High Tower Text";
	panose-1:2 4 5 2 5 5 6 3 3 3;}
@font-face
	{font-family:"Imprint MT Shadow";
	panose-1:4 2 6 5 6 3 3 3 2 2;}
@font-face
	{font-family:"Informal Roman";
	panose-1:3 6 4 2 3 4 6 11 2 4;}
@font-face
	{font-family:"Blackadder ITC";
	panose-1:4 2 5 5 5 16 7 2 13 2;}
@font-face
	{font-family:"Edwardian Script ITC";
	panose-1:3 3 3 2 4 7 7 13 8 4;}
@font-face
	{font-family:"Kristen ITC";
	panose-1:3 5 5 2 4 2 2 3 2 2;}
@font-face
	{font-family:Jokerman;
	panose-1:4 9 6 5 6 13 6 2 7 2;}
@font-face
	{font-family:"Juice ITC";
	panose-1:4 4 4 3 4 10 2 2 2 2;}
@font-face
	{font-family:"Kunstler Script";
	panose-1:3 3 4 2 2 6 7 13 13 6;}
@font-face
	{font-family:"Wide Latin";
	panose-1:2 10 10 7 5 5 5 2 4 4;}
@font-face
	{font-family:"Lucida Bright";
	panose-1:2 4 6 2 5 5 5 2 3 4;}
@font-face
	{font-family:"Lucida Calligraphy";
	panose-1:3 1 1 1 1 1 1 1 1 1;}
@font-face
	{font-family:"Lucida Fax";
	panose-1:2 6 6 2 5 5 5 2 2 4;}
@font-face
	{font-family:"Lucida Handwriting";
	panose-1:3 1 1 1 1 1 1 1 1 1;}
@font-face
	{font-family:"Lucida Sans";
	panose-1:2 11 6 2 3 5 4 2 2 4;}
@font-face
	{font-family:"Lucida Sans Typewriter";
	panose-1:2 11 5 9 3 5 4 3 2 4;}
@font-face
	{font-family:Magneto;
	panose-1:4 3 8 5 5 8 2 2 13 2;}
@font-face
	{font-family:"Maiandra GD";
	panose-1:2 14 5 2 3 3 8 2 2 4;}
@font-face
	{font-family:"Matura MT Script Capitals";
	panose-1:3 2 8 2 6 6 2 7 2 2;}
@font-face
	{font-family:Mistral;
	panose-1:3 9 7 2 3 4 7 2 4 3;}
@font-face
	{font-family:"Modern No\. 20";
	panose-1:2 7 7 4 7 5 5 2 3 3;}
@font-face
	{font-family:"Monotype Corsiva";
	panose-1:3 1 1 1 1 2 1 1 1 1;}
@font-face
	{font-family:"MT Extra";
	panose-1:5 5 1 2 1 2 5 2 2 2;}
@font-face
	{font-family:"Niagara Engraved";
	panose-1:4 2 5 2 7 7 3 3 2 2;}
@font-face
	{font-family:"Niagara Solid";
	panose-1:4 2 5 2 7 7 2 2 2 2;}
@font-face
	{font-family:"OCR A Extended";
	panose-1:2 1 5 9 2 1 2 1 3 3;}
@font-face
	{font-family:"Old English Text MT";
	panose-1:3 4 9 2 4 5 8 3 8 6;}
@font-face
	{font-family:Onyx;
	panose-1:4 5 6 2 8 7 2 2 2 3;}
@font-face
	{font-family:"MS Outlook";
	panose-1:5 1 1 0 1 0 0 0 0 0;}
@font-face
	{font-family:"Palace Script MT";
	panose-1:3 3 3 2 2 6 7 12 11 5;}
@font-face
	{font-family:Papyrus;
	panose-1:3 7 5 2 6 5 2 3 2 5;}
@font-face
	{font-family:Parchment;
	panose-1:3 4 6 2 4 7 8 4 8 4;}
@font-face
	{font-family:Perpetua;
	panose-1:2 2 5 2 6 4 1 2 3 3;}
@font-face
	{font-family:"Perpetua Titling MT";
	panose-1:2 2 5 2 6 5 5 2 8 4;}
@font-face
	{font-family:Playbill;
	panose-1:4 5 6 3 10 6 2 2 2 2;}
@font-face
	{font-family:"Poor Richard";
	panose-1:2 8 5 2 5 5 5 2 7 2;}
@font-face
	{font-family:Pristina;
	panose-1:3 6 4 2 4 4 6 8 2 4;}
@font-face
	{font-family:"Rage Italic";
	panose-1:3 7 5 2 4 5 7 7 3 4;}
@font-face
	{font-family:Ravie;
	panose-1:4 4 8 5 5 8 9 2 6 2;}
@font-face
	{font-family:"MS Reference Sans Serif";
	panose-1:2 11 6 4 3 5 4 4 2 4;}
@font-face
	{font-family:"MS Reference Specialty";
	panose-1:5 0 5 0 0 0 0 0 0 0;}
@font-face
	{font-family:"Rockwell Condensed";
	panose-1:2 6 6 3 5 4 5 2 1 4;}
@font-face
	{font-family:Rockwell;
	panose-1:2 6 6 3 2 2 5 2 4 3;}
@font-face
	{font-family:"Rockwell Extra Bold";
	panose-1:2 6 9 3 4 5 5 2 4 3;}
@font-face
	{font-family:"Script MT Bold";
	panose-1:3 4 6 2 4 6 7 8 9 4;}
@font-face
	{font-family:"Showcard Gothic";
	panose-1:4 2 9 4 2 1 2 2 6 4;}
@font-face
	{font-family:"Snap ITC";
	panose-1:4 4 10 7 6 10 2 2 2 2;}
@font-face
	{font-family:Stencil;
	panose-1:4 4 9 5 13 8 2 2 4 4;}
@font-face
	{font-family:"Tw Cen MT";
	panose-1:2 11 6 2 2 1 4 2 6 3;}
@font-face
	{font-family:"Tw Cen MT Condensed";
	panose-1:2 11 6 6 2 1 4 2 2 3;}
@font-face
	{font-family:"Tw Cen MT Condensed Extra Bold";
	panose-1:2 11 8 3 2 2 2 2 2 4;}
@font-face
	{font-family:"Tempus Sans ITC";
	panose-1:4 2 4 4 3 13 7 2 2 2;}
@font-face
	{font-family:"Viner Hand ITC";
	panose-1:3 7 5 2 3 5 2 2 2 3;}
@font-face
	{font-family:Vivaldi;
	panose-1:3 2 6 2 5 5 6 9 8 4;}
@font-face
	{font-family:"Vladimir Script";
	panose-1:3 5 4 2 4 4 7 7 3 5;}
@font-face
	{font-family:"Wingdings 2";
	panose-1:5 2 1 2 1 5 7 7 7 7;}
@font-face
	{font-family:"Wingdings 3";
	panose-1:5 4 1 2 1 8 7 7 7 7;}
@font-face
	{font-family:"Cascadia Code ExtraLight";
	panose-1:2 11 6 9 2 0 0 2 0 4;}
@font-face
	{font-family:"Cascadia Code Light";
	panose-1:2 11 6 9 2 0 0 2 0 4;}
@font-face
	{font-family:"Cascadia Code SemiLight";
	panose-1:2 11 6 9 2 0 0 2 0 4;}
@font-face
	{font-family:"Cascadia Code";
	panose-1:2 11 6 9 2 0 0 2 0 4;}
@font-face
	{font-family:"Cascadia Code SemiBold";
	panose-1:2 11 6 9 2 0 0 2 0 4;}
@font-face
	{font-family:"Cascadia Mono ExtraLight";
	panose-1:2 11 6 9 2 0 0 2 0 4;}
@font-face
	{font-family:"Cascadia Mono Light";
	panose-1:2 11 6 9 2 0 0 2 0 4;}
@font-face
	{font-family:"Cascadia Mono SemiLight";
	panose-1:2 11 6 9 2 0 0 2 0 4;}
@font-face
	{font-family:"Cascadia Mono";
	panose-1:2 11 6 9 2 0 0 2 0 4;}
@font-face
	{font-family:"Cascadia Mono SemiBold";
	panose-1:2 11 6 9 2 0 0 2 0 4;}
@font-face
	{font-family:Abadi;}
@font-face
	{font-family:"Abadi ExtraLight";}
@font-face
	{font-family:Abel;}
@font-face
	{font-family:"Abril Fatface";}
@font-face
	{font-family:"ADLaM Display";}
@font-face
	{font-family:Aharoni;}
@font-face
	{font-family:"Al Fresco";}
@font-face
	{font-family:"Alasassy Caps";}
@font-face
	{font-family:Aldhabi;}
@font-face
	{font-family:Alef;}
@font-face
	{font-family:Aleo;}
@font-face
	{font-family:"Aleo Light";}
@font-face
	{font-family:"Amasis MT Pro";}
@font-face
	{font-family:"Amasis MT Pro Black";}
@font-face
	{font-family:"Amasis MT Pro Light";}
@font-face
	{font-family:"Amasis MT Pro Medium";}
@font-face
	{font-family:"Amatic SC";}
@font-face
	{font-family:AngsanaUPC;}
@font-face
	{font-family:Anton;}
@font-face
	{font-family:Aparajita;}
@font-face
	{font-family:"Aptos Black";}
@font-face
	{font-family:"Aptos ExtraBold";}
@font-face
	{font-family:"Aptos Light";}
@font-face
	{font-family:"Aptos Mono";}
@font-face
	{font-family:"Aptos Narrow";}
@font-face
	{font-family:"Aptos SemiBold";}
@font-face
	{font-family:"Aptos Serif";}
@font-face
	{font-family:"Aptos Slab";}
@font-face
	{font-family:"Aptos Slab Black";}
@font-face
	{font-family:"Aptos Slab ExtraBold";}
@font-face
	{font-family:"Aptos Slab Light";}
@font-face
	{font-family:"Aptos Slab SemiBold";}
@font-face
	{font-family:"Arabic Typesetting";}
@font-face
	{font-family:"Aref Ruqaa";}
@font-face
	{font-family:"Arial Nova";}
@font-face
	{font-family:"Arial Nova Cond";}
@font-face
	{font-family:"Arial Nova Cond Light";}
@font-face
	{font-family:"Arial Nova Light";}
@font-face
	{font-family:Assistant;}
@font-face
	{font-family:"Assistant ExtraBold";}
@font-face
	{font-family:"Assistant ExtraLight";}
@font-face
	{font-family:"Assistant Light";}
@font-face
	{font-family:"Assistant SemiBold";}
@font-face
	{font-family:Athiti;}
@font-face
	{font-family:"Athiti ExtraLight";}
@font-face
	{font-family:"Athiti Light";}
@font-face
	{font-family:"Athiti Medium";}
@font-face
	{font-family:"Athiti SemiBold";}
@font-face
	{font-family:"Atkinson Hyperlegible Mono";}
@font-face
	{font-family:"Atkinson Hyperlegible Next";}
@font-face
	{font-family:"Avenir Next LT Pro";}
@font-face
	{font-family:"Avenir Next LT Pro Demi";}
@font-face
	{font-family:"Avenir Next LT Pro Light";}
@font-face
	{font-family:"Baguet Script";}
@font-face
	{font-family:Barlow;}
@font-face
	{font-family:"Barlow Black";}
@font-face
	{font-family:"Barlow Condensed";}
@font-face
	{font-family:"Barlow Condensed Black";}
@font-face
	{font-family:"Barlow Condensed ExtraBold";}
@font-face
	{font-family:"Barlow Condensed ExtraLight";}
@font-face
	{font-family:"Barlow Condensed Light";}
@font-face
	{font-family:"Barlow Condensed Medium";}
@font-face
	{font-family:"Barlow Condensed SemiBold";}
@font-face
	{font-family:"Barlow Condensed Thin";}
@font-face
	{font-family:"Barlow ExtraBold";}
@font-face
	{font-family:"Barlow ExtraLight";}
@font-face
	{font-family:"Barlow Light";}
@font-face
	{font-family:"Barlow Medium";}
@font-face
	{font-family:"Barlow Semi Condensed";}
@font-face
	{font-family:"Barlow Semi Condensed Black";}
@font-face
	{font-family:"Barlow Semi Condensed ExLight";}
@font-face
	{font-family:"Barlow Semi Condensed ExtraBold";}
@font-face
	{font-family:"Barlow Semi Condensed Light";}
@font-face
	{font-family:"Barlow Semi Condensed Medium";}
@font-face
	{font-family:"Barlow Semi Condensed SemiBold";}
@font-face
	{font-family:"Barlow Semi Condensed Thin";}
@font-face
	{font-family:"Barlow SemiBold";}
@font-face
	{font-family:"Barlow Thin";}
@font-face
	{font-family:BatangChe;}
@font-face
	{font-family:"Bebas Neue";}
@font-face
	{font-family:Bembo;}
@font-face
	{font-family:Bierstadt;}
@font-face
	{font-family:"Bierstadt Display";}
@font-face
	{font-family:Biome;}
@font-face
	{font-family:"Biome Light";}
@font-face
	{font-family:"Boucherie Block";}
@font-face
	{font-family:"Boucherie Sans";}
@font-face
	{font-family:"Browallia New";}
@font-face
	{font-family:BrowalliaUPC;}
@font-face
	{font-family:"Buxton Sketch";}
@font-face
	{font-family:"Caveat Brush";}
@font-face
	{font-family:Cavolini;}
@font-face
	{font-family:"Centaur Now Caption";}
@font-face
	{font-family:"Centaur Now Display";}
@font-face
	{font-family:"Centaur Now Text";}
@font-face
	{font-family:"Chamberi Super Display";}
@font-face
	{font-family:Charmonman;}
@font-face
	{font-family:"Chilgok Gwon Anja";}
@font-face
	{font-family:"Chilgok Kim Yeongbun";}
@font-face
	{font-family:"Chilgok Lee Jonghui";}
@font-face
	{font-family:"Chilgok Lee Wonsun";}
@font-face
	{font-family:Chonburi;}
@font-face
	{font-family:"Cochocib Script Latin Pro";}
@font-face
	{font-family:"Concert One";}
@font-face
	{font-family:Congenial;}
@font-face
	{font-family:"Congenial Black";}
@font-face
	{font-family:"Congenial Light";}
@font-face
	{font-family:"Congenial SemiBold";}
@font-face
	{font-family:"Congenial UltraLight";}
@font-face
	{font-family:Convection;}
@font-face
	{font-family:"Convection Condensed";}
@font-face
	{font-family:"Convection Extra Bold";}
@font-face
	{font-family:"Convection Symbol";}
@font-face
	{font-family:"Convection UI";}
@font-face
	{font-family:CordiaUPC;}
@font-face
	{font-family:Dante;}
@font-face
	{font-family:DaunPenh;}
@font-face
	{font-family:David;}
@font-face
	{font-family:Daytona;}
@font-face
	{font-family:"Daytona Condensed";}
@font-face
	{font-family:"Daytona Condensed Light";}
@font-face
	{font-family:"Daytona Light";}
@font-face
	{font-family:"DengXian Light";}
@font-face
	{font-family:"Didact Gothic";}
@font-face
	{font-family:DilleniaUPC;}
@font-face
	{font-family:"DM Mono";}
@font-face
	{font-family:"DM Mono Light";}
@font-face
	{font-family:"DM Mono Medium";}
@font-face
	{font-family:"DM Sans";}
@font-face
	{font-family:"DM Sans Medium";}
@font-face
	{font-family:"DM Serif Display";}
@font-face
	{font-family:"DM Serif Text";}
@font-face
	{font-family:DokChampa;}
@font-face
	{font-family:Dosis;}
@font-face
	{font-family:"Dosis ExtraBold";}
@font-face
	{font-family:"Dosis ExtraLight";}
@font-face
	{font-family:"Dosis Light";}
@font-face
	{font-family:"Dosis Medium";}
@font-face
	{font-family:"Dosis SemiBold";}
@font-face
	{font-family:DotumChe;}
@font-face
	{font-family:"Dreaming Outloud Pro";}
@font-face
	{font-family:"Dreaming Outloud Script Pro";}
@font-face
	{font-family:"EB Garamond";}
@font-face
	{font-family:"EB Garamond ExtraBold";}
@font-face
	{font-family:"EB Garamond Medium";}
@font-face
	{font-family:"EB Garamond SemiBold";}
@font-face
	{font-family:"Elephant Pro";}
@font-face
	{font-family:EucrosiaUPC;}
@font-face
	{font-family:Euphemia;}
@font-face
	{font-family:Fahkwang;}
@font-face
	{font-family:"Fahkwang ExtraLight";}
@font-face
	{font-family:"Fahkwang Light";}
@font-face
	{font-family:"Fahkwang Medium";}
@font-face
	{font-family:"Fahkwang SemiBold";}
@font-face
	{font-family:"Fairwater Script";}
@font-face
	{font-family:"Fairwater Script Light";}
@font-face
	{font-family:FangSong;}
@font-face
	{font-family:"Fave Script Bold Pro";}
@font-face
	{font-family:"Fira Code";}
@font-face
	{font-family:"Fira Code Light";}
@font-face
	{font-family:"Fira Code Medium";}
@font-face
	{font-family:"Fira Code Retina";}
@font-face
	{font-family:"Fira Mono";}
@font-face
	{font-family:"Fira Mono Medium";}
@font-face
	{font-family:"Fira Sans";}
@font-face
	{font-family:"Fira Sans Black";}
@font-face
	{font-family:"Fira Sans Condensed";}
@font-face
	{font-family:"Fira Sans Condensed Black";}
@font-face
	{font-family:"Fira Sans Condensed ExtraBold";}
@font-face
	{font-family:"Fira Sans Condensed ExtraLight";}
@font-face
	{font-family:"Fira Sans Condensed Light";}
@font-face
	{font-family:"Fira Sans Condensed Medium";}
@font-face
	{font-family:"Fira Sans Condensed SemiBold";}
@font-face
	{font-family:"Fira Sans Condensed Thin";}
@font-face
	{font-family:"Fira Sans Extra Condensed";}
@font-face
	{font-family:"Fira Sans Extra Condensed Black";}
@font-face
	{font-family:"Fira Sans Extra Condensed Light";}
@font-face
	{font-family:"Fira Sans Extra Condensed Thin";}
@font-face
	{font-family:"Fira Sans ExtraBold";}
@font-face
	{font-family:"Fira Sans ExtraLight";}
@font-face
	{font-family:"Fira Sans Light";}
@font-face
	{font-family:"Fira Sans Medium";}
@font-face
	{font-family:"Fira Sans SemiBold";}
@font-face
	{font-family:"Fira Sans Thin";}
@font-face
	{font-family:"Fjalla One";}
@font-face
	{font-family:"Forte Forward";}
@font-face
	{font-family:"Frank Ruhl Libre";}
@font-face
	{font-family:"Frank Ruhl Libre Black";}
@font-face
	{font-family:"Frank Ruhl Libre Light";}
@font-face
	{font-family:"Frank Ruhl Libre Medium";}
@font-face
	{font-family:FrankRuehl;}
@font-face
	{font-family:"Fredoka One";}
@font-face
	{font-family:FreesiaUPC;}
@font-face
	{font-family:Gabriela;}
@font-face
	{font-family:Gaegu;}
@font-face
	{font-family:"Gaegu Light";}
@font-face
	{font-family:"Georgia Pro";}
@font-face
	{font-family:"Georgia Pro Black";}
@font-face
	{font-family:"Georgia Pro Cond";}
@font-face
	{font-family:"Georgia Pro Cond Black";}
@font-face
	{font-family:"Georgia Pro Cond Light";}
@font-face
	{font-family:"Georgia Pro Cond Semibold";}
@font-face
	{font-family:"Georgia Pro Light";}
@font-face
	{font-family:"Georgia Pro Semibold";}
@font-face
	{font-family:"Gill Sans Nova";}
@font-face
	{font-family:"Gill Sans Nova Cond";}
@font-face
	{font-family:"Gill Sans Nova Cond Lt";}
@font-face
	{font-family:"Gill Sans Nova Cond Ultra Bold";}
@font-face
	{font-family:"Gill Sans Nova Cond XBd";}
@font-face
	{font-family:"Gill Sans Nova Light";}
@font-face
	{font-family:"Gill Sans Nova Ultra Bold";}
@font-face
	{font-family:Gisha;}
@font-face
	{font-family:"Goudy Type";}
@font-face
	{font-family:Grandview;}
@font-face
	{font-family:"Grandview Display";}
@font-face
	{font-family:Grotesque;}
@font-face
	{font-family:"Grotesque Light";}
@font-face
	{font-family:GulimChe;}
@font-face
	{font-family:Gungsuh;}
@font-face
	{font-family:GungsuhChe;}
@font-face
	{font-family:"Hadassah Friedlaender";}
@font-face
	{font-family:"Hammersmith One";}
@font-face
	{font-family:Heebo;}
@font-face
	{font-family:"Heebo Black";}
@font-face
	{font-family:"Heebo ExtraBold";}
@font-face
	{font-family:"Heebo Light";}
@font-face
	{font-family:"Heebo Medium";}
@font-face
	{font-family:"Heebo Thin";}
@font-face
	{font-family:HGGothicE;}
@font-face
	{font-family:HGMaruGothicMPRO;}
@font-face
	{font-family:HGMinchoE;}
@font-face
	{font-family:HGPGothicE;}
@font-face
	{font-family:HGPMinchoE;}
@font-face
	{font-family:HGPSoeiKakugothicUB;}
@font-face
	{font-family:HGSGothicE;}
@font-face
	{font-family:HGSMinchoE;}
@font-face
	{font-family:HGSoeiKakugothicUB;}
@font-face
	{font-family:HGSSoeiKakugothicUB;}
@font-face
	{font-family:Hind;}
@font-face
	{font-family:"Hind Colombo";}
@font-face
	{font-family:"Hind Colombo Light";}
@font-face
	{font-family:"Hind Colombo Medium";}
@font-face
	{font-family:"Hind Colombo SemiBold";}
@font-face
	{font-family:"Hind Guntur";}
@font-face
	{font-family:"Hind Guntur Light";}
@font-face
	{font-family:"Hind Guntur Medium";}
@font-face
	{font-family:"Hind Guntur SemiBold";}
@font-face
	{font-family:"Hind Jalandhar";}
@font-face
	{font-family:"Hind Jalandhar Light";}
@font-face
	{font-family:"Hind Jalandhar Medium";}
@font-face
	{font-family:"Hind Jalandhar SemiBold";}
@font-face
	{font-family:"Hind Kochi";}
@font-face
	{font-family:"Hind Kochi Light";}
@font-face
	{font-family:"Hind Kochi Medium";}
@font-face
	{font-family:"Hind Kochi SemiBold";}
@font-face
	{font-family:"Hind Light";}
@font-face
	{font-family:"Hind Madurai";}
@font-face
	{font-family:"Hind Madurai Light";}
@font-face
	{font-family:"Hind Madurai Medium";}
@font-face
	{font-family:"Hind Madurai SemiBold";}
@font-face
	{font-family:"Hind Medium";}
@font-face
	{font-family:"Hind Mysuru";}
@font-face
	{font-family:"Hind Mysuru Light";}
@font-face
	{font-family:"Hind Mysuru Medium";}
@font-face
	{font-family:"Hind Mysuru SemiBold";}
@font-face
	{font-family:"Hind SemiBold";}
@font-face
	{font-family:"Hind Siliguri";}
@font-face
	{font-family:"Hind Siliguri Light";}
@font-face
	{font-family:"Hind Siliguri Medium";}
@font-face
	{font-family:"Hind Siliguri SemiBold";}
@font-face
	{font-family:"Hind Vadodara";}
@font-face
	{font-family:"Hind Vadodara Light";}
@font-face
	{font-family:"Hind Vadodara Medium";}
@font-face
	{font-family:"Hind Vadodara SemiBold";}
@font-face
	{font-family:"IBM Plex Mono";}
@font-face
	{font-family:"IBM Plex Mono ExtraLight";}
@font-face
	{font-family:"IBM Plex Mono Light";}
@font-face
	{font-family:"IBM Plex Mono Medium";}
@font-face
	{font-family:"IBM Plex Mono SemiBold";}
@font-face
	{font-family:"IBM Plex Mono Thin";}
@font-face
	{font-family:"IBM Plex Sans";}
@font-face
	{font-family:"IBM Plex Sans Condensed";}
@font-face
	{font-family:"IBM Plex Sans Condensed Light";}
@font-face
	{font-family:"IBM Plex Sans Condensed Medium";}
@font-face
	{font-family:"IBM Plex Sans Condensed Thin";}
@font-face
	{font-family:"IBM Plex Sans ExtraLight";}
@font-face
	{font-family:"IBM Plex Sans Light";}
@font-face
	{font-family:"IBM Plex Sans Medium";}
@font-face
	{font-family:"IBM Plex Sans SemiBold";}
@font-face
	{font-family:"IBM Plex Sans Thin";}
@font-face
	{font-family:"IBM Plex Serif";}
@font-face
	{font-family:"IBM Plex Serif ExtraLight";}
@font-face
	{font-family:"IBM Plex Serif Light";}
@font-face
	{font-family:"IBM Plex Serif Medium";}
@font-face
	{font-family:"IBM Plex Serif SemiBold";}
@font-face
	{font-family:"IBM Plex Serif Thin";}
@font-face
	{font-family:Inconsolata;}
@font-face
	{font-family:"Inconsolata Black";}
@font-face
	{font-family:"Inconsolata Bold";}
@font-face
	{font-family:"Inconsolata Condensed";}
@font-face
	{font-family:"Inconsolata Condensed Black";}
@font-face
	{font-family:"Inconsolata Condensed Bold";}
@font-face
	{font-family:"Inconsolata Condensed ExtraBold";}
@font-face
	{font-family:"Inconsolata Condensed Light";}
@font-face
	{font-family:"Inconsolata Condensed Medium";}
@font-face
	{font-family:"Inconsolata Condensed SemiBold";}
@font-face
	{font-family:"Inconsolata Expanded";}
@font-face
	{font-family:"Inconsolata Expanded Black";}
@font-face
	{font-family:"Inconsolata Expanded Bold";}
@font-face
	{font-family:"Inconsolata Expanded ExtraBold";}
@font-face
	{font-family:"Inconsolata Expanded ExtraLight";}
@font-face
	{font-family:"Inconsolata Expanded Light";}
@font-face
	{font-family:"Inconsolata Expanded Medium";}
@font-face
	{font-family:"Inconsolata Expanded SemiBold";}
@font-face
	{font-family:"Inconsolata ExtraBold";}
@font-face
	{font-family:"Inconsolata ExtraCondensed";}
@font-face
	{font-family:"Inconsolata ExtraCondensed Bold";}
@font-face
	{font-family:"Inconsolata ExtraExpanded";}
@font-face
	{font-family:"Inconsolata ExtraExpanded Black";}
@font-face
	{font-family:"Inconsolata ExtraExpanded Bold";}
@font-face
	{font-family:"Inconsolata ExtraExpanded Light";}
@font-face
	{font-family:"Inconsolata ExtraLight";}
@font-face
	{font-family:"Inconsolata Light";}
@font-face
	{font-family:"Inconsolata Medium";}
@font-face
	{font-family:"Inconsolata SemiBold";}
@font-face
	{font-family:"Inconsolata SemiCondensed";}
@font-face
	{font-family:"Inconsolata SemiCondensed Black";}
@font-face
	{font-family:"Inconsolata SemiCondensed Bold";}
@font-face
	{font-family:"Inconsolata SemiCondensed Light";}
@font-face
	{font-family:"Inconsolata SemiExpanded";}
@font-face
	{font-family:"Inconsolata SemiExpanded Black";}
@font-face
	{font-family:"Inconsolata SemiExpanded Bold";}
@font-face
	{font-family:"Inconsolata SemiExpanded Light";}
@font-face
	{font-family:"Inconsolata SemiExpanded Medium";}
@font-face
	{font-family:"Inconsolata UltraCondensed";}
@font-face
	{font-family:"Inconsolata UltraCondensed Bold";}
@font-face
	{font-family:"Inconsolata UltraExpanded";}
@font-face
	{font-family:"Inconsolata UltraExpanded Black";}
@font-face
	{font-family:"Inconsolata UltraExpanded Bold";}
@font-face
	{font-family:"Inconsolata UltraExpanded Light";}
@font-face
	{font-family:IrisUPC;}
@font-face
	{font-family:"Iskoola Pota";}
@font-face
	{font-family:Italianno;}
@font-face
	{font-family:JasmineUPC;}
@font-face
	{font-family:"Josefin Sans";}
@font-face
	{font-family:"Josefin Sans Bold";}
@font-face
	{font-family:"Josefin Sans Light";}
@font-face
	{font-family:"Josefin Sans SemiBold";}
@font-face
	{font-family:"Josefin Sans Thin";}
@font-face
	{font-family:"Josefin Slab";}
@font-face
	{font-family:"Josefin Slab Light";}
@font-face
	{font-family:"Josefin Slab SemiBold";}
@font-face
	{font-family:"Josefin Slab Thin";}
@font-face
	{font-family:Jumble;}
@font-face
	{font-family:KaiTi;}
@font-face
	{font-family:Kalinga;}
@font-face
	{font-family:Karla;}
@font-face
	{font-family:"Karla ExtraBold";}
@font-face
	{font-family:"Karla ExtraLight";}
@font-face
	{font-family:"Karla Light";}
@font-face
	{font-family:"Karla Medium";}
@font-face
	{font-family:"Karla Tamil Inclined";}
@font-face
	{font-family:"Karla Tamil Upright";}
@font-face
	{font-family:Kartika;}
@font-face
	{font-family:Kermit;}
@font-face
	{font-family:"Kermit Condensed";}
@font-face
	{font-family:"Kermit Expanded";}
@font-face
	{font-family:"Kermit Extrabold";}
@font-face
	{font-family:"Kermit Extrabold Condensed";}
@font-face
	{font-family:"Kermit Extrabold Expanded";}
@font-face
	{font-family:"Kermit Extralight";}
@font-face
	{font-family:"Kermit Extralight Condensed";}
@font-face
	{font-family:"Kermit Extralight Expanded";}
@font-face
	{font-family:"Kermit Light";}
@font-face
	{font-family:"Kermit Light Condensed";}
@font-face
	{font-family:"Kermit Light Expanded";}
@font-face
	{font-family:"Kermit Semibold";}
@font-face
	{font-family:"Kermit Semibold Condensed";}
@font-face
	{font-family:"Kermit Semibold Expanded";}
@font-face
	{font-family:"Kermit Thin";}
@font-face
	{font-family:"Kermit Thin Condensed";}
@font-face
	{font-family:"Kermit Thin Expanded";}
@font-face
	{font-family:"Khmer UI";}
@font-face
	{font-family:Kigelia;}
@font-face
	{font-family:"Kigelia Arabic";}
@font-face
	{font-family:"Kigelia Arabic Light";}
@font-face
	{font-family:"Kigelia Light";}
@font-face
	{font-family:"Klee One";}
@font-face
	{font-family:"Klee One SemiBold";}
@font-face
	{font-family:KodchiangUPC;}
@font-face
	{font-family:Kokila;}
@font-face
	{font-family:Krub;}
@font-face
	{font-family:"Krub ExtraLight";}
@font-face
	{font-family:"Krub Light";}
@font-face
	{font-family:"Krub Medium";}
@font-face
	{font-family:"Krub SemiBold";}
@font-face
	{font-family:Lalezar;}
@font-face
	{font-family:"Lao UI";}
@font-face
	{font-family:Lato;}
@font-face
	{font-family:"Lato Black";}
@font-face
	{font-family:"Lato ExtraBold";}
@font-face
	{font-family:"Lato ExtraLight";}
@font-face
	{font-family:"Lato Light";}
@font-face
	{font-family:"Lato Medium";}
@font-face
	{font-family:"Lato SemiBold";}
@font-face
	{font-family:"Lato Thin";}
@font-face
	{font-family:Leelawadee;}
@font-face
	{font-family:"Levenim MT";}
@font-face
	{font-family:"Libre Barcode 128";}
@font-face
	{font-family:"Libre Barcode 128 Text";}
@font-face
	{font-family:"Libre Barcode 39";}
@font-face
	{font-family:"Libre Barcode 39 Extended";}
@font-face
	{font-family:"Libre Barcode 39 Extended Text";}
@font-face
	{font-family:"Libre Barcode 39 Text";}
@font-face
	{font-family:"Libre Barcode EAN13 Text";}
@font-face
	{font-family:"Libre Baskerville";}
@font-face
	{font-family:"Libre Franklin";}
@font-face
	{font-family:"Libre Franklin Black";}
@font-face
	{font-family:"Libre Franklin ExtraBold";}
@font-face
	{font-family:"Libre Franklin ExtraLight";}
@font-face
	{font-family:"Libre Franklin Light";}
@font-face
	{font-family:"Libre Franklin Medium";}
@font-face
	{font-family:"Libre Franklin SemiBold";}
@font-face
	{font-family:"Libre Franklin Thin";}
@font-face
	{font-family:Ligconsolata;}
@font-face
	{font-family:LilyUPC;}
@font-face
	{font-family:Livvic;}
@font-face
	{font-family:"Livvic Black";}
@font-face
	{font-family:"Livvic ExtraLight";}
@font-face
	{font-family:"Livvic Light";}
@font-face
	{font-family:"Livvic Medium";}
@font-face
	{font-family:"Livvic SemiBold";}
@font-face
	{font-family:"Livvic Thin";}
@font-face
	{font-family:Lobster;}
@font-face
	{font-family:"Lobster Two";}
@font-face
	{font-family:Lora;}
@font-face
	{font-family:"Lora Medium";}
@font-face
	{font-family:"Mangal Pro";}
@font-face
	{font-family:Meddon;}
@font-face
	{font-family:Meiryo;}
@font-face
	{font-family:"Meiryo UI";}
@font-face
	{font-family:Merriweather;}
@font-face
	{font-family:"Merriweather Black";}
@font-face
	{font-family:"Merriweather Light";}
@font-face
	{font-family:"Merriweather Sans";}
@font-face
	{font-family:"Merriweather Sans ExtraBold";}
@font-face
	{font-family:"Merriweather Sans Light";}
@font-face
	{font-family:"Microsoft GothicNeo";}
@font-face
	{font-family:"Microsoft GothicNeo Light";}
@font-face
	{font-family:"Microsoft Uighur";}
@font-face
	{font-family:MingLiU_HKSCS;}
@font-face
	{font-family:MingLiU_MSCS;}
@font-face
	{font-family:Miriam;}
@font-face
	{font-family:"Miriam Fixed";}
@font-face
	{font-family:"Miriam Libre";}
@font-face
	{font-family:Mitr;}
@font-face
	{font-family:"Mitr ExtraLight";}
@font-face
	{font-family:"Mitr Light";}
@font-face
	{font-family:"Mitr Medium";}
@font-face
	{font-family:"Mitr SemiBold";}
@font-face
	{font-family:"Modern Love";}
@font-face
	{font-family:"Modern Love Caps";}
@font-face
	{font-family:"Modern Love Grunge";}
@font-face
	{font-family:Montserrat;}
@font-face
	{font-family:"Montserrat Black";}
@font-face
	{font-family:"Montserrat ExtraBold";}
@font-face
	{font-family:"Montserrat ExtraLight";}
@font-face
	{font-family:"Montserrat Light";}
@font-face
	{font-family:"Montserrat Medium";}
@font-face
	{font-family:"Montserrat SemiBold";}
@font-face
	{font-family:"Montserrat Thin";}
@font-face
	{font-family:MoolBoran;}
@font-face
	{font-family:"Mr Gabe";}
@font-face
	{font-family:"MS PMincho";}
@font-face
	{font-family:"Mystical Woods Rough Script";}
@font-face
	{font-family:"Mystical Woods Smooth Script";}
@font-face
	{font-family:"Nanum Brush Script";}
@font-face
	{font-family:"Nanum Pen";}
@font-face
	{font-family:NanumGothic;}
@font-face
	{font-family:NanumGothicCoding;}
@font-face
	{font-family:NanumGothicExtraBold;}
@font-face
	{font-family:NanumMyeongjo;}
@font-face
	{font-family:NanumMyeongjoExtraBold;}
@font-face
	{font-family:Narkisim;}
@font-face
	{font-family:"Neue Haas Grotesk Text Pro";}
@font-face
	{font-family:"News Gothic MT";}
@font-face
	{font-family:Nina;}
@font-face
	{font-family:"Nordique Inline";}
@font-face
	{font-family:"Noto Music";}
@font-face
	{font-family:"Noto Nastaliq Urdu";}
@font-face
	{font-family:"Noto Sans";}
@font-face
	{font-family:"Noto Sans AnatoHiero";}
@font-face
	{font-family:"Noto Sans Avestan";}
@font-face
	{font-family:"Noto Sans Bassa Vah";}
@font-face
	{font-family:"Noto Sans Batak";}
@font-face
	{font-family:"Noto Sans Bhaiksuki";}
@font-face
	{font-family:"Noto Sans Brahmi";}
@font-face
	{font-family:"Noto Sans Buginese";}
@font-face
	{font-family:"Noto Sans Buhid";}
@font-face
	{font-family:"Noto Sans Carian";}
@font-face
	{font-family:"Noto Sans CaucAlban";}
@font-face
	{font-family:"Noto Sans Chakma";}
@font-face
	{font-family:"Noto Sans Coptic";}
@font-face
	{font-family:"Noto Sans Cuneiform";}
@font-face
	{font-family:"Noto Sans Cypriot";}
@font-face
	{font-family:"Noto Sans Deseret";}
@font-face
	{font-family:"Noto Sans Devanagari";}
@font-face
	{font-family:"Noto Sans Devanagari Black";}
@font-face
	{font-family:"Noto Sans Devanagari ExtraBold";}
@font-face
	{font-family:"Noto Sans Devanagari ExtraLight";}
@font-face
	{font-family:"Noto Sans Devanagari Light";}
@font-face
	{font-family:"Noto Sans Devanagari Medium";}
@font-face
	{font-family:"Noto Sans Devanagari SemiBold";}
@font-face
	{font-family:"Noto Sans Devanagari Thin";}
@font-face
	{font-family:"Noto Sans Devanagari UI";}
@font-face
	{font-family:"Noto Sans Devanagari UI Black";}
@font-face
	{font-family:"Noto Sans Devanagari UI Light";}
@font-face
	{font-family:"Noto Sans Devanagari UI Medium";}
@font-face
	{font-family:"Noto Sans Devanagari UI Thin";}
@font-face
	{font-family:"Noto Sans Duployan";}
@font-face
	{font-family:"Noto Sans EgyptHiero";}
@font-face
	{font-family:"Noto Sans Elbasan";}
@font-face
	{font-family:"Noto Sans Elymaic";}
@font-face
	{font-family:"Noto Sans Glagolitic";}
@font-face
	{font-family:"Noto Sans Gothic";}
@font-face
	{font-family:"Noto Sans Grantha";}
@font-face
	{font-family:"Noto Sans Gujarati";}
@font-face
	{font-family:"Noto Sans Gujarati Black";}
@font-face
	{font-family:"Noto Sans Gujarati ExtraBold";}
@font-face
	{font-family:"Noto Sans Gujarati ExtraLight";}
@font-face
	{font-family:"Noto Sans Gujarati Light";}
@font-face
	{font-family:"Noto Sans Gujarati Medium";}
@font-face
	{font-family:"Noto Sans Gujarati SemiBold";}
@font-face
	{font-family:"Noto Sans Gujarati Thin";}
@font-face
	{font-family:"Noto Sans Gujarati UI";}
@font-face
	{font-family:"Noto Sans Gujarati UI Black";}
@font-face
	{font-family:"Noto Sans Gujarati UI ExtraBold";}
@font-face
	{font-family:"Noto Sans Gujarati UI Light";}
@font-face
	{font-family:"Noto Sans Gujarati UI Medium";}
@font-face
	{font-family:"Noto Sans Gujarati UI SemiBold";}
@font-face
	{font-family:"Noto Sans Gujarati UI Thin";}
@font-face
	{font-family:"Noto Sans Gunjala Gondi";}
@font-face
	{font-family:"Noto Sans Hanunoo";}
@font-face
	{font-family:"Noto Sans Hatran";}
@font-face
	{font-family:"Noto Sans ImpAramaic";}
@font-face
	{font-family:"Noto Sans Indic Siyaq Numbers";}
@font-face
	{font-family:"Noto Sans InsPahlavi";}
@font-face
	{font-family:"Noto Sans InsParthi";}
@font-face
	{font-family:"Noto Sans Javanese";}
@font-face
	{font-family:"Noto Sans Kaithi";}
@font-face
	{font-family:"Noto Sans Kharoshthi";}
@font-face
	{font-family:"Noto Sans Khojki";}
@font-face
	{font-family:"Noto Sans Khudawadi";}
@font-face
	{font-family:"Noto Sans Lepcha";}
@font-face
	{font-family:"Noto Sans Limbu";}
@font-face
	{font-family:"Noto Sans Linear A";}
@font-face
	{font-family:"Noto Sans Linear B";}
@font-face
	{font-family:"Noto Sans Lycian";}
@font-face
	{font-family:"Noto Sans Lydian";}
@font-face
	{font-family:"Noto Sans Mahajani";}
@font-face
	{font-family:"Noto Sans Mandaic";}
@font-face
	{font-family:"Noto Sans Manichaean";}
@font-face
	{font-family:"Noto Sans Marchen";}
@font-face
	{font-family:"Noto Sans Masaram Gondi";}
@font-face
	{font-family:"Noto Sans Math";}
@font-face
	{font-family:"Noto Sans Mayan Numerals";}
@font-face
	{font-family:"Noto Sans Mende Kikakui";}
@font-face
	{font-family:"Noto Sans Meroitic";}
@font-face
	{font-family:"Noto Sans Miao";}
@font-face
	{font-family:"Noto Sans Modi";}
@font-face
	{font-family:"Noto Sans Mongolian";}
@font-face
	{font-family:"Noto Sans Mro";}
@font-face
	{font-family:"Noto Sans Multani";}
@font-face
	{font-family:"Noto Sans Myanmar";}
@font-face
	{font-family:"Noto Sans Myanmar Blk";}
@font-face
	{font-family:"Noto Sans Myanmar ExtBd";}
@font-face
	{font-family:"Noto Sans Myanmar ExtLt";}
@font-face
	{font-family:"Noto Sans Myanmar Light";}
@font-face
	{font-family:"Noto Sans Myanmar Med";}
@font-face
	{font-family:"Noto Sans Myanmar SemBd";}
@font-face
	{font-family:"Noto Sans Myanmar Thin";}
@font-face
	{font-family:"Noto Sans Myanmar UI";}
@font-face
	{font-family:"Noto Sans Myanmar UI Black";}
@font-face
	{font-family:"Noto Sans Myanmar UI ExtraBold";}
@font-face
	{font-family:"Noto Sans Myanmar UI ExtraLight";}
@font-face
	{font-family:"Noto Sans Myanmar UI Light";}
@font-face
	{font-family:"Noto Sans Myanmar UI Medium";}
@font-face
	{font-family:"Noto Sans Myanmar UI SemiBold";}
@font-face
	{font-family:"Noto Sans Myanmar UI Thin";}
@font-face
	{font-family:"Noto Sans Nabataean";}
@font-face
	{font-family:"Noto Sans Newa";}
@font-face
	{font-family:"Noto Sans NewTaiLue";}
@font-face
	{font-family:"Noto Sans NKo";}
@font-face
	{font-family:"Noto Sans Nushu";}
@font-face
	{font-family:"Noto Sans Ogham";}
@font-face
	{font-family:"Noto Sans Old Italic";}
@font-face
	{font-family:"Noto Sans Old Permic";}
@font-face
	{font-family:"Noto Sans Old Turkic";}
@font-face
	{font-family:"Noto Sans OldHung";}
@font-face
	{font-family:"Noto Sans OldNorArab";}
@font-face
	{font-family:"Noto Sans OldPersian";}
@font-face
	{font-family:"Noto Sans OldSogdian";}
@font-face
	{font-family:"Noto Sans OldSouArab";}
@font-face
	{font-family:"Noto Sans Oriya";}
@font-face
	{font-family:"Noto Sans Oriya Blk";}
@font-face
	{font-family:"Noto Sans Oriya Thin";}
@font-face
	{font-family:"Noto Sans Oriya UI";}
@font-face
	{font-family:"Noto Sans Oriya UI Blk";}
@font-face
	{font-family:"Noto Sans Oriya UI Thin";}
@font-face
	{font-family:"Noto Sans Osage";}
@font-face
	{font-family:"Noto Sans Osmanya";}
@font-face
	{font-family:"Noto Sans Pahawh Hmong";}
@font-face
	{font-family:"Noto Sans Palmyrene";}
@font-face
	{font-family:"Noto Sans PauCinHau";}
@font-face
	{font-family:"Noto Sans PhagsPa";}
@font-face
	{font-family:"Noto Sans Phoenician";}
@font-face
	{font-family:"Noto Sans PsaPahlavi";}
@font-face
	{font-family:"Noto Sans Rejang";}
@font-face
	{font-family:"Noto Sans Runic";}
@font-face
	{font-family:"Noto Sans Samaritan";}
@font-face
	{font-family:"Noto Sans Saurashtra";}
@font-face
	{font-family:"Noto Sans Sharada";}
@font-face
	{font-family:"Noto Sans Shavian";}
@font-face
	{font-family:"Noto Sans Siddham";}
@font-face
	{font-family:"Noto Sans Sogdian";}
@font-face
	{font-family:"Noto Sans Soyombo";}
@font-face
	{font-family:"Noto Sans Syloti Nagri";}
@font-face
	{font-family:"Noto Sans Symbols2";}
@font-face
	{font-family:"Noto Sans Syriac";}
@font-face
	{font-family:"Noto Sans Syriac Black";}
@font-face
	{font-family:"Noto Sans Syriac Thin";}
@font-face
	{font-family:"Noto Sans Tagalog";}
@font-face
	{font-family:"Noto Sans Tagbanwa";}
@font-face
	{font-family:"Noto Sans Tai Le";}
@font-face
	{font-family:"Noto Sans Tai Viet";}
@font-face
	{font-family:"Noto Sans Takri";}
@font-face
	{font-family:"Noto Sans Tamil Supplement";}
@font-face
	{font-family:"Noto Sans Thai Looped Black";}
@font-face
	{font-family:"Noto Sans Thai Looped Bold";}
@font-face
	{font-family:"Noto Sans Thai Looped ExtLight";}
@font-face
	{font-family:"Noto Sans Thai Looped Extrabold";}
@font-face
	{font-family:"Noto Sans Thai Looped Light";}
@font-face
	{font-family:"Noto Sans Thai Looped Medium";}
@font-face
	{font-family:"Noto Sans Thai Looped Regular";}
@font-face
	{font-family:"Noto Sans Thai Looped Semibold";}
@font-face
	{font-family:"Noto Sans Thai Looped Thin";}
@font-face
	{font-family:"Noto Sans Tifinagh";}
@font-face
	{font-family:"Noto Sans Tirhuta";}
@font-face
	{font-family:"Noto Sans Ugaritic";}
@font-face
	{font-family:"Noto Sans Vai";}
@font-face
	{font-family:"Noto Sans Wancho";}
@font-face
	{font-family:"Noto Sans WarangCiti";}
@font-face
	{font-family:"Noto Sans Yi";}
@font-face
	{font-family:"Noto Sans Zanabazar";}
@font-face
	{font-family:"Noto Serif";}
@font-face
	{font-family:"Noto Serif Ahom";}
@font-face
	{font-family:"Noto Serif Balinese";}
@font-face
	{font-family:"Noto Serif Dogra";}
@font-face
	{font-family:"Noto Serif Grantha";}
@font-face
	{font-family:"Noto Serif Myanmar";}
@font-face
	{font-family:"Noto Serif Myanmar Blk";}
@font-face
	{font-family:"Noto Serif Myanmar ExtBd";}
@font-face
	{font-family:"Noto Serif Myanmar ExtLt";}
@font-face
	{font-family:"Noto Serif Myanmar Light";}
@font-face
	{font-family:"Noto Serif Myanmar Med";}
@font-face
	{font-family:"Noto Serif Myanmar SemBd";}
@font-face
	{font-family:"Noto Serif Myanmar Thin";}
@font-face
	{font-family:"Noto Serif Tangut";}
@font-face
	{font-family:"Noto Traditional Nushu";}
@font-face
	{font-family:Nunito;}
@font-face
	{font-family:"Nunito Black";}
@font-face
	{font-family:"Nunito ExtraBold";}
@font-face
	{font-family:"Nunito ExtraLight";}
@font-face
	{font-family:"Nunito Light";}
@font-face
	{font-family:"Nunito Sans";}
@font-face
	{font-family:"Nunito Sans Black";}
@font-face
	{font-family:"Nunito Sans ExtraBold";}
@font-face
	{font-family:"Nunito Sans ExtraLight";}
@font-face
	{font-family:"Nunito Sans Light";}
@font-face
	{font-family:"Nunito Sans SemiBold";}
@font-face
	{font-family:"Nunito SemiBold";}
@font-face
	{font-family:Nyala;}
@font-face
	{font-family:OCRB;}
@font-face
	{font-family:"Open Sans";}
@font-face
	{font-family:"Open Sans ExtraBold";}
@font-face
	{font-family:"Open Sans Light";}
@font-face
	{font-family:"Open Sans SemiBold";}
@font-face
	{font-family:Oranienbaum;}
@font-face
	{font-family:Oswald;}
@font-face
	{font-family:"Oswald ExtraLight";}
@font-face
	{font-family:"Oswald Light";}
@font-face
	{font-family:"Oswald Medium";}
@font-face
	{font-family:"Oswald SemiBold";}
@font-face
	{font-family:Oxygen;}
@font-face
	{font-family:"Oxygen Light";}
@font-face
	{font-family:"Oxygen Mono";}
@font-face
	{font-family:Pacifico;}
@font-face
	{font-family:Palanquin;}
@font-face
	{font-family:"Palanquin ExtraLight";}
@font-face
	{font-family:"Palanquin Light";}
@font-face
	{font-family:"Palanquin Medium";}
@font-face
	{font-family:"Palanquin SemiBold";}
@font-face
	{font-family:"Palanquin Thin";}
@font-face
	{font-family:"Patrick Hand";}
@font-face
	{font-family:"Patrick Hand SC";}
@font-face
	{font-family:"Petit Formal Script";}
@font-face
	{font-family:"Plantagenet Cherokee";}
@font-face
	{font-family:"Playfair Display";}
@font-face
	{font-family:"Playfair Display Black";}
@font-face
	{font-family:"Playfair Display SC";}
@font-face
	{font-family:"Playfair Display SC Black";}
@font-face
	{font-family:"Poiret One";}
@font-face
	{font-family:Poppins;}
@font-face
	{font-family:"Poppins Black";}
@font-face
	{font-family:"Poppins ExtraBold";}
@font-face
	{font-family:"Poppins ExtraLight";}
@font-face
	{font-family:"Poppins Light";}
@font-face
	{font-family:"Poppins Medium";}
@font-face
	{font-family:"Poppins SemiBold";}
@font-face
	{font-family:"Poppins Thin";}
@font-face
	{font-family:Posterama;}
@font-face
	{font-family:Pridi;}
@font-face
	{font-family:"Pridi ExtraLight";}
@font-face
	{font-family:"Pridi Light";}
@font-face
	{font-family:"Pridi Medium";}
@font-face
	{font-family:"Pridi SemiBold";}
@font-face
	{font-family:Prompt;}
@font-face
	{font-family:"Prompt Black";}
@font-face
	{font-family:"Prompt ExtraBold";}
@font-face
	{font-family:"Prompt ExtraLight";}
@font-face
	{font-family:"Prompt Light";}
@font-face
	{font-family:"Prompt Medium";}
@font-face
	{font-family:"Prompt SemiBold";}
@font-face
	{font-family:"Prompt Thin";}
@font-face
	{font-family:"PT Mono";}
@font-face
	{font-family:"PT Sans";}
@font-face
	{font-family:"PT Sans Caption";}
@font-face
	{font-family:"PT Sans Narrow";}
@font-face
	{font-family:"PT Serif";}
@font-face
	{font-family:"PT Serif Caption";}
@font-face
	{font-family:Quattrocento;}
@font-face
	{font-family:"Quattrocento Sans";}
@font-face
	{font-family:Questrial;}
@font-face
	{font-family:"Quire Sans";}
@font-face
	{font-family:"Quire Sans Light";}
@font-face
	{font-family:"Quire Sans Pro Light";}
@font-face
	{font-family:Raleway;}
@font-face
	{font-family:"Raleway Black";}
@font-face
	{font-family:"Raleway ExtraBold";}
@font-face
	{font-family:"Raleway ExtraLight";}
@font-face
	{font-family:"Raleway Light";}
@font-face
	{font-family:"Raleway Medium";}
@font-face
	{font-family:"Raleway SemiBold";}
@font-face
	{font-family:"Raleway Thin";}
@font-face
	{font-family:"Rastanty Cortez";}
@font-face
	{font-family:"Reem Kufi";}
@font-face
	{font-family:Roboto;}
@font-face
	{font-family:"Roboto Black";}
@font-face
	{font-family:"Roboto Condensed";}
@font-face
	{font-family:"Roboto Condensed Light";}
@font-face
	{font-family:"Roboto Condensed Medium";}
@font-face
	{font-family:"Roboto Light";}
@font-face
	{font-family:"Roboto Medium";}
@font-face
	{font-family:"Roboto Mono";}
@font-face
	{font-family:"Roboto Mono Light";}
@font-face
	{font-family:"Roboto Mono Medium";}
@font-face
	{font-family:"Roboto Mono Thin";}
@font-face
	{font-family:"Roboto Serif 20pt";}
@font-face
	{font-family:"Roboto Serif 20pt Black";}
@font-face
	{font-family:"Roboto Serif 20pt ExtraBold";}
@font-face
	{font-family:"Roboto Serif 20pt ExtraLight";}
@font-face
	{font-family:"Roboto Serif 20pt Light";}
@font-face
	{font-family:"Roboto Serif 20pt Medium";}
@font-face
	{font-family:"Roboto Serif 20pt SemiBold";}
@font-face
	{font-family:"Roboto Serif 20pt Thin";}
@font-face
	{font-family:"Roboto Slab";}
@font-face
	{font-family:"Roboto Slab Black";}
@font-face
	{font-family:"Roboto Slab ExtraBold";}
@font-face
	{font-family:"Roboto Slab ExtraLight";}
@font-face
	{font-family:"Roboto Slab Light";}
@font-face
	{font-family:"Roboto Slab Medium";}
@font-face
	{font-family:"Roboto Slab SemiBold";}
@font-face
	{font-family:"Roboto Slab Thin";}
@font-face
	{font-family:"Roboto Thin";}
@font-face
	{font-family:"Rockwell Light";}
@font-face
	{font-family:"Rockwell Nova";}
@font-face
	{font-family:"Rockwell Nova Cond";}
@font-face
	{font-family:"Rockwell Nova Cond Light";}
@font-face
	{font-family:"Rockwell Nova Extra Bold";}
@font-face
	{font-family:"Rockwell Nova Light";}
@font-face
	{font-family:Rod;}
@font-face
	{font-family:"Sabon Next LT";}
@font-face
	{font-family:Sacramento;}
@font-face
	{font-family:Sagona;}
@font-face
	{font-family:"Sagona Book";}
@font-face
	{font-family:"Sagona ExtraLight";}
@font-face
	{font-family:"Sakkal Majalla";}
@font-face
	{font-family:"Sanskrit Text";}
@font-face
	{font-family:Seaford;}
@font-face
	{font-family:"Seaford Display";}
@font-face
	{font-family:"Secular One";}
@font-face
	{font-family:"Segoe Marker";}
@font-face
	{font-family:"Segoe Pro";}
@font-face
	{font-family:"Segoe Pro Black";}
@font-face
	{font-family:"Segoe Pro Cond";}
@font-face
	{font-family:"Segoe Pro Display";}
@font-face
	{font-family:"Segoe Pro Display Light";}
@font-face
	{font-family:"Segoe Pro Display Semibold";}
@font-face
	{font-family:"Segoe Pro Display SemiLight";}
@font-face
	{font-family:"Segoe Pro Light";}
@font-face
	{font-family:"Segoe Pro Semibold";}
@font-face
	{font-family:"Segoe Pro SemiLight";}
@font-face
	{font-family:"Segoe Sans Display";}
@font-face
	{font-family:"Segoe Sans Display Black";}
@font-face
	{font-family:"Segoe Sans Display Extrabold";}
@font-face
	{font-family:"Segoe Sans Display Hairline";}
@font-face
	{font-family:"Segoe Sans Display Light";}
@font-face
	{font-family:"Segoe Sans Display Semibold";}
@font-face
	{font-family:"Segoe Sans Display Semilight";}
@font-face
	{font-family:"Segoe Sans Display Thin";}
@font-face
	{font-family:"Segoe Sans Small";}
@font-face
	{font-family:"Segoe Sans Small Black";}
@font-face
	{font-family:"Segoe Sans Small Extrabold";}
@font-face
	{font-family:"Segoe Sans Small Hairline";}
@font-face
	{font-family:"Segoe Sans Small Light";}
@font-face
	{font-family:"Segoe Sans Small Semibold";}
@font-face
	{font-family:"Segoe Sans Small Semilight";}
@font-face
	{font-family:"Segoe Sans Small Thin";}
@font-face
	{font-family:"Segoe Sans Text";}
@font-face
	{font-family:"Segoe Sans Text Black";}
@font-face
	{font-family:"Segoe Sans Text Extrabold";}
@font-face
	{font-family:"Segoe Sans Text Hairline";}
@font-face
	{font-family:"Segoe Sans Text Light";}
@font-face
	{font-family:"Segoe Sans Text Semibold";}
@font-face
	{font-family:"Segoe Sans Text Semilight";}
@font-face
	{font-family:"Segoe Sans Text Thin";}
@font-face
	{font-family:"Segoe Serif Banner";}
@font-face
	{font-family:"Segoe Serif Banner Light";}
@font-face
	{font-family:"Segoe Serif Banner Semibold";}
@font-face
	{font-family:"Segoe Serif Banner Semilight";}
@font-face
	{font-family:"Segoe Serif Display";}
@font-face
	{font-family:"Segoe Serif Display Light";}
@font-face
	{font-family:"Segoe Serif Display Semibold";}
@font-face
	{font-family:"Segoe Serif Display Semilight";}
@font-face
	{font-family:"Segoe Serif Text";}
@font-face
	{font-family:"Segoe Serif Text Light";}
@font-face
	{font-family:"Segoe Serif Text Semibold";}
@font-face
	{font-family:"Segoe Serif Text Semilight";}
@font-face
	{font-family:"Segoe UI Emoji L";}
@font-face
	{font-family:"Segoe UI Variable Display Black";}
@font-face
	{font-family:"Segoe UI Variable Display Thin";}
@font-face
	{font-family:"Segoe UI Variable Small Black";}
@font-face
	{font-family:"Segoe UI Variable Small Thin";}
@font-face
	{font-family:"Segoe UI Variable Text Black";}
@font-face
	{font-family:"Segoe UI Variable Text Hairline";}
@font-face
	{font-family:"Segoe UI Variable Text Thin";}
@font-face
	{font-family:"Segoe Xbox Symbol";}
@font-face
	{font-family:Selawik;}
@font-face
	{font-family:"Selawik Light";}
@font-face
	{font-family:"Selawik Semibold";}
@font-face
	{font-family:"Shadows Into Light Two";}
@font-face
	{font-family:"Shonar Bangla";}
@font-face
	{font-family:"Simplified Arabic";}
@font-face
	{font-family:"Simplified Arabic Fixed";}
@font-face
	{font-family:Skeena;}
@font-face
	{font-family:"Skeena Display";}
@font-face
	{font-family:"Skeena Indigenous";}
@font-face
	{font-family:"Skeena Indigenous Black";}
@font-face
	{font-family:"Skeena Indigenous Extra Bold";}
@font-face
	{font-family:"Skeena Indigenous Medium";}
@font-face
	{font-family:"Skeena Indigenous Semibold";}
@font-face
	{font-family:"Source Code Pro";}
@font-face
	{font-family:"Source Code Pro Black";}
@font-face
	{font-family:"Source Code Pro ExtraLight";}
@font-face
	{font-family:"Source Code Pro Light";}
@font-face
	{font-family:"Source Code Pro Medium";}
@font-face
	{font-family:"Source Code Pro Semibold";}
@font-face
	{font-family:"Source Sans Pro";}
@font-face
	{font-family:"Source Sans Pro Black";}
@font-face
	{font-family:"Source Sans Pro ExtraLight";}
@font-face
	{font-family:"Source Sans Pro Light";}
@font-face
	{font-family:"Source Sans Pro SemiBold";}
@font-face
	{font-family:"Source Serif Pro";}
@font-face
	{font-family:"Source Serif Pro Black";}
@font-face
	{font-family:"Source Serif Pro ExtraLight";}
@font-face
	{font-family:"Source Serif Pro Light";}
@font-face
	{font-family:"Source Serif Pro SemiBold";}
@font-face
	{font-family:"Speak Pro";}
@font-face
	{font-family:"Speak Pro Light";}
@font-face
	{font-family:Staatliches;}
@font-face
	{font-family:STCaiyun;}
@font-face
	{font-family:STFangsong;}
@font-face
	{font-family:STHupo;}
@font-face
	{font-family:STKaiti;}
@font-face
	{font-family:STXihei;}
@font-face
	{font-family:STXingkai;}
@font-face
	{font-family:STXinwei;}
@font-face
	{font-family:STZhongsong;}
@font-face
	{font-family:"Suez One";}
@font-face
	{font-family:Tenorite;}
@font-face
	{font-family:"Tenorite Display";}
@font-face
	{font-family:"TH SarabunPSK";}
@font-face
	{font-family:"The Hand";}
@font-face
	{font-family:"The Hand Black";}
@font-face
	{font-family:"The Hand Extrablack";}
@font-face
	{font-family:"The Hand Light";}
@font-face
	{font-family:"The Serif Hand";}
@font-face
	{font-family:"The Serif Hand Black";}
@font-face
	{font-family:"The Serif Hand Extrablack";}
@font-face
	{font-family:"The Serif Hand Light";}
@font-face
	{font-family:"Tisa Offc Serif Pro";}
@font-face
	{font-family:"Tisa Offc Serif Pro Thin";}
@font-face
	{font-family:"Titillium Web";}
@font-face
	{font-family:"Titillium Web Black";}
@font-face
	{font-family:"Titillium Web ExtraLight";}
@font-face
	{font-family:"Titillium Web Light";}
@font-face
	{font-family:"Titillium Web SemiBold";}
@font-face
	{font-family:"Trade Gothic Inline";}
@font-face
	{font-family:"Trade Gothic Next";}
@font-face
	{font-family:"Trade Gothic Next Cond";}
@font-face
	{font-family:"Trade Gothic Next Heavy";}
@font-face
	{font-family:"Trade Gothic Next HvyCd";}
@font-face
	{font-family:"Trade Gothic Next Light";}
@font-face
	{font-family:"Trade Gothic Next Rounded";}
@font-face
	{font-family:"Traditional Arabic";}
@font-face
	{font-family:Trirong;}
@font-face
	{font-family:"Trirong Black";}
@font-face
	{font-family:"Trirong ExtraBold";}
@font-face
	{font-family:"Trirong ExtraLight";}
@font-face
	{font-family:"Trirong Light";}
@font-face
	{font-family:"Trirong Medium";}
@font-face
	{font-family:"Trirong SemiBold";}
@font-face
	{font-family:"Trirong Thin";}
@font-face
	{font-family:Ubuntu;}
@font-face
	{font-family:"Ubuntu Condensed";}
@font-face
	{font-family:"Ubuntu Light";}
@font-face
	{font-family:"Ubuntu Medium";}
@font-face
	{font-family:"Ubuntu Mono";}
@font-face
	{font-family:"UD Digi Kyokasho N-B";}
@font-face
	{font-family:"UD Digi Kyokasho N-R";}
@font-face
	{font-family:"UD Digi Kyokasho NK-B";}
@font-face
	{font-family:"UD Digi Kyokasho NK-R";}
@font-face
	{font-family:"UD Digi Kyokasho NP-B";}
@font-face
	{font-family:"UD Digi Kyokasho NP-R";}
@font-face
	{font-family:Univers;}
@font-face
	{font-family:"Univers Condensed";}
@font-face
	{font-family:"Univers Condensed Light";}
@font-face
	{font-family:"Univers Light";}
@font-face
	{font-family:"Urdu Typesetting";}
@font-face
	{font-family:Utsaah;}
@font-face
	{font-family:Vani;}
@font-face
	{font-family:"Varela Round";}
@font-face
	{font-family:"Verdana Pro";}
@font-face
	{font-family:"Verdana Pro Black";}
@font-face
	{font-family:"Verdana Pro Cond";}
@font-face
	{font-family:"Verdana Pro Cond Black";}
@font-face
	{font-family:"Verdana Pro Cond Light";}
@font-face
	{font-family:"Verdana Pro Cond Semibold";}
@font-face
	{font-family:"Verdana Pro Light";}
@font-face
	{font-family:"Verdana Pro Semibold";}
@font-face
	{font-family:Vijaya;}
@font-face
	{font-family:"Walbaum Display";}
@font-face
	{font-family:"Walbaum Display Heavy";}
@font-face
	{font-family:"Walbaum Display Light";}
@font-face
	{font-family:"Walbaum Display SemiBold";}
@font-face
	{font-family:"Walbaum Heading";}
@font-face
	{font-family:"Walbaum Text";}
@font-face
	{font-family:Wandohope;}
@font-face
	{font-family:"Work Sans";}
@font-face
	{font-family:"Work Sans Black";}
@font-face
	{font-family:"Work Sans ExtraBold";}
@font-face
	{font-family:"Work Sans ExtraLight";}
@font-face
	{font-family:"Work Sans Light";}
@font-face
	{font-family:"Work Sans Medium";}
@font-face
	{font-family:"Work Sans SemiBold";}
@font-face
	{font-family:"Work Sans Thin";}
@font-face
	{font-family:Yesteryear;}
@font-face
	{font-family:"Yu Mincho";}
@font-face
	{font-family:"Yu Mincho Demibold";}
@font-face
	{font-family:"Yu Mincho Light";}
@font-face
	{font-family:"var\(--font-mono\)";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:8.0pt;
	margin-left:0in;
	line-height:115%;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;}
h1
	{mso-style-link:"Heading 1 Char";
	margin-top:.25in;
	margin-right:0in;
	margin-bottom:4.0pt;
	margin-left:0in;
	line-height:115%;
	page-break-after:avoid;
	font-size:20.0pt;
	font-family:"Aptos Display",sans-serif;
	color:#0F4761;
	font-weight:normal;}
h2
	{mso-style-link:"Heading 2 Char";
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:4.0pt;
	margin-left:0in;
	line-height:115%;
	page-break-after:avoid;
	font-size:16.0pt;
	font-family:"Aptos Display",sans-serif;
	color:#0F4761;
	font-weight:normal;}
h3
	{mso-style-link:"Heading 3 Char";
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:4.0pt;
	margin-left:0in;
	line-height:115%;
	page-break-after:avoid;
	font-size:14.0pt;
	font-family:"Aptos",sans-serif;
	color:#0F4761;
	font-weight:normal;}
h4
	{mso-style-link:"Heading 4 Char";
	margin-top:4.0pt;
	margin-right:0in;
	margin-bottom:2.0pt;
	margin-left:0in;
	line-height:115%;
	page-break-after:avoid;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;
	color:#0F4761;
	font-weight:normal;
	font-style:italic;}
h5
	{mso-style-link:"Heading 5 Char";
	margin-top:4.0pt;
	margin-right:0in;
	margin-bottom:2.0pt;
	margin-left:0in;
	line-height:115%;
	page-break-after:avoid;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;
	color:#0F4761;
	font-weight:normal;}
h6
	{mso-style-link:"Heading 6 Char";
	margin-top:2.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	line-height:115%;
	page-break-after:avoid;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;
	color:#595959;
	font-weight:normal;
	font-style:italic;}
p.MsoHeading7, li.MsoHeading7, div.MsoHeading7
	{mso-style-link:"Heading 7 Char";
	margin-top:2.0pt;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:0in;
	line-height:115%;
	page-break-after:avoid;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;
	color:#595959;}
p.MsoHeading8, li.MsoHeading8, div.MsoHeading8
	{mso-style-link:"Heading 8 Char";
	margin:0in;
	line-height:115%;
	page-break-after:avoid;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;
	color:#272727;
	font-style:italic;}
p.MsoHeading9, li.MsoHeading9, div.MsoHeading9
	{mso-style-link:"Heading 9 Char";
	margin:0in;
	line-height:115%;
	page-break-after:avoid;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;
	color:#272727;}
p.MsoTitle, li.MsoTitle, div.MsoTitle
	{mso-style-link:"Title Char";
	margin-top:0in;
	margin-right:0in;
	margin-bottom:4.0pt;
	margin-left:0in;
	font-size:28.0pt;
	font-family:"Aptos Display",sans-serif;
	letter-spacing:-.5pt;}
p.MsoTitleCxSpFirst, li.MsoTitleCxSpFirst, div.MsoTitleCxSpFirst
	{mso-style-link:"Title Char";
	margin:0in;
	font-size:28.0pt;
	font-family:"Aptos Display",sans-serif;
	letter-spacing:-.5pt;}
p.MsoTitleCxSpMiddle, li.MsoTitleCxSpMiddle, div.MsoTitleCxSpMiddle
	{mso-style-link:"Title Char";
	margin:0in;
	font-size:28.0pt;
	font-family:"Aptos Display",sans-serif;
	letter-spacing:-.5pt;}
p.MsoTitleCxSpLast, li.MsoTitleCxSpLast, div.MsoTitleCxSpLast
	{mso-style-link:"Title Char";
	margin-top:0in;
	margin-right:0in;
	margin-bottom:4.0pt;
	margin-left:0in;
	font-size:28.0pt;
	font-family:"Aptos Display",sans-serif;
	letter-spacing:-.5pt;}
p.MsoSubtitle, li.MsoSubtitle, div.MsoSubtitle
	{mso-style-link:"Subtitle Char";
	margin-top:0in;
	margin-right:0in;
	margin-bottom:8.0pt;
	margin-left:0in;
	line-height:115%;
	font-size:14.0pt;
	font-family:"Aptos",sans-serif;
	color:#595959;
	letter-spacing:.75pt;}
a:link, span.MsoHyperlink
	{color:blue;
	text-decoration:underline;}
a:visited, span.MsoHyperlinkFollowed
	{color:purple;
	text-decoration:underline;}
code
	{font-family:"Courier New";}
pre
	{mso-style-link:"HTML Preformatted Char";
	margin:0in;
	margin-bottom:.0001pt;
	font-size:10.0pt;
	font-family:"Courier New";}
p.MsoListParagraph, li.MsoListParagraph, div.MsoListParagraph
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:8.0pt;
	margin-left:.5in;
	line-height:115%;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;}
p.MsoListParagraphCxSpFirst, li.MsoListParagraphCxSpFirst, div.MsoListParagraphCxSpFirst
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:.5in;
	line-height:115%;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;}
p.MsoListParagraphCxSpMiddle, li.MsoListParagraphCxSpMiddle, div.MsoListParagraphCxSpMiddle
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:.5in;
	line-height:115%;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;}
p.MsoListParagraphCxSpLast, li.MsoListParagraphCxSpLast, div.MsoListParagraphCxSpLast
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:8.0pt;
	margin-left:.5in;
	line-height:115%;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;}
p.MsoQuote, li.MsoQuote, div.MsoQuote
	{mso-style-link:"Quote Char";
	margin-top:8.0pt;
	margin-right:0in;
	margin-bottom:8.0pt;
	margin-left:0in;
	text-align:center;
	line-height:115%;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;
	color:#404040;
	font-style:italic;}
p.MsoIntenseQuote, li.MsoIntenseQuote, div.MsoIntenseQuote
	{mso-style-link:"Intense Quote Char";
	margin-top:.25in;
	margin-right:.6in;
	margin-bottom:.25in;
	margin-left:.6in;
	text-align:center;
	line-height:115%;
	border:none;
	padding:0in;
	font-size:12.0pt;
	font-family:"Aptos",sans-serif;
	color:#0F4761;
	font-style:italic;}
span.MsoIntenseEmphasis
	{color:#0F4761;
	font-style:italic;}
span.MsoIntenseReference
	{font-variant:small-caps;
	color:#0F4761;
	letter-spacing:.25pt;
	font-weight:bold;}
span.Heading1Char
	{mso-style-name:"Heading 1 Char";
	mso-style-link:"Heading 1";
	font-family:"Aptos Display",sans-serif;
	color:#0F4761;}
span.Heading2Char
	{mso-style-name:"Heading 2 Char";
	mso-style-link:"Heading 2";
	font-family:"Aptos Display",sans-serif;
	color:#0F4761;}
span.Heading3Char
	{mso-style-name:"Heading 3 Char";
	mso-style-link:"Heading 3";
	font-family:"Times New Roman",serif;
	color:#0F4761;}
span.Heading4Char
	{mso-style-name:"Heading 4 Char";
	mso-style-link:"Heading 4";
	font-family:"Times New Roman",serif;
	color:#0F4761;
	font-style:italic;}
span.Heading5Char
	{mso-style-name:"Heading 5 Char";
	mso-style-link:"Heading 5";
	font-family:"Times New Roman",serif;
	color:#0F4761;}
span.Heading6Char
	{mso-style-name:"Heading 6 Char";
	mso-style-link:"Heading 6";
	font-family:"Times New Roman",serif;
	color:#595959;
	font-style:italic;}
span.Heading7Char
	{mso-style-name:"Heading 7 Char";
	mso-style-link:"Heading 7";
	font-family:"Times New Roman",serif;
	color:#595959;}
span.Heading8Char
	{mso-style-name:"Heading 8 Char";
	mso-style-link:"Heading 8";
	font-family:"Times New Roman",serif;
	color:#272727;
	font-style:italic;}
span.Heading9Char
	{mso-style-name:"Heading 9 Char";
	mso-style-link:"Heading 9";
	font-family:"Times New Roman",serif;
	color:#272727;}
span.TitleChar
	{mso-style-name:"Title Char";
	mso-style-link:Title;
	font-family:"Aptos Display",sans-serif;
	letter-spacing:-.5pt;}
span.SubtitleChar
	{mso-style-name:"Subtitle Char";
	mso-style-link:Subtitle;
	font-family:"Times New Roman",serif;
	color:#595959;
	letter-spacing:.75pt;}
span.QuoteChar
	{mso-style-name:"Quote Char";
	mso-style-link:Quote;
	color:#404040;
	font-style:italic;}
span.IntenseQuoteChar
	{mso-style-name:"Intense Quote Char";
	mso-style-link:"Intense Quote";
	color:#0F4761;
	font-style:italic;}
p.msonormal0, li.msonormal0, div.msonormal0
	{mso-style-name:msonormal;
	margin-right:0in;
	margin-left:0in;
	font-size:12.0pt;
	font-family:"Times New Roman",serif;}
p.whitespace-normal, li.whitespace-normal, div.whitespace-normal
	{mso-style-name:whitespace-normal;
	margin-right:0in;
	margin-left:0in;
	font-size:12.0pt;
	font-family:"Times New Roman",serif;}
span.HTMLPreformattedChar
	{mso-style-name:"HTML Preformatted Char";
	mso-style-link:"HTML Preformatted";
	font-family:"Courier New";}
p.whitespace-pre-wrap, li.whitespace-pre-wrap, div.whitespace-pre-wrap
	{mso-style-name:whitespace-pre-wrap;
	margin-right:0in;
	margin-left:0in;
	font-size:12.0pt;
	font-family:"Times New Roman",serif;}
span.token
	{mso-style-name:token;}
span.hovertext-text-300
	{mso-style-name:"hover\:text-text-300";}
span.msoIns
	{mso-style-name:"";
	text-decoration:underline;
	color:teal;}
span.msoDel
	{mso-style-name:"";
	text-decoration:line-through;
	color:red;}
.MsoPapDefault
	{margin-bottom:8.0pt;
	line-height:115%;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;}
div.WordSection1
	{page:WordSection1;}
 /* List Definitions */
 ol
	{margin-bottom:0in;}
ul
	{margin-bottom:0in;}
-->
</style>

</head>

<body lang=EN-US link=blue vlink=purple style='word-wrap:break-word'>

<div class=WordSection1>

<p class=MsoNormal><b>Slide 1: GPU Programming</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Explanation</b></p>

<p class=MsoNormal>This lecture focuses on <b>parallel kernel programming</b> 
how GPUs execute multiple threads together to perform large computations
faster.<br>
Each GPU thread runs the same kernel (function) but operates on different data.</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128161;</span>
Use Case</b></p>

<p class=MsoNormal>Used in applications like:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Image processing</li>
 <li class=MsoNormal>Machine learning</li>
 <li class=MsoNormal>Scientific simulations</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numerical</b></p>

<p class=MsoNormal>If a GPU can run 1024 threads per block and you have 10
blocks  total threads = 10  1024 = <b>10,240 threads</b>.</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>GPU kernels are:</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Functions executed by CPU</li>
  <li class=MsoNormal>b) Functions executed by GPU in parallel <span
      style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>c) Memory blocks</li>
  <li class=MsoNormal>d) Registers</li>
 </ul>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129518;</span>
Slide 2: Matrix Multiplication (MM) Kernel</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Explanation</b></p>

<p class=MsoNormal>Each thread computes one element of the output matrix C.</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Thread(row, col) calculates C[row][col] = &#931; A[row][k]
     * B[k][col].</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128161;</span>
Use Case</b></p>

<p class=MsoNormal>Used in:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Deep learning (matrix multiplications in neural networks)</li>
 <li class=MsoNormal>Computer graphics transformations</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numerical</b></p>

<p class=MsoNormal>If n = 3 and<br>
A = [[1,2,3],[4,5,6],[7,8,9]],<br>
B = [[9,8,7],[6,5,4],[3,2,1]],<br>
then C[0][0] = 1*9 + 2*6 + 3*3 = 30.</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Each thread computes:</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) One row of C</li>
  <li class=MsoNormal>b) One column of C</li>
  <li class=MsoNormal>c) One element of C <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>d) Whole matrix</li>
 </ul>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128269;</span>
Slide 3: Explanation</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Explanation</b></p>

<p class=MsoNormal>Each thread is responsible for a unique element in C  e.g.,
thread(0,0) computes C&#8320;&#8320;.</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128161;</span>
Use Case</b></p>

<p class=MsoNormal>Parallel matrix operations in 3D rendering or physics
simulations.</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numerical</b></p>

<p class=MsoNormal>For a 55 matrix &#8594; total 25 threads.</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Thread (row=2, col=3) computes:</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) A[2][3]</li>
  <li class=MsoNormal>b) C[2][3] <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>c) B[2][3]</li>
  <li class=MsoNormal>d) Sum of row 2</li>
 </ul>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129521;</span>
Slide 45: Tiled Matrix Multiplication Kernel</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Explanation</b></p>

<p class=MsoNormal>Tiling means dividing big matrices into small square blocks
(<b>tiles</b>) to store in <b>shared memory</b> for faster access.<br>
Threads in a block cooperate to compute part of the result.</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128161;</span>
Use Case</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Large matrix operations (e.g., 10241024)</li>
 <li class=MsoNormal>GPU-based ML model training</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numerical</b></p>

<p class=MsoNormal>If TILE_SIZE=4 and matrix is 88 &#8594; we need (8/4) = <b>4
blocks</b>.</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Why use tiling?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) To increase global memory usage</li>
  <li class=MsoNormal>b) To reduce global memory access <span style='font-family:
      "Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>c) To reduce shared memory</li>
  <li class=MsoNormal>d) None</li>
 </ul>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9881;&#65039;</span>
Slide 67: Usage of Tiling</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Explanation</b></p>

<p class=MsoNormal>Without tiling: each thread repeatedly reads many elements
from slow global memory.<br>
With tiling: threads load a small part once into shared memory and reuse it  <b>saves
time and memory bandwidth.</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128161;</span>
Use Case</b></p>

<p class=MsoNormal>Image filters, where each pixel block is reused many times.</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numerical</b></p>

<p class=MsoNormal>If TILE_SIZE=16 and matrix=6464 &#8594; 44 = 16 blocks,
each block computes a 1616 tile.</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Tiling helps by:</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Increasing computation per thread</li>
  <li class=MsoNormal>b) Reducing memory bandwidth usage <span
      style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>c) Using more registers</li>
  <li class=MsoNormal>d) Slowing execution</li>
 </ul>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129513;</span>
Slide 89: Visualization of Tiling</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Explanation</b></p>

<p class=MsoNormal>Each block handles a submatrix (tile).<br>
Example: Block(0,0) &#8594; C[0..3][0..3] for a 44 tile.<br>
Threads reuse data from shared memory across multiple iterations.</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128161;</span>
Use Case</b></p>

<p class=MsoNormal>Parallel processing of large matrices divided into tiles.</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numerical</b></p>

<p class=MsoNormal>For 55 C and TILE_SIZE=4 &#8594; we have 4 tiles (22),
with one partially filled.</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>In tiling, partial tiles occur when:</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) n divides TILE_SIZE exactly</li>
  <li class=MsoNormal>b) n not divisible by TILE_SIZE <span style='font-family:
      "Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>c) GPU error</li>
  <li class=MsoNormal>d) Tile too small</li>
 </ul>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129518;</span>
Slide 10: Convolution Kernel</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Explanation</b></p>

<p class=MsoNormal>Each CUDA thread computes one <b>output pixel</b> by
applying a <b>filter kernel</b> on a region of the image.<br>
Output size = (Input - Kernel + 1).</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128161;</span>
Use Case</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Edge detection, blur, sharpen filters in images</li>
 <li class=MsoNormal>CNN layers in deep learning</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numerical</b></p>

<p class=MsoNormal>Input: 55, Filter: 22 &#8594; Output =
(5&#8722;2+1)(5&#8722;2+1)=44.</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>A 55 input with 22 filter gives output size:</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) 55</li>
  <li class=MsoNormal>b) 44 <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>c) 33</li>
  <li class=MsoNormal>d) 66</li>
 </ul>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#127912;</span>
Slide 1113: Convolution with RGB Input</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Explanation</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>The filter is applied on <b>each RGB channel separately</b>.</li>
 <li class=MsoNormal>Formula: out(i,j) = 5*center - top - bottom - left - right.</li>
 <li class=MsoNormal>Edges use zero-padding (values outside image = 0).</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128161;</span>
Use Case</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Sharpening color images</li>
 <li class=MsoNormal>Applying CNN filters to RGB channels</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numerical</b></p>

<p class=MsoNormal>Example:<br>
center=10, top=0, left=0, right=20, bottom=15 &#8594;<br>
out = 510 &#8722; (0+0+20+15) = <b>15</b>.</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What does zero-padding mean?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Filling empty pixels with 0 <span style='font-family:
      "Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>b) Removing edges</li>
  <li class=MsoNormal>c) Duplicating borders</li>
  <li class=MsoNormal>d) Ignoring zeros</li>
 </ul>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#129518;</span>
Slide 1415: Stencil Approach</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Explanation</b></p>

<p class=MsoNormal>The stencil method loads tiles + 1-pixel borders (halo) into
shared memory.<br>
Threads reuse this data for convolution efficiently, avoiding repeated reads.</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128161;</span>
Use Case</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Weather simulation (temperature grid updates)</li>
 <li class=MsoNormal>Image convolution, Laplace/blur filters</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numerical</b></p>

<p class=MsoNormal>A 1616 block needs an 1818 tile (extra 1-pixel halo).</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>The stencil method improves performance by:</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Loading each pixel many times</li>
  <li class=MsoNormal>b) Reusing neighbor data from shared memory <span
      style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>c) Ignoring neighbors</li>
  <li class=MsoNormal>d) Reducing threads</li>
 </ul>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9889;</span>
Slide 16: Efficiency and Parallelism</b></p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128221;</span>
Explanation</b></p>

<p class=MsoNormal>Each thread computes one pixel, thousands of threads run
together.<br>
Benefits:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Less global memory traffic</li>
 <li class=MsoNormal>High data reuse</li>
 <li class=MsoNormal>Massive parallel execution</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128161;</span>
Use Case</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Real-time video filters</li>
 <li class=MsoNormal>Object detection (CNNs)</li>
</ul>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128290;</span>
Numerical</b></p>

<p class=MsoNormal>For a 55 image and 33 kernel: output =
(5&#8722;3+1)(5&#8722;3+1) = 33 pixels computed by 9 threads.</p>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span>
MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Why GPU convolution is efficient?</li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>a) Because it reuses data from shared memory <span
      style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span></li>
  <li class=MsoNormal>b) Because it runs only one thread</li>
  <li class=MsoNormal>c) Because it ignores neighbors</li>
  <li class=MsoNormal>d) Because its done by CPU</li>
 </ul>
</ol>

<div style='border:none;border-bottom:double windowtext 2.25pt;padding:0in 0in 1.0pt 0in'>

<p class=MsoNormal style='border:none;padding:0in'>&nbsp;</p>

</div>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><b>Slide 1: Introduction</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;This slide simply introduces the
     topic for this lecture: writing parallel code (called &quot;kernels&quot;)
     that runs on the GPU. We'll be looking at specific examples like matrix
     multiplication and convolution.</li>
 <li class=MsoNormal><b>MCQ:</b>&nbsp;What is the main topic of this lecture?<br>
     a) CPU Cache Hierarchies<br>
     b) Parallel Kernel Programming on GPUs<br>
     c) Python for Data Science<br>
     d) Operating System Schedulers<br>
     <b>Answer:</b>&nbsp;b) Parallel Kernel Programming on GPUs</li>
 <li class=MsoNormal><b>Use Case:</b>&nbsp;Any task that can be broken down
     into many small, independent calculations, like applying a filter to every
     pixel in an image or calculating the elements of a large matrix.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 2: Matrix Multiplication (MM) Kernel</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;This is the basic,
     &quot;naive&quot; way to multiply matrices on a GPU. Each thread is
     responsible for calculating one element in the result matrix&nbsp;C. It
     figures out which row and column it should compute, then uses a loop to
     sum up the multiplications of that row from matrix&nbsp;A&nbsp;and that
     column from matrix&nbsp;B.</li>
 <li class=MsoNormal><b>MCQ:</b>&nbsp;In the naive matrix multiplication
     kernel, what does each thread compute?<br>
     a) An entire row of the result matrix.<br>
     b) The sum of all elements in the matrices.<br>
     c) A single element of the result matrix.<br>
     d) The determinant of the matrix.<br>
     <b>Answer:</b>&nbsp;c) A single element of the result matrix.</li>
 <li class=MsoNormal><b>Use Case:</b>&nbsp;Scientific computing, graphics
     transformations, and machine learning models that involve large matrix
     operations.</li>
 <li class=MsoNormal><b>Numerical:</b>&nbsp;For a 3x3 matrix, if a thread
     has&nbsp;row=1&nbsp;and&nbsp;col=2, which element of&nbsp;C&nbsp;is it
     computing? What is the loop it would perform?<br>
     <b>Answer:</b>&nbsp;It computes&nbsp;C[1][2]. The loop would be:&nbsp;sum
     = A[1][0]*B[0][2] + A[1][1]*B[1][2] + A[1][2]*B[2][2].</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 3: Explanation of Matrix Multiplication</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;This slide gives a concrete
     example of how a single element in the result matrix is calculated. It
     shows that&nbsp;C[2][3]&nbsp;is the &quot;dot product&quot; of row 2 from
     matrix&nbsp;A&nbsp;and column 3 from matrix&nbsp;B. It also visually shows
     that every thread (with its own&nbsp;row&nbsp;and&nbsp;col) works in
     parallel to fill out the entire&nbsp;C&nbsp;matrix.</li>
 <li class=MsoNormal><b>MCQ:</b>&nbsp;The calculation for an element&nbsp;C[row][col]&nbsp;is
     the dot product of:<br>
     a) A column from A and a row from B.<br>
     b) A row from A and a row from B.<br>
     c) A row from A and a column from B.<br>
     d) Two columns from A and B.<br>
     <b>Answer:</b>&nbsp;c) A row from A and a column from B.</li>
 <li class=MsoNormal><b>Use Case:</b>&nbsp;Understanding the fundamental
     mathematical operation behind many algorithms, ensuring the parallel code
     is correct.</li>
 <li class=MsoNormal><b>Numerical:</b>&nbsp;For a 2x2 matrix, if&nbsp;A&nbsp;is&nbsp;[[1,
     2], [3, 4]]&nbsp;and&nbsp;B&nbsp;is&nbsp;[[5, 6], [7, 8]], which thread
     computes&nbsp;C[1][0]&nbsp;and what is the calculation?<br>
     <b>Answer:</b>&nbsp;The thread with&nbsp;row=1,&nbsp;col=0. It
     computes&nbsp;C[1][0] = (3*5) + (4*7) = 15 + 28 = 43.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 4 &amp; 5: Tiled MM Kernel</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;This is the optimized way to do
     matrix multiplication. Instead of each thread reading all the data it
     needs directly from slow global memory, the threads in a &quot;block&quot;
     work together to load small &quot;tiles&quot; of&nbsp;A&nbsp;and&nbsp;B&nbsp;into
     fast, shared memory. The threads then reuse this data to perform their
     calculations, drastically reducing the number of slow memory accesses.</li>
 <li class=MsoNormal><b>MCQ:</b>&nbsp;What is the primary purpose of using
     shared memory in the tiled matrix multiplication kernel?<br>
     a) To store the final result.<br>
     b) To allow threads to communicate intermediate results.<br>
     c) To cache and reuse data, reducing global memory accesses.<br>
     d) To store the kernel code itself.<br>
     <b>Answer:</b>&nbsp;c) To cache and reuse data, reducing global memory
     accesses.</li>
 <li class=MsoNormal><b>Use Case:</b>&nbsp;Multiplying very large matrices
     where performance is critical, as it significantly speeds up the
     calculation.</li>
 <li class=MsoNormal><b>Numerical:</b>&nbsp;Let&nbsp;TILE_SIZE = 2&nbsp;and&nbsp;n
     = 4. How many tile iterations (m) are needed to compute one element?<br>
     <b>Answer:</b>&nbsp;(n + TILE_SIZE - 1) / TILE_SIZE = (4 + 2 - 1) / 2 = 5
     / 2 = 2&nbsp;(integer division). So, 2 iterations.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 6 &amp; 7: Usage of Tiling (Why it's faster)</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;These slides explain&nbsp;<i>why</i>&nbsp;tiling
     is so important. In the naive version, each thread does about&nbsp;2n&nbsp;reads
     from slow global memory. For a large matrix, this adds up to a huge number
     of slow accesses (O(n^3)). With tiling, threads load much smaller chunks
     of data (TILE_SIZE&nbsp;elements at a time) and, crucially, share this
     data with their neighbors, making the process much more efficient.</li>
 <li class=MsoNormal><b>MCQ:</b>&nbsp;For a 1024x1024 matrix, how many global
     memory reads does a single thread perform in the naive kernel?<br>
     a) ~1024<br>
     b) ~2048<br>
     c) ~32<br>
     d) ~64<br>
     <b>Answer:</b>&nbsp;b) ~2048 (1024 from A and 1024 from B).</li>
 <li class=MsoNormal><b>Use Case:</b>&nbsp;Justifying the extra complexity of
     the tiled kernel for high-performance computing applications.</li>
 <li class=MsoNormal><b>Numerical:</b>&nbsp;With&nbsp;n=1024&nbsp;and&nbsp;TILE_SIZE=32,
     how many global reads per thread occur in the tiled kernel?<br>
     <b>Answer:</b>&nbsp;Number of tiles&nbsp;m = 1024/32 = 32. Per iteration,
     a thread loads 1 element from A's tile and 1 from B's tile. So,&nbsp;32 *
     2 = 64&nbsp;reads.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 8 &amp; 9: Visualization of Tiling</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;These slides show how a large
     matrix is broken down into smaller blocks. Each block of threads is
     responsible for computing one tile of the result matrix. The diagrams show
     how threads load data cooperatively and handle cases where the matrix size
     isn't a perfect multiple of the tile size (using boundary checks
     like&nbsp;if (row &lt; n)).</li>
 <li class=MsoNormal><b>MCQ:</b>&nbsp;In the tiled approach, who is responsible
     for loading a tile of data into shared memory?<br>
     a) A single master thread.<br>
     b) The CPU.<br>
     c) All threads in a block working cooperatively.<br>
     d) The GPU's dedicated loading unit.<br>
     <b>Answer:</b>&nbsp;c) All threads in a block working cooperatively.</li>
 <li class=MsoNormal><b>Use Case:</b>&nbsp;Visualizing the decomposition of a
     large problem into smaller, manageable parallel chunks.</li>
 <li class=MsoNormal><b>Numerical:</b>&nbsp;For a 5x5 matrix and a&nbsp;TILE_SIZE&nbsp;of
     4, how many blocks are needed in the x and y dimensions?<br>
     <b>Answer:</b>&nbsp;(5 + 4 - 1) / 4 = 8 / 4 = 2&nbsp;blocks in both x and
     y dimensions. So, a 2x2 grid of blocks.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 10: Convolution Kernel</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;Convolution is applying a small
     filter (or kernel) to an image to create effects like blurring or edge
     detection. Each thread computes one output pixel by taking a weighted sum
     of itself and its neighbors. The example shows a simple 2x2 filter that
     subtracts the bottom-right pixel from the top-left one.</li>
 <li class=MsoNormal><b>MCQ:</b>&nbsp;In a convolution operation, each output
     pixel is calculated from:<br>
     a) Only the corresponding input pixel.<br>
     b) A weighted sum of the corresponding input pixel and its neighbors.<br>
     c) The average of the entire image.<br>
     d) A single random pixel.<br>
     <b>Answer:</b>&nbsp;b) A weighted sum of the corresponding input pixel and
     its neighbors.</li>
 <li class=MsoNormal><b>Use Case:</b>&nbsp;Image processing (blur, sharpen,
     edge detection), computer vision.</li>
 <li class=MsoNormal><b>Numerical:</b>&nbsp;Given a 2x2 input patch&nbsp;[[1,
     2], [3, 4]]&nbsp;and a filter&nbsp;[[1, 0], [0, -1]], what is the output?<br>
     <b>Answer:</b>&nbsp;(1*1) + (2*0) + (3*0) + (4*-1) = 1 - 4 = -3.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 11: Convolution with RGB Input</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;For color images, convolution is
     applied independently to each color channel (Red, Green, and Blue). The
     slide shows a 3x3 &quot;sharpening&quot; filter and how it's applied to an
     example matrix. The calculation for each pixel becomes&nbsp;5*center - top
     - bottom - left - right.</li>
 <li class=MsoNormal><b>MCQ:</b>&nbsp;How is convolution applied to an RGB
     image?<br>
     a) The filter is applied only to the Green channel.<br>
     b) The same filter is applied independently to each R, G, and B channel.<br>
     c) The RGB values are averaged first.<br>
     d) A different filter is used for each channel.<br>
     <b>Answer:</b>&nbsp;b) The same filter is applied independently to each R,
     G, and B channel.</li>
 <li class=MsoNormal><b>Use Case:</b>&nbsp;Applying Instagram-like filters,
     professional photo editing, video post-processing.</li>
 <li class=MsoNormal><b>Numerical:</b>&nbsp;For an input pixel value of 25,
     with neighbors Top=10, Bottom=40, Left=15, Right=35, what is the output
     using the sharpening filter?<br>
     <b>Answer:</b>&nbsp;(5 * 25) - 10 - 40 - 15 - 35 = 125 - 100 = 25.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 12 &amp; 13: Stencil-based Computation</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;This is the optimized way to do
     convolution on a GPU, similar to tiling for matrix multiplication. When
     processing pixels on the edge of the image, we assume values outside the
     border are zero (&quot;zero-padding&quot;). The slides walk through the
     detailed calculation for every pixel in a small example, showing how the
     filter is applied.</li>
 <li class=MsoNormal><b>MCQ:</b>&nbsp;What is &quot;zero-padding&quot; in
     stencil computation?<br>
     a) Making all output values zero.<br>
     b) Assuming pixels outside the image boundary have a value of zero.<br>
     c) Adding a border of zeros to the output image.<br>
     d) A type of encryption.<br>
     <b>Answer:</b>&nbsp;b) Assuming pixels outside the image boundary have a
     value of zero.</li>
 <li class=MsoNormal><b>Use Case:</b>&nbsp;Handling image borders during
     convolution operations cleanly and predictably.</li>
 <li class=MsoNormal><b>Numerical:</b>&nbsp;Calculate&nbsp;out(0,0)&nbsp;for a
     3x3 input&nbsp;[[5, 6, 7], [8, 9, 1], [2, 3, 4]]&nbsp;with the sharpening
     filter and zero-padding.<br>
     <b>Answer:</b>&nbsp;Center=5, Top=0, Left=0, Right=6, Bottom=8.&nbsp;(5*5)
     - 0 - 0 - 6 - 8 = 25 - 14 = 11.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 14 &amp; 15: Stencil Approach &amp; Efficiency</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;These slides explain the
     optimized &quot;stencil&quot; method. Instead of each thread fetching its
     own pixel and neighbors from slow global memory (which causes a lot of
     repeated reads), threads in a block work together to load a
     &quot;tile&quot; of the image plus a one-pixel &quot;halo&quot; or border
     into fast shared memory. This way, each pixel is loaded only once and then
     reused by all threads that need it.</li>
 <li class=MsoNormal><b>MCQ:</b>&nbsp;Why is the stencil method with shared
     memory more efficient?<br>
     a) It uses the CPU instead of the GPU.<br>
     b) It reduces redundant global memory accesses by reusing data from shared
     memory.<br>
     c) It calculates fewer output pixels.<br>
     d) It uses a simpler filter.<br>
     <b>Answer:</b>&nbsp;b) It reduces redundant global memory accesses by
     reusing data from shared memory.</li>
 <li class=MsoNormal><b>Use Case:</b>&nbsp;Real-time video processing, medical
     imaging analysis, and any application where convolution performance is
     critical.</li>
 <li class=MsoNormal><b>Numerical:</b>&nbsp;A block has 16x16 threads. How many
     pixels (including halo) need to be loaded into shared memory for a 3x3
     convolution?<br>
     <b>Answer:</b>&nbsp;The tile needs a 1-pixel halo. So,&nbsp;(16 + 2) x (16
     + 2) = 18x18&nbsp;pixels.</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 16: Visualization of Convolution Tiling</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;This slide provides a final
     visual summary. It shows how a block of 4x4 threads would load a 6x6 tile
     from the global image (the 4x4 core plus a 1-pixel halo on all sides) into
     shared memory. This allows all 16 threads to compute their output pixel
     efficiently without contending for slow global memory.</li>
 <li class=MsoNormal><b>MCQ:</b>&nbsp;For a 4x4 thread block and a 3x3 kernel,
     what is the size of the shared memory tile including the halo?<br>
     a) 4x4<br>
     b) 5x5<br>
     c) 6x6<br>
     d) 3x3<br>
     <b>Answer:</b>&nbsp;c) 6x6 (4 + 1 + 1 = 6)</li>
 <li class=MsoNormal><b>Use Case:</b>&nbsp;Designing efficient kernel launch
     configurations (block and grid sizes) for image processing tasks.</li>
 <li class=MsoNormal><b>Numerical:</b>&nbsp;If the global image is 100x100 and
     the block size is 16x16, how many blocks are needed in the grid to cover
     the entire image for a convolution?<br>
     <b>Answer:</b>&nbsp;(100 / 16) = 6.25 -&gt; 7&nbsp;blocks in each
     dimension. So, a 7x7 grid of blocks.</li>
</ul>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<div style='border:none;border-bottom:double windowtext 2.25pt;padding:0in 0in 1.0pt 0in'>

<p class=MsoNormal style='border:none;padding:0in'>&nbsp;</p>

</div>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>&nbsp;</li>
</ul>

<p class=MsoNormal>It sounds like you're looking for a comprehensive breakdown
of the provided GPU Programming lecture slides on Parallel Kernel Programming,
specifically covering Matrix Multiplication (MM) and Convolution, and then
turning that content into study materials.</p>

<p class=MsoNormal>Here is the explanation, multiple-choice questions (MCQs),
use cases, and numerical examples for each major section of the lecture.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128187;</span>
Slide 1: Title Slide</b></p>

<p class=MsoNormal><b>Slide Content:</b>&nbsp;GPU Programming, Lecture 07:
Parallel Kernel Programming&nbsp;</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;This is the title slide,
     introducing the lecture topic as&nbsp;<b>Parallel Kernel Programming</b>&nbsp;for&nbsp;<b>GPU
     Programming</b>. The core concept is performing computations
     simultaneously across many threads on a GPU to speed up execution.</li>
 <li class=MsoNormal><b>MCQ:</b></li>
 <ul style='margin-top:0in' type=disc>
  <li class=MsoNormal><b>Question:</b>&nbsp;What is the primary focus of
      Lecture 07?</li>
  <li class=MsoNormal><b>A.</b>&nbsp;Sequential CPU Programming</li>
  <li class=MsoNormal><b>B.</b>&nbsp;<b>Parallel Kernel Programming</b>&nbsp;(Correct)</li>
  <li class=MsoNormal><b>C.</b>&nbsp;Database Management</li>
  <li class=MsoNormal><b>D.</b>&nbsp;GPU Hardware Design</li>
 </ul>
 <li class=MsoNormal><b>Use Case:</b>&nbsp;Introduces the context for any task
     that can be broken down into many independent parts, like image processing
     or large-scale simulations.</li>
 <li class=MsoNormal><b>Numerical:</b>&nbsp;N/A (Introductory slide)</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128736;&#65039;</span>
Slides 2 &amp; 3: Nave Matrix Multiplication (MM) Kernel</b></p>

<p class=MsoNormal><b>Slide Content:</b>&nbsp;Matrix Multiplication (MM) Kernel
(_global_ void matrix_mul(...)), kernel code, and explanation&nbsp;</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;This section presents the most
     straightforward way to implement&nbsp;<b>Matrix Multiplication</b>&nbsp;on
     a GPU.&nbsp;The key idea is&nbsp;<b>thread-to-element mapping</b>:&nbsp;<b>each
     individual thread</b>&nbsp;in the GPU computes&nbsp;<b>exactly one element</b>&nbsp;of
     the resulting matrix&nbsp;<i>C</i>.&nbsp;For example, one thread is
     assigned to compute&nbsp;<i>C</i>[<i>row</i>][<i>col</i>]&nbsp;by
     performing the sum of products:&nbsp;<i>C</i>[<i>row</i>][<i>col</i>]=&#8721;<i>k</i>=0<i>n</i>&#8722;1<span
     style='font-family:"Arial",sans-serif'>&#8203;</span><i>A</i>[<i>row</i>][<i>k</i>]<span
     style='font-family:"Cambria Math",serif'>&#8901;</span><i>B</i>[<i>k</i>][<i>col</i>].&nbsp;The
     thread coordinates (blockIdx&nbsp;and&nbsp;threadIdx) are used to
     determine which row and column of the result matrix&nbsp;<i>C</i>&nbsp;it
     should compute.</li>
 <li class=MsoNormal><b>MCQ:</b></li>
 <ul style='margin-top:0in' type=disc>
  <li class=MsoNormal><b>Question:</b>&nbsp;In the basic MM kernel, what does a
      single CUDA thread compute?</li>
  <li class=MsoNormal><b>A.</b>&nbsp;An entire row of the matrix&nbsp;<i>C</i>.</li>
  <li class=MsoNormal><b>B.</b>&nbsp;An entire column of the matrix&nbsp;<i>C</i>.</li>
  <li class=MsoNormal><b>C.</b>&nbsp;<b>A single element&nbsp;<i>C</i>[<i>row</i>][<i>col</i>]&nbsp;of
      the result matrix.</b>&nbsp;(Correct)&nbsp;</li>
  <li class=MsoNormal><b>D.</b>&nbsp;The entire matrix&nbsp;<i>C</i>.</li>
 </ul>
 <li class=MsoNormal><b>Use Case:</b>&nbsp;Simple, easy-to-implement parallel
     algorithms where the output elements are independent.</li>
 <li class=MsoNormal><b>Numerical:</b></li>
 <ul style='margin-top:0in' type=disc>
  <li class=MsoNormal><b>Goal:</b>&nbsp;Calculate&nbsp;<i>C</i>[2][3]&nbsp;for
      a&nbsp;55&nbsp;matrix multiplication.</li>
  <li class=MsoNormal><b>Calculation:</b>&nbsp;The thread assigned to&nbsp;<i>C</i>[2][3]&nbsp;will
      compute:</li>
 </ul>
</ul>

<p class=MsoNormal><i>C</i>[2][3]=<i>A</i>[2][0]<span style='font-family:"Cambria Math",serif'>&#8901;</span><i>B</i>[0][3]+<i>A</i>[2][1]<span
style='font-family:"Cambria Math",serif'>&#8901;</span><i>B</i>[1][3]+<i>A</i>[2][2]<span
style='font-family:"Cambria Math",serif'>&#8901;</span><i>B</i>[2][3]+<i>A</i>[2][3]<span
style='font-family:"Cambria Math",serif'>&#8901;</span><i>B</i>[3][3]+<i>A</i>[2][4]<span
style='font-family:"Cambria Math",serif'>&#8901;</span><i>B</i>[4][3].</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128640;</span>
Slides 4-8: Tiled Matrix Multiplication (MM) Kernel &amp; Tiling Usage</b></p>

<p class=MsoNormal><b>Slide Content:</b>&nbsp;Tiled MM Kernel code, explanation
of tiling, and memory access optimization&nbsp;</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;Tiling (using shared memory) is
     an optimization to drastically reduce slow&nbsp;<b>global memory reads</b>.</li>
 <ul style='margin-top:0in' type=disc>
  <li class=MsoNormal><b>Problem (Nave Kernel):</b>&nbsp;Each thread computes
      its&nbsp;<i>C</i>[<i>row</i>][<i>col</i>]&nbsp;by reading an entire row
      of&nbsp;<i>A</i>&nbsp;and an entire column of&nbsp;<i>B</i>, resulting
      in&nbsp;<i>O</i>(<i>n</i>3)&nbsp;total global memory accesses for the
      whole&nbsp;<i>C</i>&nbsp;matrix.</li>
  <li class=MsoNormal><b>Solution (Tiled Kernel):</b>&nbsp;Threads in a
      block&nbsp;<b>cooperatively load</b>&nbsp;small, reusable&nbsp;<b>tiles</b>&nbsp;(sub-blocks)
      of matrices&nbsp;<i>A</i>&nbsp;and&nbsp;<i>B</i>&nbsp;into fast&nbsp;<b>shared
      memory</b>&nbsp;(tileA,&nbsp;tileB).&nbsp;Once the data is in shared
      memory, threads access it repeatedly (reuse it) for the partial
      multiplication/summation, avoiding redundant global memory fetches.&nbsp;The&nbsp;__syncthreads()&nbsp;command
      is crucial to ensure all threads finish loading their part of the tile
      before the multiplication begins.</li>
 </ul>
 <li class=MsoNormal><b>MCQ:</b></li>
 <ul style='margin-top:0in' type=disc>
  <li class=MsoNormal><b>Question:</b>&nbsp;What is the main benefit of using
      Tiling (Shared Memory) in Matrix Multiplication?</li>
  <li class=MsoNormal><b>A.</b>&nbsp;It reduces the total number of threads.</li>
  <li class=MsoNormal><b>B.</b>&nbsp;It simplifies the kernel code.</li>
  <li class=MsoNormal><b>C.</b>&nbsp;It increases the global memory reads.</li>
  <li class=MsoNormal><b>D.</b>&nbsp;<b>It drastically reduces global memory
      bandwidth usage by enabling data reuse.</b>&nbsp;(Correct)&nbsp;</li>
 </ul>
 <li class=MsoNormal><b>Use Case:</b>&nbsp;Any memory-bound algorithm where the
     computation pattern involves significant data reuse and overlapping
     access, like MM, 3D transformations, and certain types of image filters.</li>
 <li class=MsoNormal><b>Numerical:</b></li>
 <ul style='margin-top:0in' type=disc>
  <li class=MsoNormal><b>Goal:</b>&nbsp;Compare global reads for one&nbsp;<i>C</i>[<i>row</i>][<i>col</i>]&nbsp;element
      when&nbsp;<i>n</i>=1024.</li>
  <li class=MsoNormal><b>Nave Kernel:</b>&nbsp;Reads&nbsp;&#8776;2<i>n</i>=21024=<b>2048</b>&nbsp;global
      reads per thread.</li>
  <li class=MsoNormal><b>Tiled Kernel (TILE_SIZE=32):</b>&nbsp;Reads&nbsp;&#8776;2TILE_SIZE=232=<b>64</b>&nbsp;global
      reads per tile iteration.&nbsp;The total effective global load is much
      smaller due to sharing.</li>
 </ul>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128444;&#65039;</span>
Slides 9-16: Convolution Kernel &amp; Stencil-based Computation</b></p>

<p class=MsoNormal><b>Slide Content:</b>&nbsp;Visualization of Tiling, basic
Convolution kernel, Stencil approach with RGB input, and memory optimization
with halo.</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;<b>Convolution</b>&nbsp;involves
     computing an output pixel&nbsp;<i>out</i>(<i>i</i>,<i>j</i>)&nbsp;using
     the center pixel&nbsp;<i>img</i>(<i>i</i>,<i>j</i>)&nbsp;and its
     surrounding neighbors (a&nbsp;<b>stencil</b>).&nbsp;This operation
     naturally creates a massive amount of&nbsp;<b>overlapping memory access</b>.</li>
 <ul style='margin-top:0in' type=disc>
  <li class=MsoNormal><b>Stencil Approach:</b>&nbsp;Similar to Tiling in MM,
      the stencil method optimizes this by partitioning the image.&nbsp;Each
      block of threads&nbsp;<b>cooperatively loads a tile</b>&nbsp;of the input
      image&nbsp;<b>plus a halo</b>&nbsp;(an extra border of 1 pixel) into
      fast&nbsp;<b>shared memory</b>.&nbsp;This halo is necessary because
      threads at the edge of the tile need neighbors that are outside the
      tile's core area.</li>
  <li class=MsoNormal><b>Efficiency:</b>&nbsp;Once the tile (+halo) is in
      shared memory, each thread computes its output pixel independently by
      reusing the locally loaded data, which minimizes global memory traffic.&nbsp;Only
      one&nbsp;__syncthreads()&nbsp;is needed after the initial load.</li>
 </ul>
 <li class=MsoNormal><b>MCQ:</b></li>
 <ul style='margin-top:0in' type=disc>
  <li class=MsoNormal><b>Question:</b>&nbsp;What is the purpose of a&nbsp;<b>&quot;halo&quot;</b>&nbsp;in
      the stencil-based convolution approach?</li>
  <li class=MsoNormal><b>A.</b>&nbsp;To store the output pixel results.</li>
  <li class=MsoNormal><b>B.</b>&nbsp;To hold the filter (kernel) values.</li>
  <li class=MsoNormal><b>C.</b>&nbsp;<b>To load the neighbor pixels required by
      threads at the edge of the tile.</b>&nbsp;(Correct)&nbsp;</li>
  <li class=MsoNormal><b>D.</b>&nbsp;To define the block's grid size.</li>
 </ul>
 <li class=MsoNormal><b>Use Case:</b>&nbsp;Image processing, computer vision
     (edge detection, blurring), partial differential equation (PDE) solvers,
     and fluid dynamics simulations.</li>
 <li class=MsoNormal><b>Numerical:</b></li>
 <ul style='margin-top:0in' type=disc>
  <li class=MsoNormal><b>Goal:</b>&nbsp;Determine the required shared memory
      tile size for a&nbsp;33&nbsp;kernel convolution with a&nbsp;1616&nbsp;thread
      block.</li>
  <li class=MsoNormal><b>Calculation:</b>&nbsp;The thread block covers a&nbsp;1616&nbsp;area
      of the output. A&nbsp;33&nbsp;kernel needs a 1-pixel border (<b>halo</b>)
      around the entire tile.</li>
  <li class=MsoNormal>Required Tile Size = (Block Size + 2 * Halo Width)&nbsp;&nbsp;(Block
      Size + 2 * Halo Width)</li>
  <li class=MsoNormal>Required Tile Size =&nbsp;(16+21)(16+21)=<b>18</b><b>18</b>.</li>
 </ul>
</ul>

<p class=MsoNormal>Would you like me to elaborate on the difference between
global and shared memory in GPU programming?It sounds like you're looking for a
comprehensive breakdown of the provided GPU Programming lecture slides on
Parallel Kernel Programming, specifically covering Matrix Multiplication (MM)
and Convolution, and then turning that content into study materials.</p>

<p class=MsoNormal>Here is the explanation, multiple-choice questions (MCQs),
use cases, and numerical examples for each major section of the lecture.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128187;</span>
Slide 1: Title Slide</b></p>

<p class=MsoNormal><b>Slide Content:</b>&nbsp;GPU Programming, Lecture 07:
Parallel Kernel Programming&nbsp;</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;This is the title slide,
     introducing the lecture topic as&nbsp;<b>Parallel Kernel Programming</b>&nbsp;for&nbsp;<b>GPU
     Programming</b>. The core concept is performing computations
     simultaneously across many threads on a GPU to speed up execution.</li>
 <li class=MsoNormal><b>MCQ:</b></li>
 <ul style='margin-top:0in' type=disc>
  <li class=MsoNormal><b>Question:</b>&nbsp;What is the primary focus of
      Lecture 07?</li>
  <li class=MsoNormal><b>A.</b>&nbsp;Sequential CPU Programming</li>
  <li class=MsoNormal><b>B.</b>&nbsp;<b>Parallel Kernel Programming</b>&nbsp;(Correct)</li>
  <li class=MsoNormal><b>C.</b>&nbsp;Database Management</li>
  <li class=MsoNormal><b>D.</b>&nbsp;GPU Hardware Design</li>
 </ul>
 <li class=MsoNormal><b>Use Case:</b>&nbsp;Introduces the context for any task
     that can be broken down into many independent parts, like image processing
     or large-scale simulations.</li>
 <li class=MsoNormal><b>Numerical:</b>&nbsp;N/A (Introductory slide)</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128736;&#65039;</span>
Slides 2 &amp; 3: Nave Matrix Multiplication (MM) Kernel</b></p>

<p class=MsoNormal><b>Slide Content:</b>&nbsp;Matrix Multiplication (MM) Kernel
(_global_ void matrix_mul(...)), kernel code, and explanation&nbsp;</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;This section presents the most
     straightforward way to implement&nbsp;<b>Matrix Multiplication</b>&nbsp;on
     a GPU.&nbsp;The key idea is&nbsp;<b>thread-to-element mapping</b>:&nbsp;<b>each
     individual thread</b>&nbsp;in the GPU computes&nbsp;<b>exactly one element</b>&nbsp;of
     the resulting matrix&nbsp;<i>C</i>.&nbsp;For example, one thread is
     assigned to compute&nbsp;<i>C</i>[<i>row</i>][<i>col</i>]&nbsp;by
     performing the sum of products:&nbsp;<i>C</i>[<i>row</i>][<i>col</i>]=&#8721;<i>k</i>=0<i>n</i>&#8722;1<span
     style='font-family:"Arial",sans-serif'>&#8203;</span><i>A</i>[<i>row</i>][<i>k</i>]<span
     style='font-family:"Cambria Math",serif'>&#8901;</span><i>B</i>[<i>k</i>][<i>col</i>].&nbsp;The
     thread coordinates (blockIdx&nbsp;and&nbsp;threadIdx) are used to
     determine which row and column of the result matrix&nbsp;<i>C</i>&nbsp;it
     should compute.</li>
 <li class=MsoNormal><b>MCQ:</b></li>
 <ul style='margin-top:0in' type=disc>
  <li class=MsoNormal><b>Question:</b>&nbsp;In the basic MM kernel, what does a
      single CUDA thread compute?</li>
  <li class=MsoNormal><b>A.</b>&nbsp;An entire row of the matrix&nbsp;<i>C</i>.</li>
  <li class=MsoNormal><b>B.</b>&nbsp;An entire column of the matrix&nbsp;<i>C</i>.</li>
  <li class=MsoNormal><b>C.</b>&nbsp;<b>A single element&nbsp;<i>C</i>[<i>row</i>][<i>col</i>]&nbsp;of
      the result matrix.</b>&nbsp;(Correct)&nbsp;</li>
  <li class=MsoNormal><b>D.</b>&nbsp;The entire matrix&nbsp;<i>C</i>.</li>
 </ul>
 <li class=MsoNormal><b>Use Case:</b>&nbsp;Simple, easy-to-implement parallel
     algorithms where the output elements are independent.</li>
 <li class=MsoNormal><b>Numerical:</b></li>
 <ul style='margin-top:0in' type=disc>
  <li class=MsoNormal><b>Goal:</b>&nbsp;Calculate&nbsp;<i>C</i>[2][3]&nbsp;for
      a&nbsp;55&nbsp;matrix multiplication.</li>
  <li class=MsoNormal><b>Calculation:</b>&nbsp;The thread assigned to&nbsp;<i>C</i>[2][3]&nbsp;will
      compute:</li>
 </ul>
</ul>

<p class=MsoNormal><i>C</i>[2][3]=<i>A</i>[2][0]<span style='font-family:"Cambria Math",serif'>&#8901;</span><i>B</i>[0][3]+<i>A</i>[2][1]<span
style='font-family:"Cambria Math",serif'>&#8901;</span><i>B</i>[1][3]+<i>A</i>[2][2]<span
style='font-family:"Cambria Math",serif'>&#8901;</span><i>B</i>[2][3]+<i>A</i>[2][3]<span
style='font-family:"Cambria Math",serif'>&#8901;</span><i>B</i>[3][3]+<i>A</i>[2][4]<span
style='font-family:"Cambria Math",serif'>&#8901;</span><i>B</i>[4][3].</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128640;</span>
Slides 4-8: Tiled Matrix Multiplication (MM) Kernel &amp; Tiling Usage</b></p>

<p class=MsoNormal><b>Slide Content:</b>&nbsp;Tiled MM Kernel code, explanation
of tiling, and memory access optimization&nbsp;</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;Tiling (using shared memory) is
     an optimization to drastically reduce slow&nbsp;<b>global memory reads</b>.</li>
 <ul style='margin-top:0in' type=disc>
  <li class=MsoNormal><b>Problem (Nave Kernel):</b>&nbsp;Each thread computes
      its&nbsp;<i>C</i>[<i>row</i>][<i>col</i>]&nbsp;by reading an entire row
      of&nbsp;<i>A</i>&nbsp;and an entire column of&nbsp;<i>B</i>, resulting
      in&nbsp;<i>O</i>(<i>n</i>3)&nbsp;total global memory accesses for the
      whole&nbsp;<i>C</i>&nbsp;matrix.</li>
  <li class=MsoNormal><b>Solution (Tiled Kernel):</b>&nbsp;Threads in a
      block&nbsp;<b>cooperatively load</b>&nbsp;small, reusable&nbsp;<b>tiles</b>&nbsp;(sub-blocks)
      of matrices&nbsp;<i>A</i>&nbsp;and&nbsp;<i>B</i>&nbsp;into fast&nbsp;<b>shared
      memory</b>&nbsp;(tileA,&nbsp;tileB).&nbsp;Once the data is in shared
      memory, threads access it repeatedly (reuse it) for the partial
      multiplication/summation, avoiding redundant global memory fetches.&nbsp;The&nbsp;__syncthreads()&nbsp;command
      is crucial to ensure all threads finish loading their part of the tile
      before the multiplication begins.</li>
 </ul>
 <li class=MsoNormal><b>MCQ:</b></li>
 <ul style='margin-top:0in' type=disc>
  <li class=MsoNormal><b>Question:</b>&nbsp;What is the main benefit of using
      Tiling (Shared Memory) in Matrix Multiplication?</li>
  <li class=MsoNormal><b>A.</b>&nbsp;It reduces the total number of threads.</li>
  <li class=MsoNormal><b>B.</b>&nbsp;It simplifies the kernel code.</li>
  <li class=MsoNormal><b>C.</b>&nbsp;It increases the global memory reads.</li>
  <li class=MsoNormal><b>D.</b>&nbsp;<b>It drastically reduces global memory
      bandwidth usage by enabling data reuse.</b>&nbsp;(Correct)&nbsp;</li>
 </ul>
 <li class=MsoNormal><b>Use Case:</b>&nbsp;Any memory-bound algorithm where the
     computation pattern involves significant data reuse and overlapping
     access, like MM, 3D transformations, and certain types of image filters.</li>
 <li class=MsoNormal><b>Numerical:</b></li>
 <ul style='margin-top:0in' type=disc>
  <li class=MsoNormal><b>Goal:</b>&nbsp;Compare global reads for one&nbsp;<i>C</i>[<i>row</i>][<i>col</i>]&nbsp;element
      when&nbsp;<i>n</i>=1024.</li>
  <li class=MsoNormal><b>Nave Kernel:</b>&nbsp;Reads&nbsp;&#8776;2<i>n</i>=21024=<b>2048</b>&nbsp;global
      reads per thread.</li>
  <li class=MsoNormal><b>Tiled Kernel (TILE_SIZE=32):</b>&nbsp;Reads&nbsp;&#8776;2TILE_SIZE=232=<b>64</b>&nbsp;global
      reads per tile iteration.&nbsp;The total effective global load is much
      smaller due to sharing.</li>
 </ul>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b><span style='font-family:"Segoe UI Emoji",sans-serif'>&#128444;&#65039;</span>
Slides 9-16: Convolution Kernel &amp; Stencil-based Computation</b></p>

<p class=MsoNormal><b>Slide Content:</b>&nbsp;Visualization of Tiling, basic
Convolution kernel, Stencil approach with RGB input, and memory optimization
with halo.</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Explanation:</b>&nbsp;<b>Convolution</b>&nbsp;involves
     computing an output pixel&nbsp;<i>out</i>(<i>i</i>,<i>j</i>)&nbsp;using
     the center pixel&nbsp;<i>img</i>(<i>i</i>,<i>j</i>)&nbsp;and its
     surrounding neighbors (a&nbsp;<b>stencil</b>).&nbsp;This operation
     naturally creates a massive amount of&nbsp;<b>overlapping memory access</b>.</li>
 <ul style='margin-top:0in' type=disc>
  <li class=MsoNormal><b>Stencil Approach:</b>&nbsp;Similar to Tiling in MM,
      the stencil method optimizes this by partitioning the image.&nbsp;Each
      block of threads&nbsp;<b>cooperatively loads a tile</b>&nbsp;of the input
      image&nbsp;<b>plus a halo</b>&nbsp;(an extra border of 1 pixel) into
      fast&nbsp;<b>shared memory</b>.&nbsp;This halo is necessary because
      threads at the edge of the tile need neighbors that are outside the
      tile's core area.</li>
  <li class=MsoNormal><b>Efficiency:</b>&nbsp;Once the tile (+halo) is in
      shared memory, each thread computes its output pixel independently by
      reusing the locally loaded data, which minimizes global memory traffic.&nbsp;Only
      one&nbsp;__syncthreads()&nbsp;is needed after the initial load.</li>
 </ul>
 <li class=MsoNormal><b>MCQ:</b></li>
 <ul style='margin-top:0in' type=disc>
  <li class=MsoNormal><b>Question:</b>&nbsp;What is the purpose of a&nbsp;<b>&quot;halo&quot;</b>&nbsp;in
      the stencil-based convolution approach?</li>
  <li class=MsoNormal><b>A.</b>&nbsp;To store the output pixel results.</li>
  <li class=MsoNormal><b>B.</b>&nbsp;To hold the filter (kernel) values.</li>
  <li class=MsoNormal><b>C.</b>&nbsp;<b>To load the neighbor pixels required by
      threads at the edge of the tile.</b>&nbsp;(Correct)&nbsp;</li>
  <li class=MsoNormal><b>D.</b>&nbsp;To define the block's grid size.</li>
 </ul>
 <li class=MsoNormal><b>Use Case:</b>&nbsp;Image processing, computer vision
     (edge detection, blurring), partial differential equation (PDE) solvers,
     and fluid dynamics simulations.</li>
 <li class=MsoNormal><b>Numerical:</b></li>
 <ul style='margin-top:0in' type=disc>
  <li class=MsoNormal><b>Goal:</b>&nbsp;Determine the required shared memory
      tile size for a&nbsp;33&nbsp;kernel convolution with a&nbsp;1616&nbsp;thread
      block.</li>
  <li class=MsoNormal><b>Calculation:</b>&nbsp;The thread block covers a&nbsp;1616&nbsp;area
      of the output. A&nbsp;33&nbsp;kernel needs a 1-pixel border (<b>halo</b>)
      around the entire tile.</li>
  <li class=MsoNormal>Required Tile Size = (Block Size + 2 * Halo Width)&nbsp;&nbsp;(Block
      Size + 2 * Halo Width)</li>
  <li class=MsoNormal>Required Tile Size =&nbsp;(16+21)(16+21)=<b>18</b><b>18</b>.</li>
 </ul>
</ul>

<p class=MsoNormal>&nbsp;</p>

<div style='border:none;border-bottom:double windowtext 2.25pt;padding:0in 0in 1.0pt 0in'>

<p class=MsoNormal style='border:none;padding:0in'>&nbsp;</p>

</div>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><b>Slide 2: Basic Matrix Multiplication Kernel</b></p>

<p class=MsoNormal><b>Easy Explanation</b></p>

<p class=MsoNormal>Think of matrix multiplication like a spreadsheet where each
cell needs to calculate its value by multiplying and adding values from its row
and column. In GPU programming, we assign one thread to calculate each cell.
Each thread:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Knows its position (row and column)</li>
 <li class=MsoNormal>Multiplies corresponding elements from that row of matrix
     A and that column of matrix B</li>
 <li class=MsoNormal>Adds all products together to get the final value</li>
</ul>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>In the matrix multiplication kernel, what does threadIdx.y
     represent?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A) The column index within a block</li>
  <li class=MsoNormal>B) The row index within a block &#10003;</li>
  <li class=MsoNormal>C) The total number of threads</li>
  <li class=MsoNormal>D) The block size</li>
 </ul>
 <li class=MsoNormal><b>What is the purpose of the condition if (row &lt; n
     &amp;&amp; col &lt; n)?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A) To optimize performance</li>
  <li class=MsoNormal>B) To prevent out-of-bounds memory access &#10003;</li>
  <li class=MsoNormal>C) To synchronize threads</li>
  <li class=MsoNormal>D) To allocate shared memory</li>
 </ul>
 <li class=MsoNormal><b>How many times does each thread access global memory in
     the basic MM kernel for an nn matrix?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A) n times</li>
  <li class=MsoNormal>B) 2n times &#10003;</li>
  <li class=MsoNormal>C) n times</li>
  <li class=MsoNormal>D) Once</li>
 </ul>
</ol>

<p class=MsoNormal><b>Use Cases</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Image transformations</b>: Rotating, scaling images</li>
 <li class=MsoNormal><b>Neural networks</b>: Forward/backward propagation in
     deep learning</li>
 <li class=MsoNormal><b>Computer graphics</b>: 3D transformations, camera
     projections</li>
 <li class=MsoNormal><b>Scientific computing</b>: Solving linear equations,
     quantum mechanics simulations</li>
 <li class=MsoNormal><b>Signal processing</b>: Filter design, frequency
     analysis</li>
</ul>

<p class=MsoNormal><b>Numerical Problems</b></p>

<p class=MsoNormal><b>Problem 1</b>: Basic calculation</p>

<p class=MsoNormal>Given: Matrix A (22) = [1 2] Matrix B (22) = [5 6]</p>

<p class=MsoNormal> [3 4] [7 8]</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate: C[0][1] using the kernel formula</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- Thread at (row=0, col=1)</p>

<p class=MsoNormal>- C[0][1] = A[0][0]B[0][1] + A[0][1]B[1][1]</p>

<p class=MsoNormal>- C[0][1] = 16 + 28 = 6 + 16 = **22**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2**: Thread mapping</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For a 44 matrix multiplication with block size 22:</p>

<p class=MsoNormal>a) How many blocks are needed?</p>

<p class=MsoNormal>b) Which thread computes C[3][2]?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Blocks needed = (4/2)  (4/2) = **22 = 4 blocks**</p>

<p class=MsoNormal>- b) Thread: blockIdx=(1,1), threadIdx=(1,0)</p>

<p class=MsoNormal> - row = 12 + 1 = 3</p>

<p class=MsoNormal> - col = 12 + 0 = 2</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>---</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>## Slide 4-5: Tiled Matrix Multiplication</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Easy Explanation</p>

<p class=MsoNormal>Imagine you're multiplying huge matrices. Instead of each
worker (thread) going back and forth to a distant warehouse (global memory) for
every number they need, you bring a small section (tile) of numbers to a nearby
desk (shared memory) where all workers in a team can quickly access them. This
is much faster!</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Key improvements**:</p>

<p class=MsoNormal>- Workers share data efficiently</p>

<p class=MsoNormal>- Fewer trips to slow global memory</p>

<p class=MsoNormal>- Same result, much faster</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### MCQs</p>

<p class=MsoNormal>1. **What is the primary advantage of tiled matrix
multiplication?**</p>

<p class=MsoNormal> - A) Uses less threads</p>

<p class=MsoNormal> - B) Reduces global memory accesses &#10003;</p>

<p class=MsoNormal> - C) Increases accuracy</p>

<p class=MsoNormal> - D) Simplifies code</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **What does `__syncthreads()` do in the tiled kernel?**</p>

<p class=MsoNormal> - A) Stops all GPU threads</p>

<p class=MsoNormal> - B) Ensures all threads in a block reach the same point
&#10003;</p>

<p class=MsoNormal> - C) Allocates memory</p>

<p class=MsoNormal> - D) Starts new threads</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **If TILE_SIZE = 16 and n = 100, how many tile iterations
are needed?**</p>

<p class=MsoNormal> - A) 6</p>

<p class=MsoNormal> - B) 7 &#10003;</p>

<p class=MsoNormal> - C) 100</p>

<p class=MsoNormal> - D) 16</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Use Cases</p>

<p class=MsoNormal>- **Deep learning training**: Training large neural networks
(CNNs, Transformers)</p>

<p class=MsoNormal>- **Scientific simulations**: Weather forecasting, molecular
dynamics</p>

<p class=MsoNormal>- **Recommendation systems**: Computing similarity matrices
for millions of users</p>

<p class=MsoNormal>- **Financial modeling**: Portfolio optimization, risk
calculations</p>

<p class=MsoNormal>- **Computer vision**: Feature extraction in image
recognition</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numerical Problems</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1**: Memory access calculation</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For n=1024, TILE_SIZE=32:</p>

<p class=MsoNormal>a) Without tiling: How many global memory reads per thread?</p>

<p class=MsoNormal>b) With tiling: How many global memory reads per thread?</p>

<p class=MsoNormal>c) What's the speedup factor?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Without tiling: Each thread reads 2n elements = 21024
= **2048 reads**</p>

<p class=MsoNormal>- b) With tiling: Tiles = 1024/32 = 32 tiles</p>

<p class=MsoNormal> - Reads per tile = 232 = 64</p>

<p class=MsoNormal> - Total reads = 3232 = **1024 reads**</p>

<p class=MsoNormal>- c) Speedup = 2048/1024 = **2 reduction in memory access**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2**: Tile boundaries</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For n=50, TILE_SIZE=16:</p>

<p class=MsoNormal>a) How many tiles are needed in each dimension?</p>

<p class=MsoNormal>b) How many threads will be idle in the last tile?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Tiles = ceil(50/16) = ceil(3.125) = **4 tiles per
dimension**</p>

<p class=MsoNormal>- b) Last tile: 1616 = 256 threads, but only
(50%16)(50%16) = 22 = 4 do real work</p>

<p class=MsoNormal> - Idle threads = 256 - 4 = **252 threads**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>---</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>## Slide 6-9: Usage and Visualization of Tiling</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Easy Explanation</p>

<p class=MsoNormal>Think of tiling like organizing a group project:</p>

<p class=MsoNormal>- **Without tiling**: Each person works alone, repeatedly
walking to the library (slow)</p>

<p class=MsoNormal>- **With tiling**: Teams work together, sharing books
they've brought to their table (fast)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>For a 55 matrix with 44 tiles:</p>

<p class=MsoNormal>- 4 teams (blocks) work on different sections</p>

<p class=MsoNormal>- Each team loads their portion into shared workspace</p>

<p class=MsoNormal>- Team members reuse this data multiple times</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### MCQs</p>

<p class=MsoNormal>1. **For n=5 and TILE_SIZE=4, how many blocks are needed?**</p>

<p class=MsoNormal> - A) 1</p>

<p class=MsoNormal> - B) 2</p>

<p class=MsoNormal> - C) 4 &#10003;</p>

<p class=MsoNormal> - D) 25</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **What handles the partial tile at the boundary when n=5,
TILE_SIZE=4?**</p>

<p class=MsoNormal> - A) Extra kernel</p>

<p class=MsoNormal> - B) Boundary checks `if(row &lt; n &amp;&amp; col &lt;
n)` &#10003;</p>

<p class=MsoNormal> - C) Padding with zeros automatically</p>

<p class=MsoNormal> - D) CPU post-processing</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **In tiled MM, threads in a block cooperatively load
tiles into:**</p>

<p class=MsoNormal> - A) Global memory</p>

<p class=MsoNormal> - B) Register memory</p>

<p class=MsoNormal> - C) Shared memory &#10003;</p>

<p class=MsoNormal> - D) Constant memory</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Use Cases</p>

<p class=MsoNormal>- **Video processing**: Real-time video filters,
encoding/decoding</p>

<p class=MsoNormal>- **Medical imaging**: CT/MRI reconstruction, image
enhancement</p>

<p class=MsoNormal>- **Game engines**: Physics simulations, collision detection</p>

<p class=MsoNormal>- **Cryptography**: Matrix-based encryption algorithms</p>

<p class=MsoNormal>- **Data analytics**: Large-scale matrix factorization, PCA</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numerical Problems</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1**: Block coverage</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For n=100, TILE_SIZE=32:</p>

<p class=MsoNormal>a) How many blocks cover the entire matrix?</p>

<p class=MsoNormal>b) How many elements does block(2,1) compute?</p>

<p class=MsoNormal>c) What's the global row range for block(2,1)?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Blocks = ceil(100/32)  ceil(100/32) = 44 = **16
blocks**</p>

<p class=MsoNormal>- b) Block(2,1) computes 3232 = **1024 elements** (but
checks boundaries)</p>

<p class=MsoNormal>- c) Row range = blockIdx.yTILE_SIZE to
(blockIdx.y+1)TILE_SIZE</p>

<p class=MsoNormal> - = 132 to 232 = **rows 32-63**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2**: Memory efficiency</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For n=512, TILE_SIZE=16, calculate:</p>

<p class=MsoNormal>a) Total global memory reads without tiling (for entire
matrix)</p>

<p class=MsoNormal>b) Total global memory reads with tiling</p>

<p class=MsoNormal>c) Percentage reduction</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Without: Each of 512 threads reads 2512 values =
5121024 = **268M reads**</p>

<p class=MsoNormal>- b) With: 32 blocks, each loads (512/16)216 tiles =
3232512 = **16.8M reads**</p>

<p class=MsoNormal>- c) Reduction = (268-16.8)/268  100% = **93.7% reduction**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>---</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>## Slide 10: Basic Convolution Kernel</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Easy Explanation</p>

<p class=MsoNormal>Convolution is like applying a stamp or filter over an
image. Imagine you have a 22 rubber stamp (filter/kernel) and a 55 grid of
numbers (image). You press the stamp at every possible position, multiply the
overlapping numbers, and sum them up. The result is a smaller 44 grid.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Formula for output size**: (input_size - kernel_size + 1)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### MCQs</p>

<p class=MsoNormal>1. **For a 55 input with a 22 kernel, what's the output
size?**</p>

<p class=MsoNormal> - A) 55</p>

<p class=MsoNormal> - B) 44 &#10003;</p>

<p class=MsoNormal> - C) 33</p>

<p class=MsoNormal> - D) 66</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **What does each CUDA thread compute in basic
convolution?**</p>

<p class=MsoNormal> - A) One row of output</p>

<p class=MsoNormal> - B) One output pixel &#10003;</p>

<p class=MsoNormal> - C) Entire output matrix</p>

<p class=MsoNormal> - D) One kernel element</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **Why use shared memory for convolution?**</p>

<p class=MsoNormal> - A) To save global memory</p>

<p class=MsoNormal> - B) For better locality and data reuse &#10003;</p>

<p class=MsoNormal> - C) To reduce threads</p>

<p class=MsoNormal> - D) Required by CUDA</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Use Cases</p>

<p class=MsoNormal>- **Image filters**: Blurring, sharpening, edge detection</p>

<p class=MsoNormal>- **Photography apps**: Instagram filters, photo enhancement</p>

<p class=MsoNormal>- **Medical diagnostics**: Detecting tumors in X-rays, MRI
analysis</p>

<p class=MsoNormal>- **Autonomous vehicles**: Lane detection, object
recognition</p>

<p class=MsoNormal>- **Security systems**: Face detection, motion detection</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numerical Problems</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1**: Output size calculation</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Calculate output dimensions:</p>

<p class=MsoNormal>a) Input: 2828, Kernel: 33</p>

<p class=MsoNormal>b) Input: 100100, Kernel: 55</p>

<p class=MsoNormal>c) Input: 6464, Kernel: 77</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) (28-3+1)  (28-3+1) = **2626**</p>

<p class=MsoNormal>- b) (100-5+1)  (100-5+1) = **9696**</p>

<p class=MsoNormal>- c) (64-7+1)  (64-7+1) = **5858**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2**: Manual convolution</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Input (33): Kernel (22):</p>

<p class=MsoNormal>[1 2 3] [1 0]</p>

<p class=MsoNormal>[4 5 6] [0 -1]</p>

<p class=MsoNormal>[7 8 9]</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate: out[0][0] and out[1][1]</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- out[0][0] = 11 + 20 + 40 + 5(-1) = 1 - 5 = **-4**</p>

<p class=MsoNormal>- out[1][1] = 51 + 60 + 80 + 9(-1) = 5 - 9 = **-4**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>---</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>## Slide 11-13: Stencil-based Convolution (RGB)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Easy Explanation</p>

<p class=MsoNormal>Stencil computation is like calculating a value based on a
pixel and its neighbors (top, bottom, left, right). For RGB images:</p>

<p class=MsoNormal>- We have 3 layers (Red, Green, Blue)</p>

<p class=MsoNormal>- The same filter is applied to each layer separately</p>

<p class=MsoNormal>- Zero-padding means treating pixels outside the image as 0</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Formula**: `out(i,j) = 5center - top - bottom - left -
right`</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>This sharpens the image by emphasizing differences.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### MCQs</p>

<p class=MsoNormal>1. **In stencil-based convolution, what is zero-padding?**</p>

<p class=MsoNormal> - A) Setting output to zero</p>

<p class=MsoNormal> - B) Treating pixels outside boundaries as 0 &#10003;</p>

<p class=MsoNormal> - C) Removing zeros from input</p>

<p class=MsoNormal> - D) Adding zero rows/columns physically</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **For RGB convolution, how many times is the kernel
applied?**</p>

<p class=MsoNormal> - A) Once</p>

<p class=MsoNormal> - B) Twice</p>

<p class=MsoNormal> - C) Three times (once per channel) &#10003;</p>

<p class=MsoNormal> - D) Depends on image size</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **What's the value of &quot;top&quot; for pixel (0,1)
with value 20?**</p>

<p class=MsoNormal> - A) 10</p>

<p class=MsoNormal> - B) 0 &#10003;</p>

<p class=MsoNormal> - C) 20</p>

<p class=MsoNormal> - D) 30</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Use Cases</p>

<p class=MsoNormal>- **Photo editing apps**: Sharpen, blur, emboss effects</p>

<p class=MsoNormal>- **Medical imaging**: Enhancing blood vessels, tumor
boundaries</p>

<p class=MsoNormal>- **Satellite imagery**: Enhancing terrain features, cloud
detection</p>

<p class=MsoNormal>- **Quality control**: Defect detection in manufacturing</p>

<p class=MsoNormal>- **Document scanning**: Text enhancement, noise removal</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numerical Problems</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1**: Stencil calculation</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Given R channel (33):</p>

<p class=MsoNormal>[10 20 30]</p>

<p class=MsoNormal>[15 25 35]</p>

<p class=MsoNormal>[20 30 40]</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate: out(1,1) using formula: 5center - top - bottom -
left - right</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- center = 25, top = 20, bottom = 30, left = 15, right = 35</p>

<p class=MsoNormal>- out(1,1) = 525 - 20 - 30 - 15 - 35 = 125 - 100 = **25**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2**: Edge pixel</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For the same matrix, calculate: out(0,0) (top-left corner)</p>

<p class=MsoNormal>Remember: pixels outside are treated as 0</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- center = 10, top = 0, bottom = 15, left = 0, right = 20</p>

<p class=MsoNormal>- out(0,0) = 510 - 0 - 15 - 0 - 20 = 50 - 35 = **15**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 3**: Complete row</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Calculate entire first row output for:</p>

<p class=MsoNormal>[10 20 30]</p>

<p class=MsoNormal>[15 25 35]</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Formula: 5center - top - bottom - left - right</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- out(0,0) = 510 - 0 - 15 - 0 - 20 = **15**</p>

<p class=MsoNormal>- out(0,1) = 520 - 0 - 25 - 10 - 30 = **35**</p>

<p class=MsoNormal>- out(0,2) = 530 - 0 - 35 - 20 - 0 = **95**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>---</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>## Slide 14-16: Visualization &amp; Efficiency</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Easy Explanation</p>

<p class=MsoNormal>**The Problem**: Without shared memory, if 16 threads need
the same pixel, it gets loaded 16 times from slow memory.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**The Solution (Stencil Approach)**:</p>

<p class=MsoNormal>1. **Load once**: A team of threads loads a tile + halo
(extra border pixels) into fast shared memory</p>

<p class=MsoNormal>2. **Reuse**: All threads access this fast shared memory</p>

<p class=MsoNormal>3. **Sync once**: One `__syncthreads()` ensures data is
ready</p>

<p class=MsoNormal>4. **Compute in parallel**: Thousands of threads work
simultaneously</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Example**: 1616 block needs 1818 tile (16 + 1-pixel
border on each side)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### MCQs</p>

<p class=MsoNormal>1. **For a 1616 thread block with 33 kernel, what shared
memory tile size is needed?**</p>

<p class=MsoNormal> - A) 1616</p>

<p class=MsoNormal> - B) 1818 &#10003;</p>

<p class=MsoNormal> - C) 1919</p>

<p class=MsoNormal> - D) 4848</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **What's the main benefit of the stencil approach?**</p>

<p class=MsoNormal> - A) Simpler code</p>

<p class=MsoNormal> - B) Data reuse reduces memory traffic &#10003;</p>

<p class=MsoNormal> - C) Uses fewer threads</p>

<p class=MsoNormal> - D) Larger output</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **How many synchronization points are needed per tile in
stencil convolution?**</p>

<p class=MsoNormal> - A) None</p>

<p class=MsoNormal> - B) One &#10003;</p>

<p class=MsoNormal> - C) Two</p>

<p class=MsoNormal> - D) One per thread</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Use Cases</p>

<p class=MsoNormal>- **Real-time video processing**: Live streaming filters,
video conferencing effects</p>

<p class=MsoNormal>- **Augmented reality**: Real-time image enhancement in AR
glasses</p>

<p class=MsoNormal>- **Robotics**: Vision processing for navigation and object
manipulation</p>

<p class=MsoNormal>- **Scientific visualization**: Processing microscopy images
in real-time</p>

<p class=MsoNormal>- **Gaming**: Post-processing effects (bloom, motion blur,
depth of field)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numerical Problems</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1**: Memory efficiency</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For 10241024 image, 1616 blocks, 33 kernel:</p>

<p class=MsoNormal>a) Without shared memory: How many global reads for one
block?</p>

<p class=MsoNormal>b) With shared memory: How many global reads for one block?</p>

<p class=MsoNormal>c) What's the reduction factor?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Without: 1616 threads, each reads 33 = 9 pixels =
16169 = **2304 reads**</p>

<p class=MsoNormal>- b) With: Load 1818 tile once = **324 reads**</p>

<p class=MsoNormal>- c) Reduction = 2304/324 = **7.1 fewer reads**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2**: Halo calculation</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For block size BB and kernel size KK:</p>

<p class=MsoNormal>a) What's the halo width on each side?</p>

<p class=MsoNormal>b) What's the total shared memory tile size?</p>

<p class=MsoNormal>c) For B=32, K=5, calculate the tile size</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Halo width = floor(K/2) = floor(5/2) = **2 pixels on
each side**</p>

<p class=MsoNormal>- b) Tile size = (B + 2halo)  (B + 2halo)</p>

<p class=MsoNormal>- c) Tile = (32 + 22)  (32 + 22) = **3636**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 3**: Parallelism calculation</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For 512512 image with 1616 blocks:</p>

<p class=MsoNormal>a) How many blocks are launched?</p>

<p class=MsoNormal>b) How many threads execute in parallel?</p>

<p class=MsoNormal>c) If each thread takes 100 cycles, and GPU can run 10,000
threads simultaneously, </p>

<p class=MsoNormal> what's the total time (in cycles)?</p>

<p class=MsoNormal><b>Solution</b>:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>a) Blocks = (512/16)  (512/16) = 3232 = <b>1024 blocks</b></li>
 <li class=MsoNormal>b) Total threads = 1024256 = <b>262,144 threads</b></li>
 <li class=MsoNormal>c) Waves = 262,144/10,000 = 26.2 &#8776; 27 waves </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Total time = 27100 = <b>2700 cycles</b></li>
 </ul>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Summary Comparison Table</b></p>

<table class=MsoNormalTable border=0 cellspacing=3 cellpadding=0>
 <thead>
  <tr>
   <td style='padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Technique</b></p>
   </td>
   <td style='padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Memory Access</b></p>
   </td>
   <td style='padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Speedup</b></p>
   </td>
   <td style='padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Complexity</b></p>
   </td>
   <td style='padding:.75pt .75pt .75pt .75pt'>
   <p class=MsoNormal><b>Best For</b></p>
   </td>
  </tr>
 </thead>
 <tr>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Basic MM</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>High (2n per thread)</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>1</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Low</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Small matrices</p>
  </td>
 </tr>
 <tr>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Tiled MM</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Low (2TILE_SIZE per thread)</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>5-10</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Medium</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Large matrices</p>
  </td>
 </tr>
 <tr>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Basic Convolution</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>High (k per thread)</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>1</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Low</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Small images</p>
  </td>
 </tr>
 <tr>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Stencil Convolution</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Low (shared tile)</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>7-15</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Medium</p>
  </td>
  <td style='padding:.75pt .75pt .75pt .75pt'>
  <p class=MsoNormal>Large images, real-time</p>
  </td>
 </tr>
</table>

<p class=MsoNormal>These optimizations are fundamental in modern GPU
programming for AI, graphics, and scientific computing!</p>

<p class=MsoNormal>Retry</p>

<p class=MsoNormal>P</p>

<p class=MsoNormal>all slides</p>

<p class=MsoNormal>I'll provide comprehensive coverage of ALL slides with
explanations, MCQs, use cases, and numerical problems.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>SLIDE 1: GPU Programming - Lecture 07 Title</b></p>

<p class=MsoNormal><b>Easy Explanation</b></p>

<p class=MsoNormal>This lecture covers <b>parallel kernel programming</b> - the
art of writing code that runs on thousands of GPU cores simultaneously. Think
of it like managing a massive team where instead of one worker doing tasks
sequentially, thousands of workers do small pieces of work at the same time.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>What does &quot;parallel kernel programming&quot; mean?</b>
     </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A) Writing code for CPU only</li>
  <li class=MsoNormal>B) Writing code that runs on multiple GPU threads
      simultaneously &#10003;</li>
  <li class=MsoNormal>C) Managing multiple programs</li>
  <li class=MsoNormal>D) Optimizing sequential code</li>
 </ul>
 <li class=MsoNormal><b>What is a &quot;kernel&quot; in GPU programming?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A) The operating system core</li>
  <li class=MsoNormal>B) A function that runs on the GPU &#10003;</li>
  <li class=MsoNormal>C) Memory allocation function</li>
  <li class=MsoNormal>D) A debugging tool</li>
 </ul>
 <li class=MsoNormal><b>The main advantage of GPU parallel programming is:</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A) Simpler code</li>
  <li class=MsoNormal>B) Lower power consumption</li>
  <li class=MsoNormal>C) Processing many tasks simultaneously &#10003;</li>
  <li class=MsoNormal>D) Better graphics only</li>
 </ul>
</ol>

<p class=MsoNormal><b>Use Cases</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Deep Learning</b>: Training neural networks with
     millions of parameters</li>
 <li class=MsoNormal><b>Scientific Research</b>: Climate modeling, protein
     folding, particle physics</li>
 <li class=MsoNormal><b>Financial Services</b>: Risk analysis, algorithmic
     trading</li>
 <li class=MsoNormal><b>Entertainment</b>: Movie rendering, game physics</li>
 <li class=MsoNormal><b>Healthcare</b>: Medical image processing, drug
     discovery</li>
</ul>

<p class=MsoNormal><b>Numerical Problems</b></p>

<p class=MsoNormal><b>Problem 1</b>: Parallelism comparison</p>

<p class=MsoNormal>Task: Process 1,000,000 data points</p>

<p class=MsoNormal>CPU: 1 core, processes 1000 points/second</p>

<p class=MsoNormal>GPU: 2048 cores, each processes 500 points/second</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate:</p>

<p class=MsoNormal>a) CPU time</p>

<p class=MsoNormal>b) GPU time</p>

<p class=MsoNormal>c) Speedup</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) CPU time = 1,000,000 / 1000 = **1000 seconds**</p>

<p class=MsoNormal>- b) GPU time = 1,000,000 / (2048  500) = 1,000,000 /
1,024,000 &#8776; **0.98 seconds**</p>

<p class=MsoNormal>- c) Speedup = 1000 / 0.98 &#8776; **1020**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2**: Thread calculation</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>If a GPU has 80 streaming multiprocessors (SMs) and each SM
can run 2048 threads:</p>

<p class=MsoNormal>a) Maximum concurrent threads?</p>

<p class=MsoNormal>b) If each thread processes 100 data points, how much data
can be processed simultaneously?</p>

<p class=MsoNormal><b>Solution</b>:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>a) Max threads = 80  2048 = <b>163,840 threads</b></li>
 <li class=MsoNormal>b) Data processed = 163,840  100 = <b>16,384,000 data
     points</b></li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>SLIDE 2: Matrix Multiplication (MM) Kernel</b></p>

<p class=MsoNormal><b>Easy Explanation</b></p>

<p class=MsoNormal>Matrix multiplication is like filling out a spreadsheet
where each cell is calculated by multiplying corresponding row and column
values and adding them up. In GPU programming:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Each thread is a worker assigned to calculate ONE cell</li>
 <li class=MsoNormal>The thread knows its position: row (which row) and col
     (which column)</li>
 <li class=MsoNormal>It loops through, multiplying and summing: sum +=
     a[row][k] * b[k][col]</li>
</ul>

<p class=MsoNormal><b>Key Code Components</b>:</p>

<p class=MsoNormal>c</p>

<p class=MsoNormal>int row = blockIdx.y * blockDim.y + threadIdx.y; <i>//
Which row am I?</i></p>

<p class=MsoNormal>int col = blockIdx.x * blockDim.x + threadIdx.x; <i>//
Which column am I?</i></p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### MCQs</p>

<p class=MsoNormal>1. **In `int row = blockIdx.y * blockDim.y + threadIdx.y`,
what does blockDim.y represent?**</p>

<p class=MsoNormal> - A) Total number of blocks</p>

<p class=MsoNormal> - B) Number of threads per block in Y dimension &#10003;</p>

<p class=MsoNormal> - C) Global row index</p>

<p class=MsoNormal> - D) Matrix dimension</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **For matrix multiplication of A(nn) and B(nn), how
many multiply-add operations does each thread perform?**</p>

<p class=MsoNormal> - A) 1</p>

<p class=MsoNormal> - B) n &#10003;</p>

<p class=MsoNormal> - C) n</p>

<p class=MsoNormal> - D) 2n</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **What happens if we remove the boundary check `if (row &lt;
n &amp;&amp; col &lt; n)`?**</p>

<p class=MsoNormal> - A) Code runs faster</p>

<p class=MsoNormal> - B) Memory access violations may occur &#10003;</p>

<p class=MsoNormal> - C) Nothing changes</p>

<p class=MsoNormal> - D) Compilation error</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>4. **Which memory is accessed in the line `sum += a[row * n +
k] * b[k * n + col]`?**</p>

<p class=MsoNormal> - A) Shared memory</p>

<p class=MsoNormal> - B) Global memory &#10003;</p>

<p class=MsoNormal> - C) Register memory</p>

<p class=MsoNormal> - D) Constant memory</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Use Cases</p>

<p class=MsoNormal>- **Machine Learning**: Weight matrix multiplications in
neural networks</p>

<p class=MsoNormal>- **Computer Graphics**: 3D transformations (rotation,
scaling, translation)</p>

<p class=MsoNormal>- **Image Processing**: Applying linear filters and
transformations</p>

<p class=MsoNormal>- **Physics Simulations**: Quantum mechanics, finite element
analysis</p>

<p class=MsoNormal>- **Economics**: Input-output models, Leontief analysis</p>

<p class=MsoNormal>- **Robotics**: Kinematics calculations, state space
transformations</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numerical Problems</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1**: Basic Matrix Multiplication</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Matrix A (33): Matrix B (33):</p>

<p class=MsoNormal>[1 2 3] [7 8 9]</p>

<p class=MsoNormal>[4 5 6] [10 11 12]</p>

<p class=MsoNormal>[0 1 2] [13 14 15]</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate: C[1][2] manually</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- C[1][2] = A[1][0]B[0][2] + A[1][1]B[1][2] + A[1][2]B[2][2]</p>

<p class=MsoNormal>- C[1][2] = 49 + 512 + 615</p>

<p class=MsoNormal>- C[1][2] = 36 + 60 + 90 = **186**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2**: Thread Mapping</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Given:</p>

<p class=MsoNormal>- Matrix size: 88</p>

<p class=MsoNormal>- Block dimensions: 44 threads</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>a) How many blocks are needed?</p>

<p class=MsoNormal>b) Which block and thread compute C[5][6]?</p>

<p class=MsoNormal>c) What are blockIdx and threadIdx for this element?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Blocks needed = ceil(8/4)  ceil(8/4) = **22 = 4
blocks**</p>

<p class=MsoNormal>- b) For C[5][6]:</p>

<p class=MsoNormal> - blockIdx.y = 5/4 = 1, blockIdx.x = 6/4 = 1</p>

<p class=MsoNormal> - threadIdx.y = 5%4 = 1, threadIdx.x = 6%4 = 2</p>

<p class=MsoNormal> - **Block(1,1), Thread(1,2)**</p>

<p class=MsoNormal>- c) blockIdx = (1,1), threadIdx = (1,2)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 3**: Memory Access Pattern</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For n=1024 matrix multiplication:</p>

<p class=MsoNormal>a) How many global memory reads does ONE thread perform?</p>

<p class=MsoNormal>b) How many global memory writes?</p>

<p class=MsoNormal>c) Total memory accesses for entire computation?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Each thread reads n elements from A and n from B = **2048
reads**</p>

<p class=MsoNormal>- b) Each thread writes 1 result = **1 write**</p>

<p class=MsoNormal>- c) Total threads = 1024 = 1,048,576</p>

<p class=MsoNormal> - Total accesses = 1,048,576  (2048 + 1) &#8776; **2.15
billion accesses**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 4**: Computational Complexity</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For two nn matrices:</p>

<p class=MsoNormal>a) How many floating-point operations (FLOPs) for entire
multiplication?</p>

<p class=MsoNormal>b) If GPU performs 10 TFLOPs/s, how long for n=4096?</p>

<p class=MsoNormal>c) What's the computational intensity (FLOPs per byte)?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Each of n elements needs n multiply-adds = n  (2n) =
**2n FLOPs**</p>

<p class=MsoNormal>- b) For n=4096: FLOPs = 2(4096) = 137.4 billion</p>

<p class=MsoNormal> - Time = 137.410&#8313; / (1010) = **0.0137 seconds = 13.7
ms**</p>

<p class=MsoNormal>- c) Data transferred = 2n inputs + n output = 3n  4
bytes = 12n bytes</p>

<p class=MsoNormal> - Intensity = 2n / 12n = **n/6 FLOPs/byte**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 5**: Grid and Block Configuration</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For n=1000 matrix with block size 1616:</p>

<p class=MsoNormal>a) Calculate grid dimensions</p>

<p class=MsoNormal>b) How many threads will be idle?</p>

<p class=MsoNormal>c) What's the efficiency (active threads / total threads)?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Grid dims = (ceil(1000/16), ceil(1000/16)) = **(63, 63)
blocks**</p>

<p class=MsoNormal>- b) Total threads launched = 63631616 = 1,016,064</p>

<p class=MsoNormal> - Useful threads = 10001000 = 1,000,000</p>

<p class=MsoNormal> - Idle threads = **16,064 threads**</p>

<p class=MsoNormal>- c) Efficiency = 1,000,000 / 1,016,064 = **98.4%**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>---</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal># SLIDE 3: Explanation with Example</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Easy Explanation</p>

<p class=MsoNormal>This slide visualizes HOW threads map to matrix elements.
Imagine a 55 grid where:</p>

<p class=MsoNormal>- Each cell needs to be calculated</p>

<p class=MsoNormal>- We assign ONE thread per cell</p>

<p class=MsoNormal>- Thread (0,0) calculates c&#8320;&#8320;</p>

<p class=MsoNormal>- Thread (4,4) calculates c&#8324;&#8324;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Example Breakdown**: c[2][3] = a[2][0]b[0][3] + a[2][1]b[1][3]
+ ... + a[2][4]b[4][3]</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>This means: Take row 2 of A, multiply element-by-element
with column 3 of B, sum them up.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### MCQs</p>

<p class=MsoNormal>1. **Thread (row=2, col=3) computes which element?**</p>

<p class=MsoNormal> - A) c&#8322;&#8322;</p>

<p class=MsoNormal> - B) c&#8323;&#8322;</p>

<p class=MsoNormal> - C) c&#8322;&#8323; &#10003;</p>

<p class=MsoNormal> - D) c&#8323;&#8323;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **For a 55 matrix multiplication, how many threads are
needed?**</p>

<p class=MsoNormal> - A) 5</p>

<p class=MsoNormal> - B) 10</p>

<p class=MsoNormal> - C) 25 &#10003;</p>

<p class=MsoNormal> - D) 125</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **What does thread (0,0) access from matrix A?**</p>

<p class=MsoNormal> - A) First column</p>

<p class=MsoNormal> - B) First row &#10003;</p>

<p class=MsoNormal> - C) All elements</p>

<p class=MsoNormal> - D) Single element</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>4. **In the calculation c[2][3] = a[2][0]*b[0][3] + a[2][1]*b[1][3]
+ ..., how many terms are summed?**</p>

<p class=MsoNormal> - A) 2</p>

<p class=MsoNormal> - B) 3</p>

<p class=MsoNormal> - C) 5 &#10003;</p>

<p class=MsoNormal> - D) 25</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Use Cases</p>

<p class=MsoNormal>- **Image Convolution**: Applying filters (blur, sharpen,
edge detection)</p>

<p class=MsoNormal>- **Video Game Physics**: Collision detection using
transformation matrices</p>

<p class=MsoNormal>- **GPS Navigation**: Coordinate transformations</p>

<p class=MsoNormal>- **Medical Imaging**: CT/MRI reconstruction</p>

<p class=MsoNormal>- **Audio Processing**: Digital signal processing filters</p>

<p class=MsoNormal>- **Machine Learning**: Batch processing in deep neural
networks</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numerical Problems</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1**: Complete Calculation</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>A (33): B (33):</p>

<p class=MsoNormal>[2 1 3] [1 0 2]</p>

<p class=MsoNormal>[0 4 1] [3 1 4]</p>

<p class=MsoNormal>[5 2 0] [2 5 1]</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate the complete first row of C: [c&#8320;&#8320;,
c&#8320;&#8321;, c&#8320;&#8322;]</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- c&#8320;&#8320; = 21 + 13 + 32 = 2 + 3 + 6 = **11**</p>

<p class=MsoNormal>- c&#8320;&#8321; = 20 + 11 + 35 = 0 + 1 + 15 = **16**</p>

<p class=MsoNormal>- c&#8320;&#8322; = 22 + 14 + 31 = 4 + 4 + 3 = **11**</p>

<p class=MsoNormal>- **First row: [11, 16, 11]**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2**: Thread Execution Analysis</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For a 55 matrix multiplication with 55 threads:</p>

<p class=MsoNormal>a) Which threads access b[2][3]?</p>

<p class=MsoNormal>b) How many times is b[2][3] accessed total?</p>

<p class=MsoNormal>c) Which thread accesses a[3][2]?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) All threads in **column 3** (threads (0,3), (1,3), (2,3),
(3,3), (4,3))</p>

<p class=MsoNormal>- b) Accessed **5 times** (once by each thread in column 3)</p>

<p class=MsoNormal>- c) All threads in **row 3** access different elements of
row 3 of A</p>

<p class=MsoNormal> - Specifically, thread (3,k) accesses a[3][2] when k loops
to 2</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 3**: Data Reuse Analysis</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>In a 44 matrix multiplication:</p>

<p class=MsoNormal>a) How many times is a[0][0] read from global memory?</p>

<p class=MsoNormal>b) How many times is b[0][0] read from global memory?</p>

<p class=MsoNormal>c) What's the total number of redundant reads?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) a[0][0] is read by all threads in row 0 = **4 times**</p>

<p class=MsoNormal>- b) b[0][0] is read by all threads in column 0 = **4 times**</p>

<p class=MsoNormal>- c) Each element of A is read 4 times, each element of B is
read 4 times</p>

<p class=MsoNormal> - Total redundant reads = 2  16  3 = **96 redundant
reads**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 4**: Block Decomposition</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For 66 matrix with 33 blocks:</p>

<p class=MsoNormal>a) How many blocks total?</p>

<p class=MsoNormal>b) Which elements does Block(0,1) compute?</p>

<p class=MsoNormal>c) Which elements does Block(1,0) compute?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Blocks = (6/3)  (6/3) = **4 blocks (22 grid)**</p>

<p class=MsoNormal>- b) Block(0,1) computes elements with:</p>

<p class=MsoNormal> - rows: 03 to 13-1 = 0-2</p>

<p class=MsoNormal> - cols: 13 to 23-1 = 3-5</p>

<p class=MsoNormal> - **Elements: c[0-2][3-5]**</p>

<p class=MsoNormal>- c) Block(1,0) computes:</p>

<p class=MsoNormal> - rows: 13 to 23-1 = 3-5</p>

<p class=MsoNormal> - cols: 03 to 13-1 = 0-2</p>

<p class=MsoNormal> - **Elements: c[3-5][0-2]**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 5**: Parallelism vs Sequential</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Sequential CPU: Computes one element per 10 nanoseconds</p>

<p class=MsoNormal>Parallel GPU: All elements computed simultaneously in 100 nanoseconds
(due to memory latency)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>For nn matrices, at what value of n does GPU become faster?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- CPU time = n  10 ns</p>

<p class=MsoNormal>- GPU time = 100 ns</p>

<p class=MsoNormal>- GPU faster when: n  10 &gt; 100</p>

<p class=MsoNormal>- n &gt; 10</p>

<p class=MsoNormal>- n &gt; 3.16</p>

<p class=MsoNormal>- **GPU is faster for n &#8805; 4**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>---</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal># SLIDE 4: Tiled MM Kernel (Part 1)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Easy Explanation</p>

<p class=MsoNormal>**The Problem with Basic MM**: Every thread repeatedly
fetches data from slow global memory. For a 10001000 matrix, each thread makes
2000 global memory reads!</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**The Tiled Solution**: </p>

<p class=MsoNormal>1. **Divide and conquer**: Break matrices into small tiles (e.g.,
1616)</p>

<p class=MsoNormal>2. **Cooperative loading**: Threads in a block work together
to load a tile into fast shared memory</p>

<p class=MsoNormal>3. **Reuse**: All threads access the fast shared memory
multiple times</p>

<p class=MsoNormal>4. **Repeat**: Move to next tile, repeat until done</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Key Innovation**: `__shared__ int tileA[TILE_SIZE][TILE_SIZE]`
- This is like a shared whiteboard that's 100 faster to access than going to
the library (global memory).</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### MCQs</p>

<p class=MsoNormal>1. **What is the purpose of `__shared__` memory?**</p>

<p class=MsoNormal> - A) To share data between different GPU programs</p>

<p class=MsoNormal> - B) To provide fast memory accessible by all threads in
a block &#10003;</p>

<p class=MsoNormal> - C) To save global memory space</p>

<p class=MsoNormal> - D) To communicate with CPU</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **How many tiles of A are processed for n=1024, TILE_SIZE=16?**</p>

<p class=MsoNormal> - A) 16</p>

<p class=MsoNormal> - B) 32</p>

<p class=MsoNormal> - C) 64 &#10003;</p>

<p class=MsoNormal> - D) 1024</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **What does the variable 'm' represent in the tiling loop?**</p>

<p class=MsoNormal> - A) Matrix size</p>

<p class=MsoNormal> - B) Tile index / which tile we're currently processing
&#10003;</p>

<p class=MsoNormal> - C) Thread index</p>

<p class=MsoNormal> - D) Memory address</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>4. **Why is `temp` used instead of directly writing to c[row*n+col]?**</p>

<p class=MsoNormal> - A) To save memory</p>

<p class=MsoNormal> - B) To accumulate partial sums across tiles &#10003;</p>

<p class=MsoNormal> - C) For synchronization</p>

<p class=MsoNormal> - D) Required by CUDA</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Use Cases</p>

<p class=MsoNormal>- **Deep Learning Training**: Efficiently multiplying large
weight matrices in neural networks</p>

<p class=MsoNormal>- **Scientific Computing**: Solving large linear systems in
climate models, fluid dynamics</p>

<p class=MsoNormal>- **Recommendation Systems**: Computing user-item similarity
matrices for Netflix, Amazon</p>

<p class=MsoNormal>- **Financial Analytics**: Portfolio optimization with
covariance matrices</p>

<p class=MsoNormal>- **Computer Vision**: Feature transformation in object detection
(YOLO, R-CNN)</p>

<p class=MsoNormal>- **Quantum Computing Simulation**: Matrix exponentials for
quantum gates</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numerical Problems</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1**: Tile Calculation</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Given: n=100, TILE_SIZE=20</p>

<p class=MsoNormal>a) How many tiles in each dimension?</p>

<p class=MsoNormal>b) How many total tile iterations per block?</p>

<p class=MsoNormal>c) What's the size of the last tile?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Tiles per dimension = ceil(100/20) = **5 tiles**</p>

<p class=MsoNormal>- b) Total iterations = **5 iterations** (m = 0, 1, 2, 3, 4)</p>

<p class=MsoNormal>- c) Last tile is full 2020, but boundary checks ensure
only valid elements are used</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2**: Memory Access Comparison</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For n=512, TILE_SIZE=32:</p>

<p class=MsoNormal>a) Basic MM: Memory reads per thread</p>

<p class=MsoNormal>b) Tiled MM: Memory reads per thread</p>

<p class=MsoNormal>c) Reduction factor</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Basic: 2n = 2512 = **1024 reads per thread**</p>

<p class=MsoNormal>- b) Tiled: Number of tiles = 512/32 = 16</p>

<p class=MsoNormal> - Reads per tile = 2TILE_SIZE = 232 = 64</p>

<p class=MsoNormal> - Total = **64 reads per thread** (each tile loaded once)</p>

<p class=MsoNormal>- c) Reduction = 1024/64 = **16 fewer reads**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 3**: Shared Memory Requirements</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For TILE_SIZE=32, int is 4 bytes:</p>

<p class=MsoNormal>a) Memory for one tileA</p>

<p class=MsoNormal>b) Memory for one tileB</p>

<p class=MsoNormal>c) Total shared memory per block</p>

<p class=MsoNormal>d) If GPU has 48KB shared memory per SM, how many blocks can
run concurrently?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) tileA = 32324 bytes = **4096 bytes = 4KB**</p>

<p class=MsoNormal>- b) tileB = 32324 bytes = **4KB**</p>

<p class=MsoNormal>- c) Total = 4+4 = **8KB per block**</p>

<p class=MsoNormal>- d) Blocks per SM = 48KB / 8KB = **6 blocks**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 4**: Load Distribution</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For TILE_SIZE=16 (256 threads per block):</p>

<p class=MsoNormal>a) How many loads does each thread perform per tile
iteration?</p>

<p class=MsoNormal>b) Total loads to fill both tileA and tileB</p>

<p class=MsoNormal>c) Are loads balanced across threads?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Each thread loads **2 elements** (one for tileA, one for
tileB)</p>

<p class=MsoNormal>- b) Total elements = 21616 = 512 elements</p>

<p class=MsoNormal> - Total loads = **512 loads** distributed across 256
threads</p>

<p class=MsoNormal>- c) Yes, **perfectly balanced**: each thread does exactly 2
loads</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 5**: Performance Estimation</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Given:</p>

<p class=MsoNormal>- Global memory latency: 400 cycles</p>

<p class=MsoNormal>- Shared memory latency: 20 cycles</p>

<p class=MsoNormal>- n=1024, TILE_SIZE=32</p>

<p class=MsoNormal>- Basic MM: Each thread reads 2048 elements from global
memory</p>

<p class=MsoNormal>- Tiled MM: Each thread reads 64 elements from global, then
accesses shared</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate approximate latency savings:</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- Basic MM latency: 2048  400 = **819,200 cycles**</p>

<p class=MsoNormal>- Tiled MM:</p>

<p class=MsoNormal> - Global reads: 64  400 = 25,600 cycles</p>

<p class=MsoNormal> - Shared reads: (2048-64)  20 = 39,680 cycles</p>

<p class=MsoNormal> - Total: 25,600 + 39,680 = **65,280 cycles**</p>

<p class=MsoNormal>- Speedup = 819,200 / 65,280 &#8776; **12.5 faster**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>---</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal># SLIDE 5: Tiled MM Kernel (Part 2)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Easy Explanation</p>

<p class=MsoNormal>This slide shows the second part of the tiled kernel,
focusing on:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>1. **Zero Padding**: If we're at the edge and there's no
more data, fill with zeros</p>

<p class=MsoNormal>2. **`__syncthreads()`**: Wait! Make sure ALL threads have
loaded their data before anyone starts computing</p>

<p class=MsoNormal>3. **Computation**: Multiply the tiles we just loaded</p>

<p class=MsoNormal>4. **Another sync**: Wait again before loading new tiles (so
we don't overwrite data other threads are still using)</p>

<p class=MsoNormal>5. **Final write**: After all tiles processed, write result
to global memory</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Critical Concept**: The two `__syncthreads()` calls act
like traffic lights ensuring no thread goes ahead until everyone is ready.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### MCQs</p>

<p class=MsoNormal>1. **Why do we set tileA and tileB to 0 when out of bounds?**</p>

<p class=MsoNormal> - A) To save memory</p>

<p class=MsoNormal> - B) To prevent garbage values from affecting computation
&#10003;</p>

<p class=MsoNormal> - C) Required by CUDA syntax</p>

<p class=MsoNormal> - D) To optimize performance</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **What happens if we remove the first `__syncthreads()`?**</p>

<p class=MsoNormal> - A) Code runs faster</p>

<p class=MsoNormal> - B) Race condition - threads may read before data is
loaded &#10003;</p>

<p class=MsoNormal> - C) Compilation error</p>

<p class=MsoNormal> - D) Nothing changes</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **Why is there a second `__syncthreads()` after the
multiplication?**</p>

<p class=MsoNormal> - A) To write results</p>

<p class=MsoNormal> - B) To prevent tiles from being overwritten before all
threads finish using them &#10003;</p>

<p class=MsoNormal> - C) To allocate new memory</p>

<p class=MsoNormal> - D) For debugging</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>4. **The variable `temp` accumulates values across:**</p>

<p class=MsoNormal> - A) All threads</p>

<p class=MsoNormal> - B) All tiles for one output element &#10003;</p>

<p class=MsoNormal> - C) One tile only</p>

<p class=MsoNormal> - D) All blocks</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Use Cases</p>

<p class=MsoNormal>- **Training CNNs**: Convolutional layers in image classification
(ResNet, VGG)</p>

<p class=MsoNormal>- **Transformer Models**: Attention mechanism calculations
in GPT, BERT</p>

<p class=MsoNormal>- **3D Graphics Rendering**: Bone transformations for
character animation</p>

<p class=MsoNormal>- **Molecular Dynamics**: Force calculations between
particles</p>

<p class=MsoNormal>- **Seismic Analysis**: Processing earthquake sensor data</p>

<p class=MsoNormal>- **Cryptography**: Large integer arithmetic in RSA
encryption</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numerical Problems</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1**: Synchronization Analysis</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Block with 256 threads (1616), TILE_SIZE=16:</p>

<p class=MsoNormal>a) How many times is __syncthreads() called per tile?</p>

<p class=MsoNormal>b) Total syncs for n=1024?</p>

<p class=MsoNormal>c) If sync costs 10 cycles, what's the total sync overhead?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) **2 syncs per tile** (after load, after compute)</p>

<p class=MsoNormal>- b) Tiles = 1024/16 = 64, so **128 syncs total**</p>

<p class=MsoNormal>- c) Overhead = 128  10 = **1,280 cycles per block**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2**: Boundary Handling</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>n=50, TILE_SIZE=16, consider Block(3,3):</p>

<p class=MsoNormal>a) What global row/col does this block cover?</p>

<p class=MsoNormal>b) Which elements are valid (within n)?</p>

<p class=MsoNormal>c) How many threads do actual work?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Rows: 316 = 48 to 63, Cols: 316 = 48 to 63</p>

<p class=MsoNormal>- b) Valid: rows 48-49, cols 48-49 (since n=50)</p>

<p class=MsoNormal> - **22 = 4 valid elements**</p>

<p class=MsoNormal>- c) **4 threads** do useful work, 252 threads load zeros/pad</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 3**: Accumulation Trace</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For c[0][0], TILE_SIZE=4, n=8:</p>

<p class=MsoNormal>Trace the value of `temp` through tile iterations:</p>

<p class=MsoNormal>- Tile 0: tileA[0][0-3]  tileB[0-3][0]</p>

<p class=MsoNormal>- Tile 1: tileA[0][0-3]  tileB[0-3][0]</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Assume:</p>

<p class=MsoNormal>A row 0: [1,2,3,4,5,6,7,8]</p>

<p class=MsoNormal>B col 0: [1,1,1,1,1,1,1,1]</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Show temp after each tile.</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- Initial: temp = 0</p>

<p class=MsoNormal>- Tile 0 (m=0): temp += 11 + 21 + 31 + 41 = **10**</p>

<p class=MsoNormal>- Tile 1 (m=1): temp += 51 + 61 + 71 + 81 = 10 + 26 = **36**</p>

<p class=MsoNormal>- Final: c[0][0] = **36**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 4**: Shared Memory Bank Conflicts</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>TILE_SIZE=32, assuming 32 memory banks:</p>

<p class=MsoNormal>a) When threads access tileA[threadIdx.y][threadIdx.x], is
there a bank conflict?</p>

<p class=MsoNormal>b) When accessing tileB[k][threadIdx.x] in the
multiplication loop?</p>

<p class=MsoNormal>c) Suggest a solution for part b if conflicts exist.</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) **No conflict** - each thread accesses different column,
mapping to different banks</p>

<p class=MsoNormal>- b) All threads in a warp access tileB[k][0], tileB[k][1], ...
</p>

<p class=MsoNormal> - If k is same for all, different columns &#8594; **No
conflict**</p>

<p class=MsoNormal>- c) Already optimized; conflicts are avoided by accessing
different columns</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 5**: Performance Analysis</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Specs:</p>

<p class=MsoNormal>- n=2048, TILE_SIZE=32</p>

<p class=MsoNormal>- Global memory bandwidth: 900 GB/s</p>

<p class=MsoNormal>- Each element: 4 bytes</p>

<p class=MsoNormal>- Compute throughput: 20 TFLOPS</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate:</p>

<p class=MsoNormal>a) Time for memory transfers (tiled version)</p>

<p class=MsoNormal>b) Time for computation</p>

<p class=MsoNormal>c) Is it memory-bound or compute-bound?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Data loaded = 2n elements (A and B) + n writes (C) =
320484 bytes = 50.3 MB</p>

<p class=MsoNormal> - Time = 50.3 MB / (900 GB/s) = **0.056 ms**</p>

<p class=MsoNormal>- b) FLOPs = 2n = 22048 = 17.2 GFLOPS</p>

<p class=MsoNormal> - Time = 17.2 / 20,000 = **0.86 ms**</p>

<p class=MsoNormal>- c) **Compute-bound** (0.86 ms &gt;&gt; 0.056 ms) -
computation takes much longer</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>---</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal># SLIDE 6-7: Usage of Tiling (Diagrams)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Easy Explanation</p>

<p class=MsoNormal>These diagrams show the **visual concept** of how tiling
works:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Without Tiling**:</p>

<p class=MsoNormal>- Imagine each worker (thread) needs ingredients from a
warehouse</p>

<p class=MsoNormal>- Every time they need something, they walk to the warehouse
(slow!)</p>

<p class=MsoNormal>- Lots of repeated trips for the same items</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**With Tiling**:</p>

<p class=MsoNormal>- Workers are organized into teams (blocks)</p>

<p class=MsoNormal>- The team brings a cart of supplies (tile) to their workstation
(shared memory)</p>

<p class=MsoNormal>- Everyone on the team can quickly grab what they need from
the cart</p>

<p class=MsoNormal>- Much fewer trips to the warehouse!</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Key Insight**: If 16 workers need the same ingredient,
instead of 16 warehouse trips, the team makes 1 trip and shares.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### MCQs</p>

<p class=MsoNormal>1. **In the tiling visualization, what does each &quot;tile&quot;
represent?**</p>

<p class=MsoNormal> - A) One thread's data</p>

<p class=MsoNormal> - B) A small block of matrix elements loaded into shared
memory &#10003;</p>

<p class=MsoNormal> - C) A complete matrix</p>

<p class=MsoNormal> - D) Global memory</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **The main visual difference between &quot;without
tiling&quot; and &quot;with tiling&quot; is:**</p>

<p class=MsoNormal> - A) Number of threads</p>

<p class=MsoNormal> - B) Pattern of memory access and reuse &#10003;</p>

<p class=MsoNormal> - C) Matrix size</p>

<p class=MsoNormal> - D) Number of operations</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **In the diagram showing C matrix divided into blocks,
each block represents:**</p>

<p class=MsoNormal> - A) One thread</p>

<p class=MsoNormal> - B) Work done by one thread block &#10003;</p>

<p class=MsoNormal> - C) One row of C</p>

<p class=MsoNormal> - D) One tile of A</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>4. **The overlapping data access pattern visible in tiling
diagrams illustrates:**</p>

<p class=MsoNormal> - A) Memory conflicts</p>

<p class=MsoNormal> - B) Data reuse opportunities &#10003;</p>

<p class=MsoNormal> - C) Errors in computation</p>

<p class=MsoNormal> - D) Random access</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Use Cases</p>

<p class=MsoNormal>- **Data Analytics**: Large-scale matrix operations in Spark,
Hadoop</p>

<p class=MsoNormal>- **Image Processing Pipelines**: Multi-stage filters in
Instagram, Photoshop</p>

<p class=MsoNormal>- **Medical Imaging**: Real-time MRI/CT scan reconstruction</p>

<p class=MsoNormal>- **Weather Forecasting**: Numerical weather prediction
models</p>

<p class=MsoNormal>- **Autonomous Vehicles**: Sensor fusion and SLAM (Simultaneous
Localization and Mapping)</p>

<p class=MsoNormal>- **Drug Discovery**: Molecular docking simulations</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numerical Problems</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1**: Visual Data Flow</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For n=64, TILE_SIZE=16:</p>

<p class=MsoNormal>a) How many tiles cover matrix A?</p>

<p class=MsoNormal>b) How many tiles cover matrix B?</p>

<p class=MsoNormal>c) For computing one tile of C, how many tiles of A and B
are needed?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Tiles in A = (64/16)  (64/16) = **16 tiles**</p>

<p class=MsoNormal>- b) Tiles in B = (64/16)  (64/16) = **16 tiles**</p>

<p class=MsoNormal>- c) For one tile of C: need **4 tiles from A (one row of
tiles)** and **4 tiles from B (one column of tiles)**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2**: Data Reuse Visualization</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For a 44 tile being computed:</p>

<p class=MsoNormal>a) How many elements from A are loaded into shared memory?</p>

<p class=MsoNormal>b) How many times is each element of A reused?</p>

<p class=MsoNormal>c) Total reuses across the tile?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) **16 elements** of A (one 44 tile)</p>

<p class=MsoNormal>- b) Each element used **4 times** (once for each column of
output)</p>

<p class=MsoNormal>- c) Total reuses = 16  4 = **64 accesses to shared memory**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 3**: Block Work Distribution</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For n=128, TILE_SIZE=32, visualize:</p>

<p class=MsoNormal>a) How many blocks in grid?</p>

<p class=MsoNormal>b) How many output elements per block?</p>

<p class=MsoNormal>c) What fraction of work does each block do?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Blocks = (128/32)  (128/32) = **16 blocks (44 grid)**</p>

<p class=MsoNormal>- b) Each block computes 3232 = **1024 elements**</p>

<p class=MsoNormal>- c) Fraction = 1024 / (128128) = 1024/16384 = **1/16 = 6.25%**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 4**: Memory Traffic Visualization</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Without tiling (n=256):</p>

<p class=MsoNormal>- Each thread reads 2n = 512 elements</p>

<p class=MsoNormal>- Total threads = 256 = 65,536</p>

<p class=MsoNormal>- Total reads = ?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>With tiling (TILE_SIZE=32):</p>

<p class=MsoNormal>- Tiles per dimension = 256/32 = 8</p>

<p class=MsoNormal>- Each block loads 232 per tile  8 tiles</p>

<p class=MsoNormal>- Total blocks = 64</p>

<p class=MsoNormal>- Total reads = ?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate and compare:</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- Without tiling: 65,536  512 = **33,554,432 reads**</p>

<p class=MsoNormal>- With tiling: 64 blocks  8 tiles  2  1024 elements = **1,048,576
reads**</p>

<p class=MsoNormal>- Reduction = 33,554,432 / 1,048,576 = **32 fewer reads**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 5**: Tile Overlap Analysis</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For computing C[0:32][0:32] and C[0:32][32:64]:</p>

<p class=MsoNormal>a) Which tiles of A are shared?</p>

<p class=MsoNormal>b) Which tiles of B are shared?</p>

<p class=MsoNormal>c) What's the data reuse factor?</p>

<p class=MsoNormal><b>Solution</b>:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>a) <b>Same row of A tiles</b> is shared between both C
     tiles </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A[0:32][0:32], A[0:32][32:64], etc.</li>
 </ul>
 <li class=MsoNormal>b) <b>Different column tiles of B</b> (no sharing between
     these two C tiles)</li>
 <li class=MsoNormal>c) If computing 4 adjacent C tiles in same row: </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A tiles reused 4 times</li>
  <li class=MsoNormal>Reuse factor = <b>4</b></li>
 </ul>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>SLIDE 8: C Matrix Division with Boundary Handling</b></p>

<p class=MsoNormal><b>Easy Explanation</b></p>

<p class=MsoNormal>This slide shows a practical example:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>C matrix is 55</b> (small for illustration)</li>
 <li class=MsoNormal><b>TILE_SIZE is 44</b></li>
 <li class=MsoNormal>We need <b>4 blocks</b> arranged in a 22 grid: </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Block(0,0): handles C[</li>
 </ul>
</ul>

<p class=MsoNormal>Retry</p>

<p class=MsoNormal>P</p>

<p class=MsoNormal>Continue</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>SLIDE 8: C Matrix Division with Boundary Handling
(Continued)</b></p>

<p class=MsoNormal><b>Easy Explanation (Continued)</b></p>

<p class=MsoNormal>This slide shows a practical example:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>C matrix is 55</b> (small for illustration)</li>
 <li class=MsoNormal><b>TILE_SIZE is 44</b></li>
 <li class=MsoNormal>We need <b>4 blocks</b> arranged in a 22 grid: </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>Block(0,0): handles C[0-3][0-3]</li>
  <li class=MsoNormal>Block(1,0): handles C[0-3][4] (partially filled!)</li>
  <li class=MsoNormal>Block(0,1): handles C[4][0-3] (partially filled!)</li>
  <li class=MsoNormal>Block(1,1): handles C[4][4] (corner - mostly empty!)</li>
 </ul>
</ul>

<p class=MsoNormal><b>The Boundary Problem</b>: Since 5 doesn't divide evenly
by 4, the last row and column of tiles are only partially filled. CUDA handles
this with the boundary check if(row &lt; n &amp;&amp; col &lt; n).</p>

<p class=MsoNormal><b>Key Point</b>: It's okay to launch more threads than
needed - inactive threads simply don't write results.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>For n=5, TILE_SIZE=4, how many blocks are launched?</b>
     </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A) 1</li>
  <li class=MsoNormal>B) 2</li>
  <li class=MsoNormal>C) 4 &#10003;</li>
  <li class=MsoNormal>D) 25</li>
 </ul>
 <li class=MsoNormal><b>In Block(1,1) for this example, how many threads
     actually compute valid results?</b> </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A) 16</li>
  <li class=MsoNormal>B) 4</li>
  <li class=MsoNormal>C) 1 &#10003;</li>
  <li class=MsoNormal>D) 0</li>
 </ul>
 <li class=MsoNormal><b>What prevents out-of-bounds writes in boundary blocks?</b>
     </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A) Hardware protection</li>
  <li class=MsoNormal>B) The condition if(row &lt; n &amp;&amp; col &lt; n)
      &#10003;</li>
  <li class=MsoNormal>C) Automatic zero padding</li>
  <li class=MsoNormal>D) CUDA runtime</li>
 </ul>
 <li class=MsoNormal><b>For n=100, TILE_SIZE=32, which blocks are fully filled?</b>
     </li>
 <ul style='margin-top:0in' type=circle>
  <li class=MsoNormal>A) All blocks</li>
  <li class=MsoNormal>B) Only Block(0,0)</li>
  <li class=MsoNormal>C) All except last row and column of blocks &#10003;</li>
  <li class=MsoNormal>D) None</li>
 </ul>
</ol>

<p class=MsoNormal><b>Use Cases</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal><b>Variable-sized Image Processing</b>: Photos of
     different resolutions</li>
 <li class=MsoNormal><b>Dynamic Batch Processing</b>: Neural network batches
     with varying sizes</li>
 <li class=MsoNormal><b>Text Processing</b>: Documents with different lengths</li>
 <li class=MsoNormal><b>Adaptive Mesh Refinement</b>: Computational fluid
     dynamics with irregular grids</li>
 <li class=MsoNormal><b>Video Streaming</b>: Frames with different dimensions</li>
 <li class=MsoNormal><b>Database Operations</b>: Tables with non-uniform
     dimensions</li>
</ul>

<p class=MsoNormal><b>Numerical Problems</b></p>

<p class=MsoNormal><b>Problem 1</b>: Efficiency Calculation</p>

<p class=MsoNormal>For n=5, TILE_SIZE=4:</p>

<p class=MsoNormal>a) Total threads launched</p>

<p class=MsoNormal>b) Threads doing useful work</p>

<p class=MsoNormal>c) Thread efficiency</p>

<p class=MsoNormal>d) Wasted computational resources</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Blocks = 22 = 4, threads per block = 44 = 16</p>

<p class=MsoNormal> - Total = 416 = **64 threads**</p>

<p class=MsoNormal>- b) Only 55 = **25 threads** compute valid elements</p>

<p class=MsoNormal>- c) Efficiency = 25/64 = **39.1%**</p>

<p class=MsoNormal>- d) Wasted = 64-25 = **39 threads (60.9% waste)**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2**: Optimal Tile Size</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For n=1000, test TILE_SIZE values: 16, 20, 25, 32</p>

<p class=MsoNormal>Calculate efficiency for each and determine the best choice.</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- TILE_SIZE=16: blocks=6363=3969,
threads=3969256=1,015,824, useful=1M &#8594; **98.4% &#10003; BEST**</p>

<p class=MsoNormal>- TILE_SIZE=20: blocks=5050=2500,
threads=2500400=1,000,000 &#8594; **100%** (perfect but 20 not power of 2)</p>

<p class=MsoNormal>- TILE_SIZE=25: blocks=4040=1600,
threads=1600625=1,000,000 &#8594; **100%** (perfect but 25 not common)</p>

<p class=MsoNormal>- TILE_SIZE=32: blocks=3232=1024,
threads=10241024=1,048,576, useful=1M &#8594; **95.4%**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Note**: TILE_SIZE=16 is often preferred as it's a power of
2 (hardware-friendly) with good efficiency.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 3**: Boundary Block Analysis</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>n=70, TILE_SIZE=16:</p>

<p class=MsoNormal>a) How many blocks total?</p>

<p class=MsoNormal>b) How many blocks are fully utilized?</p>

<p class=MsoNormal>c) How many boundary blocks?</p>

<p class=MsoNormal>d) Average efficiency across boundary blocks?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Blocks = ceil(70/16)  ceil(70/16) = 55 = **25
blocks**</p>

<p class=MsoNormal>- b) Inner blocks = 44 = **16 blocks** fully utilized</p>

<p class=MsoNormal>- c) Boundary blocks = 25-16 = **9 blocks**</p>

<p class=MsoNormal>- d) Last row/col covers 70%16 = 6 elements</p>

<p class=MsoNormal> - Edge blocks: 166 = 96 active / 256 total = 37.5%</p>

<p class=MsoNormal> - Corner block: 66 = 36 active / 256 total = 14.1%</p>

<p class=MsoNormal> - Average for 8 edge + 1 corner = (896 + 136)/(9256) =
**35.2%**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 4**: Padding vs No-Padding Trade-off</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Compare two strategies for n=100, TILE_SIZE=32:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Strategy A: No padding, boundary checks</p>

<p class=MsoNormal>- Threads launched: ?</p>

<p class=MsoNormal>- Useful threads: ?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Strategy B: Pad matrix to 128128 with zeros</p>

<p class=MsoNormal>- Threads launched: ?</p>

<p class=MsoNormal>- Useful threads: ?</p>

<p class=MsoNormal>- Extra computation cost: ?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>**Strategy A**:</p>

<p class=MsoNormal>- Blocks = 44 = 16, Threads = 161024 = **16,384 launched**</p>

<p class=MsoNormal>- Useful = **10,000 threads**</p>

<p class=MsoNormal>- Efficiency = 61%</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Strategy B**:</p>

<p class=MsoNormal>- Blocks = 44 = 16, Threads = **16,384 launched**</p>

<p class=MsoNormal>- All compute (including padded zeros), but results are
wasted</p>

<p class=MsoNormal>- Extra computation = (128-100)/100 = 63.8% more work</p>

<p class=MsoNormal>- **Strategy A is better** (no wasted computation, just idle
threads)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 5**: Multiple Boundary Scenarios</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Calculate thread efficiency for:</p>

<p class=MsoNormal>a) n=1024, TILE_SIZE=32 (perfect fit)</p>

<p class=MsoNormal>b) n=1025, TILE_SIZE=32 (one element over)</p>

<p class=MsoNormal>c) n=1023, TILE_SIZE=32 (one element under)</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Blocks = 3232 = 1024, efficiency = **100%**</p>

<p class=MsoNormal>- b) Blocks = 3333 = 1089, threads = 1,0891024 = 1,115,136</p>

<p class=MsoNormal> - Useful = 1025 = 1,050,625</p>

<p class=MsoNormal> - Efficiency = 1,050,625/1,115,136 = **94.2%**</p>

<p class=MsoNormal>- c) Blocks = 3232 = 1024, threads = 1,048,576</p>

<p class=MsoNormal> - Useful = 1023 = 1,046,529</p>

<p class=MsoNormal> - Efficiency = 1,046,529/1,048,576 = **99.8%**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>---</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal># SLIDE 9: Visualization with Block Coverage</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Easy Explanation</p>

<p class=MsoNormal>This slide shows **exactly which elements** each block
computes in our 55 example:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Block(0,0)** computes:</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>C[0,0] C[0,1] C[0,2] C[0,3]</p>

<p class=MsoNormal>C[1,0] C[1,1] C[1,2] C[1,3]</p>

<p class=MsoNormal>C[2,0] C[2,1] C[2,2] C[2,3]</p>

<p class=MsoNormal>C[3,0] C[3,1] C[3,2] C[3,3]</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Block(1,0)** computes:</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>C[0,4]</p>

<p class=MsoNormal>C[1,4]</p>

<p class=MsoNormal>C[2,4]</p>

<p class=MsoNormal>C[3,4]</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Block(0,1)** computes:</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>C[4,0] C[4,1] C[4,2] C[4,3]</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Block(1,1)** computes:</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>C[4,4]</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>The slide then shows the **tile iteration process**: to
compute Block(0,0), we need TWO tile iterations (m=0 and m=1) because n=5
requires ceiling(5/4)=2 tiles.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### MCQs</p>

<p class=MsoNormal>1. **For Block(0,0) with TILE_SIZE=4, the thread at
threadIdx=(2,3) computes:**</p>

<p class=MsoNormal> - A) C[2,3] &#10003;</p>

<p class=MsoNormal> - B) C[3,2]</p>

<p class=MsoNormal> - C) C[6,7]</p>

<p class=MsoNormal> - D) Invalid</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **In the example, why does m loop from 0 to 1 (2
iterations)?**</p>

<p class=MsoNormal> - A) Two matrices to multiply</p>

<p class=MsoNormal> - B) Need ceil(5/4)=2 tile passes to cover dimension n=5
&#10003;</p>

<p class=MsoNormal> - C) Two blocks</p>

<p class=MsoNormal> - D) Error in code</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **During m=1 (second tile iteration) for Block(0,0), what
gets loaded?**</p>

<p class=MsoNormal> - A) Same tiles as m=0</p>

<p class=MsoNormal> - B) Column 4 of A, Row 4 of B (the 5th column/row,
zero-padded) &#10003;</p>

<p class=MsoNormal> - C) Nothing</p>

<p class=MsoNormal> - D) Entire matrices</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>4. **Which block has the most &quot;wasted&quot; threads in
this example?**</p>

<p class=MsoNormal> - A) Block(0,0)</p>

<p class=MsoNormal> - B) Block(1,0)</p>

<p class=MsoNormal> - C) Block(0,1)</p>

<p class=MsoNormal> - D) Block(1,1) &#10003; (15 out of 16 threads idle)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Use Cases</p>

<p class=MsoNormal>- **Mini-batch Processing**: Small batches in neural
networks</p>

<p class=MsoNormal>- **Embedded Systems**: Limited memory GPUs processing small
matrices</p>

<p class=MsoNormal>- **Real-time Applications**: Low-latency requirements with
smaller data</p>

<p class=MsoNormal>- **Mobile GPU Computing**: Smartphone image processing</p>

<p class=MsoNormal>- **Edge AI**: Inference on edge devices</p>

<p class=MsoNormal>- **Prototyping**: Testing algorithms on small data before
scaling</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numerical Problems</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1**: Tile Iteration Trace</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For n=5, TILE_SIZE=4, Block(0,0):</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>m=0: Which elements of A and B are loaded?</p>

<p class=MsoNormal>m=1: Which elements of A and B are loaded?</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Show the exact indices.</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>**m=0** (first tile):</p>

<p class=MsoNormal>- tileA loads: A[0:3][0:3] (rows 0-3, cols 0-3)</p>

<p class=MsoNormal>- tileB loads: B[0:3][0:3] (rows 0-3, cols 0-3)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**m=1** (second tile):</p>

<p class=MsoNormal>- tileA loads: A[0:3][4] (rows 0-3, col 4) + padding</p>

<p class=MsoNormal>- tileB loads: B[4][0:3] (row 4, cols 0-3) + padding</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2**: Partial Result Accumulation</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For C[0][0] with n=5, TILE_SIZE=4:</p>

<p class=MsoNormal>A row 0 = [1, 2, 3, 4, 5]</p>

<p class=MsoNormal>B col 0 = [1, 1, 1, 1, 1]</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Show temp after each tile iteration:</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- Initial: temp = 0</p>

<p class=MsoNormal>- **m=0**: temp += 11 + 21 + 31 + 41 = 0 + 10 = **10**</p>

<p class=MsoNormal>- **m=1**: temp += 51 = 10 + 5 = **15**</p>

<p class=MsoNormal>- Final: C[0][0] = **15**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 3**: Thread Mapping Detail</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For Block(1,0) (covers C[0:3][4]):</p>

<p class=MsoNormal>a) What is blockIdx for this block?</p>

<p class=MsoNormal>b) Thread at threadIdx=(2,0) computes which element?</p>

<p class=MsoNormal>c) Is this thread active (within n=5)?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) blockIdx = **(1, 0)** (x=1, y=0)</p>

<p class=MsoNormal>- b) row = 04 + 2 = 2, col = 14 + 0 = 4</p>

<p class=MsoNormal> - Computes **C[2][4]**</p>

<p class=MsoNormal>- c) **Yes, active** (2 &lt; 5 and 4 &lt; 5)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 4**: Memory Access Pattern</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For computing Block(0,0), list all unique elements accessed
from:</p>

<p class=MsoNormal>a) Matrix A</p>

<p class=MsoNormal>b) Matrix B</p>

<p class=MsoNormal>c) Total unique accesses vs total accesses made</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) A: rows 0-3, all columns &#8594; **20 unique elements**
(4 rows  5 cols)</p>

<p class=MsoNormal>- b) B: all rows, cols 0-3 &#8594; **20 unique elements** (5
rows  4 cols)</p>

<p class=MsoNormal>- c) Total unique = 40</p>

<p class=MsoNormal> - Without tiling: 16 threads  5 accesses = 80 accesses to
A, 80 to B = **160 total**</p>

<p class=MsoNormal> - With tiling: Load 40 unique elements once</p>

<p class=MsoNormal> - **Reduction = 160/40 = 4**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 5**: Block Work Imbalance</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For n=5, TILE_SIZE=4, calculate:</p>

<p class=MsoNormal>a) Work done by Block(0,0) (number of multiply-adds)</p>

<p class=MsoNormal>b) Work done by Block(1,1)</p>

<p class=MsoNormal>c) Load imbalance ratio</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Block(0,0): 16 threads  5 multiply-adds = **80
operations**</p>

<p class=MsoNormal>- b) Block(1,1): 1 thread  5 multiply-adds = **5
operations**</p>

<p class=MsoNormal>- c) Imbalance = 80/5 = **16 imbalance**</p>

<p class=MsoNormal> - This is why padding to power-of-2 dimensions is
sometimes used despite extra work</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>---</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal># SLIDE 10: Convolution Kernel</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Easy Explanation</p>

<p class=MsoNormal>**Convolution** is like using a stamp on paper:</p>

<p class=MsoNormal>- You have an **input image** (55 grid of numbers)</p>

<p class=MsoNormal>- You have a **filter/kernel** (22 stamp)</p>

<p class=MsoNormal>- You slide the stamp across the image, multiplying
overlapping numbers and summing them</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Output Size Formula**: (input_size - kernel_size + 1) = (5
- 2 + 1) = 44</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>In the example shown:</p>

<p class=MsoNormal>- Input: 55 matrix starting with [1,2,3,4,5] in first row</p>

<p class=MsoNormal>- Kernel: 22 (not shown in detail, but assume simple
subtraction operation)</p>

<p class=MsoNormal>- Output: 44 matrix with results like -6, -6, -6...</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**GPU Implementation**: Each thread computes ONE output
pixel by applying the filter.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### MCQs</p>

<p class=MsoNormal>1. **For a 1010 input and 33 kernel, what's the output
size?**</p>

<p class=MsoNormal> - A) 1010</p>

<p class=MsoNormal> - B) 88 &#10003;</p>

<p class=MsoNormal> - C) 77</p>

<p class=MsoNormal> - D) 1212</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **What does &quot;each CUDA thread computes one output
pixel&quot; mean?**</p>

<p class=MsoNormal> - A) One thread does all pixels</p>

<p class=MsoNormal> - B) One thread calculates one element of the output
&#10003;</p>

<p class=MsoNormal> - C) Multiple threads per pixel</p>

<p class=MsoNormal> - D) Threads share pixel computation</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **Why use shared memory for convolution (stencil
approach)?**</p>

<p class=MsoNormal> - A) To save global memory</p>

<p class=MsoNormal> - B) Neighboring pixels overlap - shared memory allows
reuse &#10003;</p>

<p class=MsoNormal> - C) Required by CUDA</p>

<p class=MsoNormal> - D) To increase precision</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>4. **In the example, output is 44 because:**</p>

<p class=MsoNormal> - A) We use 44 blocks</p>

<p class=MsoNormal> - B) Formula: (5-2+1)(5-2+1) = 44 &#10003;</p>

<p class=MsoNormal> - C) Input is divided by 4</p>

<p class=MsoNormal> - D) Random choice</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Use Cases</p>

<p class=MsoNormal>- **Photo Filters**: Instagram, Snapchat filters (blur,
sharpen, emboss)</p>

<p class=MsoNormal>- **Edge Detection**: Self-driving cars detecting lane
lines, road signs</p>

<p class=MsoNormal>- **Medical Imaging**: Tumor detection, X-ray enhancement</p>

<p class=MsoNormal>- **Security Cameras**: Motion detection, face recognition</p>

<p class=MsoNormal>- **Satellite Imagery**: Detecting changes, identifying
features</p>

<p class=MsoNormal>- **Quality Control**: Manufacturing defect detection</p>

<p class=MsoNormal>- **Document Processing**: OCR (Optical Character
Recognition)</p>

<p class=MsoNormal>- **Video Games**: Post-processing effects (glow, blur)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numerical Problems</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1**: Output Size Calculation</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Calculate output dimensions for:</p>

<p class=MsoNormal>a) Input: 224224, Kernel: 33</p>

<p class=MsoNormal>b) Input: 512512, Kernel: 55</p>

<p class=MsoNormal>c) Input: 19201080, Kernel: 77</p>

<p class=MsoNormal>d) Input: 2828, Kernel: 55</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) (224-3+1)  (224-3+1) = **222222**</p>

<p class=MsoNormal>- b) (512-5+1)  (512-5+1) = **508508**</p>

<p class=MsoNormal>- c) (1920-7+1)  (1080-7+1) = **19141074**</p>

<p class=MsoNormal>- d) (28-5+1)  (28-5+1) = **2424**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2**: Basic Convolution Computation</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Input (33): Kernel (22):</p>

<p class=MsoNormal>[1 2 3] [1 0]</p>

<p class=MsoNormal>[4 5 6] [0 -1]</p>

<p class=MsoNormal>[7 8 9]</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate all 4 output values: out[0][0], out[0][1],
out[1][0], out[1][1]</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- out[0][0] = 11 + 20 + 40 + 5(-1) = 1 - 5 = **-4**</p>

<p class=MsoNormal>- out[0][1] = 21 + 30 + 50 + 6(-1) = 2 - 6 = **-4**</p>

<p class=MsoNormal>- out[1][0] = 41 + 50 + 70 + 8(-1) = 4 - 8 = **-4**</p>

<p class=MsoNormal>- out[1][1] = 51 + 60 + 80 + 9(-1) = 5 - 9 = **-4**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 3**: Thread Allocation</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For 10241024 input, 33 kernel:</p>

<p class=MsoNormal>a) Output dimensions</p>

<p class=MsoNormal>b) How many threads needed (one per output pixel)?</p>

<p class=MsoNormal>c) If using 1616 thread blocks, how many blocks?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Output = (1024-3+1)  (1024-3+1) = **10221022**</p>

<p class=MsoNormal>- b) Threads needed = 1022 = **1,044,484 threads**</p>

<p class=MsoNormal>- c) Blocks = ceil(1022/16)  ceil(1022/16) = 6464 =
**4,096 blocks**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 4**: Convolution Types</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Calculate output for a 55 input with 33 kernel for:</p>

<p class=MsoNormal>a) Valid convolution (no padding)</p>

<p class=MsoNormal>b) Same convolution (output same size as input - requires
padding)</p>

<p class=MsoNormal>c) Full convolution (maximum overlap)</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Valid: (5-3+1)  (5-3+1) = **33**</p>

<p class=MsoNormal>- b) Same: Requires padding of floor(3/2)=1 on each side
&#8594; input becomes 77</p>

<p class=MsoNormal> - Output = (7-3+1)  (7-3+1) = **55** (same as original)</p>

<p class=MsoNormal>- c) Full: (5+3-1)  (5+3-1) = **77** (includes all partial
overlaps)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 5**: Memory Access Analysis</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For 512512 input, 55 kernel, without shared memory:</p>

<p class=MsoNormal>a) How many global memory reads per thread?</p>

<p class=MsoNormal>b) Total reads for all threads?</p>

<p class=MsoNormal>c) If elements overlap 50%, what's the actual unique reads?</p>

<p class=MsoNormal>d) Potential speedup with shared memory?</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) Each thread reads **25 elements** (55 kernel)</p>

<p class=MsoNormal>- b) Output = 508508 = 258,064 threads</p>

<p class=MsoNormal> - Total reads = 258,064  25 = **6,451,600 reads**</p>

<p class=MsoNormal>- c) Unique elements in input = 512 = 262,144</p>

<p class=MsoNormal> - Actual unique = **262,144 elements**</p>

<p class=MsoNormal>- d) Speedup potential = 6,451,600 / 262,144 = **24.6
reduction possible**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>---</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal># SLIDE 11: Convolution with RGB Input - Stencil Computation</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Easy Explanation</p>

<p class=MsoNormal>Now we're working with **color images** (RGB - Red, Green,
Blue channels):</p>

<p class=MsoNormal>- Input: 55 image with 3 channels (R, G, B)</p>

<p class=MsoNormal>- Each channel is a separate 55 matrix</p>

<p class=MsoNormal>- **Same kernel applied to each channel independently**</p>

<p class=MsoNormal>- Output: Three separate 55 matrices (one for each channel)</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**The Stencil Formula**: `out(i,j) = 5center - top - bottom
- left - right`</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>This is a **sharpening filter** (also called Laplacian):</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Kernel: [0 -1 0]</p>

<p class=MsoNormal> [-1 5 -1]</p>

<p class=MsoNormal> [0 -1 0]</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Zero Padding**: Pixels outside the image boundary are
treated as 0.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### MCQs</p>

<p class=MsoNormal>1. **For RGB convolution, how many separate convolutions are
performed?**</p>

<p class=MsoNormal> - A) 1</p>

<p class=MsoNormal> - B) 2</p>

<p class=MsoNormal> - C) 3 (one per channel) &#10003;</p>

<p class=MsoNormal> - D) 6</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **What does &quot;zero padding&quot; mean in this
context?**</p>

<p class=MsoNormal> - A) Setting output to zero</p>

<p class=MsoNormal> - B) Treating pixels outside the image boundary as 0
&#10003;</p>

<p class=MsoNormal> - C) Adding zeros to the kernel</p>

<p class=MsoNormal> - D) Removing zero values</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **The formula `5center - top - bottom - left - right`
implements:**</p>

<p class=MsoNormal> - A) Blur filter</p>

<p class=MsoNormal> - B) Edge detection</p>

<p class=MsoNormal> - C) Sharpening filter &#10003;</p>

<p class=MsoNormal> - D) Color inversion</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>4. **For a pixel at position (0,0), which neighbors are
zero-padded?**</p>

<p class=MsoNormal> - A) All neighbors</p>

<p class=MsoNormal> - B) Top and left &#10003;</p>

<p class=MsoNormal> - C) Bottom and right</p>

<p class=MsoNormal> - D) None</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Use Cases</p>

<p class=MsoNormal>- **Photo Editing**: Photoshop, GIMP - sharpen, blur, edge
enhance</p>

<p class=MsoNormal>- **Medical Imaging**: MRI/CT enhancement for better
diagnosis</p>

<p class=MsoNormal>- **Satellite Imagery**: Enhancing terrain features, cloud
detection</p>

<p class=MsoNormal>- **Security Systems**: License plate enhancement</p>

<p class=MsoNormal>- **Astronomy**: Star field enhancement</p>

<p class=MsoNormal>- **Microscopy**: Cellular structure enhancement</p>

<p class=MsoNormal>- **Video Processing**: Real-time video filters on YouTube,
TikTok</p>

<p class=MsoNormal>- **Augmented Reality**: Real-time image processing for AR
filters</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numerical Problems</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1**: Basic Stencil Calculation</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>R channel (33):</p>

<p class=MsoNormal>[10 20 30]</p>

<p class=MsoNormal>[15 25 35]</p>

<p class=MsoNormal>[20 30 40]</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate: out(1,1) using formula: 5center - top - bottom -
left - right</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- center = 25</p>

<p class=MsoNormal>- top = 20, bottom = 30, left = 15, right = 35</p>

<p class=MsoNormal>- out(1,1) = 525 - 20 - 30 - 15 - 35</p>

<p class=MsoNormal>- out(1,1) = 125 - 100 = **25**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2**: Corner Pixel with Zero Padding</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>R channel (33):</p>

<p class=MsoNormal>[10 20 30]</p>

<p class=MsoNormal>[15 25 35]</p>

<p class=MsoNormal>[20 30 40]</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate: out(0,0) (top-left corner)</p>

<p class=MsoNormal>Remember: pixels outside boundary = 0</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- center = 10</p>

<p class=MsoNormal>- top = 0 (outside), left = 0 (outside), bottom = 15, right
= 20</p>

<p class=MsoNormal>- out(0,0) = 510 - 0 - 15 - 0 - 20</p>

<p class=MsoNormal>- out(0,0) = 50 - 35 = **15**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 3**: Edge Pixel</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Same matrix as Problem 2, calculate: out(0,1) (top edge,
middle)</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- center = 20</p>

<p class=MsoNormal>- top = 0 (outside), left = 10, right = 30, bottom = 25</p>

<p class=MsoNormal>- out(0,1) = 520 - 0 - 25 - 10 - 30</p>

<p class=MsoNormal>- out(0,1) = 100 - 65 = **35**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 4**: Complete Row Calculation</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>R channel (23):</p>

<p class=MsoNormal>[10 20 30]</p>

<p class=MsoNormal>[15 25 35]</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate entire first row output: [out(0,0), out(0,1),
out(0,2)]</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- **out(0,0)**: center=10, top=0, left=0, right=20,
bottom=15</p>

<p class=MsoNormal> - = 50 - 35 = **15**</p>

<p class=MsoNormal>- **out(0,1)**: center=20, top=0, left=10, right=30,
bottom=25</p>

<p class=MsoNormal> - = 100 - 65 = **35**</p>

<p class=MsoNormal>- **out(0,2)**: center=30, top=0, left=20, right=0,
bottom=35</p>

<p class=MsoNormal> - = 150 - 55 = **95**</p>

<p class=MsoNormal>- **Answer: [15, 35, 95]**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 5**: RGB Processing</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Given RGB values at position (1,1):</p>

<p class=MsoNormal>R=50, G=100, B=150</p>

<p class=MsoNormal>Neighbors (same for all channels):</p>

<p class=MsoNormal>top=40, bottom=60, left=45, right=55</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate output for all three channels:</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- **R channel**: out = 550 - 40 - 60 - 45 - 55 = 250 - 200
= **50**</p>

<p class=MsoNormal>- **G channel**: out = 5100 - 40 - 60 - 45 - 55 = 500 - 200
= **300**</p>

<p class=MsoNormal>- **B channel**: out = 5150 - 40 - 60 - 45 - 55 = 750 - 200
= **550**</p>

<p class=MsoNormal>- **Output RGB: (50, 300, 550)**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>---</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal># SLIDE 12: Stencil-based Computation Details</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Easy Explanation</p>

<p class=MsoNormal>This slide walks through the **step-by-step calculation**
for specific pixels:</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Example 1: Pixel at (0,0) with value 10**</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal> 0 &#8592; top (outside, = 0)</p>

<p class=MsoNormal>0 10 20 &#8592; left=0, center=10, right=20</p>

<p class=MsoNormal> 15 &#8592; bottom</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>- Formula: 510 - 0 - 15 - 0 - 20 = 50 - 35 = **15**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Example 2: Pixel at (0,1) with value 20**</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal> 0 &#8592; top (outside, = 0)</p>

<p class=MsoNormal>10 20 30 &#8592; left=10, center=20, right=30</p>

<p class=MsoNormal> 25 &#8592; bottom</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>- Formula: 520 - 0 - 25 - 10 - 30 = 100 - 65 = **35**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Key Insight**: The stencil pattern is consistent - we
always look at the center pixel and its 4 neighbors (up, down, left, right).</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### MCQs</p>

<p class=MsoNormal>1. **In stencil computation, the &quot;center&quot; refers
to:**</p>

<p class=MsoNormal> - A) Middle of the entire image</p>

<p class=MsoNormal> - B) The pixel whose output we're computing &#10003;</p>

<p class=MsoNormal> - C) Center of the kernel</p>

<p class=MsoNormal> - D) Average of neighbors</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>2. **For a pixel at position (0,1), which direction has a
valid neighbor?**</p>

<p class=MsoNormal> - A) Top</p>

<p class=MsoNormal> - B) Left &#10003;</p>

<p class=MsoNormal> - C) Both A and B</p>

<p class=MsoNormal> - D) Neither</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>3. **The zero-padding assumption means:**</p>

<p class=MsoNormal> - A) We add zeros to the image physically</p>

<p class=MsoNormal> - B) We treat non-existent neighbors as 0 in calculations
&#10003;</p>

<p class=MsoNormal> - C) We skip boundary pixels</p>

<p class=MsoNormal> - D) We wrap around to the other side</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>4. **In the example, why is out(0,0) = 15 instead of 50?**</p>

<p class=MsoNormal> - A) Calculation error</p>

<p class=MsoNormal> - B) We subtract neighbors from the amplified center
&#10003;</p>

<p class=MsoNormal> - C) Zero padding increases value</p>

<p class=MsoNormal> - D) Random result</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Use Cases</p>

<p class=MsoNormal>- **Image Sharpening**: Making blurry photos clearer</p>

<p class=MsoNormal>- **Medical Image Enhancement**: Making tumors more visible
in scans</p>

<p class=MsoNormal>- **Astronomy**: Enhancing faint stars in telescope images</p>

<p class=MsoNormal>- **Document Scanning**: Improving text clarity</p>

<p class=MsoNormal>- **Forensics**: Enhancing fingerprints, license plates</p>

<p class=MsoNormal>- **Microscopy**: Cell structure enhancement</p>

<p class=MsoNormal>- **Satellite Monitoring**: Detecting changes in land use</p>

<p class=MsoNormal>- **Video Upscaling**: Improving video quality</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>### Numerical Problems</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 1**: Systematic Calculation</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>R channel (44):</p>

<p class=MsoNormal>[5 10 15 20]</p>

<p class=MsoNormal>[10 15 20 25]</p>

<p class=MsoNormal>[15 20 25 30]</p>

<p class=MsoNormal>[20 25 30 35]</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate: out(1,1)</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- center = 15</p>

<p class=MsoNormal>- top = 10, bottom = 20, left = 10, right = 20</p>

<p class=MsoNormal>- out(1,1) = 515 - 10 - 20 - 10 - 20</p>

<p class=MsoNormal>- out(1,1) = 75 - 60 = **15**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 2**: All Corners</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>For a 33 matrix:</p>

<p class=MsoNormal>[A B C]</p>

<p class=MsoNormal>[D E F]</p>

<p class=MsoNormal>[G H I]</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Using zero-padding, write formulas for all 4 corners:</p>

<p class=MsoNormal>a) out(0,0)</p>

<p class=MsoNormal>b) out(0,2)</p>

<p class=MsoNormal>c) out(2,0)</p>

<p class=MsoNormal>d) out(2,2)</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) out(0,0) = 5A - 0 - D - 0 - B = **5A - B - D**</p>

<p class=MsoNormal>- b) out(0,2) = 5C - 0 - F - B - 0 = **5C - B - F**</p>

<p class=MsoNormal>- c) out(2,0) = 5G - D - 0 - 0 - H = **5G - D - H**</p>

<p class=MsoNormal>- d) out(2,2) = 5I - F - 0 - H - 0 = **5I - F - H**</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 3**: Edge vs Interior</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Matrix (33):</p>

<p class=MsoNormal>[10 10 10]</p>

<p class=MsoNormal>[10 20 10]</p>

<p class=MsoNormal>[10 10 10]</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate:</p>

<p class=MsoNormal>a) out(1,1) (center)</p>

<p class=MsoNormal>b) out(0,1) (top edge)</p>

<p class=MsoNormal>c) Compare the two results</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- a) out(1,1) = 520 - 10 - 10 - 10 - 10 = 100 - 40 = **60**</p>

<p class=MsoNormal>- b) out(0,1) = 510 - 0 - 20 - 10 - 10 = 50 - 40 = **10**</p>

<p class=MsoNormal>- c) **Center pixel gets amplified more** (60 vs 10) because
it's surrounded by lower values</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 4**: Uniform vs Varying</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Compare two scenarios:</p>

<p class=MsoNormal>Scenario A - Uniform: Scenario B - Varying:</p>

<p class=MsoNormal>[20 20 20] [10 20 30]</p>

<p class=MsoNormal>[20 20 20] [15 20 25]</p>

<p class=MsoNormal>[20 20 20] [20 20 20]</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate out(1,1) for both:</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>**Solution**:</p>

<p class=MsoNormal>- **Scenario A**: center=20, all neighbors=20</p>

<p class=MsoNormal> - out = 520 - 20 - 20 - 20 - 20 = 100 - 80 = **20** (no
change!)</p>

<p class=MsoNormal>- **Scenario B**: center=20, top=20, bottom=20, left=15,
right=25</p>

<p class=MsoNormal> - out = 520 - 20 - 20 - 15 - 25 = 100 - 80 = **20** (no
change!)</p>

<p class=MsoNormal> </p>

<p class=MsoNormal>**Insight**: Laplacian filter responds to **rate of
change**. Uniform areas stay unchanged.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>**Problem 5**: Negative Values</p>

<p class=MsoNormal>```</p>

<p class=MsoNormal>Matrix (33):</p>

<p class=MsoNormal>[0 0 0]</p>

<p class=MsoNormal>[0 10 0]</p>

<p class=MsoNormal>[0 0 0]</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Calculate out(1,1):</p>

<p class=MsoNormal>What does this tell us about the filter?</p>

<p class=MsoNormal><b>Solution</b>:</p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>center = 10, all neighbors = 0</li>
 <li class=MsoNormal>out(1,1) = 510 - 0 - 0 - 0 - 0 = <b>50</b></li>
 <li class=MsoNormal><b>Interpretation</b>: Isolated bright pixels get <b>amplified
     5</b> - this filter enhances features!</li>
</ul>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>SLIDE 13: Detailed Row Calculations</b></p>

<p class=MsoNormal><b>Easy Explanation</b></p>

<p class=MsoNormal>This slide shows the **complete</p>

<p class=MsoNormal>Retry</p>

<p class=MsoNormal>This response paused because Claude reached its max length
for a message. Hit continue to nudge Claude along.</p>

<p class=MsoNormal>Continue</p>

<p class=MsoNormal><a
href="https://support.anthropic.com/en/articles/8525154-claude-is-providing-incorrect-or-misleading-responses-what-s-going-on"
target="_blank">Claude can make mistakes. <br>
Please double-check responses.</a></p>

<div style='border:none;border-bottom:double windowtext 2.25pt;padding:0in 0in 1.0pt 0in'>

<p class=MsoNormal style='border:none;padding:0in'>Session limit reached
&#8729; resets 10:30 PM</p>

</div>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><b>Slide 1: GPU Programming - Lecture 07: Parallel Kernel
Programming</b></p>

<p class=MsoNormal><b>Explanation in Easy Language:</b> This is the title slide
for the lecture. It introduces the topic of parallel kernel programming on
GPUs, which means writing special functions (kernels) that run many tasks at
the same time on a graphics processing unit (GPU) to speed up computations like
math operations on large data sets.</p>

<p class=MsoNormal><b>MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is the main focus of Lecture 07? a) Sequential
     programming b) Parallel kernel programming c) CPU optimization d) Web
     development (Answer: b)</li>
 <li class=MsoNormal>What does &quot;kernel&quot; refer to in GPU programming?
     a) The core of an operating system b) A function that runs in parallel on
     the GPU c) A type of data structure d) A hardware component (Answer: b)</li>
 <li class=MsoNormal>Why is parallel programming important for GPUs? a) To slow
     down computations b) To handle large data efficiently by running many
     tasks simultaneously c) To reduce memory usage only d) To make code
     shorter (Answer: b)</li>
</ol>

<p class=MsoNormal><b>Use Cases:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Accelerating scientific simulations, like weather
     forecasting, where many calculations run in parallel.</li>
 <li class=MsoNormal>Speeding up video game graphics rendering by processing
     pixels simultaneously.</li>
 <li class=MsoNormal>Optimizing machine learning training, where models process
     huge datasets at once.</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>If a GPU has 1024 cores and a kernel launches 1024
     threads, how many threads run in parallel assuming perfect utilization?
     (Answer: 1024)</li>
 <li class=MsoNormal>Suppose a simple kernel adds two arrays of size 100.
     Calculate the total operations if done sequentially vs. in parallel
     (assume 1 operation per addition). Sequential: 100 operations one by one.
     Parallel: Up to 100 operations at once if 100 threads are used.</li>
 <li class=MsoNormal>For a grid of 2x2 blocks, each with 4x4 threads, compute
     total threads launched. (Answer: 2<i>2</i>4*4 = 64)</li>
</ol>

<p class=MsoNormal><b>Slide 2: Matrix Multiplication (MM) Kernel</b></p>

<p class=MsoNormal><b>Explanation in Easy Language:</b> This slide shows a
simple CUDA kernel (function) for multiplying two square matrices A and B to
get C. Each thread (small worker) calculates one element of C by summing
products from a row of A and a column of B. It uses block and thread indices to
figure out which row and column each thread handles, and checks if it's within
the matrix size to avoid errors.</p>

<p class=MsoNormal><b>MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What does the 'row' variable represent in the kernel? a)
     Column index b) Global Y position for the thread c) Matrix size d) Sum
     value (Answer: b)</li>
 <li class=MsoNormal>Why is there an 'if (row &lt; n &amp;&amp; col &lt; n)'
     check? a) To initialize sum b) To ensure threads don't access
     out-of-bounds memory c) To synchronize threads d) To multiply matrices
     (Answer: b)</li>
 <li class=MsoNormal>How many times does the inner loop run for an n x n
     matrix? a) n times b) n^2 times c) 1 time d) Infinite (Answer: a)</li>
</ol>

<p class=MsoNormal><b>Use Cases:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>In computer graphics for transforming 3D models (e.g.,
     rotating objects in games).</li>
 <li class=MsoNormal>In machine learning for neural network layers where
     weights are multiplied by inputs.</li>
 <li class=MsoNormal>In scientific computing for solving linear equations in
     physics simulations.</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>For n=3, matrices A=[[1,2,3],[4,5,6],[7,8,9]],
     B=[[9,8,7],[6,5,4],[3,2,1]], compute C[1][1] manually. (Answer: 4<i>8 + 5</i>5
     + 6*2 = 32+25+12=69)</li>
 <li class=MsoNormal>If n=4, how many global memory accesses per thread for A
     and B combined in the loop? (Answer: 4 for A + 4 for B = 8)</li>
 <li class=MsoNormal>For a 2x2 matrix, if thread (0,0) computes C[0][0]=5,
     thread (0,1) computes C[0][1]=10, what is total sum operations across all
     threads? (Answer: 4 threads * 2 loops each = 8)</li>
</ol>

<p class=MsoNormal><b>Slide 3: Explanation</b></p>

<p class=MsoNormal><b>Explanation in Easy Language:</b> This slide explains how
the matrix multiplication works with an example. For a 5x5 matrix C, each
element like C[2][3] is calculated by multiplying row 2 of A with column 3 of B
and summing. Each thread is assigned one C element: thread (0,0) does C[0][0],
up to thread (4,4) for C[4][4]. It's like dividing the work among many workers.</p>

<p class=MsoNormal><b>MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What does thread (row=2, col=3) compute? a) C[2][3] b)
     A[2][3] c) B[3][2] d) Sum only (Answer: a)</li>
 <li class=MsoNormal>In the example, how is C[2][3] calculated? a) Sum of
     A[2][k] * B[k][3] for k=0 to 4 b) Average of row 2 c) Product of diagonals
     d) Subtraction (Answer: a)</li>
 <li class=MsoNormal>For a 5x5 matrix, how many threads are needed ideally? a)
     5 b) 25 c) 10 d) 1 (Answer: b)</li>
</ol>

<p class=MsoNormal><b>Use Cases:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Image processing, like applying filters by multiplying
     pixel matrices.</li>
 <li class=MsoNormal>Financial modeling for portfolio risk calculations using
     matrix ops.</li>
 <li class=MsoNormal>Engineering simulations, such as stress analysis in
     structures.</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>For n=3, A row 1=[4,5,6], B col 1=[8,5,2], compute
     C[1][1]. (Answer: 4<i>8 + 5</i>5 + 6*2 = 69)</li>
 <li class=MsoNormal>If each multiplication takes 1 unit time, total time for
     one C element with n=4? (Answer: 4 units for loop)</li>
 <li class=MsoNormal>For 4x4 matrix, number of additions per C element?
     (Answer: 3, since 4 multiplies summed with 3 adds)</li>
</ol>

<p class=MsoNormal><b>Slide 4: Tiled MM Kernel</b></p>

<p class=MsoNormal><b>Explanation in Easy Language:</b> This is part 1 of an
improved matrix multiplication kernel using &quot;tiling.&quot; It uses shared
memory (fast local storage) to store small chunks (tiles) of A and B. Threads
in a block work together to load these tiles from slow global memory, then compute
partial sums. The loop goes over multiple tiles to handle the full matrix, with
checks for edges.</p>

<p class=MsoNormal><b>MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is 'tileA' and 'tileB' used for? a) Global memory b)
     Shared memory for sub-blocks of A and B c) Output storage d) Thread
     indices (Answer: b)</li>
 <li class=MsoNormal>Why is there a loop over 'm'? a) To compute rows b) To
     process multiple tiles along the matrix dimension c) To synchronize d) To
     initialize zero (Answer: b)</li>
 <li class=MsoNormal>What happens if row &gt;= n in loading tileA? a) Set to
     zero b) Error c) Skip loop d) Multiply (Answer: a)</li>
</ol>

<p class=MsoNormal><b>Use Cases:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Large-scale data analysis in big data systems like Hadoop
     with matrix ops.</li>
 <li class=MsoNormal>Deep learning frameworks (e.g., TensorFlow) for efficient
     batch processing.</li>
 <li class=MsoNormal>Cryptography for matrix-based encryption algorithms.</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>For TILE_SIZE=2, n=4, how many 'm' iterations? (Answer:
     (4+2-1)/2 = 2.5 &#8594; 3, but integer ceiling to 3)</li>
 <li class=MsoNormal>If tileA is 4x4, elements loaded per block? (Answer: 16
     for A + 16 for B = 32 per tile)</li>
 <li class=MsoNormal>For n=5, TILE_SIZE=4, compute m loop upper bound. (Answer:
     (5+4-1)/4 = 2)</li>
</ol>

<p class=MsoNormal><b>Slide 5: Tiled MM Kernel.</b></p>

<p class=MsoNormal><b>Explanation in Easy Language:</b> This is part 2 of the
tiled kernel. After loading tiles, threads wait (__syncthreads()) so everyone
has the data. Then they multiply the tiles and add to a temporary sum. Another
sync ensures readiness for the next tile. Finally, if within bounds, store the
result in C. This reduces slow memory accesses by reusing shared data.</p>

<p class=MsoNormal><b>MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What does __syncthreads() do? a) Multiply tiles b) Wait
     for all threads in block to finish loading c) Store result d) Loop over m
     (Answer: b)</li>
 <li class=MsoNormal>Where is the final result stored? a) tileA b) temp c)
     c[row*n + col] d) tileB (Answer: c)</li>
 <li class=MsoNormal>How many __syncthreads() calls per m iteration? a) 1 b) 2
     c) 0 d) TILE_SIZE (Answer: b)</li>
</ol>

<p class=MsoNormal><b>Use Cases:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>High-performance computing in supercomputers for climate
     modeling.</li>
 <li class=MsoNormal>Real-time video processing in streaming apps.</li>
 <li class=MsoNormal>Bioinformatics for gene sequence alignments via matrices.</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>For TILE_SIZE=3, inner multiply loop runs how many times?
     (Answer: 3)</li>
 <li class=MsoNormal>If temp starts at 0, after one tile multiply with values
     tileA[0][k]=1, tileB[k][0]=2 for k=0 to 2, what is temp? (Answer: 1<i>2 +1</i>2
     +1*2=6)</li>
 <li class=MsoNormal>Total sync calls for m=2? (Answer: 4)</li>
</ol>

<p class=MsoNormal><b>Slide 6: Usage of Tiling</b></p>

<p class=MsoNormal><b>Explanation in Easy Language:</b> This slide explains why
tiling is useful in basic matrix multiplication. Without it, each thread reads
a whole row of A and column of B from slow global memory, leading to ~2n reads
per thread. For an n x n matrix, total global reads are O(n^3), which is
inefficient. Tiling shares data to cut down on these reads.</p>

<p class=MsoNormal><b>MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>In non-tiled version, reads per thread? a) ~2n b) n^2 c) 1
     d) TILE_SIZE (Answer: a)</li>
 <li class=MsoNormal>Total global memory accesses for whole C? a) O(n) b)
     O(n^2) c) O(n^3) d) O(1) (Answer: c)</li>
 <li class=MsoNormal>What does the formula C[row][col] = sum
     A[row][k]*B[k][col] show? a) Tiling b) How each element is computed c)
     Synchronization d) Padding (Answer: b)</li>
</ol>

<p class=MsoNormal><b>Use Cases:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Optimization in recommendation systems (e.g., Netflix)
     using matrix factorization.</li>
 <li class=MsoNormal>Physics engines in games for collision detection.</li>
 <li class=MsoNormal>Economic modeling with large input-output matrices.</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>For n=4, reads per thread without tiling? (Answer: ~8)</li>
 <li class=MsoNormal>Total global accesses for n=2? (Answer: 4 threads * ~4
     reads = ~16, but O(8))</li>
 <li class=MsoNormal>If n=1024, approximate total accesses without tiling?
     (Answer: ~1024^3 = ~1e9)</li>
</ol>

<p class=MsoNormal><b>Slide 7: Usage of Tiling</b></p>

<p class=MsoNormal><b>Explanation in Easy Language:</b> Using n=1024 example,
without tiling, each thread loads 1024 elements each from A and B (~2048
reads). With tiling (TILE_SIZE=32), it loads only 32 each per iteration (~64
reads), and data is shared among threads, making overall memory use much lower
and computation faster.</p>

<p class=MsoNormal><b>MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>For n=1024, non-tiled reads per thread? a) ~64 b) ~2048 c)
     32 d) 1024 (Answer: b)</li>
 <li class=MsoNormal>In tiled (TILE_SIZE=32), reads per thread? a) ~2048 b) ~64
     c) 1024 d) 0 (Answer: b)</li>
 <li class=MsoNormal>Why is actual global load smaller in tiling? a) Data is
     shared in block b) No loops c) Larger tiles d) Slower threads (Answer: a)</li>
</ol>

<p class=MsoNormal><b>Use Cases:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Large-scale AI training where matrices are huge (e.g., GPT
     models).</li>
 <li class=MsoNormal>Medical imaging for MRI data processing.</li>
 <li class=MsoNormal>Autonomous driving simulations with sensor data matrices.</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>For TILE_SIZE=32, n=1024, m iterations? (Answer:
     1024/32=32)</li>
 <li class=MsoNormal>Total reads per thread in tiled: 32*32 for A/B? (No, per
     iteration 1 for A +1 for B, times 32 iterations=64)</li>
 <li class=MsoNormal>Reduction factor: 2048/64=32x fewer reads per thread.</li>
</ol>

<p class=MsoNormal><b>Slide 8: Without tiling... (Comparison and Division)</b></p>

<p class=MsoNormal><b>Explanation in Easy Language:</b> Without tiling, threads
fetch ~n elements each from global memory, wasting bandwidth. With tiling,
threads load tiles into fast shared memory and reuse them, speeding things up.
For a 5x5 C, it's divided into 4x4 blocks with boundary checks for partial tiles.</p>

<p class=MsoNormal><b>MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Main benefit of tiling? a) Increases global reads b)
     Reduces global memory bandwidth usage c) Removes threads d) Adds padding
     only (Answer: b)</li>
 <li class=MsoNormal>How is C divided for n=5, TILE_SIZE=4? a) 1 block b) 2x2
     blocks of 4x4 c) 5x5 blocks d) No division (Answer: b)</li>
 <li class=MsoNormal>What handles partial tiles? a) if(row &lt; n &amp;&amp;
     col &lt; n) b) Loop over m c) Shared memory d) All threads (Answer: a)</li>
</ol>

<p class=MsoNormal><b>Use Cases:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Parallel database queries with matrix joins.</li>
 <li class=MsoNormal>Weather prediction models with grid data.</li>
 <li class=MsoNormal>Stock market analysis using covariance matrices.</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>For n=5, TILE_SIZE=4, blocks needed? (Answer: ceil(5/4)=2
     per dim, 4 blocks)</li>
 <li class=MsoNormal>Elements per tile: 4*4=16, but for last tile partial ~1 (5
     mod 4=1).</li>
 <li class=MsoNormal>Global reads reduction: Assume block has 16 threads,
     shared loads 16 for A+16 for B per tile, vs. non-tiled 16*5=80 per dim.</li>
</ol>

<p class=MsoNormal><b>Slide 9: Visualization</b></p>

<p class=MsoNormal><b>Explanation in Easy Language:</b> Shows how a 5x5 C is
split into blocks like Block(0,0) for top-left 4x4. Each thread loads one
element into shared tiles. In m=0, load full tiles; in m=1, pad partial with
0s. Threads compute partial results per tile and add up.</p>

<p class=MsoNormal><b>MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What does Block(0,0) compute for TILE_SIZE=4? a)
     C[0..3][0..3] b) Whole C c) Only edges d) Nothing (Answer: a)</li>
 <li class=MsoNormal>In m=1, what happens to unused space? a) Error b) Padded
     with 0 c) Skipped d) Multiplied (Answer: b)</li>
 <li class=MsoNormal>How many m iterations for n=5, TILE_SIZE=4? a) 1 b) 2 c) 5
     d) 4 (Answer: b)</li>
</ol>

<p class=MsoNormal><b>Use Cases:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Computer vision for feature extraction via matrix
     multiplies.</li>
 <li class=MsoNormal>Robotics for path planning with transformation matrices.</li>
 <li class=MsoNormal>Signal processing in audio apps.</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>For Block(0,0), threads: 4x4=16, each computes one square.</li>
 <li class=MsoNormal>Partial contribution in m=1: Assume A row[0..3]
     col[4]=[5,6,7,8], B row[4] col[0..3]=[9,10,11,12], temp += sum products.
     (Example: for thread(0,0): 5*9 if k=4 only, but adjusted).</li>
 <li class=MsoNormal>Total tiles processed per block: 2.</li>
</ol>

<p class=MsoNormal><b>Slide 10: Convolution Kernel (Refer code from Collab)</b></p>

<p class=MsoNormal><b>Explanation in Easy Language:</b> Convolution applies a
small filter (kernel) to an image to create effects like blurring. For a 5x5
input and 2x2 filter, output is 4x4. Each thread computes one output pixel by
sliding the filter over the image. Shared memory helps for efficiency. Example
shows all outputs as -6 for a simple subtract filter.</p>

<p class=MsoNormal><b>MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Output size for 5x5 input, 2x2 filter? a) 5x5 b) 4x4 c)
     3x3 d) 6x6 (Answer: b)</li>
 <li class=MsoNormal>What computes one output pixel? a) One thread b) Whole
     block c) Filter only d) Input (Answer: a)</li>
 <li class=MsoNormal>Why use shared memory? a) For better locality in stencil
     b) To increase size c) To pad zeros d) No reason (Answer: a)</li>
</ol>

<p class=MsoNormal><b>Use Cases:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Image editing apps (e.g., Photoshop filters like edge
     detection).</li>
 <li class=MsoNormal>Medical imaging for tumor detection in scans.</li>
 <li class=MsoNormal>Self-driving cars for object recognition in camera feeds.</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>For input=[[1,2,3,4,5],[6,7,8,9,10],...], filter subtract
     as shown, out(0,0)=1-7=-6. Compute out(1,1)=7-13=-6.</li>
 <li class=MsoNormal>Total output elements: 4*4=16.</li>
 <li class=MsoNormal>Formula: (n - k + 1)^2, for n=5, k=2: 4^2=16.</li>
</ol>

<p class=MsoNormal><b>Slide 11: Convolution with RGB Input (Refer code from
Collab)</b></p>

<p class=MsoNormal><b>Explanation in Easy Language:</b> Now for color (RGB)
images: 5x5 with R,G,B channels. Apply 3x3 kernel separately to each channel.
Kernel is like sharpening: 5*center - neighbors. Output is three 5x5 matrices
(padded). Example shows R input and result.</p>

<p class=MsoNormal><b>MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>How is kernel applied to RGB? a) Combined b) Separately
     per channel c) Only to R d) Not applied (Answer: b)</li>
 <li class=MsoNormal>Output size here? a) 4x4 b) 5x5 (with padding) c) 3x3 d)
     6x6 (Answer: b)</li>
 <li class=MsoNormal>Formula for out(i,j)? a) 5*center - top - bottom - left -
     right b) Sum only c) Average d) Subtract all (Answer: a)</li>
</ol>

<p class=MsoNormal><b>Use Cases:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Photo enhancement in social media filters.</li>
 <li class=MsoNormal>Video compression in streaming services.</li>
 <li class=MsoNormal>Augmented reality apps for overlay effects.</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>For R[0][0]=10, neighbors top=0, bottom=15, left=0,
     right=20: 5*10 -0-15-0-20=50-35=15.</li>
 <li class=MsoNormal>Compute R out[0][1]: center=20, left=10, right=30, top=0,
     bottom=25: 100-65=35.</li>
 <li class=MsoNormal>Total operations per pixel: 5 multiplies (but simplified
     to 5*center -4 neighbors).</li>
</ol>

<p class=MsoNormal><b>Slide 12: Stencil-based Computation</b></p>

<p class=MsoNormal><b>Explanation in Easy Language:</b> Stencil means using a
pattern (like the kernel) over the image with zero-padding for edges (add 0s
around borders). For each output, calculate using center and neighbors.
Examples: For top-left (10), pad and compute 5<i>10 - (0+0+20+15)=15; for next
(20), 5</i>20 - (0+25+10+30)=35.</p>

<p class=MsoNormal><b>MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is zero-padding? a) Adding zeros around edges b)
     Removing borders c) Multiplying by zero d) No effect (Answer: a)</li>
 <li class=MsoNormal>For center=10, out(0,0)=? a) 50 - 35 = 15 b) 10 c) 0 d) 35
     (Answer: a)</li>
 <li class=MsoNormal>Why stencil? a) For different convolution manner b) To
     speed up c) To reduce size d) All (Answer: a)</li>
</ol>

<p class=MsoNormal><b>Use Cases:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Noise reduction in audio signals.</li>
 <li class=MsoNormal>Weather map smoothing.</li>
 <li class=MsoNormal>Game terrain generation.</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Center=20, top=0, bottom=25, left=10, right=30: 100 -
     65=35.</li>
 <li class=MsoNormal>If kernel changes to 4*center - neighbors, recompute
     (0,0): 40 - 35=5.</li>
 <li class=MsoNormal>Neighbors for (0,0): 4 (top, bottom, left, right, some
     padded).</li>
</ol>

<p class=MsoNormal><b>Slide 13: (Detailed Calculations)</b></p>

<p class=MsoNormal><b>Explanation in Easy Language:</b> This slide lists
step-by-step calculations for every element in the 5x5 R output using the
stencil formula with padding. For example, row 0: 15,35,55,75,155; row
1:20,25,35,45,120; and so on, showing how each uses center and neighbors.</p>

<p class=MsoNormal><b>MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is out(2,2)? a) 45 b) 35 c) 55 d) 130 (Answer: a)</li>
 <li class=MsoNormal>How many rows calculated? a) 4 b) 5 c) 3 d) 1 (Answer: b)</li>
 <li class=MsoNormal>For (4,4), center=70, neighbors? a) Bottom=0, right=0,
     left=60, top=65 &#8594; 350 - (65+0+60+0)=225? Wait, per text 350-(65+60?
     wait, text says 350-(65+70+60)? Error in query, but per text 155. (Answer:
     Per calculations, 155)</li>
</ol>

<p class=MsoNormal><b>Use Cases:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Detailed image analysis in forensics.</li>
 <li class=MsoNormal>Scientific data visualization.</li>
 <li class=MsoNormal>Educational tools for teaching convolution.</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Verify (1,0): center=15, up=10, down=20, right=25, left=0
     (pad): 75 - (10+20+0+25)=20.</li>
 <li class=MsoNormal>Sum of row 0: 15+35+55+75+155=335.</li>
 <li class=MsoNormal>Average output value: Total sum /25, approximate ~70.</li>
</ol>

<p class=MsoNormal><b>Slide 14: Visualization (Convolution with RGB Input)</b></p>

<p class=MsoNormal><b>Explanation in Easy Language:</b> Convolution needs
overlapping neighbor data for each pixel, leading to redundant slow memory
reads without optimization. Stencil fixes this by loading tiles plus a
&quot;halo&quot; (border) into shared memory. For 16x16 threads, load 18x18
tile. This minimizes global accesses and allows reuse.</p>

<p class=MsoNormal><b>MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Problem without stencil? a) Redundant memory accesses b)
     No overlap c) Faster d) Less data (Answer: a)</li>
 <li class=MsoNormal>Halo size for 3x3 kernel? a) 0 b) 1 pixel border c) Full
     image d) TILE_SIZE (Answer: b)</li>
 <li class=MsoNormal>For 16x16 block, shared tile size? a) 16x16 b) 18x18 c)
     14x14 d) 32x32 (Answer: b)</li>
</ol>

<p class=MsoNormal><b>Use Cases:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>CNNs in AI for image classification (e.g., identifying
     cats in photos).</li>
 <li class=MsoNormal>Video game effects like blur or sharpen.</li>
 <li class=MsoNormal>Satellite image processing.</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>For kernel 3x3, halo=1, block 4x4: shared=6x6=36 elements.</li>
 <li class=MsoNormal>Redundant fetches without: For 4x4 output, each pixel 9
     fetches, total 144, but with overlap ~ much less unique.</li>
 <li class=MsoNormal>Efficiency gain: Loads per block ~ (block+halo)^2 vs.
     threads* kernel_size.</li>
</ol>

<p class=MsoNormal><b>Slide 15: Visualization (Convolution with RGB Input) -
Parallelism and Efficiency</b></p>

<p class=MsoNormal><b>Explanation in Easy Language:</b> Each thread gets one
output pixel. After loading shared memory, sync once, then compute sum of
kernel * tile parts. Thousands of threads work in parallel. Efficient because
data is loaded once per block, reused, reducing slow memory traffic and
enabling high parallelism.</p>

<p class=MsoNormal><b>MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>How many syncs needed? a) 1 after load b) None c) Per
     pixel d) Per thread (Answer: a)</li>
 <li class=MsoNormal>Main efficiency reason? a) Data reuse in shared memory b)
     More global accesses c) Slower threads d) No halo (Answer: a)</li>
 <li class=MsoNormal>Thread assignment? a) One per pixel b) One per image c)
     One per channel d) Random (Answer: a)</li>
</ol>

<p class=MsoNormal><b>Use Cases:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Real-time face detection in cameras.</li>
 <li class=MsoNormal>MRI image enhancement.</li>
 <li class=MsoNormal>Animation rendering in movies.</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>For 100x100 image, threads needed: 10000.</li>
 <li class=MsoNormal>If block=16x16=256 threads, grids= ceil(100/16)^2 &#8776;
     49.</li>
 <li class=MsoNormal>Compute sum for pixel:
     kernel=[[0,-1,0],[-1,5,-1],[0,-1,0]], tile center=10, neighbors as before:
     5*10 - (up+down+left+right).</li>
</ol>

<p class=MsoNormal><b>Slide 16: Visualization (Convolution with RGB Input) -
Example</b></p>

<p class=MsoNormal><b>Explanation in Easy Language:</b> For 5x5 image, 3x3
kernel, 4x4 block: Load 6x6 tile (with halo). 16 threads compute 4x4 output in
parallel. Borders are shared, so fetched once, not 16 times, saving memory.</p>

<p class=MsoNormal><b>MCQs:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Tile size for 4x4 block, 3x3 kernel? a) 4x4 b) 6x6 c) 5x5
     d) 3x3 (Answer: b)</li>
 <li class=MsoNormal>Threads per block? a) 16 b) 25 c) 9 d) 1 (Answer: a)</li>
 <li class=MsoNormal>Benefit for borders? a) Fetched multiple times b) Fetched
     once, shared c) Ignored d) Padded only (Answer: b)</li>
</ol>

<p class=MsoNormal><b>Use Cases:</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Mobile photo apps for quick filters.</li>
 <li class=MsoNormal>Drone imagery analysis.</li>
 <li class=MsoNormal>Virtual reality texture processing.</li>
</ul>

<p class=MsoNormal><b>Numericals:</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Elements in tile: 6*6=36.</li>
 <li class=MsoNormal>Savings: Without shared, 16 threads *9 fetches=144; with
     shared, ~36 unique loads.</li>
 <li class=MsoNormal>For larger block 8x8, tile=10x10=100, threads=64,
     ratio=100/ (64*9) &#8776;0.17x fewer.</li>
</ol>

<p class=MsoNormal>&nbsp;</p>

<div style='border:none;border-bottom:double windowtext 2.25pt;padding:0in 0in 1.0pt 0in'>

<p class=MsoNormal style='border:none;padding:0in'>&nbsp;</p>

</div>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><b>GPU Programming Lecture 07: Parallel Kernel Programming -
Study Guide</b></p>

<p class=MsoNormal><b>Slide 1: Matrix Multiplication (MM) Kernel</b></p>

<p class=MsoNormal><b>Explanation in Easy Language</b></p>

<p class=MsoNormal>This slide shows a CUDA kernel function that performs matrix
multiplication. In GPU programming, a kernel is a function that runs on the
GPU. This specific kernel multiplies two matrices (A and B) and stores the
result in matrix C. Each thread on the GPU calculates one element of the result
matrix. The code determines which element to calculate based on the thread's
position in the grid.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What does the <b>__global__</b> keyword indicate in CUDA?
     a) The function runs on the CPU b) The function runs on the GPU c) The
     function runs on both CPU and GPU d) The function is a regular C++
     function</li>
 <li class=MsoNormal>In the matrix multiplication kernel, what does <b>blockIdx.y
     * blockDim.y + threadIdx.y</b> calculate? a) The column index b) The row
     index c) The tile size d) The matrix dimension</li>
 <li class=MsoNormal>What is the purpose of the condition <b>if (row &lt; n
     &amp;&amp; col &lt; n)</b>? a) To ensure only valid matrix elements are
     computed b) To optimize memory access c) To synchronize threads d) To
     allocate shared memory</li>
</ol>

<p class=MsoNormal><b>Use Cases</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Scientific computing requiring large matrix operations</li>
 <li class=MsoNormal>Machine learning algorithms (neural networks)</li>
 <li class=MsoNormal>Image processing transformations</li>
 <li class=MsoNormal>Financial modeling and risk analysis</li>
</ul>

<p class=MsoNormal><b>Numerical Problems</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Given two 33 matrices A and B, write the values of <b>row</b>
     and <b>col</b> for the thread that computes the element at position [1,2]
     in the result matrix C, assuming a block size of 22.</li>
 <li class=MsoNormal>If you have matrices of size 10241024 and a block size of
     1616, how many blocks are needed in each dimension?</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=0 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 2: Explanation</b></p>

<p class=MsoNormal><b>Explanation in Easy Language</b></p>

<p class=MsoNormal>This slide provides a visual explanation of how matrix
multiplication works. It shows a 55 result matrix C where each element is
computed by taking the dot product of the corresponding row from matrix A and
column from matrix B. For example, to calculate the element at position [2,3]
in matrix C, you multiply elements from row 2 of matrix A with elements from
column 3 of matrix B and sum them up.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>In matrix multiplication, how is the element c[2][3]
     calculated? a) a[2][3] * b[2][3] b) Sum of a[2][k] * b[k][3] for all k c)
     Sum of a[k][2] * b[3][k] for all k d) a[3][2] * b[2][3]</li>
 <li class=MsoNormal>If matrix A is 34 and matrix B is 45, what will be the
     dimensions of the result matrix C? a) 35 b) 44 c) 34 d) 45</li>
 <li class=MsoNormal>In the example shown, what elements are multiplied to
     compute c[2][3]? a) a[2][0]*b[0][3], a[2]*b[3], ..., a[2][4]*b[4][3] b)
     a[0][2]*b[3][0], a[2]*b[3], ..., a[4][2]*b[3][4] c) a[2][3]*b[2][3] d)
     a[3][2]*b[3][2]</li>
</ol>

<p class=MsoNormal><b>Use Cases</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Educational purposes to understand matrix multiplication
     fundamentals</li>
 <li class=MsoNormal>Algorithm design for parallel processing</li>
 <li class=MsoNormal>Basis for more complex operations in linear algebra</li>
 <li class=MsoNormal>Computer graphics transformations</li>
</ul>

<p class=MsoNormal><b>Numerical Problems</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Calculate the element c[2] in the result matrix if: A =
     [[1,2,3], [4,5,6], [7,8,9]] B = [[9,8,7], [6,5,4], [3,2,1]]</li>
 <li class=MsoNormal>Given matrices A (23) and B (32), write out all the
     calculations needed to compute the complete result matrix C.</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=0 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 3: Thread Assignment</b></p>

<p class=MsoNormal><b>Explanation in Easy Language</b></p>

<p class=MsoNormal>This slide explains how different threads are assigned to
compute different elements of the result matrix. Each thread is responsible for
calculating one specific element in matrix C. For example, the thread with
(row=0, col=0) calculates the top-left element c[0][0], while the thread with
(row=4, col=4) calculates the bottom-right element c[4][4]. This parallel
assignment allows multiple elements of the result matrix to be computed
simultaneously.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>In the thread assignment model shown, how many threads are
     needed to compute a 55 result matrix? a) 5 b) 10 c) 25 d) 125</li>
 <li class=MsoNormal>Which thread computes the element c[3]? a) Thread (row=1,
     col=3) b) Thread (row=3, col=1) c) Thread (row=1, col=1) d) Thread (row=3,
     col=3)</li>
 <li class=MsoNormal>What is the advantage of assigning one thread per element
     in matrix multiplication? a) It reduces memory usage b) It allows parallel
     computation of multiple elements c) It simplifies the code d) It reduces
     the number of required threads</li>
</ol>

<p class=MsoNormal><b>Use Cases</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Parallel processing of large matrices</li>
 <li class=MsoNormal>Understanding thread-to-data mapping in GPU programming</li>
 <li class=MsoNormal>Optimizing thread allocation for GPU kernels</li>
 <li class=MsoNormal>Educational purposes for parallel computing concepts</li>
</ul>

<p class=MsoNormal><b>Numerical Problems</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>If you have a 1010 matrix and a block size of 44, how
     many blocks are needed in each dimension? Which thread computes the
     element at position [7,5]?</li>
 <li class=MsoNormal>For a 66 matrix multiplication with a block size of 22,
     list the thread coordinates for the elements at positions [0,0], [1,3],
     [4,2], and [5,5].</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=0 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 4: Tiled MM Kernel (Part 1)</b></p>

<p class=MsoNormal><b>Explanation in Easy Language</b></p>

<p class=MsoNormal>This slide introduces an optimized version of the matrix
multiplication kernel called &quot;Tiled MM Kernel.&quot; Instead of each
thread directly accessing global memory for all required elements, this
approach uses shared memory. The matrix is divided into smaller tiles (blocks)
that fit into shared memory. Each thread block loads a tile of matrices A and B
into shared memory, which can be accessed much faster than global memory. This
reduces the number of slow global memory accesses.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is the purpose of <b>__shared__</b> in the tiled
     matrix multiplication kernel? a) To allocate memory in global memory b) To
     allocate memory in shared memory c) To synchronize threads d) To define a
     constant</li>
 <li class=MsoNormal>In the tiled approach, what does TILE_SIZE represent? a)
     The size of the entire matrix b) The size of each tile/block c) The number
     of threads d) The number of blocks</li>
 <li class=MsoNormal>Why is shared memory used in the tiled matrix
     multiplication? a) It has larger capacity than global memory b) It is
     faster to access than global memory c) It is persistent across kernel
     launches d) It requires less code to implement</li>
</ol>

<p class=MsoNormal><b>Use Cases</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>High-performance matrix multiplication for large datasets</li>
 <li class=MsoNormal>Deep learning training where matrix operations are
     frequent</li>
 <li class=MsoNormal>Scientific simulations requiring efficient matrix
     computations</li>
 <li class=MsoNormal>Image and signal processing applications</li>
</ul>

<p class=MsoNormal><b>Numerical Problems</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>If you have a 10241024 matrix and TILE_SIZE is 32, how
     many tiles are needed in each dimension?</li>
 <li class=MsoNormal>Calculate the number of global memory accesses saved when
     using tiled matrix multiplication with TILE_SIZE=16 for multiplying two
     512512 matrices, compared to the non-tiled approach.</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=0 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 5: Tiled MM Kernel (Part 2)</b></p>

<p class=MsoNormal><b>Explanation in Easy Language</b></p>

<p class=MsoNormal>This slide continues the tiled matrix multiplication kernel.
After loading tiles of matrices A and B into shared memory, the threads
synchronize using <b>__syncthreads()</b> to ensure all data is loaded before
computation begins. Then, each thread computes its partial result by
multiplying elements from the shared memory tiles. This process repeats for all
tiles needed to compute the final result. Finally, the computed value is stored
in the result matrix C.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is the purpose of <b>__syncthreads()</b> in the tiled
     matrix multiplication kernel? a) To terminate the kernel b) To ensure all
     threads have loaded their data before computation c) To allocate more
     memory d) To switch between global and shared memory</li>
 <li class=MsoNormal>In the tiled approach, how many times does each thread
     access global memory for each element of the result matrix? a) n times
     (where n is the matrix dimension) b) TILE_SIZE times c) Once per tile d)
     Only once</li>
 <li class=MsoNormal>What happens in the inner loop <b>for (int k = 0; k &lt;
     TILE_SIZE; k++)</b>? a) Loading data from global memory b) Computing
     partial results from shared memory tiles c) Storing results to global
     memory d) Synchronizing threads</li>
</ol>

<p class=MsoNormal><b>Use Cases</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Optimizing memory bandwidth utilization in GPU
     applications</li>
 <li class=MsoNormal>Reducing latency in matrix operations for real-time
     systems</li>
 <li class=MsoNormal>Efficient computation in resource-constrained environments</li>
 <li class=MsoNormal>High-performance computing clusters</li>
</ul>

<p class=MsoNormal><b>Numerical Problems</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>If TILE_SIZE=8 and matrix dimension n=1024, how many
     iterations of the outer tile loop (m loop) will be executed?</li>
 <li class=MsoNormal>For a 6464 matrix with TILE_SIZE=16, calculate how many
     times each element of matrices A and B will be loaded into shared memory
     across all thread blocks.</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=0 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 6: Usage of Tiling (Empty Slide)</b></p>

<p class=MsoNormal><b>Explanation in Easy Language</b></p>

<p class=MsoNormal>This slide appears to be a placeholder for explaining the
benefits of tiling in matrix multiplication. Tiling is a technique that
improves performance by optimizing memory access patterns. It reduces the
number of times data needs to be fetched from slow global memory by reusing
data that has been loaded into fast shared memory.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is the primary benefit of using tiling in matrix
     multiplication? a) Reducing the number of threads required b) Improving
     memory access patterns and reducing global memory traffic c) Simplifying
     the code d) Increasing the size of matrices that can be processed</li>
 <li class=MsoNormal>In tiled matrix multiplication, where is data temporarily
     stored for reuse? a) Global memory b) Local memory c) Shared memory d)
     Constant memory</li>
 <li class=MsoNormal>How does tiling affect the computational complexity of
     matrix multiplication? a) It reduces the complexity from O(n) to O(n) b)
     It doesn't change the complexity but improves performance c) It increases
     the complexity due to additional overhead d) It changes the complexity to
     O(n log n)</li>
</ol>

<p class=MsoNormal><b>Use Cases</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Performance optimization in GPU programming</li>
 <li class=MsoNormal>Memory bandwidth optimization in parallel computing</li>
 <li class=MsoNormal>Educational purposes for understanding memory hierarchies</li>
 <li class=MsoNormal>Designing efficient algorithms for data-intensive
     applications</li>
</ul>

<p class=MsoNormal><b>Numerical Problems</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Calculate the theoretical speedup of tiled matrix
     multiplication if global memory access is 100 times slower than shared
     memory access, and each element is reused 10 times in shared memory.</li>
 <li class=MsoNormal>For a 20482048 matrix multiplication with TILE_SIZE=32,
     calculate the total number of shared memory accesses across all thread
     blocks.</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=0 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 7: Usage of Tiling</b></p>

<p class=MsoNormal><b>Explanation in Easy Language</b></p>

<p class=MsoNormal>This slide explains the benefits of tiling in matrix
multiplication. Without tiling, each thread would need to fetch approximately n
elements of matrices A and B from global memory, which is slow. With tiling,
each thread only fetches TILE_SIZE elements per tile from global memory and
then reuses them multiple times from fast shared memory. This significantly
reduces global memory bandwidth usage and makes the kernel faster. The slide
also shows how the result matrix C is divided into tiles, with each block
computing a specific tile.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>How does tiling reduce global memory bandwidth usage? a)
     By reducing the size of the matrices b) By reusing data loaded into shared
     memory multiple times c) By compressing the data before loading d) By
     reducing the number of threads</li>
 <li class=MsoNormal>In the example shown, how is the C matrix divided? a) Into
     individual elements b) Into rows c) Into 44 tiles computed by each block
     d) Into columns</li>
 <li class=MsoNormal>What happens to tiles at the edges when the matrix size is
     not a multiple of TILE_SIZE? a) They are ignored b) They are padded with
     zeros c) CUDA handles them with boundary checks d) They cause errors in
     the computation</li>
</ol>

<p class=MsoNormal><b>Use Cases</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Optimizing memory access patterns in GPU applications</li>
 <li class=MsoNormal>Reducing power consumption in mobile GPU computing</li>
 <li class=MsoNormal>Improving performance of large-scale matrix operations</li>
 <li class=MsoNormal>Efficient utilization of memory bandwidth in parallel
     systems</li>
</ul>

<p class=MsoNormal><b>Numerical Problems</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>For a 10001000 matrix multiplication with TILE_SIZE=32,
     calculate how many global memory accesses are saved by using tiling
     compared to the non-tiled approach.</li>
 <li class=MsoNormal>If global memory bandwidth is 900 GB/s and shared memory
     bandwidth is 64 TB/s, calculate the effective bandwidth when using tiling
     with TILE_SIZE=16 for a 512512 matrix multiplication.</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=0 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 8: More on Tiling</b></p>

<p class=MsoNormal><b>Explanation in Easy Language</b></p>

<p class=MsoNormal>This slide provides more details on how tiling works,
especially for matrices where the dimensions are not multiples of TILE_SIZE.
When the matrix size (N) is not a multiple of TILE_SIZE, the last row or column
of tiles will be partially filled. CUDA handles this situation with boundary
checks (using conditions like <b>if(row &lt; n &amp;&amp; col &lt; n)</b>) to
ensure that threads don't access memory outside the matrix boundaries. The
slide also shows a visualization of how a 55 matrix is divided into tiles,
with Block(0,0) covering elements C[0..3][0..3], and so on.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>How does CUDA handle tiles at the edges when the matrix
     size is not a multiple of TILE_SIZE? a) By padding the matrix with zeros
     b) By ignoring the edge elements c) With boundary checks like <b>if(row
     &lt; n &amp;&amp; col &lt; n)</b> d) By using a different TILE_SIZE for
     edge tiles</li>
 <li class=MsoNormal>In the visualization shown, what does Block(0,0) compute?
     a) The entire C matrix b) Elements C[0..3][0..3] c) Elements C[4][4] d)
     Elements C[0..4][0..4]</li>
 <li class=MsoNormal>What is the purpose of loading tiles of A and B into
     shared memory? a) To reduce global memory accesses b) To increase the
     number of threads c) To simplify the computation d) To reduce the size of
     the matrices</li>
</ol>

<p class=MsoNormal><b>Use Cases</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Handling non-square matrices in GPU computations</li>
 <li class=MsoNormal>Processing images with dimensions not aligned to tile
     sizes</li>
 <li class=MsoNormal>Optimizing GPU memory usage for irregular data structures</li>
 <li class=MsoNormal>Implementing boundary-aware algorithms in parallel
     computing</li>
</ul>

<p class=MsoNormal><b>Numerical Problems</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>For a 1717 matrix with TILE_SIZE=8, calculate how many
     blocks are needed in each dimension and how many threads in the last block
     will be idle.</li>
 <li class=MsoNormal>If a 10001000 matrix is processed with TILE_SIZE=32,
     calculate the percentage of threads that will be idle in the edge blocks.</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=0 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 9: Example of Block(0,0) with TILE_SIZE=4</b></p>

<p class=MsoNormal><b>Explanation in Easy Language</b></p>

<p class=MsoNormal>This slide provides a detailed example of how Block(0,0)
works with TILE_SIZE=4. The threads inside Block(0,0) compute elements
C[0..3][0..3] of the result matrix. Each thread loads one element of A and one
element of B into shared memory tiles (tileA and tileB). The computation
happens in iterations over tiles (m loop). In the first iteration (m=0), A
loads rows and columns 0..3, and B loads rows and columns 0..3. In the second
iteration (m=1), A loads the last column (column 4) and B loads the last row (row
4), with padding with zeros for unused space. Each small square in the result
matrix is computed by one thread.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>In the example with TILE_SIZE=4, what elements of the
     result matrix does Block(0,0) compute? a) C[0..4][0..4] b) C[0..3][0..3]
     c) C[4][4] d) C[0..4][0..3]</li>
 <li class=MsoNormal>How many iterations of the tile loop (m loop) are needed
     for a 55 matrix with TILE_SIZE=4? a) 1 b) 2 c) 4 d) 5</li>
 <li class=MsoNormal>What happens in the second tile load (m=1) for a 55
     matrix with TILE_SIZE=4? a) A loads row[4], B loads column[4] b) A loads
     column[4], B loads row[4] c) A loads row[0..3], B loads column[0..3] d) A
     loads row[0..4], B loads column[0..4]</li>
</ol>

<p class=MsoNormal><b>Use Cases</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Understanding the detailed execution of tiled matrix
     multiplication</li>
 <li class=MsoNormal>Debugging GPU kernels for matrix operations</li>
 <li class=MsoNormal>Optimizing tile sizes for specific hardware architectures</li>
 <li class=MsoNormal>Educational purposes for parallel computing concepts</li>
</ul>

<p class=MsoNormal><b>Numerical Problems</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>For a 66 matrix with TILE_SIZE=4, trace the execution of
     Block(0,0) and list which elements of A and B are loaded in each iteration
     of the tile loop.</li>
 <li class=MsoNormal>Calculate the number of shared memory accesses made by
     Block(0,0) when computing a 55 matrix multiplication with TILE_SIZE=4.</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=0 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 10: Convolution Kernel</b></p>

<p class=MsoNormal><b>Explanation in Easy Language</b></p>

<p class=MsoNormal>This slide introduces the concept of convolution, which is a
fundamental operation in image processing. Convolution applies a filter (or
kernel) to an input image to produce an output image. In the example, a 55
input image is convolved with a 22 kernel to produce a 44 output image. Each
output pixel is computed by applying the filter over a corresponding region of
the input image. In CUDA, each thread computes one output pixel by applying the
filter over the image region (this is called a stencil operation).</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is the size of the output image when convolving a 55
     input image with a 22 kernel? a) 55 b) 22 c) 44 d) 77</li>
 <li class=MsoNormal>In CUDA convolution, what does each thread compute? a) One
     row of the output image b) One column of the output image c) One output
     pixel d) The entire output image</li>
 <li class=MsoNormal>What is a stencil operation in the context of convolution?
     a) A pattern of memory accesses b) A type of kernel c) A synchronization
     primitive d) A memory allocation technique</li>
</ol>

<p class=MsoNormal><b>Use Cases</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Image filtering and enhancement</li>
 <li class=MsoNormal>Edge detection in computer vision</li>
 <li class=MsoNormal>Feature extraction in machine learning</li>
 <li class=MsoNormal>Signal processing applications</li>
</ul>

<p class=MsoNormal><b>Numerical Problems</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Calculate the output size when convolving a 1010 input
     image with a 33 kernel.</li>
 <li class=MsoNormal>For the given example, calculate the value of out(1,2) if
     the input image is: [[1,2,3,4,5], [6,7,8,9,10], [11,12,13,14,15],
     [16,17,18,19,20], [21,22,23,24,25]] and the kernel is: [[1,0], [0,-1]]</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=0 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 11: Convolution with RGB Input</b></p>

<p class=MsoNormal><b>Explanation in Easy Language</b></p>

<p class=MsoNormal>This slide extends the convolution operation to RGB images,
where each pixel has three color channels (Red, Green, and Blue). The kernel is
applied separately to each channel, resulting in three output matrices (one for
each channel). The example shows a specific kernel for a stencil-based
computation where each output pixel is calculated as 5 times the center pixel
minus its top, bottom, left, and right neighbors. The slide shows the input for
the R channel and the resulting output after applying the kernel.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>How is convolution applied to RGB images? a) By combining
     all channels into one and applying the kernel once b) By applying the
     kernel separately to each channel c) By applying the kernel only to the R
     channel d) By converting RGB to grayscale first</li>
 <li class=MsoNormal>In the given kernel, what is the formula for computing the
     output pixel? a) 5<i>center - top - bottom - left - right b) center - top
     - bottom - left - right c) 5</i>center + top + bottom + left + right d)
     center + top + bottom + left + right</li>
 <li class=MsoNormal>What is the purpose of zero-padding in convolution? a) To
     increase the size of the output image b) To handle edge pixels where
     neighbors are outside the image c) To improve the quality of the output
     image d) To reduce the computational complexity</li>
</ol>

<p class=MsoNormal><b>Use Cases</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Image filtering in computer graphics</li>
 <li class=MsoNormal>Color-based feature extraction in computer vision</li>
 <li class=MsoNormal>RGB image enhancement in photo editing software</li>
 <li class=MsoNormal>Real-time video processing applications</li>
</ul>

<p class=MsoNormal><b>Numerical Problems</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Calculate the output for the G channel if the input is:
     [[10,20,30,40,50], [15,25,35,45,55], [20,30,40,50,60], [25,35,45,55,65],
     [30,40,50,60,70]] and the kernel is: [[0,-1,0], [-1,5,-1], [0,-1,0]]</li>
 <li class=MsoNormal>For the given R channel input, calculate the output value
     at position (2,3) using the stencil-based computation.</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=0 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 12: Stencil-based Computation</b></p>

<p class=MsoNormal><b>Explanation in Easy Language</b></p>

<p class=MsoNormal>This slide explains the stencil-based computation approach
for convolution. In this method, zero-padding is applied around the input
matrix to handle edge pixels where neighbors are outside the image boundaries.
The slide shows a detailed calculation for the first element (0,0) of the
output matrix. For this element, the center is 10, and since it's at the edge,
its top and left neighbors are considered 0 (due to zero-padding). The output
is calculated as 5*10 - (top=0 + left=0 + right=20 + bottom=15) = 50 - 35 = 15.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is zero-padding in the context of convolution? a)
     Adding zeros to increase the size of the input image b) Replacing edge
     pixels with zeros c) Assuming neighbors outside the image are zero d)
     Filling the kernel with zeros</li>
 <li class=MsoNormal>For the element at position (0,0), which neighbors are
     considered zero? a) Right and bottom b) Top and left c) All neighbors d)
     No neighbors</li>
 <li class=MsoNormal>How is the output at position (0,0) calculated? a) 5<i>10
     - (0 + 0 + 20 + 15) b) 5</i>10 - (20 + 15) c) 5*10 + (0 + 0 + 20 + 15) d)
     10 - (0 + 0 + 20 + 15)</li>
</ol>

<p class=MsoNormal><b>Use Cases</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Edge detection algorithms in image processing</li>
 <li class=MsoNormal>Scientific simulations with boundary conditions</li>
 <li class=MsoNormal>Signal processing with finite impulse response filters</li>
 <li class=MsoNormal>Numerical solutions to partial differential equations</li>
</ul>

<p class=MsoNormal><b>Numerical Problems</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Calculate the output value at position (0,1) using the
     stencil-based computation with zero-padding.</li>
 <li class=MsoNormal>For a 33 input matrix [[1,2,3], [4,5,6], [7,8,9]] and the
     kernel [[0,-1,0], [-1,5,-1], [0,-1,0]], calculate the complete output
     matrix using stencil-based computation with zero-padding.</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=0 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 13: More Stencil-based Computation</b></p>

<p class=MsoNormal><b>Explanation in Easy Language</b></p>

<p class=MsoNormal>This slide continues the stencil-based computation by
showing calculations for multiple elements in the matrix. It provides detailed
calculations for each element in the output matrix, showing how the center
pixel and its neighbors contribute to the final value. For example, for
position (0,1), the center is 20, and its neighbors are left=10, right=30,
top=0 (due to zero-padding), and bottom=25. The output is calculated as 5*20 -
0 - 25 - 10 - 30 = 35. The slide shows calculations for all elements in the matrix.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>For position (1,0), what is the center value? a) 10 b) 15
     c) 20 d) 25</li>
 <li class=MsoNormal>How is the output at position (1,1) calculated? a) 5<i>25
     - (20 + 30 + 15 + 35) b) 5</i>25 + (20 + 30 + 15 + 35) c) 5<i>20 - (10 +
     30 + 0 + 25) d) 5</i>35 - (30 + 40 + 25 + 45)</li>
 <li class=MsoNormal>What is the output value at position (4,4)? a) 70 b) 140
     c) 155 d) 350</li>
</ol>

<p class=MsoNormal><b>Use Cases</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Image sharpening filters in photo editing</li>
 <li class=MsoNormal>Noise reduction in signal processing</li>
 <li class=MsoNormal>Feature enhancement in medical imaging</li>
 <li class=MsoNormal>Edge-preserving smoothing algorithms</li>
</ul>

<p class=MsoNormal><b>Numerical Problems</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Calculate the output value at position (2,2) using the
     stencil-based computation.</li>
 <li class=MsoNormal>For a 44 input matrix [[1,2,3,4], [5,6,7,8],
     [9,10,11,12], [13,14,15,16]] and the kernel [[0,-1,0], [-1,5,-1],
     [0,-1,0]], calculate the output value at position (1,2) using
     stencil-based computation with zero-padding.</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=0 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 14: Visualization (Convolution with RGB Input)</b></p>

<p class=MsoNormal><b>Explanation in Easy Language</b></p>

<p class=MsoNormal>This slide explains the memory access patterns required for
convolution and introduces the inefficiency of the naive approach. For each
output pixel, convolution with a 33 kernel needs the center pixel and its
eight neighbors. If each thread independently fetched its pixel and neighbors
directly from global memory, there would be many redundant memory accesses
because neighboring pixels would be fetched multiple times by different
threads. This leads to poor memory bandwidth usage. The slide introduces the
stencil method as a solution to this problem.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is the main problem with each thread independently
     fetching its pixel and neighbors from global memory? a) It requires too
     many threads b) It leads to redundant memory accesses c) It produces
     incorrect results d) It requires too much shared memory</li>
 <li class=MsoNormal>For a 33 kernel, how many input pixels are needed to
     compute one output pixel? a) 1 b) 3 c) 9 d) 27</li>
 <li class=MsoNormal>What is the purpose of the stencil method? a) To reduce
     the number of threads required b) To minimize redundant memory accesses c)
     To simplify the convolution operation d) To increase the size of the
     output image</li>
</ol>

<p class=MsoNormal><b>Use Cases</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Optimizing memory access patterns in GPU implementations</li>
 <li class=MsoNormal>Reducing memory bandwidth requirements in image processing</li>
 <li class=MsoNormal>Efficient implementation of convolutional neural networks</li>
 <li class=MsoNormal>High-performance video processing systems</li>
</ul>

<p class=MsoNormal><b>Numerical Problems</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Calculate the number of global memory accesses required
     for a 1010 image convolution with a 33 kernel using the naive approach
     where each thread fetches its own pixel and neighbors.</li>
 <li class=MsoNormal>If each pixel is fetched multiple times by different
     threads in the naive approach, calculate the redundancy factor for a 55
     image convolution with a 33 kernel.</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=0 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 15: Stencil Approach</b></p>

<p class=MsoNormal><b>Explanation in Easy Language</b></p>

<p class=MsoNormal>This slide explains the stencil approach to optimize memory
access patterns in convolution. The method involves partitioning the image into
tiles (e.g., 1616 threads per block). Each block of threads cooperatively
loads a tile of pixels plus a halo (extra 1-pixel border) into shared memory.
For a 1616 block, an 1818 tile is needed in shared memory to account for the
halo. Once the tile is in shared memory, every thread in the block can reuse
the data to compute its convolution result. This approach requires only one
synchronization point after loading shared memory, ensuring all neighbor data
is ready.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>What is a &quot;halo&quot; in the context of the stencil
     approach? a) The center pixel of the tile b) An extra border of pixels
     around the tile c) The kernel used for convolution d) The synchronization
     point</li>
 <li class=MsoNormal>For a 1616 block of threads, what size tile is needed in
     shared memory for a 33 kernel? a) 1616 b) 1717 c) 1818 d) 1919</li>
 <li class=MsoNormal>When is synchronization required in the stencil approach?
     a) Before loading data into shared memory b) After each computation step
     c) After loading data into shared memory and before computation d) Only at
     the end of the kernel</li>
</ol>

<p class=MsoNormal><b>Use Cases</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Efficient implementation of convolution operations in GPU</li>
 <li class=MsoNormal>Optimizing memory access patterns in image processing</li>
 <li class=MsoNormal>High-performance computing for stencil-based algorithms</li>
 <li class=MsoNormal>Parallel implementation of finite difference methods</li>
</ul>

<p class=MsoNormal><b>Numerical Problems</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Calculate the amount of shared memory needed for a 3232
     block of threads processing a 55 kernel.</li>
 <li class=MsoNormal>For a 1010 image divided into 44 blocks with a 33
     kernel, calculate the total number of shared memory accesses across all
     blocks.</li>
</ol>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=0 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 16: Example (55 image, 33 kernel, 44 block)</b></p>

<p class=MsoNormal><b>Explanation in Easy Language</b></p>

<p class=MsoNormal>This slide provides a concrete example of the stencil
approach with a 55 image, a 33 kernel, and a 44 block of threads. Each
thread block of 44 threads covers part of the image. They load a 66 tile (44
+ halo of 1 pixel around) into shared memory. Each of the 16 threads computes
one output pixel in parallel. The borders of the tile are shared between
threads, so they are fetched once instead of multiple times. This approach
significantly reduces global memory traffic and improves performance.</p>

<p class=MsoNormal><b>MCQs</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>In the example, how many threads are in each block? a) 4
     b) 16 c) 25 d) 36</li>
 <li class=MsoNormal>What size tile is loaded into shared memory for a 44
     block with a 33 kernel? a) 44 b) 55 c) 66 d) 77</li>
 <li class=MsoNormal>How many output pixels does each thread compute in this
     example? a) 1 b) 4 c) 16 d) 25</li>
</ol>

<p class=MsoNormal><b>Use Cases</b></p>

<ul style='margin-top:0in' type=disc>
 <li class=MsoNormal>Understanding the implementation details of stencil-based
     convolution</li>
 <li class=MsoNormal>Optimizing block sizes for specific image dimensions</li>
 <li class=MsoNormal>Educational purposes for parallel programming concepts</li>
 <li class=MsoNormal>Designing efficient GPU kernels for image processing</li>
</ul>

<p class=MsoNormal><b>Numerical Problems</b></p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal>Calculate the number of global memory accesses saved by
     using the stencil approach for a 55 image with a 33 kernel and 44
     blocks.</li>
 <li class=MsoNormal>For a 1010 image with a 33 kernel and 88 blocks,
     calculate the total shared memory required and the number of blocks
     needed.</li>
</ol>

<p class=MsoNormal>&nbsp;</p>

<div style='border:none;border-bottom:double windowtext 2.25pt;padding:0in 0in 1.0pt 0in'>

<p class=MsoNormal style='border:none;padding:0in'>&nbsp;</p>

</div>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal><b>Slide 1: Matrix Multiplication (MM) Kernel</b></p>

<p class=MsoNormal>Explanation:<br>
This slide shows a CUDA kernel for matrix multiplication. Each thread computes
one element of the output matrix C by multiplying a row from matrix A with a
column from matrix B. The thread's row and column are determined by its block
and thread indices. The kernel loops over the common dimension to compute the
dot product for each output element.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:<br>
Which of the following best describes the role of a thread in the matrix
multiplication kernel?<br>
A) Each thread computes an entire row of matrix C<br>
B) Each thread computes one element of matrix C<br>
C) Each thread computes one column of matrix C<br>
D) Each thread computes the entire matrix C<br>
Answer:&nbsp;B</p>

<p class=MsoNormal>Use Case:<br>
Matrix multiplication is used in scientific computing, machine learning, and
graphics rendering where large matrices need to be processed quickly.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Numerical Example:<br>
For matrices A (22) and B (22):<br>
A = [, ], B = [, ]<span style='font-family:"Arial",sans-serif'>&#8203;</span><br>
C = 15 + 27 = 19<br>
C = 16 + 28 = 22<span style='font-family:"Arial",sans-serif'>&#8203;</span><br>
C = 35 + 47 = 43<span style='font-family:"Arial",sans-serif'>&#8203;</span><br>
C = 36 + 48 = 50<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 2: Explanation of Matrix Multiplication</b></p>

<p class=MsoNormal>Explanation:<br>
This slide explains how each element of the output matrix C is computed. For
example, c is the sum of products of the 2nd row of A and the 3rd column of B.
Each thread is responsible for computing one such element.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:<br>
What does c represent in matrix multiplication?<br>
A) The sum of the 2nd row of A and 3rd column of B<br>
B) The dot product of the 2nd row of A and 3rd column of B<br>
C) The product of the 2nd row of A and 3rd column of B<br>
D) The sum of the 2nd column of A and 3rd row of B<br>
Answer:&nbsp;B</p>

<p class=MsoNormal>Use Case:<br>
This concept is used in neural networks for forward propagation and in graphics
for transformations.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Numerical Example:<br>
A = [, ], B = [, , ]<span style='font-family:"Arial",sans-serif'>&#8203;</span><br>
c = 48 + 510 + 612 = 32 + 50 + 72 = 154<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 3: Thread Assignment</b></p>

<p class=MsoNormal>Explanation:<br>
Each thread is assigned to compute one element of the output matrix. For
example, thread (row=0, col=0) computes c00, thread (row=0, col=1) computes
c01, and so on.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:<br>
If a thread has row=2 and col=3, which element does it compute?<br>
A) c<br>
B) c<br>
C) c<br>
D) c<br>
Answer:&nbsp;A</p>

<p class=MsoNormal>Use Case:<br>
This is used in parallel algorithms where each thread handles a small,
independent task.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Numerical Example:<br>
For a 33 matrix, thread (row=1, col=2) computes c.<span style='font-family:
"Arial",sans-serif'>&#8203;</span></p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 4: Tiled MM Kernel</b></p>

<p class=MsoNormal>Explanation:<br>
This slide introduces tiling, where threads cooperatively load small blocks
(tiles) of matrices A and B into shared memory. This reduces global memory
accesses and speeds up computation.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:<br>
What is the main advantage of using tiling in matrix multiplication?<br>
A) Reduces the number of threads needed<br>
B) Reduces global memory bandwidth usage<br>
C) Increases the size of the matrices<br>
D) Simplifies the kernel code<br>
Answer:&nbsp;B</p>

<p class=MsoNormal>Use Case:<br>
Tiling is used in high-performance computing to optimize memory access
patterns.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Numerical Example:<br>
For a 44 matrix with tile size 2, each block loads a 22 tile of A and B into
shared memory.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 5: Usage of Tiling</b></p>

<p class=MsoNormal>Explanation:<br>
Without tiling, each thread fetches many elements from global memory. With
tiling, threads fetch only a few elements per tile and reuse them from shared
memory, reducing memory traffic.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:<br>
How does tiling reduce memory traffic?<br>
A) By increasing the number of threads<br>
B) By reusing data from shared memory<br>
C) By using larger matrices<br>
D) By simplifying the kernel<br>
Answer:&nbsp;B</p>

<p class=MsoNormal>Use Case:<br>
Tiling is used in applications like deep learning and scientific simulations
where memory bandwidth is a bottleneck.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Numerical Example:<br>
For a 55 matrix, each thread fetches only 4 elements per tile instead of 5.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 6: Visualization of Tiling</b></p>

<p class=MsoNormal>Explanation:<br>
This slide shows how the output matrix is divided into tiles, each computed by
a block of threads. Boundary checks ensure correct handling of partial tiles.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:<br>
What happens if a tile extends beyond the matrix boundary?<br>
A) The kernel crashes<br>
B) The extra elements are ignored<br>
C) The extra elements are padded with zeros<br>
D) The kernel skips the tile<br>
Answer:&nbsp;C</p>

<p class=MsoNormal>Use Case:<br>
This is used in image processing and matrix operations where matrices may not
be perfectly divisible by tile size.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Numerical Example:<br>
For a 55 matrix with tile size 4, the last row and column are partially filled
and padded with zeros.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 7: Convolution Kernel</b></p>

<p class=MsoNormal>Explanation:<br>
This slide shows a convolution kernel where each thread computes one output
pixel by applying a filter to a region of the input image. Shared memory is
used for better locality.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:<br>
What is the purpose of using shared memory in convolution?<br>
A) To store the entire image<br>
B) To reduce redundant memory accesses<br>
C) To increase the filter size<br>
D) To simplify the kernel<br>
Answer:&nbsp;B</p>

<p class=MsoNormal>Use Case:<br>
Convolution is used in image processing, computer vision, and neural networks.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Numerical Example:<br>
For a 55 image and 22 filter, the output size is 44.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 8: Convolution with RGB Input</b></p>

<p class=MsoNormal>Explanation:<br>
This slide extends convolution to RGB images, where the kernel is applied to
each color channel separately. The output is three matrices, one for each
channel.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:<br>
How is convolution applied to RGB images?<br>
A) The kernel is applied to all channels together<br>
B) The kernel is applied to each channel separately<br>
C) Only the red channel is processed<br>
D) The kernel is applied to the average of all channels<br>
Answer:&nbsp;B</p>

<p class=MsoNormal>Use Case:<br>
This is used in color image processing and deep learning for computer vision.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Numerical Example:<br>
For a 55 RGB image, the output is three 55 matrices, one for each channel.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 9: Stencil-based Computation</b></p>

<p class=MsoNormal>Explanation:<br>
This slide explains stencil-based computation, where each output pixel depends
on its neighbors. Zero-padding is used to handle edge cases.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:<br>
What is zero-padding used for in stencil computation?<br>
A) To increase the image size<br>
B) To handle edge pixels<br>
C) To reduce memory usage<br>
D) To simplify the kernel<br>
Answer:&nbsp;B</p>

<p class=MsoNormal>Use Case:<br>
Stencil computation is used in image filtering, physics simulations, and
numerical methods.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Numerical Example:<br>
For a 33 kernel, the center pixel and its neighbors are used to compute the
output.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 10: Visualization (Convolution with RGB Input)</b></p>

<p class=MsoNormal>Explanation:<br>
This slide shows how convolution works with RGB input, requiring overlapping
neighborhoods of the input image for each output pixel.<span style='font-family:
"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:<br>
Why are overlapping neighborhoods needed in convolution?<br>
A) To reduce memory usage<br>
B) To ensure each output pixel has all required neighbors<br>
C) To increase the filter size<br>
D) To simplify the kernel<br>
Answer:&nbsp;B</p>

<p class=MsoNormal>Use Case:<br>
This is used in advanced image processing and deep learning.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Numerical Example:<br>
For a 55 image and 33 kernel, each output pixel depends on a 33
neighborhood.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 11: Stencil Approach</b></p>

<p class=MsoNormal>Explanation:<br>
The stencil approach partitions the image into tiles, with each block loading a
tile and its halo into shared memory. This reduces redundant memory accesses.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:<br>
What is the purpose of the halo in stencil computation?<br>
A) To increase the image size<br>
B) To store extra data for neighbors<br>
C) To reduce memory usage<br>
D) To simplify the kernel<br>
Answer:&nbsp;B</p>

<p class=MsoNormal>Use Case:<br>
This is used in high-performance computing and scientific simulations.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Numerical Example:<br>
For a 1616 block, a 1818 tile is loaded into shared memory.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 12: Visualization (Convolution with RGB Input)</b></p>

<p class=MsoNormal>Explanation:<br>
This slide shows how parallelism happens in convolution, with each thread
computing one output pixel independently after shared memory is loaded.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:<br>
How does parallelism work in convolution?<br>
A) Each thread computes the entire image<br>
B) Each thread computes one output pixel<br>
C) Each thread computes one row of the image<br>
D) Each thread computes one column of the image<br>
Answer:&nbsp;B</p>

<p class=MsoNormal>Use Case:<br>
This is used in real-time image processing and deep learning.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Numerical Example:<br>
For a 44 block, 16 threads compute 16 output pixels in parallel.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 13: Why Its Efficient</b></p>

<p class=MsoNormal>Explanation:<br>
Data reuse and reduced global memory traffic make stencil-based convolution
efficient. Each input pixel is loaded once per block into shared memory.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:<br>
What makes stencil-based convolution efficient?<br>
A) Increased memory usage<br>
B) Data reuse and reduced memory traffic<br>
C) Larger filter sizes<br>
D) More threads<br>
Answer:&nbsp;B</p>

<p class=MsoNormal>Use Case:<br>
This is used in applications requiring high throughput and low latency.<span
style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Numerical Example:<br>
For a 1616 block, each input pixel is loaded once into shared memory.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=1 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 14: Example (55 image, 33 kernel, 44 block)</b></p>

<p class=MsoNormal>Explanation:<br>
This slide shows an example where a 44 block of threads processes part of a
55 image using a 33 kernel. Each thread computes one output pixel in
parallel.<span style='font-family:"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>MCQ:<br>
How many threads are needed for a 44 block?<br>
A) 8<br>
B) 12<br>
C) 16<br>
D) 20<br>
Answer:&nbsp;C</p>

<p class=MsoNormal>Use Case:<br>
This is used in image processing and computer vision.<span style='font-family:
"Arial",sans-serif'>&#8203;</span></p>

<p class=MsoNormal>Numerical Example:<br>
For a 55 image and 33 kernel, a 44 block computes 16 output pixels.</p>

<p class=MsoNormal>&nbsp;</p>

<div style='border:none;border-bottom:double windowtext 2.25pt;padding:0in 0in 1.0pt 0in'>

<p class=MsoNormal style='border:none;padding:0in'>&nbsp;</p>

</div>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>Thanks, Pankaj! The lecture covers <b>GPU parallel kernel
programming</b>, focusing on <b>matrix multiplication</b> and <b>convolution
kernels</b> using CUDA. Ill now break down each slide with:</p>

<ol style='margin-top:0in' start=1 type=1>
 <li class=MsoNormal><b>Easy explanation</b></li>
 <li class=MsoNormal><b>MCQs</b></li>
 <li class=MsoNormal><b>Use cases</b></li>
 <li class=MsoNormal><b>Numerical examples</b></li>
</ol>

<p class=MsoNormal>Lets go slide by slide:</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 2: Matrix Multiplication Kernel</b></p>

<p class=MsoNormal><b>Explanation</b>:<br>
Each CUDA thread computes one element of the output matrix C. It multiplies a
row from matrix A with a column from matrix B.</p>

<p class=MsoNormal><b>MCQ</b>:<br>
<b>Q:</b> What does each thread compute in the matrix multiplication kernel?<br>
A. A row of matrix A<br>
B. A column of matrix B<br>
C. One element of matrix C <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
D. Entire matrix C</p>

<p class=MsoNormal><b>Use Case</b>:<br>
Used in graphics, scientific computing, and ML (e.g., multiplying weight
matrices in neural networks).</p>

<p class=MsoNormal><b>Numerical</b>:<br>
If n = 2, and<br>
A = [[1, 2], [3, 4]],<br>
B = [[5, 6], [7, 8]],<br>
Then C[0][0] = 15 + 27 = 19</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 3: Explanation of MM</b></p>

<p class=MsoNormal><b>Explanation</b>:<br>
Each thread is assigned a unique (row, col) and computes the dot product of the
corresponding row of A and column of B.</p>

<p class=MsoNormal><b>MCQ</b>:<br>
<b>Q:</b> Which thread computes C[2][3]?<br>
A. Thread(2,3) <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
B. Thread(3,2)<br>
C. Thread(0,0)<br>
D. Thread(4,4)</p>

<p class=MsoNormal><b>Use Case</b>:<br>
Parallel matrix multiplication in simulations, image transformations.</p>

<p class=MsoNormal><b>Numerical</b>:<br>
C[2][3] = A[2][0]B[0][3] + A[2][1]B[1][3] + ...</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slides 45: Tiled Matrix Multiplication</b></p>

<p class=MsoNormal><b>Explanation</b>:<br>
Instead of fetching full rows/columns from global memory, threads load small
tiles into shared memory and reuse them.</p>

<p class=MsoNormal><b>MCQ</b>:<br>
<b>Q:</b> What is the benefit of tiling in matrix multiplication?<br>
A. Increases memory usage<br>
B. Reduces global memory access <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
C. Slows down computation<br>
D. Avoids using shared memory</p>

<p class=MsoNormal><b>Use Case</b>:<br>
Efficient matrix multiplication in large-scale ML models and physics
simulations.</p>

<p class=MsoNormal><b>Numerical</b>:<br>
If TILE_SIZE = 2, and n = 4, then each block loads 22 tiles and computes
partial results.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slides 69: Usage of Tiling</b></p>

<p class=MsoNormal><b>Explanation</b>:<br>
Tiling reduces memory bandwidth usage. Threads in a block load tiles
cooperatively and compute partial results.</p>

<p class=MsoNormal><b>MCQ</b>:<br>
<b>Q:</b> What happens if the matrix size is not divisible by TILE_SIZE?<br>
A. CUDA ignores extra elements<br>
B. Threads crash<br>
C. Boundary checks handle it <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
D. Tiles are skipped</p>

<p class=MsoNormal><b>Use Case</b>:<br>
Used in deep learning frameworks like TensorFlow and PyTorch for optimized GPU
computation.</p>

<p class=MsoNormal><b>Numerical</b>:<br>
Matrix size = 55, TILE_SIZE = 4 &#8594; last tile is partially filled.</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 10: Convolution Kernel</b></p>

<p class=MsoNormal><b>Explanation</b>:<br>
Each thread applies a filter (kernel) to a region of the image and computes one
output pixel.</p>

<p class=MsoNormal><b>MCQ</b>:<br>
<b>Q:</b> What is the output size for a 55 image and 22 kernel?<br>
A. 55<br>
B. 44 <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
C. 33<br>
D. 22</p>

<p class=MsoNormal><b>Use Case</b>:<br>
Image processing, edge detection, feature extraction in CNNs.</p>

<p class=MsoNormal><b>Numerical</b>:<br>
out(0,0) = 1 - 7 = -6</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slide 1113: Convolution with RGB Input</b></p>

<p class=MsoNormal><b>Explanation</b>:<br>
Each channel (R, G, B) is processed separately. A stencil-based approach is
used for better memory efficiency.</p>

<p class=MsoNormal><b>MCQ</b>:<br>
<b>Q:</b> What does stencil-based computation use?<br>
A. Only global memory<br>
B. Shared memory with halo <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
C. Registers<br>
D. No memory</p>

<p class=MsoNormal><b>Use Case</b>:<br>
Used in real-time image filters, video processing, and medical imaging.</p>

<p class=MsoNormal><b>Numerical</b>:<br>
out(0,0) = 510 - (20 + 15) = 15</p>

<div class=MsoNormal align=center style='text-align:center'>

<hr size=2 width="100%" align=center>

</div>

<p class=MsoNormal><b>Slides 1416: Visualization of Convolution</b></p>

<p class=MsoNormal><b>Explanation</b>:<br>
Each thread block loads a tile + halo into shared memory. Threads compute
output pixels using shared data.</p>

<p class=MsoNormal><b>MCQ</b>:<br>
<b>Q:</b> Why is shared memory used in convolution?<br>
A. To increase latency<br>
B. To reduce redundant memory access <span style='font-family:"Segoe UI Emoji",sans-serif'>&#9989;</span><br>
C. To avoid synchronization<br>
D. To store output</p>

<p class=MsoNormal><b>Use Case</b>:<br>
Efficient convolution in CNNs, especially in edge devices with limited memory.</p>

<p class=MsoNormal><b>Numerical</b>:<br>
For a 55 image and 33 kernel, each 44 block loads a 66 tile.</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

<p class=MsoNormal>&nbsp;</p>

</div>

</body>

</html>
